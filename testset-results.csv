input,predicted if,expected if,exact match,BLEU-4 score,CodeBLEU score,% exact matches,Model CodeBLEU score,Average BLEU-4 score
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> if DEBUG_COMM : <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> if ignore_non_errors and is_noerr ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise",if ignore_timeouts and is_timeouts ( e ) :,if ignore_timeouts and is_timeout ( e ) :,False,98.91,73.61,26.62,90.46,97.06
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """""" cache hidden states into memory. """""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> if reuse_len is not None and reuse_len > 0 : <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem",if prev_mem is None :,if prev_mem is None :,True,100.0,99.49,,,
def filtered ( gen ) : <TAB> for example in gen : <TAB> <TAB> example_len = length_fn ( example ) <TAB> <TAB> # Checking max length boundary. <TAB> <TAB> if max_length is not None: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Checking min length boundary. <TAB> <TAB> if min_length is not None: <TAB> <TAB> <TAB> if example_len < min_length: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Within bounds. <TAB> <TAB> yield example,if example_len > max_length :,if example_len > max_length :,True,100.0,99.28,,,
"def search ( self , query ) : <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query: <TAB> <TAB> logger.debug(""Empty search query"") <TAB> <TAB> return [] <TAB> logger.debug('Searching TuneIn for ""%s""' % query) <TAB> args = ""&query="" + query <TAB> search_results = self._tunein(""Search.ashx"", args) <TAB> results = [] <TAB> for item in self._flatten(search_results): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Only return stations <TAB> <TAB> <TAB> self._stations[item[""guide_id""]] = item <TAB> <TAB> <TAB> results.append(item) <TAB> return results","if item [ ""guide_id"" ] not in self . _stations :","if item . get ( ""type"" , """" ) == ""audio"" :",False,92.47,60.35,,,
"def _check_script ( self , script , directive ) : <TAB> for var in compile_script ( script ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Skip variable checks <TAB> <TAB> <TAB> return False <TAB> <TAB> if var.can_contain("".""): <TAB> <TAB> <TAB> # Yay! Our variable can contain any symbols! <TAB> <TAB> <TAB> reason = ( <TAB> <TAB> <TAB> <TAB> 'At least variable ""${var}"" can contain untrusted user input'.format( <TAB> <TAB> <TAB> <TAB> <TAB> var=var.name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.add_issue(directive=[directive] + var.providers, reason=reason) <TAB> <TAB> <TAB> return True <TAB> return False","if not isinstance ( var , Variable ) :","if var . must_contain ( ""/"" ) :",False,95.69,65.58,,,
"def getAllDataLinkIDs ( ) : <TAB> linkDataIDs = set ( ) <TAB> dataType = _forestData . dataTypeBySocket <TAB> for socketID , linkedIDs in _forestData . linkedSockets . items ( ) : <TAB> <TAB> for linkedID in linkedIDs : <TAB> <TAB> <TAB> <IF-STMT> # check which one is origin/target <TAB> <TAB> <TAB> <TAB> linkDataIDs.add( <TAB> <TAB> <TAB> <TAB> <TAB> (socketID, linkedID, dataType[socketID], dataType[linkedID]) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> linkDataIDs.add( <TAB> <TAB> <TAB> <TAB> <TAB> (linkedID, socketID, dataType[linkedID], dataType[socketID]) <TAB> <TAB> <TAB> <TAB> ) <TAB> return linkDataIDs",if linkedID == _forestData . originSocket :,if socketID [ 1 ] :,False,95.92,71.36,,,
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> if curses : <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama : <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False","if sys . stderr is getattr ( curses . initialise , ""wrapped_stderr"" , object ( ) ) :","if curses . tigetnum ( ""colors"" ) > 0 :",False,92.43,70.6,,,
"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB> <TAB> if isinstance ( ty , SimTypeBottom ) : <TAB> <TAB> <TAB> l . warning ( <TAB> <TAB> <TAB> <TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB> <TAB> <TAB> <TAB> "" element size. "" , <TAB> <TAB> <TAB> <TAB> self . name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self . _pack : <TAB> <TAB> <TAB> align = ty . alignment <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> offset_so_far + = align - offset_so_far % align <TAB> <TAB> offsets [ name ] = offset_so_far <TAB> <TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets",if align > offset_so_far % align :,if offset_so_far % align != 0 :,False,97.79,73.01,,,
"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB> <TAB> if issubclass ( picker . __class__ , wx . FileDialog ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value [ - 1 ] <TAB> <TAB> picker . SetPath ( value ) <TAB> <TAB> return True <TAB> return False","if value [ - 1 ] == ""/"" :",if type ( value ) == list :,False,91.98,61.61,,,
"def dt_s_tup_to_string ( dt_s_tup ) : <TAB> dt_string = dt_s_tup [ 0 ] # string for identifying the file to parse. <TAB> if dt_s_tup[1] > 0: # if there are seasons in the model <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dt_string = dt_string[:2] + ""s"" + dt_string[2:] <TAB> <TAB> else: <TAB> <TAB> <TAB> dt_string = ""s"" + dt_string <TAB> return dt_string",if dt_string [ 2 ] > 0 :,"if ""co"" in dt_string or ""ci"" in dt_string or ""nc"" in dt_string :",False,85.4,60.6,,,
"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB> <TAB> stream . write ( sep ) <TAB> <TAB> sep = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> if not PY3K : <TAB> <TAB> <TAB> if not isinstance ( item , unicode ) : <TAB> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" )","if not isinstance ( item , str ) :","if not isinstance ( item , str ) :",True,100.0,74.36,,,
"def _get_result_keys ( self , config ) : <TAB> result_key = config . get ( "" result_key "" ) <TAB> if result_key is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result_key = [ result_key ] <TAB> <TAB> result_key = [ jmespath . compile ( rk ) for rk in result_key ] <TAB> <TAB> return result_key","if isinstance ( result_key , list ) :","if not isinstance ( result_key , list ) :",False,97.69,71.93,,,
"def _download_build_artifacts ( self , build : Dict [ str , Any ] ) - > None : <TAB> arch = build [ "" arch_tag "" ] <TAB> snap_build = self . _lp_load_url ( build [ "" self_link "" ] ) <TAB> urls = snap_build . getFileUrls ( ) <TAB> if not urls : <TAB> <TAB> logger . error ( f "" Snap file not available for arch  { arch !r} . "" ) <TAB> <TAB> return <TAB> for url in urls : <TAB> <TAB> file_name = _get_url_basename ( url ) <TAB> <TAB> self . _download_file ( url = url , dst = file_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . info ( f "" Snapped  { file_name } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" Fetched  { file_name } "" )",if self . _snap_is_available ( url ) :,"if file_name . endswith ( "".snap"" ) :",False,95.51,68.63,,,
"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB> <TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB> <TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB> <TAB> if not isinstance ( custom_statements , list ) : <TAB> <TAB> <TAB> custom_statements = [ custom_statements ] <TAB> <TAB> statement = self . resource_policy [ "" Statement "" ] <TAB> <TAB> if not isinstance ( statement , list ) : <TAB> <TAB> <TAB> statement = [ statement ] <TAB> <TAB> for s in custom_statements : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> statement . append ( s ) <TAB> <TAB> self . resource_policy [ "" Statement "" ] = statement",if s not in statement :,if s not in statement :,True,100.0,74.59,,,
"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """""" Display a failure for a single method / endpoint. """""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB> <TAB> message : Optional [ str ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message = f "" { idx } .  { check . message } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast ( Case , check . example ) # filtered in `_get_unique_failures` <TAB> <TAB> display_example(example, check.name, message, result.seed) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> if idx != len(checks): <TAB> <TAB> <TAB> click.echo(""\n"")",if check . message is not None :,if check . message :,False,98.13,96.79,,,
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" qangaroo "" ) <TAB> version = "" v1.1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,True,100.0,74.46,,,
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" qangaroo "" ) <TAB> version = "" v1.1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if self . dropout_prob > 0.0,False,95.56,71.41,,,
"def jupyter_progress_bar ( min = 0 , max = 1.0 ) : <TAB> """""" Returns an ipywidget progress bar or None if we can ' t import it """""" <TAB> widgets = wandb . util . get_module ( "" ipywidgets "" ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB> <TAB> <TAB> from IPython.html import widgets # type: ignore <TAB> <TAB> assert hasattr(widgets, ""VBox"") <TAB> <TAB> assert hasattr(widgets, ""Label"") <TAB> <TAB> assert hasattr(widgets, ""FloatProgress"") <TAB> <TAB> return ProgressWidget(widgets, min=min, max=max) <TAB> except (ImportError, AssertionError): <TAB> <TAB> return None","if hasattr ( widgets , ""ProgressWidget"" ) :",if widgets is None :,False,95.33,64.27,,,
"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB> <TAB> self . events [ path ] . append ( events ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not os . path . exists ( path ) : <TAB> <TAB> <TAB> <TAB> self . watches . pop ( path ) . close ( )",if error :,if events | pyuv . fs . UV_RENAME :,False,89.85,68.62,,,
"def _get_v1_id_from_tags ( self , tags_obj , tag ) : <TAB> """""" Get image id from array of tags """""" <TAB> if isinstance ( tags_obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return tags_obj [ tag ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> elif isinstance ( tags_obj , [ ] ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> for tag_dict in tags_obj : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return tag_dict [ "" layer "" ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> return "" ""","if tag_dict [ ""tag"" ] == tag :","if tag_dict [ ""name"" ] == tag :",False,98.78,73.31,,,
"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB> <TAB> rs = domain . connection . query_with_attributes ( <TAB> <TAB> <TAB> domain , query , attr_names , next_token = next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if num_results == max_items : <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results + = 1 <TAB> <TAB> next_token = rs . next_token <TAB> <TAB> more_results = next_token != None",if max_items :,if max_items :,True,100.0,74.46,,,
"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB> <TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kValue = array . get ( unicode ( k ) ) <TAB> <TAB> <TAB> if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) : <TAB> <TAB> <TAB> <TAB> res . append ( kValue ) <TAB> <TAB> k + = 1 <TAB> return args . space . ConstructArray ( res )",if array . has_property ( unicode ( k ) ) :,if array . has_property ( unicode ( k ) ) :,True,100.0,74.6,,,
"def every_one_is ( self , dst ) : <TAB> msg = "" all members of  %r  should be  %r , but the  %d th is  %r "" <TAB> for index , item in enumerate ( self . _src ) : <TAB> <TAB> if self . _range : <TAB> <TAB> <TAB> if index < self . _range [ 0 ] or index > self . _range [ 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> error = msg % ( self . _src , dst , index , item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AssertionError ( error ) <TAB> return True","if error != ""is not %r"" % ( dst , index ) :",if item != dst :,False,90.89,62.63,,,
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> if delete : <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> if key in LoggerFactory . schedule_logger_dict : <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id )",if LoggerFactory . schedule_logger_dict [ key ] . is_scheduled :,if job_id in key :,False,94.83,72.2,,,
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",elif item [ 2 ] :,elif item [ 2 ] :,True,100.0,74.42,,,
"def _read_data_from_all_categories ( self , directory , config , categories ) : <TAB> lines = [ ] <TAB> for category in categories : <TAB> <TAB> data_file = os . path . join ( directory , _DATASET_VERSION , category , config ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with open ( data_file ) as f : <TAB> <TAB> <TAB> <TAB> ls = f . read ( ) . split ( "" \n "" ) <TAB> <TAB> <TAB> <TAB> for l in ls [ : : - 1 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if not l : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ls . remove ( l ) <TAB> <TAB> <TAB> <TAB> lines . extend ( ls ) <TAB> return lines",if os . path . exists ( data_file ) :,if os . path . exists ( data_file ) :,True,100.0,74.52,,,
"def find_handlers ( self , forms ) : <TAB> handlers = { } <TAB> for form in forms . itervalues ( ) : <TAB> <TAB> for action_name , _action_label in form . actions : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> handlers [ action_name ] = form <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise HandlerError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" More than one form defines the handler  %s "" % action_name <TAB> <TAB> <TAB> <TAB> ) <TAB> return handlers","if _action_label == ""handler"" :",if action_name not in handlers :,False,93.95,62.63,,,
"def get_story_task_completed_body ( payload : Dict [ str , Any ] ) - > Optional [ str ] : <TAB> action = get_action_with_primary_id ( payload ) <TAB> kwargs = { <TAB> <TAB> "" task_description "" : action [ "" description "" ] , <TAB> } <TAB> story_id = action [ "" story_id "" ] <TAB> for ref in payload [ "" references "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs [ "" name_template "" ] = STORY_NAME_TEMPLATE . format ( <TAB> <TAB> <TAB> <TAB> name = ref [ "" name "" ] , <TAB> <TAB> <TAB> <TAB> app_url = ref [ "" app_url "" ] , <TAB> <TAB> <TAB> ) <TAB> if action [ "" changes "" ] [ "" complete "" ] [ "" new "" ] : <TAB> <TAB> return STORY_TASK_COMPLETED_TEMPLATE . format ( * * kwargs ) <TAB> else : <TAB> <TAB> return None","if ref [ ""id"" ] == story_id :","if ref [ ""id"" ] == story_id :",True,100.0,74.59,,,
"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB> <TAB> for j in range ( len ( nodes ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB> <TAB> <TAB> if graph . has_edge ( edge ) : <TAB> <TAB> <TAB> <TAB> graph . del_edge ( edge ) <TAB> <TAB> <TAB> graph . add_edge ( edge , 1 )",if i == j :,if i == j :,True,100.0,74.37,,,
"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> <TAB> return op . body <TAB> <TAB> if op . attr_key == "" virtual_thread "" : <TAB> <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> <TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" )","if op . attr_key == ""virtual_thread"" :","if op . attr_key == ""storage_scope"" :",False,98.17,73.79,,,
"def format_lazy_import ( names ) : <TAB> """""" Formats lazy import lines """""" <TAB> lines = "" "" <TAB> for _ , name , asname in names : <TAB> <TAB> pkg , _ , _ = name . partition ( "" . "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line = "" {pkg}  = _LazyModule.load( {pkg!r} ,  {mod!r} ) \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> line = "" {asname}  = _LazyModule.load( {pkg!r} ,  {mod!r} ,  {asname!r} ) \n "" <TAB> <TAB> lines + = line . format ( pkg = pkg , mod = name , asname = asname ) <TAB> return lines","if asname == ""default"" :",if asname is None :,False,96.58,97.53,,,
"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . endswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self . words : <TAB> <TAB> <TAB> <TAB> matched = bool ( re . search ( _regex , w ) ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] )",if not matched :,if matched :,False,99.14,74.18,,,
"def setup ( self , ir : "" IR "" , aconf : Config ) - > bool : <TAB> if self . kind == "" ConsulResolver "" : <TAB> <TAB> self . resolve_with = "" consul "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . post_error ( "" ConsulResolver is required to have a datacenter "" ) <TAB> <TAB> <TAB> return False <TAB> elif self . kind == "" KubernetesServiceResolver "" : <TAB> <TAB> self . resolve_with = "" k8s "" <TAB> elif self . kind == "" KubernetesEndpointResolver "" : <TAB> <TAB> self . resolve_with = "" k8s "" <TAB> else : <TAB> <TAB> self . post_error ( f "" Resolver kind  { self . kind }  unknown "" ) <TAB> <TAB> return False <TAB> return True","elif self . kind == ""datacenter"" :","if not self . get ( ""datacenter"" ) :",False,95.27,71.23,,,
"def get_success_url ( self ) : <TAB> """""" Continue to the flow index or redirect according `?back` parameter. """""" <TAB> if "" back "" in self . request . GET : <TAB> <TAB> back_url = self . request . GET [ "" back "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> back_url = "" / "" <TAB> <TAB> return back_url <TAB> return reverse ( self . success_url )","if not back_url . endswith ( ""/"" ) :","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) :",False,80.44,83.07,,,
"def get_success_url ( self ) : <TAB> """""" Continue to the flow index or redirect according `?back` parameter. """""" <TAB> if "" back "" in self . request . GET : <TAB> <TAB> back_url = self . request . GET [ "" back "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> back_url = "" / "" <TAB> <TAB> return back_url <TAB> return reverse ( self . success_url )","if not back_url . endswith ( ""/"" ) :","if not url . startswith ( ""http://"" ) :",False,93.48,92.21,,,
"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB> <TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> buf . append ( "" line  "" ) <TAB> <TAB> buf . append ( str ( self . line ) ) <TAB> <TAB> if self . column != - 1 : <TAB> <TAB> <TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB> <TAB> buf . append ( "" : "" ) <TAB> buf . append ( "" "" ) <TAB> return str ( "" "" ) . join ( buf )",if self . line != - 1 :,if not self . fileName :,False,95.72,72.2,,,
"def parse_bash_set_output ( output ) : <TAB> """""" Parse Bash-like  ' set '  output """""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB> <TAB> line = line.rstrip() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> continue # skip black lines <TAB> <TAB> item = _ParseBashEnvStr(line) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> environ[item[0]] = item[1] <TAB> return environ",if item :,if item :,True,100.0,74.47,,,
"def remove_selected ( self ) : <TAB> """""" Removes selected items from list. """""" <TAB> to_delete = [ ] <TAB> for i in range ( len ( self ) ) : <TAB> <TAB> if self [ i ] . selected : <TAB> <TAB> <TAB> to_delete . append ( i ) <TAB> to_delete . reverse ( ) <TAB> for i in to_delete : <TAB> <TAB> self . pop ( i ) <TAB> if len ( to_delete ) > 0 : <TAB> <TAB> first_to_delete = to_delete [ - 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self [ 0 ] . selected = True <TAB> <TAB> elif first_to_delete > 0 : <TAB> <TAB> <TAB> self [ first_to_delete - 1 ] . selected = True",if first_to_delete == 0 :,if first_to_delete == 0 and len ( self ) > 0 :,False,96.4,89.13,,,
"def update ( self , update_tracks = True ) : <TAB> self . enable_update_metadata_images ( False ) <TAB> old_album_title = self . metadata [ "" album "" ] <TAB> self . metadata [ "" album "" ] = config . setting [ "" nat_name "" ] <TAB> for track in self . tracks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> track . metadata [ "" album "" ] = self . metadata [ "" album "" ] <TAB> <TAB> for file in track . linked_files : <TAB> <TAB> <TAB> track . update_file_metadata ( file ) <TAB> self . enable_update_metadata_images ( True ) <TAB> super ( ) . update ( update_tracks )","if track . metadata [ ""album"" ] != old_album_title :","if old_album_title == track . metadata [ ""album"" ] :",False,96.6,72.48,,,
"def on_input ( self , target , message ) : <TAB> if message . strip ( ) == "" "" : <TAB> <TAB> self . panel ( "" No commit message provided "" ) <TAB> <TAB> return <TAB> if target : <TAB> <TAB> command = [ "" git "" , "" add "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> command . append ( "" --all "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> command . extend ( ( "" -- "" , target ) ) <TAB> <TAB> self . run_command ( command , functools . partial ( self . add_done , message ) ) <TAB> else : <TAB> <TAB> self . add_done ( message , "" "" )","if target == [ ""all"" , [ ] :","if target == ""*"" :",False,95.65,72.71,,,
"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB> <TAB> filename , position = self . last_edit_cursor_pos <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> self . load ( filename ) <TAB> <TAB> <TAB> editor = self . get_current_editor ( ) <TAB> <TAB> <TAB> if position < editor . document ( ) . characterCount ( ) : <TAB> <TAB> <TAB> <TAB> editor . set_cursor_position ( position )","if filename == ""default"" :",if not osp . isfile ( filename ) :,False,95.42,61.65,,,
"def returnByType ( self , results ) : <TAB> new_results = { } <TAB> for r in results : <TAB> <TAB> type_name = r . get ( "" type "" , "" movie "" ) + "" s "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_results [ type_name ] = [ ] <TAB> <TAB> new_results [ type_name ] . append ( r ) <TAB> # Combine movies, needs a cleaner way.. <TAB> if ""movies"" in new_results: <TAB> <TAB> new_results[""movies""] = self.combineOnIMDB(new_results[""movies""]) <TAB> return new_results",if type_name not in new_results :,if type_name not in new_results :,True,100.0,74.31,,,
"def cache_sns_topics_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> if config.get(""environment"") == ""prod"": <TAB> <TAB> <TAB> cache_sns_topics_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cache_sns_topics_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if config . get ( ""environment"" ) == ""local"" :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",False,92.2,64.09,,,
"def get ( self , subject , topic ) : <TAB> """""" Handles GET requests. """""" <TAB> if subject in feconf . AVAILABLE_LANDING_PAGES : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . render_template ( "" topic-landing-page.mainpage.html "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise self . PageNotFoundException <TAB> else : <TAB> <TAB> raise self . PageNotFoundException",if topic == feconf . TEST_TOPIC :,if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :,False,89.9,89.49,,,
"def callback ( compiled ) : <TAB> <IF-STMT> <TAB> <TAB> logger . show_tabulated ( <TAB> <TAB> <TAB> "" Compiled "" , showpath ( codepath ) , "" without writing to file. "" <TAB> <TAB> ) <TAB> else : <TAB> <TAB> with univ_open ( destpath , "" w "" ) as opened : <TAB> <TAB> <TAB> writefile ( opened , compiled ) <TAB> <TAB> logger . show_tabulated ( "" Compiled to "" , showpath ( destpath ) , "" . "" ) <TAB> if self . show : <TAB> <TAB> print ( compiled ) <TAB> if run : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . execute ( compiled , path = codepath , allow_show = False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . execute_file ( destpath )",if not writefile :,if destpath is None :,False,95.65,70.83,,,
"def _find_start_index ( self , string , start , end ) : <TAB> while True : <TAB> <TAB> index = string . find ( "" { "" , start , end ) - 1 <TAB> <TAB> if index < 0 : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return index <TAB> <TAB> start = index + 2",if string . startswith ( start ) :,"if self . _start_index_is_ok ( string , index ) :",False,86.73,68.69,,,
"def _get_nlu_target_format ( export_path : Text ) - > Text : <TAB> guessed_format = loading . guess_format ( export_path ) <TAB> if guessed_format not in { MARKDOWN , RASA , RASA_YAML } : <TAB> <TAB> if rasa . shared . data . is_likely_json_file ( export_path ) : <TAB> <TAB> <TAB> guessed_format = RASA <TAB> <TAB> elif rasa . shared . data . is_likely_markdown_file ( export_path ) : <TAB> <TAB> <TAB> guessed_format = MARKDOWN <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> guessed_format = RASA_YAML <TAB> return guessed_format",elif rasa . shared . data . is_likely_yamlfile ( export_path ) :,elif rasa . shared . data . is_likely_yaml_file ( export_path ) :,False,97.54,73.05,,,
"def moveToThreadNext ( self ) : <TAB> """""" Move a position to threadNext position. """""" <TAB> p = self <TAB> if p . v : <TAB> <TAB> if p . v . children : <TAB> <TAB> <TAB> p . moveToFirstChild ( ) <TAB> <TAB> el <IF-STMT> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> while p : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> <TAB> <TAB> <TAB> break # found <TAB> <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> # not found. <TAB> return p",if p . moveToNext :,if p . hasNext ( ) :,False,95.81,92.87,,,
"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB> <TAB> value = getattr ( obj , attr , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB> if formatter is not None : <TAB> <TAB> <TAB> value = formatter ( attr , value ) <TAB> <TAB> info_add ( name , value )",if value is None :,if value is None :,True,100.0,74.25,,,
"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB> <TAB> <TAB> if attr != None : <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB> <TAB> <TAB> <TAB> yield element","if desc . getAttributeNodeNS ( namespace , name ) == aboutUri :","if desc . getAttributeNS ( RDF_NAMESPACE , ""about"" ) == aboutUri :",False,92.7,64.23,,,
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ),if self . counter >= self . count :,if self . timeout is not None :,False,96.76,90.98,,,
"def _parse_fixits ( message , titer , line ) : <TAB> """""" Parses fixit messages. """""" <TAB> while ( <TAB> <TAB> OutputParser . message_line_re . match ( line ) is None <TAB> <TAB> and OutputParser . note_line_re . match ( line ) is None <TAB> ) : <TAB> <TAB> message_text = line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message . fixits . append ( <TAB> <TAB> <TAB> <TAB> Note ( <TAB> <TAB> <TAB> <TAB> <TAB> message . path , <TAB> <TAB> <TAB> <TAB> <TAB> message . line , <TAB> <TAB> <TAB> <TAB> <TAB> line . find ( message_text ) + 1 , <TAB> <TAB> <TAB> <TAB> <TAB> message_text , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> line = next ( titer ) <TAB> return line",if message_text :,"if message_text != """" :",False,97.86,65.77,,,
"def _connect_db ( self , force_reconnect = False ) : <TAB> thread_id = thread . get_ident ( ) <TAB> if force_reconnect and thread_id in ENGINES : <TAB> <TAB> del ENGINES [ thread_id ] <TAB> conn = None <TAB> try : <TAB> <TAB> engine = ENGINES [ thread_id ] <TAB> <TAB> conn = engine . connect ( ) <TAB> <TAB> _test = conn . execute ( "" SELECT 1 "" ) <TAB> <TAB> _test . fetchall ( ) <TAB> except ( KeyError , MySQLdb . OperationalError ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conn . close ( ) <TAB> <TAB> engine = sqla . create_engine ( self . db_url , pool_recycle = 3600 ) <TAB> <TAB> ENGINES [ thread_id ] = engine <TAB> <TAB> conn = engine . connect ( ) <TAB> return conn",if conn :,if conn :,True,100.0,74.54,,,
"def read ( self , n ) : <TAB> if self . current_frame : <TAB> <TAB> data = self . current_frame . read ( n ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current_frame = None <TAB> <TAB> <TAB> return self . file_read ( n ) <TAB> <TAB> if len ( data ) < n : <TAB> <TAB> <TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return self . file_read ( n )",if not data :,if not data and n != 0 :,False,95.53,71.36,,,
"def __setLoadCmd ( self ) : <TAB> base = self . __rawLoadCmd <TAB> for _ in range ( self . __machHeader . ncmds ) : <TAB> <TAB> command = LOAD_COMMAND . from_buffer_copy ( base ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND . from_buffer_copy ( base ) <TAB> <TAB> <TAB> self . __setSections ( segment , base [ 56 : ] , 32 ) <TAB> <TAB> elif command . cmd == MACHOFlags . LC_SEGMENT_64 : <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND64 . from_buffer_copy ( base ) <TAB> <TAB> <TAB> self . __setSections ( segment , base [ 72 : ] , 64 ) <TAB> <TAB> base = base [ command . cmdsize : ]",if command . cmd == MACHOFlags . LC_SEGMENT_32 :,if command . cmd == MACHOFlags . LC_SEGMENT :,False,98.28,73.46,,,
"def emit_post_sync_signal ( created_models , verbosity , interactive , db ) : <TAB> # Emit the post_sync signal for every application. <TAB> for app in models.get_apps(): <TAB> <TAB> app_name = app.__name__.split(""."")[-2] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""Running post-sync handlers for application %s"" % app_name) <TAB> <TAB> models.signals.post_syncdb.send( <TAB> <TAB> <TAB> sender=app, <TAB> <TAB> <TAB> app=app, <TAB> <TAB> <TAB> created_models=created_models, <TAB> <TAB> <TAB> verbosity=verbosity, <TAB> <TAB> <TAB> interactive=interactive, <TAB> <TAB> <TAB> db=db, <TAB> <TAB> )","if app_name in [ ""post"" , ""post"" ] :",if verbosity >= 2 :,False,93.54,63.43,,,
"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB> <TAB> repo = _get_repo ( ) <TAB> <TAB> _confirm_dangerous ( ) <TAB> <TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB> <TAB> if url in repo . remotes : <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo . remotes . get ( origin ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> repo . pull ( origin_uri = url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB> <TAB> print ( command_help [ "" git pull "" ] )",if url :,if url :,True,100.0,74.52,,,
"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB> <TAB> repo = _get_repo ( ) <TAB> <TAB> _confirm_dangerous ( ) <TAB> <TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB> <TAB> if url in repo . remotes : <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo . remotes . get ( origin ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> repo . pull ( origin_uri = url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB> <TAB> print ( command_help [ "" git pull "" ] )",if url :,"if line . lower ( ) . startswith ( ""version:"" ) :",False,93.02,66.07,,,
"def increment ( self , metric , labels , delta ) : <TAB> """""" Increment a value by |delta|. """""" <TAB> with self . _lock : <TAB> <TAB> key = self . _get_key ( metric . name , labels ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> start_time = self . _store [ key ] . start_time <TAB> <TAB> <TAB> value = self . _store [ key ] . value + delta <TAB> <TAB> else : <TAB> <TAB> <TAB> start_time = time . time ( ) <TAB> <TAB> <TAB> value = metric . default_value + delta <TAB> <TAB> self . _store [ key ] = _StoreValue ( metric , labels , start_time , value )",if self . _store [ key ] :,if key in self . _store :,False,96.95,95.61,,,
"def get_current_connections ( session ) : <TAB> """""" Retrieves open connections using the the given session """""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session.sql(""SHOW PROCESSLIST"").execute() <TAB> rows = res.fetch_all() <TAB> connections = {} <TAB> for row in rows: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> connections[row.get_string(""User"")] = [row.get_string(""Host"")] <TAB> <TAB> else: <TAB> <TAB> <TAB> connections[row.get_string(""User"")].append(row.get_string(""Host"")) <TAB> return connections","if row . get_string ( ""User"" ) not in connections :","if row . get_string ( ""User"" ) not in connections :",True,100.0,74.17,,,
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> if path == paths [ - 1 ] : <TAB> <TAB> <TAB> <TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )",if os . path . isfile ( fspath ) :,if env . cache_static :,False,96.66,72.57,,,
def thread_loop ( self ) - > None : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> new_trials = self . study . trials <TAB> <TAB> with self . lock : <TAB> <TAB> <TAB> need_to_add_callback = self . new_trials is None <TAB> <TAB> <TAB> self . new_trials = new_trials <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . doc . add_next_tick_callback ( self . update_callback ),if need_to_add_callback :,if need_to_add_callback :,True,100.0,99.24,,,
"def _cache_db_tables_iterator ( tables , cache_alias , db_alias ) : <TAB> no_tables = not tables <TAB> cache_aliases = settings . CACHES if cache_alias is None else ( cache_alias , ) <TAB> db_aliases = settings . DATABASES if db_alias is None else ( db_alias , ) <TAB> for db_alias in db_aliases : <TAB> <TAB> if no_tables : <TAB> <TAB> <TAB> tables = connections [ db_alias ] . introspection . table_names ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for cache_alias in cache_aliases : <TAB> <TAB> <TAB> <TAB> yield cache_alias , db_alias , tables",if tables :,if tables :,True,100.0,74.38,,,
"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB> <TAB> if hasattr ( subscriber , "" _pyroRelease "" ) : <TAB> <TAB> <TAB> subscriber . _pyroRelease ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> <TAB> proxy . _pyroRelease ( ) <TAB> <TAB> <TAB> <TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . subscribers [ topic ] . discard ( subscriber )","elif hasattr ( subscriber , ""_pyroUri"" ) :","if hasattr ( subscriber , ""_pyroUri"" ) :",False,98.7,73.22,,,
"def test_constructor ( job_id ) : <TAB> with patch ( "" apscheduler.job.Job._modify "" ) as _modify : <TAB> <TAB> scheduler_mock = MagicMock ( BaseScheduler ) <TAB> <TAB> job = Job ( scheduler_mock , id = job_id ) <TAB> <TAB> assert job . _scheduler is scheduler_mock <TAB> <TAB> assert job . _jobstore_alias is None <TAB> <TAB> modify_kwargs = _modify . call_args [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert len ( modify_kwargs [ "" id "" ] ) == 32 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert modify_kwargs [ "" id "" ] == job_id","if isinstance ( modify_kwargs [ ""id"" ] , str ) :",if job_id is None :,False,92.56,64.81,,,
"def get_connection ( self ) : <TAB> if self . config . proxy_host != "" "" : <TAB> <TAB> return httplib . HTTPConnection ( self . config . proxy_host , self . config . proxy_port ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return httplib . HTTPSConnection ( self . config . simpledb_host ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return httplib . HTTPConnection ( self . config . simpledb_host )",if self . config . simpledb_port == 443 :,if self . config . use_https :,False,94.16,72.08,,,
"def notify_login ( self , ipaddress = "" "" ) : <TAB> if app . NOTIFY_ON_LOGIN : <TAB> <TAB> update_text = common . notifyStrings [ common . NOTIFY_LOGIN_TEXT ] <TAB> <TAB> title = common . notifyStrings [ common . NOTIFY_LOGIN ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _notify_pht ( title , update_text . format ( ipaddress ) )",if self . _is_pht ( title ) :,if update_text and title and ipaddress :,False,90.66,68.42,,,
"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """""" Returns the full height of the item to be inserted in the form """""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB> <TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB> <TAB> # Set radio button layout <TAB> <TAB> if item[""layout""] == ""horiz"": <TAB> <TAB> <TAB> return 0.03 + ctrl.labelHeight * 3 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl.labelHeight * len(item[""options""])","elif item [ ""layout"" ] == ""horizontal"" :","elif item [ ""layout"" ] == ""vert"" :",False,98.64,98.35,,,
"def _get_errors_lines ( self ) : <TAB> """""" Return the number of lines that contains errors to highlight. """""" <TAB> errors_lines = [ ] <TAB> block = self . document ( ) . begin ( ) <TAB> while block . isValid ( ) : <TAB> <TAB> user_data = get_user_data ( block ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errors_lines . append ( block . blockNumber ( ) ) <TAB> <TAB> block = block . next ( ) <TAB> return errors_lines","if user_data [ ""error"" ] :",if user_data . error :,False,95.44,95.39,,,
"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB> <TAB> self . is_pulsing = False <TAB> <TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB> <TAB> self . pbar . set_text ( progress ) <TAB> <TAB> if frac > 1 : <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB> <TAB> gtk . gdk . threads_leave ( )",if frac < 0 :,if frac < 0 :,True,100.0,74.4,,,
"def list_files ( basedir ) : <TAB> """""" List files in the directory rooted at |basedir|. """""" <TAB> if not os . path . isdir ( basedir ) : <TAB> <TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB> <TAB> d = directories . pop ( ) <TAB> <TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB> <TAB> <TAB> filename = os . path . join ( d , basename ) <TAB> <TAB> <TAB> if os . path . isdir ( os . path . join ( basedir , filename ) ) : <TAB> <TAB> <TAB> <TAB> directories . append ( filename ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield filename","if os . path . isdir ( os . path . join ( basedir , filename , "".py"" ) ) :","elif os . path . exists ( os . path . join ( basedir , filename ) ) :",False,94.72,93.4,,,
"def assistive ( self ) : <TAB> """""" Detects if item can be used as assistance """""" <TAB> # Make sure we cache results <TAB> if self.__assistive is None: <TAB> <TAB> assistive = False <TAB> <TAB> # Go through all effects and find first assistive <TAB> <TAB> for effect in self.effects.values(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # If we find one, stop and mark item as assistive <TAB> <TAB> <TAB> <TAB> assistive = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> self.__assistive = assistive <TAB> return self.__assistive",if effect . assistive :,if effect . isAssistance is True :,False,97.4,71.81,,,
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB> if filter is None or (row, col) not in filter: <TAB> <TAB> <TAB> <TAB> if self.map[row][col] == UNSEEN: <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen",if dist < min_dist :,if dist < min_dist :,True,100.0,74.44,,,
"def _maybe_has_default_route ( self ) : <TAB> for route in self . iter_routes ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> for iface in self . iter_interfaces ( ) : <TAB> <TAB> for subnet in iface . get ( "" subnets "" , [ ] ) : <TAB> <TAB> <TAB> for route in subnet . get ( "" routes "" , [ ] ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if route . get ( ""default"" , False ) :",if self . _is_default_route ( route ) :,False,86.91,60.84,,,
"def data ( self , data ) : <TAB> if data is None : <TAB> <TAB> raise Exception ( "" Data cannot be None "" ) <TAB> val = [ ] <TAB> for d in data : <TAB> <TAB> if isinstance ( d , str ) : <TAB> <TAB> <TAB> val . append ( bytes ( d , "" utf-8 "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val . append ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Invalid type, data can only be an str or a bytes not  {} :  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> type ( data ) , d <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> self . __data = val","elif isinstance ( d , bytes ) :","elif isinstance ( d , bytes ) :",True,100.0,74.56,,,
"def get_one_segment_function ( data , context , echoerr ) : <TAB> ext = data [ "" ext "" ] <TAB> function_name = context [ - 2 ] [ 1 ] . get ( "" function "" ) <TAB> if function_name : <TAB> <TAB> module , function_name = get_function_strings ( function_name , context , ext ) <TAB> <TAB> func = import_segment ( function_name , data , context , echoerr , module = module ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield func",if func :,if func :,True,100.0,74.22,,,
"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB> <TAB> if isinstance ( value , list ) : <TAB> <TAB> <TAB> for item in value : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . visit ( item , parents ) <TAB> <TAB> elif isinstance ( value , AST ) : <TAB> <TAB> <TAB> self . visit ( value , parents )","if isinstance ( item , AST ) :","if isinstance ( item , AST ) :",True,100.0,74.38,,,
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" SCE_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","if v [ ""Type"" ] == ""constant"" :","if v [ ""Category"" ] != ""Deprecated"" :",False,96.53,72.58,,,
"def things ( self , query ) : <TAB> limit = query . pop ( "" limit "" , 100 ) <TAB> offset = query . pop ( "" offset "" , 0 ) <TAB> keys = set ( self . docs ) <TAB> for k , v in query . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # query keys need to be flattened properly, <TAB> <TAB> <TAB> # this corrects any nested keys that have been included <TAB> <TAB> <TAB> # in values. <TAB> <TAB> <TAB> flat = common.flatten_dict(v)[0] <TAB> <TAB> <TAB> k += ""."" + web.rstrips(flat[0], "".key"") <TAB> <TAB> <TAB> v = flat[1] <TAB> <TAB> keys = set(k for k in self.filter_index(self.index, k, v) if k in keys) <TAB> keys = sorted(keys) <TAB> return keys[offset : offset + limit]","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.55,,,
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> if self . _keys [ hash_ ] is self . _empty : <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB> if initial_hash == hash_: <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",if self . _len == 0 :,elif self . _keys [ hash_ ] == key :,False,95.32,70.5,,,
"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB> <TAB> response = self.fetch(""/?error=1"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""requires HTTP/1.x"") <TAB> <TAB> if self.http_client.configured_class != SimpleAsyncHTTPClient: <TAB> <TAB> <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB> <TAB> self.assertEqual(response.code, 599)",if response . status != 200 :,if not self . http1 :,False,95.5,69.32,,,
"def __str__ ( self ) - > str : <TAB> text = "" \n "" <TAB> for k , r in self . result . items ( ) : <TAB> <TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text + = "" #  {}  (failed) \n "" . format ( k ) <TAB> <TAB> else : <TAB> <TAB> <TAB> text + = "" #  {}  (succeeded) \n "" . format ( k ) <TAB> <TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB> <TAB> for sub_r in r : <TAB> <TAB> <TAB> text + = "" ****  {} \n "" . format ( sub_r . name ) <TAB> <TAB> <TAB> text + = "" {} \n "" . format ( sub_r ) <TAB> return text",if r . failed :,if r . failed :,True,100.0,74.58,,,
"def DeleteTask ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB> <TAB> result = Mongo . coll [ "" Task "" ] . delete_one ( { "" _id "" : ObjectId ( oid ) } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = Mongo . coll [ "" Result "" ] . delete_many ( { "" task_id "" : ObjectId ( oid ) } ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return "" success "" <TAB> return "" fail """,if result :,if result . deleted_count > 0 :,False,94.87,71.83,,,
"def _replace_vars ( self , line , extracted , env_variables ) : <TAB> for e in extracted : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = env_variables . get ( e ) <TAB> <TAB> <TAB> if isinstance ( value , dict ) or isinstance ( value , list ) : <TAB> <TAB> <TAB> <TAB> value = pprint . pformat ( value ) <TAB> <TAB> <TAB> decorated = self . _decorate_var ( e ) <TAB> <TAB> <TAB> line = line . replace ( decorated , str ( value ) ) <TAB> return line",if e in env_variables :,if e in env_variables :,True,100.0,74.35,,,
"def should_include ( service ) : <TAB> for f in filt : <TAB> <TAB> if f == "" status "" : <TAB> <TAB> <TAB> state = filt [ f ] <TAB> <TAB> <TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB> <TAB> <TAB> if not has_container_with_state ( containers , state ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == "" source "" : <TAB> <TAB> <TAB> source = filt [ f ] <TAB> <TAB> <TAB> if source == "" image "" or source == "" build "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True","if not has_container_with_state ( containers , source ) :",if source not in service . options :,False,94.95,72.3,,,
def state_callback_loop ( ) : <TAB> if usercallback : <TAB> <TAB> when = 1 <TAB> <TAB> while ( <TAB> <TAB> <TAB> when <TAB> <TAB> <TAB> and not self . future_removed . done ( ) <TAB> <TAB> <TAB> and not self . session . shutdownstarttime <TAB> <TAB> ) : <TAB> <TAB> <TAB> result = usercallback ( self . get_state ( ) ) <TAB> <TAB> <TAB> when = ( await result ) if iscoroutine ( result ) else result <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> await sleep ( when ),if when :,if when > 0.0 and not self . session . shutdownstarttime :,False,93.55,64.66,,,
"def __get_new_timeout ( self , timeout ) : <TAB> """""" When using --timeout_multiplier=#.# """""" <TAB> self . __check_scope ( ) <TAB> try : <TAB> <TAB> timeout_multiplier = float ( self . timeout_multiplier ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> timeout_multiplier = 0.5 <TAB> <TAB> timeout = int ( math . ceil ( timeout_multiplier * timeout ) ) <TAB> <TAB> return timeout <TAB> except Exception : <TAB> <TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB> <TAB> return timeout",if timeout_multiplier < 0.5 :,if timeout_multiplier <= 0.5 :,False,98.4,97.8,,,
"def readexactly ( self , n ) : <TAB> buf = b "" "" <TAB> while n : <TAB> <TAB> yield IORead ( self . s ) <TAB> <TAB> res = self . s . read ( n ) <TAB> <TAB> assert res is not None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield IOReadDone ( self . s ) <TAB> <TAB> <TAB> break <TAB> <TAB> buf + = res <TAB> <TAB> n - = len ( res ) <TAB> return buf",if len ( res ) == 0 :,if not res :,False,93.61,71.08,,,
"def contract_rendering_pane ( event ) : <TAB> """""" Expand the rendering pane. """""" <TAB> c = event . get ( "" c "" ) <TAB> if c : <TAB> <TAB> vr = c . frame . top . findChild ( QtWidgets . QWidget , "" viewrendered_pane "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vr . contract ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Just open the pane. <TAB> <TAB> <TAB> viewrendered(event)",if vr :,if vr :,True,100.0,99.16,,,
"def translate_headers ( self , environ ) : <TAB> """""" Translate CGI-environ header names to HTTP header names. """""" <TAB> for cgiName in environ : <TAB> <TAB> # We assume all incoming header keys are uppercase already. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield self.headerNames[cgiName], environ[cgiName] <TAB> <TAB> elif cgiName[:5] == ""HTTP_"": <TAB> <TAB> <TAB> # Hackish attempt at recovering original header names. <TAB> <TAB> <TAB> translatedHeader = cgiName[5:].replace(""_"", ""-"") <TAB> <TAB> <TAB> yield translatedHeader, environ[cgiName]",if cgiName in self . headerNames :,if cgiName in self . headerNames :,True,100.0,99.24,,,
"def get_value_from_string ( self , string_value ) : <TAB> """""" Return internal representation starting from CFN/user-input value. """""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> string_value = str ( string_value ) . strip ( ) <TAB> <TAB> <TAB> if string_value != "" NONE "" : <TAB> <TAB> <TAB> <TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB> <TAB> self . pcluster_config . warn ( <TAB> <TAB> <TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB> <TAB> <TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB> <TAB> ) <TAB> return param_value","if self . key in ( ""user-input"" , ""password"" ) :",if string_value is not None :,False,93.71,59.13,,,
"def monitor_filter ( self ) : <TAB> """""" Return filtered service objects list """""" <TAB> services = self . client . services . list ( filters = { "" label "" : "" com.ouroboros.enable "" } ) <TAB> monitored_services = [ ] <TAB> for service in services : <TAB> <TAB> ouro_label = service . attrs [ "" Spec "" ] [ "" Labels "" ] . get ( "" com.ouroboros.enable "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> monitored_services . append ( service ) <TAB> self . data_manager . monitored_containers [ self . socket ] = len ( monitored_services ) <TAB> self . data_manager . set ( self . socket ) <TAB> return monitored_services",if ouro_label == self . socket :,"if not self . config . label_enable or ouro_label . lower ( ) in [ ""true"" , ""yes"" ] :",False,86.85,89.58,,,
"def nextEditable ( self ) : <TAB> """""" Moves focus of the cursor to the next editable window """""" <TAB> if self . currentEditable is None : <TAB> <TAB> if len ( self . _editableChildren ) : <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> if ref in self . _editableChildren : <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if nei >= len ( self . _editableChildren ) :,if nei >= len ( self . _editableChildren ) :,True,100.0,99.56,,,
"def linkify_cm_by_tp ( self , timeperiods ) : <TAB> for rm in self : <TAB> <TAB> mtp_name = rm . modulation_period . strip ( ) <TAB> <TAB> # The new member list, in id <TAB> <TAB> mtp = timeperiods.find_by_name(mtp_name) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> err = ( <TAB> <TAB> <TAB> <TAB> ""Error: the business impact modulation '%s' got an unknown "" <TAB> <TAB> <TAB> <TAB> ""modulation_period '%s'"" % (rm.get_name(), mtp_name) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> rm.configuration_errors.append(err) <TAB> <TAB> rm.modulation_period = mtp",if mtp is None :,"if mtp_name != """" and mtp is None :",False,95.71,50.99,,,
def close_open_fds ( keep = None ) : # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.close(fd) <TAB> <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> <TAB> if exc.errno != errno.EBADF: <TAB> <TAB> <TAB> <TAB> <TAB> raise,if fd not in keep :,if fd not in keep :,True,100.0,74.17,,,
"def _append_child_from_unparsed_xml ( father_node , unparsed_xml ) : <TAB> """""" Append child xml nodes to a node. """""" <TAB> dom_tree = parseString ( unparsed_xml ) <TAB> if dom_tree . hasChildNodes ( ) : <TAB> <TAB> first_child = dom_tree . childNodes [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> child_nodes = first_child . childNodes <TAB> <TAB> <TAB> for _ in range ( len ( child_nodes ) ) : <TAB> <TAB> <TAB> <TAB> childNode = child_nodes . item ( 0 ) <TAB> <TAB> <TAB> <TAB> father_node . appendChild ( childNode ) <TAB> <TAB> <TAB> return <TAB> raise DistutilsInternalError ( <TAB> <TAB> "" Could not Append append elements to  "" "" the Windows msi descriptor. "" <TAB> )",if first_child . nodeType == Node . ELEMENT_NODE :,if first_child . hasChildNodes ( ) :,False,95.73,93.88,,,
"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB> <TAB> request . uri = request . uri . replace ( old , new ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> body = six . ensure_str ( request . body ) <TAB> <TAB> <TAB> if old in body : <TAB> <TAB> <TAB> <TAB> request . body = body . replace ( old , new ) <TAB> return request",if request . body :,if is_text_payload ( request ) and request . body :,False,91.52,70.35,,,
"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB> <TAB> from pygments . lexers . _luabuiltins import MODULES <TAB> <TAB> for mod , func in MODULES . iteritems ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options )","if isinstance ( func , ( Module , Module ) ) :",if mod not in self . disabled_modules :,False,93.66,70.03,,,
"def GetBestSizeForParentSize ( self , parentSize ) : <TAB> """""" Finds the best width and height given the parent ' s width and height. """""" <TAB> if len ( self . GetChildren ( ) ) == 1 : <TAB> <TAB> win = self . GetChildren ( ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> temp_dc = wx . ClientDC ( self ) <TAB> <TAB> <TAB> childSize = win . GetBestSizeForParentSize ( parentSize ) <TAB> <TAB> <TAB> clientParentSize = self . _art . GetPanelClientSize ( <TAB> <TAB> <TAB> <TAB> temp_dc , self , wx . Size ( * parentSize ) , None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> overallSize = self . _art . GetPanelSize ( <TAB> <TAB> <TAB> <TAB> temp_dc , self , wx . Size ( * clientParentSize ) , None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return overallSize <TAB> return self . GetSize ( )",if win . GetWidth ( ) == wx . WindowWidth ( self ) :,"if isinstance ( win , RibbonControl ) :",False,94.78,91.25,,,
"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> pid = int ( pid ) <TAB> <TAB> <TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> if name in cmdline . split ( "" "" , 1 ) [ 0 ] : <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name )",if pname in cmdline :,if name in pname :,False,97.77,72.67,,,
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> if idx == num : <TAB> <TAB> <TAB> return element <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> if not isinstance ( i , int ) : <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx",if element [ 3 ] :,if element [ 3 ] and element [ 4 ] :,False,96.72,71.53,,,
"def scan_block_scalar_indentation ( self ) : <TAB> # See the specification for details. <TAB> chunks = [] <TAB> max_indent = 0 <TAB> end_mark = self.get_mark() <TAB> while self.peek() in "" \r\n\x85\u2028\u2029"": <TAB> <TAB> if self.peek() != "" "": <TAB> <TAB> <TAB> chunks.append(self.scan_line_break()) <TAB> <TAB> <TAB> end_mark = self.get_mark() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.forward() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> max_indent = self.column <TAB> return chunks, max_indent, end_mark",if self . column > max_indent :,if self . column > max_indent :,True,100.0,74.19,,,
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == LEGAL :,elif col == FOOD :,False,99.16,73.99,,,
"def prepare_data ( entry ) : <TAB> branch_wise_entries = { } <TAB> gross_pay = 0 <TAB> for d in entry : <TAB> <TAB> gross_pay + = d . gross_pay <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB> <TAB> else : <TAB> <TAB> <TAB> branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB> <TAB> <TAB> <TAB> d . mode_of_payment , d . net_pay <TAB> <TAB> <TAB> ) <TAB> return branch_wise_entries , gross_pay",if d . branch in branch_wise_entries . keys ( ) :,if branch_wise_entries . get ( d . branch ) :,False,96.1,71.08,,,
"def prepare_data ( entry ) : <TAB> branch_wise_entries = { } <TAB> gross_pay = 0 <TAB> for d in entry : <TAB> <TAB> gross_pay + = d . gross_pay <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB> <TAB> else : <TAB> <TAB> <TAB> branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB> <TAB> <TAB> <TAB> d . mode_of_payment , d . net_pay <TAB> <TAB> <TAB> ) <TAB> return branch_wise_entries , gross_pay",if d . branch in branch_wise_entries . keys ( ) :,if task_id in self . cluster_state . tasks,False,92.38,69.73,,,
"def prepare_data ( entry ) : <TAB> branch_wise_entries = { } <TAB> gross_pay = 0 <TAB> for d in entry : <TAB> <TAB> gross_pay + = d . gross_pay <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB> <TAB> else : <TAB> <TAB> <TAB> branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB> <TAB> <TAB> <TAB> d . mode_of_payment , d . net_pay <TAB> <TAB> <TAB> ) <TAB> return branch_wise_entries , gross_pay",if d . branch in branch_wise_entries . keys ( ) :,"if os . path . basename ( p ) != ""CVS"" and os . path . isdir ( os . path . join ( d , p ) )",False,84.43,54.05,,,
"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB> <TAB> self . connect ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> command = [ command ] <TAB> <TAB> for item in command : <TAB> <TAB> <TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> if len ( e . args ) == 1 : <TAB> <TAB> <TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> _errno , errmsg = e . args <TAB> <TAB> raise ConnectionError ( <TAB> <TAB> <TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> raise","if isinstance ( command , list ) :","if isinstance ( command , str ) :",False,99.02,73.86,,,
"def run ( self ) : <TAB> """""" Start the scanner """""" <TAB> logging . info ( "" Dirscanner starting up "" ) <TAB> self . shutdown = False <TAB> while not self . shutdown : <TAB> <TAB> # Wait to be woken up or triggered <TAB> <TAB> with self.loop_condition: <TAB> <TAB> <TAB> self.loop_condition.wait(self.dirscan_speed) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.scan()",if self . loop_condition . is_set ( ) :,if self . dirscan_speed and not self . shutdown :,False,92.25,93.59,,,
"def __aexit__ ( <TAB> self , exc_type : type , exc_value : BaseException , tb : TracebackType ) - > None : <TAB> if exc_type is not None : <TAB> <TAB> await self . close ( ) <TAB> await self . _task <TAB> while not self . _receive_queue . empty ( ) : <TAB> <TAB> data = await self . _receive_queue . get ( ) <TAB> <TAB> if isinstance ( data , bytes ) : <TAB> <TAB> <TAB> self . response_data . extend ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise data",if self . _raise_on_error :,"elif not isinstance ( data , HTTPDisconnect ) :",False,93.28,69.6,,,
"def f ( msg ) : <TAB> text = extractor ( msg ) <TAB> for px in prefix : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> chunks = text [ len ( px ) : ] . split ( separator ) <TAB> <TAB> <TAB> return chunks [ 0 ] , ( chunks [ 1 : ] , ) if pass_args else ( ) <TAB> return ( ( None , ) , ) # to distinguish with `None`",if text . startswith ( px ) :,if text . startswith ( px ) :,True,100.0,74.27,,,
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> if type ( item ) is ActionHandle : <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> if type ( ah ) is not ActionHandle : # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else: # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs","elif isinstance ( item , list ) :","elif type ( item ) in ( list , tuple , dict , set ) :",False,94.54,69.52,,,
"def find_class ( self , module , name ) : <TAB> # Subclasses may override this. <TAB> sys.audit(""pickle.find_class"", module, name) <TAB> if self.proto < 3 and self.fix_imports: <TAB> <TAB> if (module, name) in _compat_pickle.NAME_MAPPING: <TAB> <TAB> <TAB> module, name = _compat_pickle.NAME_MAPPING[(module, name)] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module = _compat_pickle.IMPORT_MAPPING[module] <TAB> __import__(module, level=0) <TAB> if self.proto >= 4: <TAB> <TAB> return _getattribute(sys.modules[module], name)[0] <TAB> else: <TAB> <TAB> return getattr(sys.modules[module], name)",if module in _compat_pickle . IMPORT_MAPPING :,elif module in _compat_pickle . IMPORT_MAPPING :,False,98.84,72.38,,,
"def _send_until_done ( self , data ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . connection . send ( data ) <TAB> <TAB> except OpenSSL . SSL . WantWriteError : <TAB> <TAB> <TAB> wr = util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise timeout ( ) <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL . SSL . SysCallError as e : <TAB> <TAB> <TAB> raise SocketError ( str ( e ) )",if not wr :,if not wr :,True,100.0,74.39,,,
"def __new__ ( cls , * args , * * kwargs ) : <TAB> """""" Hack to ensure method defined as async are implemented as such. """""" <TAB> coroutines = inspect . getmembers ( BaseManager , predicate = inspect . iscoroutinefunction ) <TAB> for coroutine in coroutines : <TAB> <TAB> implemented_method = getattr ( cls , coroutine [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( "" The method  %s  must be a coroutine "" % implemented_method ) <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )",if not implemented_method . iscoroutinefunction ( ) :,if not inspect . iscoroutinefunction ( implemented_method ) :,False,96.23,84.96,,,
"def add_directive ( self , name , obj , content = None , arguments = None , * * options ) : <TAB> if isinstance ( obj , clstypes ) and issubclass ( obj , Directive ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ExtensionError ( <TAB> <TAB> <TAB> <TAB> "" when adding directive classes, no  "" "" additional arguments may be given "" <TAB> <TAB> <TAB> ) <TAB> <TAB> directives . register_directive ( name , directive_dwim ( obj ) ) <TAB> else : <TAB> <TAB> obj . content = content <TAB> <TAB> obj . arguments = arguments <TAB> <TAB> obj . options = options <TAB> <TAB> directives . register_directive ( name , obj )",if arguments is None :,if content or arguments or options :,False,96.47,71.65,,,
"def create ( self , w ) : <TAB> if w . use_eventloop : <TAB> <TAB> # does not use dedicated timer thread. <TAB> <TAB> w.timer = _Timer(max_interval=10.0) <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Default Timer is set by the pool, as for example, the <TAB> <TAB> <TAB> # eventlet pool needs a custom timer implementation. <TAB> <TAB> <TAB> w.timer_cls = w.pool_cls.Timer <TAB> <TAB> w.timer = self.instantiate( <TAB> <TAB> <TAB> w.timer_cls, <TAB> <TAB> <TAB> max_interval=w.timer_precision, <TAB> <TAB> <TAB> on_error=self.on_timer_error, <TAB> <TAB> <TAB> on_tick=self.on_timer_tick, <TAB> <TAB> )",if w . timer_cls is None :,if not w . timer_cls :,False,97.81,71.74,,,
"def _config ( _molecule_file , request ) : <TAB> with open ( _molecule_file ) as f : <TAB> <TAB> d = util . safe_load ( f ) <TAB> if hasattr ( request , "" param "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d2 = util . safe_load ( request . getfixturevalue ( request . param ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d2 = request . getfixturevalue ( request . param ) <TAB> <TAB> # print(100, d) <TAB> <TAB> # print(200, d2) <TAB> <TAB> d = util.merge_dicts(d, d2) <TAB> <TAB> # print(300, d) <TAB> return d","if isinstance ( request . getfixturevalue ( request . param ) , dict ) :","if isinstance ( request . getfixturevalue ( request . param ) , str ) :",False,98.68,73.34,,,
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model","if isinstance ( value , tf . keras . layers . Layer ) :","if isinstance ( value , tf . keras . layers . Layer ) :",True,100.0,74.41,,,
"def is_accepted_drag_event ( self , event ) : <TAB> if event . source ( ) == self . table : <TAB> <TAB> return True <TAB> mime = event . mimeData ( ) <TAB> if mime . hasUrls ( ) : <TAB> <TAB> for url in mime . urls ( ) : <TAB> <TAB> <TAB> # Only support local files. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # And only allow supported extensions. <TAB> <TAB> <TAB> filename = url.toLocalFile() <TAB> <TAB> <TAB> extension = os.path.splitext(filename)[1].lower()[1:] <TAB> <TAB> <TAB> if extension not in _dictionary_formats(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> return True <TAB> return False",if url . isLocalFile ( ) :,if not url . isLocalFile ( ) :,False,98.93,73.34,,,
"def explain ( self , other , depth = 0 ) : <TAB> exp = super ( UnionType , self ) . explain ( other , depth ) <TAB> for ndx , subtype in enumerate ( self . params [ "" allowed_types "" ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exp + = "" \n {} and "" . format ( "" "" . join ( [ "" \t "" ] * depth ) ) <TAB> <TAB> exp + = "" \n "" + subtype . explain ( other , depth = depth + 1 ) <TAB> return exp",if ndx == 0 :,if ndx > 0 :,False,97.31,73.2,,,
"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB> <TAB> observed = aug.augment_image(self.base_img) <TAB> <TAB> if np.array_equal(observed, self.blur3x3): <TAB> <TAB> <TAB> seen[0] += True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seen[1] += True <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB> <TAB> if all(seen): <TAB> <TAB> <TAB> break <TAB> assert np.all(seen)","elif np . array_equal ( observed , self . blur2x3 ) :","elif np . array_equal ( observed , self . blur5x5 ) :",False,98.85,72.84,,,
"def test_get_message ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> message_id = await self . _send_message ( ) <TAB> <TAB> <TAB> message = await self . chat_thread_client . get_message ( message_id ) <TAB> <TAB> <TAB> assert message . id == message_id <TAB> <TAB> <TAB> assert message . type == ChatMessageType . TEXT <TAB> <TAB> <TAB> assert message . content . message == "" hello world "" <TAB> <TAB> # delete chat threads <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",if self . thread_id :,if not self . is_playback ( ) :,False,95.97,71.25,,,
"def test_get_message ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> message_id = await self . _send_message ( ) <TAB> <TAB> <TAB> message = await self . chat_thread_client . get_message ( message_id ) <TAB> <TAB> <TAB> assert message . id == message_id <TAB> <TAB> <TAB> assert message . type == ChatMessageType . TEXT <TAB> <TAB> <TAB> assert message . content . message == "" hello world "" <TAB> <TAB> # delete chat threads <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",if self . thread_id :,"if isinstance ( device , IOCB )",False,96.4,71.06,,,
"def fit ( self , dataset , force_retrain ) : <TAB> if force_retrain : <TAB> <TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB> <TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB> <TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB> <TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> else : <TAB> <TAB> if not self . sub_unit_1 [ "" fitted "" ] : <TAB> <TAB> <TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB> <TAB> <TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB> <TAB> <TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> return self","if not self . sub_unit_2 [ ""fitted"" ] :","if not self . sub_unit_2 [ ""fitted"" ] :",True,100.0,74.58,,,
"def _insert_with_loop ( self ) : <TAB> id_list = [ ] <TAB> last_id = None <TAB> return_id_list = self . _return_id_list <TAB> for row in self . _rows : <TAB> <TAB> last_id = InsertQuery ( self . model_class , row ) . upsert ( self . _upsert ) . execute ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> id_list . append ( last_id ) <TAB> <IF-STMT> <TAB> <TAB> return id_list <TAB> else : <TAB> <TAB> return last_id",if return_id_list :,if return_id_list :,True,100.0,74.24,,,
"def merge_block ( self ) : <TAB> """""" merges a block in the map """""" <TAB> for i in range ( self . block . x ) : <TAB> <TAB> for j in range ( self . block . x ) : <TAB> <TAB> <TAB> c = self . block . get ( i , j ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . map [ ( i + self . block . pos . x , j + self . block . pos . y ) ] = c",if c != - 1 :,if c :,False,95.81,86.91,,,
"def configure_plex ( config ) : <TAB> core . PLEX_SSL = int ( config [ "" Plex "" ] [ "" plex_ssl "" ] ) <TAB> core . PLEX_HOST = config [ "" Plex "" ] [ "" plex_host "" ] <TAB> core . PLEX_PORT = config [ "" Plex "" ] [ "" plex_port "" ] <TAB> core . PLEX_TOKEN = config [ "" Plex "" ] [ "" plex_token "" ] <TAB> plex_section = config [ "" Plex "" ] [ "" plex_sections "" ] or [ ] <TAB> if plex_section : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> plex_section = "" , "" . join ( plex_section ) # fix in case this imported as list. <TAB> <TAB> plex_section = [tuple(item.split("","")) for item in plex_section.split(""|"")] <TAB> core.PLEX_SECTION = plex_section","if isinstance ( plex_section , list ) :","if isinstance ( plex_section , list ) :",True,100.0,74.53,,,
"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB> <TAB> xlib . XNextEvent ( self . _display , e ) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if xlib.XFilterEvent(e, e.xany.window): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> dispatch = self._window_map[e.xany.window] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch(e)","if xlib . XFilterEvent ( e , e . xany . window ) :","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) :",False,93.61,68.5,,,
"def format_message ( self ) : <TAB> bits = [ self . message ] <TAB> if self . possibilities : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bits . append ( "" Did you mean  %s ? "" % self . possibilities [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> possibilities = sorted ( self . possibilities ) <TAB> <TAB> <TAB> bits . append ( "" (Possible options:  %s ) "" % "" ,  "" . join ( possibilities ) ) <TAB> return "" "" . join ( bits )",if len ( self . possibilities ) == 1 :,if len ( self . possibilities ) == 1 :,True,100.0,74.36,,,
"def _collect_logs ( model ) : <TAB> page_token = None <TAB> all_logs = [ ] <TAB> while True : <TAB> <TAB> paginated_logs = model . lookup_logs ( now , later , page_token = page_token ) <TAB> <TAB> page_token = paginated_logs . next_page_token <TAB> <TAB> all_logs . extend ( paginated_logs . logs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return all_logs",if not paginated_logs :,if page_token is None :,False,95.01,70.25,,,
"def run ( self ) : <TAB> while True : <TAB> <TAB> context_id_list_tuple = self . _inflated_addresses . get ( block = True ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> c_id , inflated_address_list = context_id_list_tuple <TAB> <TAB> inflated_value_map = dict ( inflated_address_list ) <TAB> <TAB> if c_id in self . _contexts : <TAB> <TAB> <TAB> self . _contexts [ c_id ] . set_from_tree ( inflated_value_map )",if context_id_list_tuple is None :,if context_id_list_tuple is _SHUTDOWN_SENTINEL :,False,96.5,72.46,,,
"def _setup_prefix ( self ) : <TAB> # we assume here that our metadata may be nested inside a ""basket"" <TAB> # of multiple eggs; that's why we use module_path instead of .archive <TAB> path = self.module_path <TAB> old = None <TAB> while path != old: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.egg_name = os.path.basename(path) <TAB> <TAB> <TAB> self.egg_info = os.path.join(path, ""EGG-INFO"") <TAB> <TAB> <TAB> self.egg_root = path <TAB> <TAB> <TAB> break <TAB> <TAB> old = path <TAB> <TAB> path, base = os.path.split(path)",if os . path . isdir ( path ) :,"if path . lower ( ) . endswith ( "".egg"" ) :",False,93.64,63.63,,,
"def get_filename ( self , prompt ) : <TAB> okay = False <TAB> val = "" "" <TAB> while not okay : <TAB> <TAB> val = raw_input ( "" %s :  %s "" % ( prompt , val ) ) <TAB> <TAB> val = os . path . expanduser ( val ) <TAB> <TAB> if os . path . isfile ( val ) : <TAB> <TAB> <TAB> okay = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = val <TAB> <TAB> <TAB> val = self . choose_from_list ( os . listdir ( path ) ) <TAB> <TAB> <TAB> if val : <TAB> <TAB> <TAB> <TAB> val = os . path . join ( path , val ) <TAB> <TAB> <TAB> <TAB> okay = True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> val = "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Invalid value:  %s "" % val ) <TAB> <TAB> <TAB> val = "" "" <TAB> return val",elif os . path . isdir ( val ) :,elif os . path . isdir ( val ) :,True,100.0,74.63,,,
"def versions ( self , sitename , data ) : <TAB> # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB> if ""query"" in data: <TAB> <TAB> q = json.loads(data[""query""]) <TAB> <TAB> itemid = self._get_itemid(q.get(""key"")) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = q[""key""] <TAB> <TAB> <TAB> return json.dumps([self.dummy_edit(key)]) <TAB> # if not just go the default way <TAB> return ConnectionMiddleware.versions(self, sitename, data)",if itemid :,if itemid :,True,100.0,74.08,,,
"def read_stanza ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> stanza_end = self . _buffer . index ( b "" \n "" ) <TAB> <TAB> <TAB> stanza = self . decoder . decode ( self . _buffer [ : stanza_end ] ) <TAB> <TAB> <TAB> self . _buffer = self . _buffer [ stanza_end + 1 : ] <TAB> <TAB> <TAB> colon = stanza . index ( "" : "" ) <TAB> <TAB> <TAB> return stanza [ : colon ] , stanza [ colon + 1 : ] <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> bytes = self . read_bytes ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _buffer + = bytes",if not bytes :,if not bytes :,True,100.0,74.54,,,
def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB> <TAB> mask = 1 << bit <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if attrnames . has_key ( mask ) : <TAB> <TAB> <TAB> <TAB> names . append ( attrnames [ mask ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> names . append ( hex ( mask ) ) <TAB> return names,if len ( attrs ) == 1 and attrs [ bit ] == 0 :,if attrs & mask :,False,87.9,65.51,,,
"def _set_http_cookie ( ) : <TAB> if conf . cookie : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = "" ;  "" . join ( <TAB> <TAB> <TAB> <TAB> map ( lambda x : "" = "" . join ( x ) , conf . cookie . items ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = conf . cookie",if HTTP_HEADER . COOKIE not in conf . cookie :,"if isinstance ( conf . cookie , dict ) :",False,92.8,69.85,,,
"def __ne__ ( self , other ) : <TAB> if isinstance ( other , WeakMethod ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self is not other <TAB> <TAB> return weakref . ref . __ne__ ( self , other ) or self . _func_ref != other . _func_ref <TAB> return True",if self . _alive != other . _alive :,if not self . _alive or not other . _alive :,False,93.67,68.59,,,
"def update_unread ( self , order_id , reset = False ) : <TAB> conn = Database . connect_database ( self . PATH ) <TAB> with conn : <TAB> <TAB> cursor = conn . cursor ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cursor . execute ( <TAB> <TAB> <TAB> <TAB> """""" UPDATE sales SET unread = unread + 1 WHERE id=?; """""" , ( order_id , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cursor . execute ( """""" UPDATE sales SET unread=0 WHERE id=?; """""" , ( order_id , ) ) <TAB> <TAB> conn . commit ( ) <TAB> conn . close ( )",if reset :,if reset is False :,False,98.11,97.54,,,
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value","elif key == ""nw_dst"" :","elif key == ""nw_dst"" :",True,100.0,74.54,,,
"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB> <TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if keep_nested is not None : <TAB> <TAB> <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield k , v",if keep_current is not None and k != keep_current :,if k in keep_current :,False,94.21,71.77,,,
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """""" Select the next marked node. """""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> elif p : <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> elif wrapped : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",if p . isMarked ( ) :,if p and p . isMarked ( ) :,False,98.68,83.53,,,
"def sample ( self , * * config ) : <TAB> """""" Sample a configuration from this search space. """""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( v , NestedSpace ) : <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB> <TAB> <TAB> <TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret [ k ] = v <TAB> return ret",if k not in striped_keys :,if k in striped_keys :,False,98.87,98.9,,,
"def update_gradients_full ( self , dL_dK , X , X2 = None ) : <TAB> if self . ARD : <TAB> <TAB> phi1 = self . phi ( X ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> phi2 = self . phi ( X2 ) <TAB> <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi2 ) <TAB> else : <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,ij "" , dL_dK , self . _K ( X , X2 ) ) * self . beta",if self . ARD_SPARSE :,if X2 is None or X is X2 :,False,95.74,70.89,,,
"def post ( self ) : <TAB> host_json = json . loads ( request . data ) <TAB> host_os = host_json . get ( "" os "" ) <TAB> if host_os : <TAB> <TAB> result = get_monkey_executable ( host_os . get ( "" type "" ) , host_os . get ( "" machine "" ) ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> # change resulting from new base path <TAB> <TAB> <TAB> executable_filename = result[""filename""] <TAB> <TAB> <TAB> real_path = MonkeyDownload.get_executable_full_path(executable_filename) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result[""size""] = os.path.getsize(real_path) <TAB> <TAB> <TAB> <TAB> return result <TAB> return {}",if os . path . exists ( real_path ) :,if os . path . isfile ( real_path ) :,False,98.87,73.31,,,
"def _encode_data ( <TAB> self , <TAB> data , <TAB> content_type , ) : <TAB> if content_type is MULTIPART_CONTENT : <TAB> <TAB> return encode_multipart ( BOUNDARY , data ) <TAB> else : <TAB> <TAB> # Encode the content so that the byte representation is correct. <TAB> <TAB> match = CONTENT_TYPE_RE.match(content_type) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> charset = match.group(1) <TAB> <TAB> else: <TAB> <TAB> <TAB> charset = settings.DEFAULT_CHARSET <TAB> <TAB> return force_bytes(data, encoding=charset)",if match :,if match :,True,100.0,74.18,,,
"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB> <TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> if not re . match ( "" [0-9] "" , str ( tokens [ s ] ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB> <TAB> <TAB> i - = 1 <TAB> return tokens","if re . match ( ""[+-]$"" , str ( tokens [ e ] ) ) :","if re . match ( ""[0-9]"" , str ( tokens [ e ] ) ) :",False,98.1,73.96,,,
"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self[key] = result <TAB> <TAB> if type(result) in (ConvertingDict, ConvertingList, ConvertingTuple): <TAB> <TAB> <TAB> result.parent = self <TAB> <TAB> <TAB> result.key = key <TAB> return result",if key != key :,if replace :,False,95.87,72.0,,,
"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB> <TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB> <TAB> for bp in bplist : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if text . strip ( ) . lower ( ) == "" none "" : <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp . cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self . RespondDebuggerData ( )",if bp . id == item_id :,if id ( bp ) == item_id :,False,97.45,72.62,,,
"def add ( self , url : str , future_nzo : NzbObject , when : Optional [ int ] = None ) : <TAB> """""" Add an URL to the URLGrabber queue,  ' when '  is seconds from now """""" <TAB> if future_nzo and when : <TAB> <TAB> # Always increase counter <TAB> <TAB> future_nzo.url_tries += 1 <TAB> <TAB> # Too many tries? Cancel <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.fail_to_history(future_nzo, url, T(""Maximum retries"")) <TAB> <TAB> <TAB> return <TAB> <TAB> future_nzo.url_wait = time.time() + when <TAB> self.queue.put((url, future_nzo))",if future_nzo . url_tries > future_nzo . url_tries :,if future_nzo . url_tries > cfg . max_url_retries ( ) :,False,95.35,96.21,,,
def _is_datetime_string ( series ) : <TAB> if series . dtype == object : <TAB> <TAB> not_numeric = False <TAB> <TAB> try : <TAB> <TAB> <TAB> pd . to_numeric ( series ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> not_numeric = True <TAB> <TAB> datetime_col = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> datetime_col = pd . to_datetime ( series ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> if datetime_col is not None : <TAB> <TAB> <TAB> return True <TAB> return False,if not_numeric :,if not_numeric :,True,100.0,99.44,,,
def _is_datetime_string ( series ) : <TAB> if series . dtype == object : <TAB> <TAB> not_numeric = False <TAB> <TAB> try : <TAB> <TAB> <TAB> pd . to_numeric ( series ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> not_numeric = True <TAB> <TAB> datetime_col = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> datetime_col = pd . to_datetime ( series ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> if datetime_col is not None : <TAB> <TAB> <TAB> return True <TAB> return False,if not_numeric :,if self . prefix == event [ : len ( self . prefix ) ] :,False,91.96,64.09,,,
"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> if name.startswith(""_""): <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr(bonobo, name) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo.__all__","if not isinstance ( attr , types . Attribute ) :",if inspect . ismodule ( attr ) :,False,93.88,69.26,,,
"def relint_views ( wid = None ) : <TAB> windows = [ sublime . Window ( wid ) ] if wid else sublime . windows ( ) <TAB> for window in windows : <TAB> <TAB> for view in window . views ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> hit ( view , "" relint_views "" )",if view . relint_views :,if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) :,False,80.06,64.39,,,
def _check_for_unknown_gender ( self ) : <TAB> if self . obj . get_gender ( ) == Person . UNKNOWN : <TAB> <TAB> d = GenderDialog ( parent = self . window ) <TAB> <TAB> gender = d . run ( ) <TAB> <TAB> d . destroy ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . obj . set_gender ( gender ),if gender :,if gender >= 0 :,False,95.55,68.13,,,
"def add_to_path ( self , fnames ) : <TAB> """""" Add fnames to path """""" <TAB> indexes = [ ] <TAB> for path in fnames : <TAB> <TAB> project = self . get_source_project ( path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . parent_widget . emit ( SIGNAL ( "" pythonpath_changed() "" ) ) <TAB> <TAB> <TAB> indexes . append ( self . get_index ( path ) ) <TAB> if indexes : <TAB> <TAB> self . reset_icon_provider ( ) <TAB> <TAB> for index in indexes : <TAB> <TAB> <TAB> self . update ( index )",if project . is_changed ( ) :,if project . add_to_pythonpath ( path ) :,False,95.32,70.06,,,
"def validate ( self , value ) : <TAB> if value . grid_id is not None : <TAB> <TAB> if not isinstance ( value , self . proxy_class ) : <TAB> <TAB> <TAB> self . error ( "" FileField only accepts GridFSProxy values "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . error ( "" Invalid GridFSProxy value "" )",if value . grid_id not in self . proxy_class . _grid_ids :,"if not isinstance ( value . grid_id , ObjectId ) :",False,85.68,67.72,,,
"def shortcut ( self , input , ch_out , stride , name , if_first = False ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB> <TAB> return input",if if_first :,if if_first :,True,100.0,74.34,,,
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( )",elif code == Path . CURVE4 :,elif code == Path . CURVE4 :,True,100.0,74.56,,,
"def _get_build_status ( self , job_name , build_number ) : <TAB> try : <TAB> <TAB> build_info = self . server . get_build_info ( job_name , build_number ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" building "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" built "" <TAB> except jenkins . NotFoundException : <TAB> <TAB> return "" not found ""","if build_info [ ""status"" ] == ""built"" :","if build_info [ ""building"" ] :",False,92.94,65.92,,,
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> if default . lower ( ) == "" true "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default . lower ( ) == "" false "" : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default )",if type ( default ) == float :,if type ( default ) == float :,True,100.0,74.66,,,
"def get_fills ( self , exchange_order_id ) : <TAB> async with aiohttp . ClientSession ( ) as client : <TAB> <TAB> response : aiohttp . ClientResponse = await client . get ( <TAB> <TAB> <TAB> f "" { BASE_URL } { FILLS_ROUTE } "" , <TAB> <TAB> <TAB> params = { "" orderId "" : exchange_order_id , "" limit "" : 100 } , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> msg = await response . json ( ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> msg = await response . text ( ) <TAB> <TAB> <TAB> raise DydxAsyncAPIError ( response . status , msg ) <TAB> <TAB> return await response . json ( )",if response . status != 200 :,if response . status >= 300 :,False,97.96,73.22,,,
"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB> <TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key, value in list(semanticTags.items()): <TAB> <TAB> if not isinstance(key, int): <TAB> <TAB> <TAB> raise TypeError(""At least one key is not a valid int position"") <TAB> <TAB> if not isinstance(value, list): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> <TAB> ) <TAB> self.__semanticTags = semanticTags","if not isinstance ( x , str ) :","if not isinstance ( x , str ) :",True,100.0,74.57,,,
"def start_cutting_tool ( self , event , axis , direction ) : <TAB> toggle = event . EventObject <TAB> self . cutting = toggle . Value <TAB> if toggle . Value : <TAB> <TAB> # Disable the other toggles <TAB> <TAB> for child in self.cutsizer.Children: <TAB> <TAB> <TAB> child = child.Window <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> child.Value = False <TAB> <TAB> self.cutting_axis = axis <TAB> <TAB> self.cutting_direction = direction <TAB> else: <TAB> <TAB> self.cutting_axis = None <TAB> <TAB> self.cutting_direction = None <TAB> self.cutting_dist = None",if child . Value == True :,if child != toggle :,False,96.55,71.93,,,
"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB> <TAB> for patching in patched . patchings : <TAB> <TAB> <TAB> arg = exit_stack . enter_context ( patching ) <TAB> <TAB> <TAB> if patching . attribute_name is not None : <TAB> <TAB> <TAB> <TAB> keywargs . update ( arg ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> extra_args . append ( arg ) <TAB> <TAB> args + = tuple ( extra_args ) <TAB> <TAB> yield ( args , keywargs )",if arg is not None :,elif patching . new is DEFAULT :,False,95.72,70.87,,,
def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB> <TAB> mask = 1 << bit <TAB> <TAB> if attrs & mask : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> names . append ( attrnames [ mask ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> names . append ( hex ( mask ) ) <TAB> return names,if mask in attrnames :,if attrnames . has_key ( mask ) :,False,92.59,92.7,,,
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",True,100.0,74.3,,,
"def handle_socket ( self , request ) : <TAB> conn = request . connection <TAB> while True : <TAB> <TAB> chunk = conn . recv ( 4 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> slen = struct . unpack ( "" >L "" , chunk ) [ 0 ] <TAB> <TAB> chunk = conn . recv ( slen ) <TAB> <TAB> while len ( chunk ) < slen : <TAB> <TAB> <TAB> chunk = chunk + conn . recv ( slen - len ( chunk ) ) <TAB> <TAB> obj = pickle . loads ( chunk ) <TAB> <TAB> record = logging . makeLogRecord ( obj ) <TAB> <TAB> self . log_output + = record . msg + "" \n "" <TAB> <TAB> self . handled . release ( )",if not chunk :,if len ( chunk ) < 4 :,False,96.3,71.96,,,
"def on_source_foreach ( self , model , path , iter , id ) : <TAB> m_id = model . get_value ( iter , self . COLUMN_ID ) <TAB> if m_id == id : <TAB> <TAB> if self . _foreach_mode == "" get "" : <TAB> <TAB> <TAB> self . _foreach_take = model . get_value ( iter , self . COLUMN_ENABLED ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _foreach_take = iter","elif self . _foreach_mode == ""set"" :","elif self . _foreach_mode == ""set"" :",True,100.0,74.17,,,
"def parts ( ) : <TAB> for l in lists . leaves : <TAB> <TAB> head_name = l . get_head_name ( ) <TAB> <TAB> if head_name == "" System`List "" : <TAB> <TAB> <TAB> yield l . leaves <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l )","elif head_name == ""System`List"" :","elif head_name != ""System`Missing"" :",False,95.12,71.14,,,
"def __fill_counter_values ( self , command : str ) : <TAB> result = [ ] <TAB> regex = r "" (item[0-9]+ \ .counter_value) "" <TAB> for token in re . split ( regex , command ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> result . append ( str ( self . simulator_config . item_dict [ token ] . value ) ) <TAB> <TAB> <TAB> except ( KeyError , ValueError , AttributeError ) : <TAB> <TAB> <TAB> <TAB> logger . error ( "" Could not get counter value for  "" + token ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( token ) <TAB> return "" "" . join ( result )",if token in self . simulator_config . item_dict :,"if re . match ( regex , token ) is not None :",False,94.03,69.68,,,
"def IMPORTFROM ( self , node ) : <TAB> <IF-STMT> <TAB> <TAB> if not self . futuresAllowed : <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> if alias . name == "" * "" : <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation )",if self . scope :,"if node . module == ""__future__"" :",False,88.74,65.07,,,
"def _split_batch_list ( args , batch_list ) : <TAB> new_list = [ ] <TAB> for batch in batch_list . batches : <TAB> <TAB> new_list . append ( batch ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield batch_pb2 . BatchList ( batches = new_list ) <TAB> <TAB> <TAB> new_list = [ ] <TAB> if new_list : <TAB> <TAB> yield batch_pb2 . BatchList ( batches = new_list )",if len ( new_list ) == 1 :,if len ( new_list ) == args . batch_size_limit :,False,93.67,71.21,,,
"def get_branch_or_use_upstream ( branch_name , arg , repo ) : <TAB> if not branch_name : # use upstream branch <TAB> <TAB> current_b = repo.current_branch <TAB> <TAB> upstream_b = current_b.upstream <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""No {0} branch specified and the current branch has no upstream "" <TAB> <TAB> <TAB> <TAB> ""branch set"".format(arg) <TAB> <TAB> <TAB> ) <TAB> <TAB> ret = current_b.upstream <TAB> else: <TAB> <TAB> ret = get_branch(branch_name, repo) <TAB> return ret",if not upstream_b :,if not upstream_b :,True,100.0,74.24,,,
"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB> <TAB> if name not in default_settings : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> self . __class__ . __name__ , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr ( self , name , value )","if isinstance ( value , ( dict , list ) ) :","if not hasattr ( self , name ) :",False,95.62,71.22,,,
"def _declare ( self , name , obj , included = False , quals = 0 ) : <TAB> if name in self . _declarations : <TAB> <TAB> prevobj , prevquals = self . _declarations [ name ] <TAB> <TAB> if prevobj is obj and prevquals == quals : <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise api . FFIError ( <TAB> <TAB> <TAB> <TAB> "" multiple declarations of  %s  (for interactive usage,  "" <TAB> <TAB> <TAB> <TAB> "" try cdef(xx, override=True)) "" % ( name , ) <TAB> <TAB> <TAB> ) <TAB> assert "" __dotdotdot__ "" not in name . split ( ) <TAB> self . _declarations [ name ] = ( obj , quals ) <TAB> if included : <TAB> <TAB> self . _included_declarations . add ( obj )",if name in self . _included_declarations :,if not self . _override :,False,96.38,72.57,,,
"def include_file ( name , fdir = tmp_dir , b64 = False ) : <TAB> try : <TAB> <TAB> if fdir is None : <TAB> <TAB> <TAB> fdir = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with io . open ( os . path . join ( fdir , name ) , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> return base64 . b64encode ( f . read ( ) ) . decode ( "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with io . open ( os . path . join ( fdir , name ) , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> <TAB> return f . read ( ) <TAB> except ( OSError , IOError ) as e : <TAB> <TAB> logger . error ( "" Could not include file  ' {} ' :  {} "" . format ( name , e ) )",if b64 :,if b64 :,True,100.0,74.63,,,
"def to_raw_json ( self ) : <TAB> parts = { } <TAB> for p in self . parts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts [ p [ 0 ] ] = [ ] <TAB> <TAB> parts [ p [ 0 ] ] . append ( { "" value "" : p [ 2 ] , "" parameters "" : p [ 1 ] } ) <TAB> children = [ x . to_raw_json ( ) for x in self . children ] <TAB> return { <TAB> <TAB> "" type "" : self . __class__ . __name__ , <TAB> <TAB> "" children "" : children , <TAB> <TAB> "" parts "" : parts , <TAB> }",if p [ 0 ] not in parts :,if p [ 0 ] not in parts :,True,100.0,74.49,,,
"def process_output ( <TAB> output : str , filename : str , start_line : int ) - > Tuple [ Optional [ str ] , bool ] : <TAB> error_found = False <TAB> for line in output . splitlines ( ) : <TAB> <TAB> t = get_revealed_type ( line , filename , start_line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return t , error_found <TAB> <TAB> elif "" error: "" in line : <TAB> <TAB> <TAB> error_found = True <TAB> return None , True # finding no reveal_type is an error",if t is not None :,if t :,False,96.9,72.77,,,
"def __init__ ( <TAB> self , resize_keyboard = None , one_time_keyboard = None , selective = None , row_width = 3 ) : <TAB> if row_width > self . max_row_keys : <TAB> <TAB> # Todo: Will be replaced with Exception in future releases <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""Telegram does not support reply keyboard row width over %d."" <TAB> <TAB> <TAB> <TAB> % self.max_row_keys <TAB> <TAB> <TAB> ) <TAB> <TAB> row_width = self.max_row_keys <TAB> self.resize_keyboard = resize_keyboard <TAB> self.one_time_keyboard = one_time_keyboard <TAB> self.selective = selective <TAB> self.row_width = row_width <TAB> self.keyboard = []",if resize_keyboard is not None and self . max_row_keys > self . max_row_keys :,if not DISABLE_KEYLEN_ERROR :,False,90.57,70.65,,,
"def realizeElementExpressions ( innerElement ) : <TAB> elementHasBeenRealized = False <TAB> for exp in innerElement . expressions : <TAB> <TAB> if not hasattr ( exp , "" realize "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> # else: <TAB> <TAB> before, during, after = exp.realize(innerElement) <TAB> <TAB> elementHasBeenRealized = True <TAB> <TAB> for n in before: <TAB> <TAB> <TAB> newStream.append(n) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newStream.append(during) <TAB> <TAB> for n in after: <TAB> <TAB> <TAB> newStream.append(n) <TAB> if elementHasBeenRealized is False: <TAB> <TAB> newStream.append(innerElement)",if elementHasBeenRealized is False :,if during is not None :,False,97.12,71.24,,,
"def lex_number ( self , pos ) : <TAB> # numeric literal <TAB> start = pos <TAB> found_dot = False <TAB> while pos < len(self.string) and ( <TAB> <TAB> self.string[pos].isdigit() or self.string[pos] == ""."" <TAB> ): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if found_dot is True: <TAB> <TAB> <TAB> <TAB> raise ValueError(""Invalid number. Found multiple '.'"") <TAB> <TAB> <TAB> found_dot = True <TAB> <TAB> # technically we allow more than one ""."" and let float()'s parsing <TAB> <TAB> # complain later <TAB> <TAB> pos += 1 <TAB> val = self.string[start:pos] <TAB> return Token(TokenType.LNUM, val, len(val))","if self . string [ pos ] == ""."" :","if self . string [ pos ] == ""."" :",True,100.0,74.41,,,
"def rename ( src , dst ) : <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename(src, dst): <TAB> <TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try: <TAB> <TAB> os.rename(src, dst) <TAB> except OSError as e: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> old = ""%s-%08x"" % (dst, random.randint(0, sys.maxsize)) <TAB> <TAB> os.rename(dst, old) <TAB> <TAB> os.rename(src, dst) <TAB> <TAB> try: <TAB> <TAB> <TAB> os.unlink(old) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass",if e . errno != errno . EEXIST :,if e . errno != errno . EEXIST :,True,100.0,74.31,,,
"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB> <TAB> if num > 1 : <TAB> <TAB> <TAB> args = [ point , index ] <TAB> <TAB> else : <TAB> <TAB> <TAB> args = [ point ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . append ( widget ) <TAB> <TAB> try_callback ( callback , * args ) <TAB> return",if event_id == widget . IDGET_EVENT :,if pass_widget :,False,92.62,71.76,,,
"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB> <TAB> error = True <TAB> <TAB> try : <TAB> <TAB> <TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> if self . expect_exception : <TAB> <TAB> <TAB> assert error",if self . expect_exception :,if not self . expect_exception :,False,98.15,72.54,,,
"def handle ( self , * args : Any , * * options : Any ) - > None : <TAB> realm = self . get_realm ( options ) <TAB> if options [ "" all "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> <TAB> "" You must specify a realm if you choose the --all option. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> self . fix_all_users ( realm ) <TAB> <TAB> return <TAB> self . fix_emails ( realm , options [ "" emails "" ] )",if not realm :,if realm is None :,False,97.01,71.81,,,
"def recv_tdi ( self , nbits , pos ) : <TAB> bits = 0 <TAB> for n in range ( nbits * 2 ) : <TAB> <TAB> yield from self . _wait_for_tck ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bits = ( bits << 1 ) | ( yield self . tdi . o ) <TAB> return bits",if self . tdi . o != 0 :,if ( yield self . tck . o ) == pos :,False,88.88,66.83,,,
"def _split_head ( self ) : <TAB> if not hasattr ( self , "" _severed_head "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tree = self . _tree . copy ( ) <TAB> <TAB> <TAB> head = tree . get_heading_text ( ) <TAB> <TAB> <TAB> tree . remove_heading ( ) <TAB> <TAB> <TAB> self . _severed_head = ( head , tree ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _severed_head = ( None , None ) <TAB> return self . _severed_head",if self . _tree :,if self . _tree :,True,100.0,74.29,,,
"def buildSearchTrie ( self , choices ) : <TAB> searchtrie = trie . Trie ( ) <TAB> for choice in choices : <TAB> <TAB> for token in self . tokenizeChoice ( choice ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> searchtrie [ token ] = [ ] <TAB> <TAB> <TAB> searchtrie [ token ] . append ( choice ) <TAB> return searchtrie",if token not in searchtrie :,if not searchtrie . has_key ( token ) :,False,90.39,68.8,,,
"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter(params) <TAB> <TAB> if params: <TAB> <TAB> <TAB> sql = sql_to_string(sql) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv.params <TAB> <TAB> else: <TAB> <TAB> <TAB> params = () <TAB> for param in params or (): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rv.append(""NULL"") <TAB> <TAB> param = safe_repr(param) <TAB> <TAB> rv.append(param) <TAB> return sql, rv",if param is None :,if param is None :,True,100.0,74.41,,,
def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB> <TAB> if len ( ql ) > 0 : <TAB> <TAB> <TAB> observer . on_next ( False ) <TAB> <TAB> <TAB> observer . on_completed ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> observer . on_next ( True ) <TAB> <TAB> <TAB> observer . on_completed ( ),elif len ( ql ) > 0 :,elif donel [ 0 ] :,False,93.7,92.74,,,
"def notify_digest ( self , frequency , changes ) : <TAB> notifications = defaultdict ( list ) <TAB> users = { } <TAB> for change in changes : <TAB> <TAB> for user in self . get_users ( frequency , change ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> notifications [ user . pk ] . append ( change ) <TAB> <TAB> <TAB> <TAB> users [ user . pk ] = user <TAB> for user in users . values ( ) : <TAB> <TAB> self . send_digest ( <TAB> <TAB> <TAB> user . profile . language , <TAB> <TAB> <TAB> user . email , <TAB> <TAB> <TAB> notifications [ user . pk ] , <TAB> <TAB> <TAB> subscription = user . current_subscription , <TAB> <TAB> )",if user . email not in notifications [ user . pk ] :,if change . project is None or user . can_access_project ( change . project ) :,False,91.49,69.14,,,
"def _any_listener_using ( self , target_group_arn ) : <TAB> for load_balancer in self . load_balancers . values ( ) : <TAB> <TAB> for listener in load_balancer . listeners . values ( ) : <TAB> <TAB> <TAB> for rule in listener . rules : <TAB> <TAB> <TAB> <TAB> for action in rule . actions : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if action . target_group_arn == target_group_arn :,"if action . data . get ( ""target_group_arn"" ) == target_group_arn :",False,93.27,61.5,,,
"def train_dict ( self , triples ) : <TAB> """""" Train a dict lemmatizer given training (word, pos, lemma) triples. """""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB> <TAB> w, pos, l = p <TAB> <TAB> if (w, pos) not in self.composite_dict: <TAB> <TAB> <TAB> self.composite_dict[(w, pos)] = l <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.word_dict[w] = l <TAB> return","if ( w , pos ) not in self . word_dict :",if w not in self . word_dict :,False,96.88,72.03,,,
"def parse_git_config ( path ) : <TAB> """""" Parse git config file. """""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> config [ section ] = dict ( ) <TAB> <TAB> <TAB> elif section : <TAB> <TAB> <TAB> <TAB> key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB> <TAB> <TAB> <TAB> config [ section ] [ key ] = value <TAB> return config",if section is None :,"if line . startswith ( ""["" ) :",False,95.75,86.43,,,
"def send_signal ( self , pid , signum ) : <TAB> if pid in self . processes : <TAB> <TAB> process = self . processes [ pid ] <TAB> <TAB> hook_result = self . call_hook ( "" before_signal "" , pid = pid , signum = signum ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> "" before_signal hook didn ' t return True  "" <TAB> <TAB> <TAB> <TAB> "" => signal  %i  is not sent to  %i "" % ( signum , pid ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> process . send_signal ( signum ) <TAB> <TAB> self . call_hook ( "" after_signal "" , pid = pid , signum = signum ) <TAB> else : <TAB> <TAB> logger . debug ( "" process  %s  does not exist "" % pid )",if hook_result :,if signum != signal . SIGKILL and not hook_result :,False,95.96,71.64,,,
"def validate_pos_return ( self ) : <TAB> if self . is_pos and self . is_return : <TAB> <TAB> total_amount_in_payments = 0 <TAB> <TAB> for payment in self . payments : <TAB> <TAB> <TAB> total_amount_in_payments + = payment . amount <TAB> <TAB> invoice_total = self . rounded_total or self . grand_total <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Total payments amount can ' t be greater than  {} "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> - invoice_total <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if total_amount_in_payments > invoice_total :,if total_amount_in_payments < invoice_total :,False,98.74,73.15,,,
"def delete ( key , inner_key = None ) : <TAB> if inner_key is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> del cache [ key ] [ inner_key ] <TAB> <TAB> <TAB> del use_count [ key ] [ inner_key ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del cache [ key ] <TAB> <TAB> <TAB> <TAB> del use_count [ key ] <TAB> <TAB> <TAB> wrapper . cache_size - = 1 <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return True <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> wrapper . cache_size - = len ( cache [ key ] ) <TAB> <TAB> <TAB> del cache [ key ] <TAB> <TAB> <TAB> del use_count [ key ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return True",if key in use_count :,if not cache [ key ] :,False,97.78,72.59,,,
"def insertionsort ( array ) : <TAB> size = array . getsize ( ) <TAB> array . reset ( "" Insertion sort "" ) <TAB> for i in range ( 1 , size ) : <TAB> <TAB> j = i - 1 <TAB> <TAB> while j > = 0 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> array . swap ( j , j + 1 ) <TAB> <TAB> <TAB> j = j - 1 <TAB> array . message ( "" Sorted "" )",if array . get ( j ) == 0 :,"if array . compare ( j , j + 1 ) <= 0 :",False,93.34,69.74,,,
"def publish_state ( cls , payload , state ) : <TAB> try : <TAB> <TAB> if isinstance ( payload , LiveActionDB ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cls . process ( payload ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> print ( payload )","if state == ""publish"" :",if state == action_constants . LIVEACTION_STATUS_REQUESTED :,False,92.13,63.05,,,
"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB> <TAB> if type ( submob ) == AnnularSector : <TAB> <TAB> <TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self.opacity_function(r) <TAB> <TAB> submob.set_fill(opacity=alpha)",if submob . shadow :,if type ( submob ) != AnnularSector :,False,95.59,71.31,,,
"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """""" Check the warning is suppressed or not. """""" <TAB> if type is None : <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target , subtarget = warning_type , None <TAB> <TAB> if target == type : <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == "" * "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if ""."" in warning_type :","if ""."" in warning_type :",True,100.0,99.6,,,
"def set_many ( self , mapping , timeout = None ) : <TAB> timeout = self . _normalize_timeout ( timeout ) <TAB> # Use transaction=False to batch without calling redis MULTI <TAB> # which is not supported by twemproxy <TAB> pipe = self._client.pipeline(transaction=False) <TAB> for key, value in _items(mapping): <TAB> <TAB> dump = self.dump_object(value) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pipe.set(name=self.key_prefix + key, value=dump) <TAB> <TAB> else: <TAB> <TAB> <TAB> pipe.setex(name=self.key_prefix + key, value=dump, time=timeout) <TAB> return pipe.execute()",if timeout is None :,if timeout == - 1 :,False,97.02,71.58,,,
"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB> <TAB> return path # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB> <TAB> prevdir = dir <TAB> <TAB> dir, name = os.path.split(prevdir) <TAB> <TAB> if dir == prevdir or not dir: <TAB> <TAB> <TAB> return path # failed to make it relative <TAB> <TAB> names.append(name) <TAB> <TAB> try: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> names.reverse() <TAB> <TAB> <TAB> <TAB> return os.path.join(*names) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass","if name . startswith ( ""/"" ) :","if samefile ( dir , os . curdir ) :",False,96.15,62.34,,,
"def word_range ( word ) : <TAB> for ind in range ( len ( word ) ) : <TAB> <TAB> temp = word [ ind ] <TAB> <TAB> for c in [ chr ( x ) for x in range ( ord ( "" a "" ) , ord ( "" z "" ) + 1 ) ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield word [ : ind ] + c + word [ ind + 1 : ]",if c in temp :,if c != temp :,False,96.88,72.86,,,
"def validate ( self ) : <TAB> self . update_soil_edit ( "" sand_composition "" ) <TAB> for soil_type in self . soil_types : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" {0}  should be a value between 0 and 100 "" ) . format ( soil_type ) ) <TAB> if sum ( self . get ( soil_type ) for soil_type in self . soil_types ) != 100 : <TAB> <TAB> frappe . throw ( _ ( "" Soil compositions do not add up to 100 "" ) )","if not isinstance ( self . get ( soil_type ) , int ) :",if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 :,False,89.88,68.27,,,
"def on_click ( self , event ) : <TAB> run = self . _is_running ( ) <TAB> if event [ "" button "" ] == self . button_activate : <TAB> <TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -activate "" ] ) <TAB> if event [ "" button "" ] == self . button_toggle : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -exit "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Because we want xscreensaver to continue running after <TAB> <TAB> <TAB> # exit, we instead use preexec_fn=setpgrp here. <TAB> <TAB> <TAB> Popen( <TAB> <TAB> <TAB> <TAB> [""xscreensaver"", ""-no-splash"", ""-no-capture-stderr""], <TAB> <TAB> <TAB> <TAB> stdout=PIPE, <TAB> <TAB> <TAB> <TAB> stderr=PIPE, <TAB> <TAB> <TAB> <TAB> preexec_fn=setpgrp, <TAB> <TAB> <TAB> )",if run :,if run :,True,100.0,74.53,,,
"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB> <TAB> return path # already relative <TAB> dir = path <TAB> names = [] <TAB> while True: <TAB> <TAB> prevdir = dir <TAB> <TAB> dir, name = os.path.split(prevdir) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return path # failed to make it relative <TAB> <TAB> names.append(name) <TAB> <TAB> try: <TAB> <TAB> <TAB> if samefile(dir, os.curdir): <TAB> <TAB> <TAB> <TAB> names.reverse() <TAB> <TAB> <TAB> <TAB> return os.path.join(*names) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> pass",if name in names :,if dir == prevdir or not dir :,False,95.91,70.36,,,
"def _format_micros ( self , datestring ) : <TAB> parts = datestring [ : - 1 ] . split ( "" . "" ) <TAB> if len ( parts ) == 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return datestring [ : - 1 ] + "" .000000Z "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return datestring + "" .000000Z "" <TAB> else : <TAB> <TAB> micros = parts [ - 1 ] [ : 6 ] if len ( parts [ - 1 ] ) > 6 else parts [ - 1 ] <TAB> <TAB> return "" . "" . join ( parts [ : - 1 ] + [ "" {:06d} "" . format ( int ( micros ) ) ] ) + "" Z ""","if parts [ - 1 ] . endswith ( "".000000Z"" ) :","if datestring . endswith ( ""Z"" ) :",False,94.59,72.04,,,
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if line [ 0 ] == "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" )",if len ( line ) > 1 :,"if line != "" "" and line != """" :",False,95.0,64.53,,,
"def set ( self , item , data ) : <TAB> if not type ( item ) is slice : <TAB> <TAB> item = slice ( item , item + len ( data ) , None ) <TAB> virt_item = self . item2virtitem ( item ) <TAB> if not virt_item : <TAB> <TAB> return <TAB> off = 0 <TAB> for s , n_item in virt_item : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> i = slice ( off , n_item . stop + off - n_item . start , n_item . step ) <TAB> <TAB> <TAB> data_slice = data . __getitem__ ( i ) <TAB> <TAB> <TAB> s . content . __setitem__ ( n_item , data_slice ) <TAB> <TAB> <TAB> off = i . stop <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" TODO XXX "" ) <TAB> return",if n_item . step :,"if isinstance ( s , ProgBits ) :",False,96.77,72.1,,,
"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part.get_content_maintype() == ""multipart"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part.get_content_type() <TAB> <TAB> if ctype is None: <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part.get_filename() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = PART_FN_TPL % (partnum) <TAB> <TAB> headers = dict(part) <TAB> <TAB> LOG.debug(headers) <TAB> <TAB> headers[""Content-Type""] = ctype <TAB> <TAB> payload = util.fully_decoded_payload(part) <TAB> <TAB> callback(data, filename, payload, headers) <TAB> <TAB> partnum = partnum + 1",if filename is None :,if not filename :,False,98.24,72.52,,,
"def _run_wes ( args ) : <TAB> """""" Run CWL using a Workflow Execution Service (WES) endpoint """""" <TAB> main_file , json_file , project_name = _get_main_and_json ( args . directory ) <TAB> main_file = _pack_cwl ( main_file ) <TAB> if args . host and "" stratus "" in args . host : <TAB> <TAB> _run_wes_stratus ( args , main_file , json_file ) <TAB> else : <TAB> <TAB> opts = [ "" --no-wait "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> opts + = [ "" --host "" , args . host ] <TAB> <TAB> if args . auth : <TAB> <TAB> <TAB> opts + = [ "" --auth "" , args . auth ] <TAB> <TAB> cmd = [ "" wes-client "" ] + opts + [ main_file , json_file ] <TAB> <TAB> _run_tool ( cmd )",if args . host :,if args . host :,True,100.0,99.54,,,
"def insertTestData ( self , rows ) : <TAB> for row in rows : <TAB> <TAB> if isinstance ( row , Worker ) : <TAB> <TAB> <TAB> self . workers [ row . id ] = dict ( <TAB> <TAB> <TAB> <TAB> id = row . id , name = row . name , paused = 0 , graceful = 0 , info = row . info <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> row . id = row . buildermasterid * 10000 + row . workerid <TAB> <TAB> <TAB> self . configured [ row . id ] = dict ( <TAB> <TAB> <TAB> <TAB> buildermasterid = row . buildermasterid , workerid = row . workerid <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance ( row , ConnectedWorker ) : <TAB> <TAB> <TAB> self . connected [ row . id ] = dict ( masterid = row . masterid , workerid = row . workerid )","elif isinstance ( row , Builder ) :","elif isinstance ( row , ConfiguredWorker ) :",False,98.91,73.85,,,
"def local_shape_to_shape_i ( node ) : <TAB> if node . op == T . shape : <TAB> <TAB> # This optimization needs ShapeOpt and fgraph.shape_feature <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> shape_feature = node.fgraph.shape_feature <TAB> <TAB> ret = shape_feature.make_vector_shape(node.inputs[0]) <TAB> <TAB> # We need to copy over stack trace from input to output <TAB> <TAB> copy_stack_trace(node.outputs[0], ret) <TAB> <TAB> return [ret]",if node . fgraph . shape_feature is None :,"if not hasattr ( node . fgraph , ""shape_feature"" ) :",False,92.96,59.6,,,
"def get_config ( ) : <TAB> """""" Get INI parser with version.ini data. """""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""version.ini"") <TAB> <IF-STMT> <TAB> <TAB> ini_path = os.path.join(THIS_DIRECTORY, ""../../version.ini"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError(""Couldn't find version.ini"") <TAB> config = configparser.ConfigParser() <TAB> config.read(ini_path) <TAB> return config",if not os . path . exists ( ini_path ) :,if not os . path . exists ( ini_path ) :,True,100.0,74.2,,,
"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB> <TAB> logger = logging . getLogger ( ) <TAB> <TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB> <TAB> for m in self . modules ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <TAB> elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) : <TAB> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> else : <TAB> <TAB> raise TypeError ( "" pretrained must be a str or None "" )","if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Conv2d ) :",True,100.0,74.52,,,
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value )",if valid_value == value :,"if value == ""DD-MM-YYYY"" :",False,97.24,66.3,,,
"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB> <TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> box_keys = [ ] <TAB> <TAB> if hasattr ( py_obj , "" masks "" ) and py_obj . masks : <TAB> <TAB> <TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask_keys = [ ] <TAB> <TAB> return cls ( box_keys , mask_keys )","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :","if hasattr ( py_obj , ""_boxes"" ) and py_obj . _boxes :",True,100.0,74.5,,,
"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB> <TAB> if stat . S_ISREG ( st . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" file "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts . append ( "" dir "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB> <TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" link "" ) <TAB> return "" "" . join ( parts )",elif stat . S_ISDIR ( st . st_mode ) :,elif stat . S_ISDIR ( st . st_mode ) :,True,100.0,74.44,,,
"def is_destructive ( queries ) : <TAB> """""" Returns if any of the queries in *queries* is destructive. """""" <TAB> keywords = ( "" drop "" , "" shutdown "" , "" delete "" , "" truncate "" , "" alter "" ) <TAB> for query in sqlparse . split ( queries ) : <TAB> <TAB> if query : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif query_starts_with ( <TAB> <TAB> <TAB> <TAB> query , [ "" update "" ] <TAB> <TAB> <TAB> ) is True and not query_has_where_clause ( query ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if query in keywords :,"if query_starts_with ( query , keywords ) is True :",False,93.56,93.0,,,
"def _store_gsuite_membership_post ( self ) : <TAB> """""" Flush storing gsuite memberships. """""" <TAB> if not self . member_cache : <TAB> <TAB> return <TAB> self . session . flush ( ) <TAB> # session.execute automatically flushes <TAB> if self.membership_items: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # SQLite doesn't support bulk insert <TAB> <TAB> <TAB> for item in self.membership_items: <TAB> <TAB> <TAB> <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(item) <TAB> <TAB> <TAB> <TAB> self.session.execute(stmt) <TAB> <TAB> else: <TAB> <TAB> <TAB> stmt = self.dao.TBL_MEMBERSHIP.insert(self.membership_items) <TAB> <TAB> <TAB> self.session.execute(stmt)","if self . db_type == ""sqlite"" :","if get_sql_dialect ( self . session ) == ""sqlite"" :",False,95.34,95.69,,,
"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB> <TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB> <TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB> <TAB> outputs . append ( block_out ) <TAB> <TAB> if i < 2 : <TAB> <TAB> <TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB> <TAB> <TAB> route = self . upsample ( route ) <TAB> return outputs",if i < 1 :,if i > 0 :,False,98.21,73.27,,,
"def deep_dict ( self , root = None ) : <TAB> if root is None : <TAB> <TAB> root = self <TAB> result = { } <TAB> for key , value in root . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ key ] = self . deep_dict ( root = self . __class__ . _get_next ( key , root ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = value <TAB> return result","if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",True,100.0,74.31,,,
"def deep_dict ( self , root = None ) : <TAB> if root is None : <TAB> <TAB> root = self <TAB> result = { } <TAB> for key , value in root . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ key ] = self . deep_dict ( root = self . __class__ . _get_next ( key , root ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = value <TAB> return result","if isinstance ( value , dict ) :","if "" : "" in header :",False,94.24,61.93,,,
"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if groups is not None : <TAB> <TAB> <TAB> <TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB> <TAB> <TAB> for v in _ungroup ( v , groups ) : <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else : <TAB> <TAB> <TAB> yield v","if isinstance ( v , ( list , tuple ) ) :","if isinstance ( v , ( list , tuple ) ) :",True,100.0,74.32,,,
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB> <TAB> <TAB> <TAB> if obj [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] )",if item_key in resource_group_cache :,"if item_key != ""sourceVault"" :",False,96.95,69.46,,,
"def haslayer ( self , cls ) : <TAB> """""" true if self has a layer that is an instance of cls. Superseded by  "" cls in self ""  syntax. """""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB> <TAB> return 1 <TAB> for f in self . packetfields : <TAB> <TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB> <TAB> if fvalue_gen is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f . islist : <TAB> <TAB> <TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB> <TAB> for fvalue in fvalue_gen : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret = fvalue . haslayer ( cls ) <TAB> <TAB> <TAB> <TAB> if ret : <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self . payload . haslayer ( cls )","if hasattr ( fvalue , ""haslayer"" ) :","if isinstance ( fvalue , Packet ) :",False,97.31,69.7,,,
"def _post_attachment ( self , message , channel , color , sub_fields = None ) : <TAB> if channel is None : <TAB> <TAB> message_channels = self . channels <TAB> else : <TAB> <TAB> message_channels = [ channel ] <TAB> for message_channel in message_channels : <TAB> <TAB> attachment = { <TAB> <TAB> <TAB> "" fallback "" : message , <TAB> <TAB> <TAB> "" text "" : message , <TAB> <TAB> <TAB> "" color "" : color , <TAB> <TAB> } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attachment [ "" fields "" ] = sub_fields <TAB> <TAB> self . slack_client . api_call ( <TAB> <TAB> <TAB> "" chat.postMessage "" , <TAB> <TAB> <TAB> channel = message_channel , <TAB> <TAB> <TAB> attachments = [ attachment ] , <TAB> <TAB> <TAB> as_user = True , <TAB> <TAB> )",if sub_fields :,if sub_fields is not None :,False,98.18,72.58,,,
"def create ( cls , repository , args ) : <TAB> key = cls ( ) <TAB> passphrase = os . environ . get ( "" ATTIC_PASSPHRASE "" ) <TAB> if passphrase is not None : <TAB> <TAB> passphrase2 = passphrase <TAB> else : <TAB> <TAB> passphrase , passphrase2 = 1 , 2 <TAB> while passphrase != passphrase2 : <TAB> <TAB> passphrase = getpass ( "" Enter passphrase:  "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" Passphrase must not be blank "" ) <TAB> <TAB> <TAB> continue <TAB> <TAB> passphrase2 = getpass ( "" Enter same passphrase again:  "" ) <TAB> <TAB> if passphrase != passphrase2 : <TAB> <TAB> <TAB> print ( "" Passphrases do not match "" ) <TAB> key . init ( repository , passphrase ) <TAB> if passphrase : <TAB> <TAB> print ( "" Remember your passphrase. Your data will be inaccessible without it. "" ) <TAB> return key",if not passphrase :,if not passphrase :,True,100.0,74.61,,,
"def _generate_create_date ( self ) : <TAB> if self . timezone is not None : <TAB> <TAB> # First, assume correct capitalization <TAB> <TAB> tzinfo = tz.gettz(self.timezone) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Fall back to uppercase <TAB> <TAB> <TAB> tzinfo = tz.gettz(self.timezone.upper()) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise util.CommandError(""Can't locate timezone: %s"" % self.timezone) <TAB> <TAB> create_date = ( <TAB> <TAB> <TAB> datetime.datetime.utcnow().replace(tzinfo=tz.tzutc()).astimezone(tzinfo) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> create_date = datetime.datetime.now() <TAB> return create_date",if not tzinfo :,if tzinfo is None :,False,96.0,68.75,,,
"def _read_header_lines ( fp ) : <TAB> """""" Read lines with headers until the start of body """""" <TAB> lines = deque ( ) <TAB> for line in fp : <TAB> <TAB> if is_empty ( line ) : <TAB> <TAB> <TAB> break <TAB> <TAB> # tricky case if it's not a header and not an empty line <TAB> <TAB> # usually means that user forgot to separate the body and newlines <TAB> <TAB> # so ""unread"" this line here, what means to treat it like a body <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fp.seek(fp.tell() - len(line)) <TAB> <TAB> <TAB> break <TAB> <TAB> lines.append(line) <TAB> return lines","if line . startswith ( ""HTTP/1.1"" ) and line . endswith ( ""HTTP/1.1"" ) :",if not _RE_HEADER . match ( line ) :,False,89.99,95.23,,,
"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB> <TAB> try : <TAB> <TAB> <TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> uri , unused = uri_tuple <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if utils . is_media_file ( uri ) == True : <TAB> <TAB> <TAB> <TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB> <TAB> return <TAB> open_dropped_files ( files )",if uri :,if os . path . exists ( uri ) == True :,False,93.89,69.77,,,
"def remove_importlib ( frame , options ) : <TAB> if frame is None : <TAB> <TAB> return None <TAB> for child in frame . children : <TAB> <TAB> remove_importlib ( child , options = options ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # remove this node, moving the self_time and children up to the parent <TAB> <TAB> <TAB> frame.self_time += child.self_time <TAB> <TAB> <TAB> frame.add_children(child.children, after=child) <TAB> <TAB> <TAB> child.remove_from_parent() <TAB> return frame",if child . is_parent ( ) :,"if ""<frozen importlib._bootstrap"" in child . file_path :",False,91.12,61.58,,,
"def __call__ ( self , graph ) : <TAB> for layer_name , data in self . params : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> node = graph . get_node ( layer_name ) <TAB> <TAB> <TAB> node . data = self . adjust_parameters ( node , data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print_stderr ( "" Ignoring parameters for non-existent layer:  %s "" % layer_name ) <TAB> return graph",if self . is_node_valid ( layer_name ) :,if layer_name in graph :,False,90.7,70.17,,,
"def test_with_three_points ( self ) : <TAB> cba = ia . Polygon ( [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 5 ) ] ) <TAB> for i , xy in enumerate ( cba ) : <TAB> <TAB> assert i in [ 0 , 1 , 2 ] <TAB> <TAB> if i == 0 : <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 1 , 2 ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 3 , 4 ) ) <TAB> <TAB> elif i == 2 : <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 5 , 5 ) ) <TAB> assert i == 2",elif i == 1 :,elif i == 1 :,True,100.0,74.52,,,
"def _serve ( self ) : <TAB> self . _conn = self . manager . request ( REQUEST_DNS_LISTENER , self . domain ) <TAB> conn = MsgPackMessages ( self . _conn ) <TAB> while self . active : <TAB> <TAB> request = conn . recv ( ) <TAB> <TAB> if not request : <TAB> <TAB> <TAB> logger . warning ( "" DNS: Recieved empty request. Shutdown "" ) <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> now = time . time ( ) <TAB> <TAB> response = self . handler . process ( request ) <TAB> <TAB> if not response : <TAB> <TAB> <TAB> response = [ ] <TAB> <TAB> used = time . time ( ) - now <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( "" DNS: Slow processing speed ( %s )s "" , used ) <TAB> <TAB> conn . send ( response )",if used > self . speed :,if used > 1 :,False,98.12,73.5,,,
"def read ( cls , fp , * * kwargs ) : <TAB> major_version , minor_version , count = read_fmt ( "" 2HI "" , fp ) <TAB> items = [ ] <TAB> for _ in range ( count ) : <TAB> <TAB> length = read_fmt ( "" I "" , fp ) [ 0 ] - 4 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with io . BytesIO ( fp . read ( length ) ) as f : <TAB> <TAB> <TAB> <TAB> items . append ( Annotation . read ( f ) ) <TAB> return cls ( major_version = major_version , minor_version = minor_version , items = items )",if length > 0 :,if length > 0 :,True,100.0,74.44,,,
"def save_uploaded_files ( ) : <TAB> files = [ ] <TAB> unzip = bool ( request . form . get ( "" unzip "" ) in [ "" true "" , "" on "" ] ) <TAB> for uploaded_file in request . files . getlist ( "" files "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with zipfile . ZipFile ( uploaded_file , "" r "" ) as zf : <TAB> <TAB> <TAB> <TAB> for info in zf . infolist ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> name = info . filename <TAB> <TAB> <TAB> <TAB> <TAB> size = info . file_size <TAB> <TAB> <TAB> <TAB> <TAB> data = zf . read ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> if size > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> files . append ( save_file ( data , filename = name . split ( "" / "" ) [ - 1 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> files . append ( save_file ( uploaded_file ) ) <TAB> return files",if unzip :,if unzip and zipfile . is_zipfile ( uploaded_file ) :,False,95.66,72.29,,,
"def analyze_string_content ( self , string , line_num , filename ) : <TAB> output = { } <TAB> if self . keyword_exclude and self . keyword_exclude . search ( string ) : <TAB> <TAB> return output <TAB> for identifier in self . secret_generator ( <TAB> <TAB> string , <TAB> <TAB> filetype = determine_file_type ( filename ) , <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> secret = PotentialSecret ( <TAB> <TAB> <TAB> self . secret_type , <TAB> <TAB> <TAB> filename , <TAB> <TAB> <TAB> identifier , <TAB> <TAB> <TAB> line_num , <TAB> <TAB> ) <TAB> <TAB> output [ secret ] = secret <TAB> return output",if identifier in self . keywords :,if self . is_secret_false_positive ( identifier ) :,False,93.96,71.67,,,
"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """""" Placeholder docstring """""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB> <TAB> if name not in self.hyperparam_dict: <TAB> <TAB> <TAB> spec = definition[""spec""] <TAB> <TAB> <TAB> if ""DefaultValue"" in spec: <TAB> <TAB> <TAB> <TAB> self.hyperparam_dict[name] = spec[""DefaultValue""] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError(""Required hyperparameter: %s is not set"" % name)",if name not in self . hyperparam_definitions :,"elif ""IsRequired"" in spec and spec [ ""IsRequired"" ] :",False,92.81,68.68,,,
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> if mod_type == imp . PY_SOURCE : <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> elif mod_type == imp . PY_COMPILED : <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",if self . _get_delegate :,elif mod_type == imp . PKG_DIRECTORY :,False,95.51,72.22,,,
"def eigh_abstract_eval ( operand , lower ) : <TAB> if isinstance ( operand , ShapedArray ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Argument to symmetric eigendecomposition must have shape [..., n, n], "" <TAB> <TAB> <TAB> <TAB> "" got shape  {} "" . format ( operand . shape ) <TAB> <TAB> <TAB> ) <TAB> <TAB> batch_dims = operand . shape [ : - 2 ] <TAB> <TAB> n = operand . shape [ - 1 ] <TAB> <TAB> v = ShapedArray ( batch_dims + ( n , n ) , operand . dtype ) <TAB> <TAB> w = ShapedArray ( batch_dims + ( n , ) , lax . lax . _complex_basetype ( operand . dtype ) ) <TAB> else : <TAB> <TAB> v , w = operand , operand <TAB> return v , w",if lower != operand . shape :,if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] :,False,91.64,68.44,,,
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> if dsn [ i ] . isspace ( ) : <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> if i > = length : <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret",if param_match is None :,if not param_match :,False,97.95,73.21,,,
"def load_weights_from_unsupervised ( self , unsupervised_model ) : <TAB> update_state_dict = copy . deepcopy ( self . network . state_dict ( ) ) <TAB> for param , weights in unsupervised_model . network . state_dict ( ) . items ( ) : <TAB> <TAB> if param . startswith ( "" encoder "" ) : <TAB> <TAB> <TAB> # Convert encoder's layers name to match <TAB> <TAB> <TAB> new_param = ""tabnet."" + param <TAB> <TAB> else: <TAB> <TAB> <TAB> new_param = param <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # update only common layers <TAB> <TAB> <TAB> update_state_dict[new_param] = weights <TAB> self.network.load_state_dict(update_state_dict)",if new_param in self . common_layers :,if self . network . state_dict ( ) . get ( new_param ) is not None :,False,91.55,67.25,,,
"def viewer_setup ( self ) : <TAB> for key , value in DEFAULT_CAMERA_CONFIG . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> getattr ( self . viewer . cam , key ) [ : ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( self . viewer . cam , key , value )","if isinstance ( value , list ) :","if isinstance ( value , np . ndarray ) :",False,95.18,70.73,,,
"def colormap_changed ( change ) : <TAB> if change [ "" new "" ] : <TAB> <TAB> cmap_colors = [ <TAB> <TAB> <TAB> color [ 1 : ] for color in cmap . step . __dict__ [ "" _schemes "" ] [ colormap . value ] <TAB> <TAB> ] <TAB> <TAB> palette . value = "" ,  "" . join ( cmap_colors ) <TAB> <TAB> colorbar = getattr ( cmap . step , colormap . value ) <TAB> <TAB> colorbar_output = self . colorbar_widget <TAB> <TAB> with colorbar_output : <TAB> <TAB> <TAB> colorbar_output . clear_output ( ) <TAB> <TAB> <TAB> display ( colorbar ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> labels = [ f "" Class  { i + 1 } "" for i in range ( len ( palette . value . split ( "" , "" ) ) ) ] <TAB> <TAB> <TAB> legend_labels . value = "" ,  "" . join ( labels )","if change [ ""new"" ] :","if len ( palette . value ) > 0 and "","" in palette . value :",False,93.29,69.94,,,
"def invalidate ( self , layers = None ) : <TAB> if layers is None : <TAB> <TAB> layers = Layer . AllLayers <TAB> if layers : <TAB> <TAB> layers = set ( layers ) <TAB> <TAB> self . invalidLayers . update ( layers ) <TAB> <TAB> blockRenderers = [ <TAB> <TAB> <TAB> br <TAB> <TAB> <TAB> for br in self . blockRenderers <TAB> <TAB> <TAB> if br . layer is Layer . Blocks or br . layer not in layers <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . forgetDisplayLists ( ) <TAB> <TAB> self . blockRenderers = blockRenderers <TAB> <TAB> if self . renderer . showRedraw and Layer . Blocks in layers : <TAB> <TAB> <TAB> self . needsRedisplay = True",if blockRenderers :,if len ( blockRenderers ) < len ( self . blockRenderers ) :,False,93.83,70.18,,,
"def fromstring ( cls , input ) : <TAB> productions = [ ] <TAB> for linenum , line in enumerate ( input . split ( "" \n "" ) ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> productions + = _read_dependency_production ( line ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" Unable to parse line  %s :  %s "" % ( linenum , line ) ) <TAB> if len ( productions ) == 0 : <TAB> <TAB> raise ValueError ( "" No productions found! "" ) <TAB> return DependencyGrammar ( productions )",if not line :,"if line . startswith ( ""#"" ) or line == """" :",False,91.52,50.2,,,
"def repl ( m , base_path , rel_path = None ) : <TAB> if m . group ( "" comments "" ) : <TAB> <TAB> tag = m . group ( "" comments "" ) <TAB> else : <TAB> <TAB> tag = m . group ( "" open "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB> <TAB> <TAB> <TAB> lambda m2 : repl_absolute ( m2 , base_path ) , m . group ( "" attr "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB> <TAB> <TAB> <TAB> lambda m2 : repl_relative ( m2 , base_path , rel_path ) , m . group ( "" attr "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> tag + = m . group ( "" close "" ) <TAB> return tag",if rel_path is None :,if rel_path is None :,True,100.0,74.58,,,
"def encode ( path ) : <TAB> if isinstance ( path , str_cls ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> path = path . encode ( fs_encoding , "" strict "" ) <TAB> <TAB> except UnicodeEncodeError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> path = path . encode ( fs_fallback_encoding , "" strict "" ) <TAB> return path",if not fs_fallback_encoding :,if not platform . is_linux ( ) :,False,93.08,69.79,,,
"def __iter__ ( self ) : <TAB> base_iterator = super ( ProcessIterable , self ) . __iter__ ( ) <TAB> if getattr ( self . queryset , "" _coerced "" , False ) : <TAB> <TAB> for process in base_iterator : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> process = coerce_to_related_instance ( <TAB> <TAB> <TAB> <TAB> <TAB> process , process . flow_class . process_class <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield process <TAB> else : <TAB> <TAB> for process in base_iterator : <TAB> <TAB> <TAB> yield process","if isinstance ( process , Process ) :","if isinstance ( process , self . queryset . model ) :",False,96.43,71.25,,,
"def footnotes_under ( n : Element ) - > Iterator [ nodes . footnote ] : <TAB> if isinstance ( n , nodes . footnote ) : <TAB> <TAB> yield n <TAB> else : <TAB> <TAB> for c in n . children : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif isinstance ( c , nodes . Element ) : <TAB> <TAB> <TAB> <TAB> yield from footnotes_under ( c )","if isinstance ( c , nodes . footnote ) :","if isinstance ( c , addnodes . start_of_file ) :",False,93.65,71.77,,,
"def _process_submissions ( self ) - > None : <TAB> """""" Process all submissions which have not been processed yet. """""" <TAB> while self . _to_be_processed : <TAB> <TAB> job = self . _to_be_processed [ 0 ] <TAB> <TAB> job . process ( ) # trigger computation <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> heapq.heappush( <TAB> <TAB> <TAB> <TAB> self._steady_priority_queue, <TAB> <TAB> <TAB> <TAB> OrderedJobs(job.release_time, self._order, job), <TAB> <TAB> <TAB> ) <TAB> <TAB> self._to_be_processed.popleft() # remove right after it is added to the heap queue <TAB> <TAB> self._order += 1",if job . release_time > self . _last_release_time :,if not self . batch_mode :,False,93.13,95.87,,,
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",if not match :,if match :,False,98.72,98.41,,,
"def _get_payload_hash ( self , method , data = None ) : <TAB> if method in ( "" POST "" , "" PUT "" ) : <TAB> <TAB> if data : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # File upload; don't try to read the entire payload <TAB> <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> <TAB> <TAB> return _hash(data) <TAB> <TAB> else: <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> else: <TAB> <TAB> return _hash("""")",if self . _upload_file ( data ) :,"if hasattr ( data , ""next"" ) or hasattr ( data , ""__next__"" ) :",False,87.55,63.48,,,
"def get_download_info ( self ) : <TAB> try : <TAB> <TAB> download_info = self . api . get_download_info ( self . game ) <TAB> <TAB> result = True <TAB> except NoDownloadLinkFound as e : <TAB> <TAB> print ( e ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> Config . unset ( "" current_download "" ) <TAB> <TAB> GLib . idle_add ( <TAB> <TAB> <TAB> self . parent . parent . show_error , <TAB> <TAB> <TAB> _ ( "" Download error "" ) , <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> "" There was an error when trying to fetch the download link! \n {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> e <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> download_info = False <TAB> <TAB> result = False <TAB> return result , download_info",if e . response . status == 404 :,"if Config . get ( ""current_download"" ) == self . game . id :",False,93.72,65.55,,,
"def find_id ( self , doc_id ) : <TAB> self . _lock . acquire ( ) <TAB> try : <TAB> <TAB> doc = self . _docs . get ( doc_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> doc = copy . deepcopy ( doc ) <TAB> <TAB> <TAB> doc [ "" id "" ] = doc_id <TAB> <TAB> <TAB> return doc <TAB> finally : <TAB> <TAB> self . _lock . release ( )",if doc :,if doc :,True,100.0,74.15,,,
"def assign_art ( self , session , task ) : <TAB> """""" Place the discovered art in the filesystem. """""" <TAB> if task in self . art_candidates : <TAB> <TAB> candidate = self . art_candidates . pop ( task ) <TAB> <TAB> self . _set_art ( task . album , candidate , not self . src_removed ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> task . prune ( candidate . path )",if candidate . path :,if self . src_removed :,False,94.48,71.33,,,
"def _replace_named ( self , named , replace_scalar ) : <TAB> for item in named : <TAB> <TAB> for name , value in self . _get_replaced_named ( item , replace_scalar ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise DataError ( "" Argument names must be strings. "" ) <TAB> <TAB> <TAB> yield name , value","if not isinstance ( name , str ) :",if not is_string ( name ) :,False,94.4,70.39,,,
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr(val, ""__len__""): <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB> if len(val) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res","if '""' in value :","if Driver . needsQuoting ( val , True ) :",False,96.06,64.8,,,
"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled ( n ) <TAB> <TAB> if has_unknown_shape ( tiled_n ) : <TAB> <TAB> <TAB> if any ( c . key not in chunk_result for c in tiled_n . chunks ) : <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB> <TAB> <TAB> for node in (n, tiled_n): <TAB> <TAB> <TAB> <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB> <TAB> <TAB> tiled_n._nsplits = new_nsplits",if n . _ops != failed_ops :,if n . op in failed_ops :,False,97.9,72.83,,,
"def _read_filter ( self , data ) : <TAB> if data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . inner_sha . update ( data ) <TAB> <TAB> if self . expected_inner_md5sum : <TAB> <TAB> <TAB> self . inner_md5 . update ( data ) <TAB> return data",if self . expected_inner_shasum :,if self . expected_inner_sha256 :,False,97.15,71.31,,,
"def find_previous_editable ( self , * args ) : <TAB> if self . editw == 0 : <TAB> <TAB> if self . _active_page > 0 : <TAB> <TAB> <TAB> self . switch_page ( self . _active_page - 1 ) <TAB> if not self . editw == 0 : <TAB> <TAB> # remember that xrange does not return the 'last' value, <TAB> <TAB> # so go to -1, not 0! (fence post error in reverse) <TAB> <TAB> for n in range(self.editw - 1, -1, -1): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.editw = n <TAB> <TAB> <TAB> <TAB> break",if self . xrange ( n ) == 0 :,if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden :,False,88.18,67.13,,,
"def _get_event_for_message ( self , message_id ) : <TAB> with self . event_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Event for message[ {} ] should have been created before accessing "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> message_id <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _events [ message_id ]",if message_id not in self . _events :,if message_id not in self . _events :,True,100.0,74.17,,,
"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB> <TAB> if len ( t ) == 1 : <TAB> <TAB> <TAB> return t [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> for part in t : <TAB> <TAB> <TAB> <TAB> res = self . _get_deepest ( part ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None",if res is not None :,if res :,False,96.9,72.45,,,
"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> elif self . _chain_notify : <TAB> <TAB> <TAB> return self . _chain_notify <TAB> return None",if action_node . notify :,if action_node . notify :,True,100.0,74.02,,,
"def __init__ ( self , centered = None , shape_params = ( ) ) : <TAB> assert centered is None or isinstance ( centered , ( float , torch . Tensor ) ) <TAB> assert isinstance ( shape_params , ( tuple , list ) ) <TAB> assert all ( isinstance ( name , str ) for name in shape_params ) <TAB> if is_validation_enabled ( ) : <TAB> <TAB> if isinstance ( centered , float ) : <TAB> <TAB> <TAB> assert 0 < = centered and centered < = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert ( 0 < = centered ) . all ( ) <TAB> <TAB> <TAB> assert ( centered < = 1 ) . all ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert centered is None <TAB> self . centered = centered <TAB> self . shape_params = shape_params","elif isinstance ( centered , tuple ) :","elif isinstance ( centered , torch . Tensor ) :",False,97.92,73.16,,,
"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB> <TAB> squid_host = self . squid_hosts [ nickname ] <TAB> <TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB> <TAB> if fulldata is not None : <TAB> <TAB> <TAB> fulldata = fulldata . splitlines ( ) <TAB> <TAB> <TAB> for data in fulldata : <TAB> <TAB> <TAB> <TAB> matches = self . stat_pattern . match ( data ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . publish_counter ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> )",if matches :,if matches :,True,100.0,74.56,,,
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 7 :,elif size <= 9 :,False,98.87,73.7,,,
"def wait_for_initial_conf ( self , timeout = 1.0 ) : <TAB> logger . info ( "" Waiting for initial configuration "" ) <TAB> cur_timeout = timeout <TAB> # Arbiter do not already set our have_conf param <TAB> while not self.new_conf and not self.interrupted: <TAB> <TAB> elapsed, _, _ = self.handleRequests(cur_timeout) <TAB> <TAB> if elapsed: <TAB> <TAB> <TAB> cur_timeout -= elapsed <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> cur_timeout = timeout <TAB> <TAB> sys.stdout.write(""."") <TAB> <TAB> sys.stdout.flush()",if cur_timeout <= 0 :,if cur_timeout > 0 :,False,98.09,72.82,,,
"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB> <TAB> self . querylist = [ ] <TAB> else : <TAB> <TAB> self . querylist = querylist <TAB> <TAB> for query in self . querylist : <TAB> <TAB> <TAB> if self . query_id == - 1 : <TAB> <TAB> <TAB> <TAB> self . query_id = query . query_id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" query in list must be same query_id "" )",if query . query_id != self . query_id :,if self . query_id != query . query_id :,False,98.34,72.78,,,
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> if matchSelf : <TAB> <TAB> <TAB> yield s <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> if s . siblingAbove is None : <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",elif recurseAnon :,if recurseInAnon :,False,98.62,73.44,,,
"def get_default_params ( problem_type : str , penalty : str ) : <TAB> # TODO: get seed from seeds provider <TAB> if problem_type == REGRESSION: <TAB> <TAB> default_params = {""C"": None, ""random_state"": 0, ""fit_intercept"": True} <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> default_params[""solver""] = ""auto"" <TAB> else: <TAB> <TAB> default_params = { <TAB> <TAB> <TAB> ""C"": None, <TAB> <TAB> <TAB> ""random_state"": 0, <TAB> <TAB> <TAB> ""solver"": _get_solver(problem_type), <TAB> <TAB> <TAB> ""n_jobs"": -1, <TAB> <TAB> <TAB> ""fit_intercept"": True, <TAB> <TAB> } <TAB> model_params = list(default_params.keys()) <TAB> return model_params, default_params","if penalty == ""auto"" :",if penalty == L2 :,False,98.17,70.14,,,
"def _UploadDirectory ( local_dir : str , gcs_bucket : storage . Bucket , gcs_dir : str ) : <TAB> """""" Upload the contents of a local directory to a GCS Bucket. """""" <TAB> for file_name in os . listdir ( local_dir ) : <TAB> <TAB> path = os . path . join ( local_dir , file_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . info ( "" Skipping  %s  as it ' s not a file. "" , path ) <TAB> <TAB> <TAB> continue <TAB> <TAB> logging . info ( "" Uploading:  %s "" , path ) <TAB> <TAB> gcs_blob = gcs_bucket . blob ( f "" { gcs_dir } / { file_name } "" ) <TAB> <TAB> gcs_blob . upload_from_filename ( path )",if not os . path . isfile ( path ) :,if not os . path . isfile ( path ) :,True,100.0,99.53,,,
"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB> <TAB> self . decode_query_ids ( trans , conditional . left ) <TAB> <TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB> <TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB> <TAB> if left_base in self . FIELDS : <TAB> <TAB> <TAB> field = self . FIELDS [ left_base ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> conditional . right = trans . security . decode_id ( conditional . right )","if field . get ( ""type"" ) == ""id"" :",if field . id_decode :,False,93.17,65.41,,,
"def data_dir ( self ) - > Path : <TAB> try : <TAB> <TAB> from appdirs import user_data_dir <TAB> except ImportError : <TAB> <TAB> # linux <TAB> <TAB> path = Path.home() / "".local"" / ""share"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return path / ""dephell"" <TAB> <TAB> # mac os <TAB> <TAB> path = Path.home() / ""Library"" / ""Application Support"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return path / ""dephell"" <TAB> <TAB> self.pip_main([""install"", ""appdirs""]) <TAB> <TAB> from appdirs import user_data_dir <TAB> return Path(user_data_dir(""dephell""))",if path . exists ( ) :,if path . exists ( ) :,True,100.0,74.36,,,
"def setGameCard ( self , isGameCard = False ) : <TAB> if isGameCard : <TAB> <TAB> targetValue = 1 <TAB> else : <TAB> <TAB> targetValue = 0 <TAB> for nca in self : <TAB> <TAB> if isinstance ( nca , Nca ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> Print . info ( "" writing isGameCard for  %s ,  %d "" % ( str ( nca . _path ) , targetValue ) ) <TAB> <TAB> <TAB> nca . header . setIsGameCard ( targetValue )",if nca . header . isGameCard ( ) :,if nca . header . getIsGameCard ( ) == targetValue :,False,95.37,71.53,,,
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","elif s . startswith ( ""APNS-Key"" ) and ""ENCRYPTED"" in s :","elif mode == ""key"" :",False,94.63,70.46,,,
"def register_aggregate_groups ( conn , * groups ) : <TAB> seen = set ( ) <TAB> for group in groups : <TAB> <TAB> klasses = AGGREGATE_COLLECTION [ group ] <TAB> <TAB> for klass in klasses : <TAB> <TAB> <TAB> name = getattr ( klass , "" name "" , klass . __name__ ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> seen . add ( name ) <TAB> <TAB> <TAB> <TAB> conn . create_aggregate ( name , - 1 , klass )",if name not in seen :,if name not in seen :,True,100.0,74.28,,,
"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 : # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> if isinstance(inputs[1], int): <TAB> <TAB> <TAB> axis = int(inputs[1]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> axis = inputs[1] <TAB> <TAB> else: <TAB> <TAB> <TAB> axis = list(_infer_shape(inputs[1])) <TAB> <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)","elif isinstance ( inputs [ 1 ] , list ) :",elif _is_int_seq ( inputs [ 1 ] ) :,False,95.41,71.42,,,
"def walks_generator ( ) : <TAB> if filelist is not None : <TAB> <TAB> bucket = [ ] <TAB> <TAB> for filename in filelist : <TAB> <TAB> <TAB> with io . open ( filename ) as inf : <TAB> <TAB> <TAB> <TAB> for line in inf : <TAB> <TAB> <TAB> <TAB> <TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB> <TAB> <TAB> <TAB> <TAB> bucket . append ( walk ) <TAB> <TAB> <TAB> <TAB> <TAB> if len ( bucket ) == batch_size : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield bucket <TAB> else : <TAB> <TAB> for _ in range ( epoch ) : <TAB> <TAB> <TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB> <TAB> <TAB> <TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB> <TAB> <TAB> <TAB> yield walks",if epoch == 0 :,if len ( bucket ) :,False,98.22,73.16,,,
"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> if resultset[""result""]: <TAB> <TAB> <TAB> <TAB> results[""num_passed_states""] += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results[""num_failed_states""] += 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results","if state == ""passed"" :","if isinstance ( resultset , dict ) and ""duration"" in resultset :",False,94.26,68.73,,,
"def _replicator_primary_device ( ) - > snt_replicator . Replicator : <TAB> # NOTE: The explicit device list is required since currently Replicator <TAB> # only considers CPU and GPU devices. This means on TPU by default we only <TAB> # mirror on the local CPU. <TAB> for device_type in (""TPU"", ""GPU"", ""CPU""): <TAB> <TAB> devices = tf.config.experimental.list_logical_devices(device_type=device_type) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> devices = [d.name for d in devices] <TAB> <TAB> <TAB> logging.info(""Replicating over %s"", devices) <TAB> <TAB> <TAB> return snt_replicator.Replicator(devices=devices) <TAB> assert False, ""No TPU/GPU or CPU found""",if devices :,if devices :,True,100.0,74.34,,,
"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB> <TAB> return [ ] <TAB> if not http . headers : <TAB> <TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB> <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse(value) <TAB> <TAB> if not ua: <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self.get_tag_from_ua(ua) <TAB> <TAB> if result: <TAB> <TAB> <TAB> output.append(result) <TAB> return output","if key . startswith ( ""HTTP_"" ) :","if key != ""User-Agent"" :",False,96.09,72.4,,,
"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB> <TAB> if not value : <TAB> <TAB> <TAB> return None <TAB> <TAB> el <IF-STMT> <TAB> <TAB> <TAB> return quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value","if metadata . get ( ""commands"" ) [ 0 ] :","if not metadata . get ( ""nargs"" ) :",False,91.02,68.56,,,
"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB> <TAB> # take action <TAB> <TAB> if self.action_input.selected_index == 0: # Cancel <TAB> <TAB> <TAB> self.back_to_parent() <TAB> <TAB> elif self.action_input.selected_index == 1: # Apply <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> client.core.get_config().addCallback(self._update_preferences) <TAB> <TAB> <IF-STMT> # OK <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> self.back_to_parent()","elif c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] :",elif self . action_input . selected_index == 2 :,False,92.96,68.57,,,
def logic ( ) : <TAB> if reset == 1 : <TAB> <TAB> lfsr . next = 1 <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # lfsr.next[24:1] = lfsr[23:0] <TAB> <TAB> <TAB> lfsr.next = lfsr << 1 <TAB> <TAB> <TAB> lfsr.next[0] = lfsr[23] ^ lfsr[22] ^ lfsr[21] ^ lfsr[16],if reset == 2 :,if enable :,False,95.3,93.3,,,
"def action_delete ( self , request , attachments ) : <TAB> deleted_attachments = [ ] <TAB> desynced_posts = [ ] <TAB> for attachment in attachments : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> deleted_attachments . append ( attachment . pk ) <TAB> <TAB> <TAB> desynced_posts . append ( attachment . post_id ) <TAB> if desynced_posts : <TAB> <TAB> with transaction . atomic ( ) : <TAB> <TAB> <TAB> for post in Post . objects . filter ( id__in = desynced_posts ) : <TAB> <TAB> <TAB> <TAB> self . delete_from_cache ( post , deleted_attachments ) <TAB> for attachment in attachments : <TAB> <TAB> attachment . delete ( ) <TAB> message = _ ( "" Selected attachments have been deleted. "" ) <TAB> messages . success ( request , message )",if attachment . is_deleted ( ) :,if attachment . post :,False,96.94,73.21,,,
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> if index < 0 or index > = len ( self . features ) : <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> if feature : <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]","if isinstance ( index , Indexer ) :","elif isinstance ( index , slice ) :",False,98.24,73.23,,,
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self . _pos == start : <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> if stop is not None and self . _pos > stop : <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( )",if self . _pos >= len ( chunk ) :,if self . _pos < start :,False,96.71,72.84,,,
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if ""qemu86"" in root or ""qemu86"" in root :","if ""meta-environment"" in root or ""cross-canadian"" in root :",False,97.12,72.25,,,
"def _load_windows_store_certs ( self , storename , purpose ) : <TAB> certs = bytearray ( ) <TAB> try : <TAB> <TAB> for cert , encoding , trust in enum_certificates ( storename ) : <TAB> <TAB> <TAB> # CA certs are never PKCS#7 encoded <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if trust is True or purpose.oid in trust: <TAB> <TAB> <TAB> <TAB> <TAB> certs.extend(cert) <TAB> except PermissionError: <TAB> <TAB> warnings.warn(""unable to enumerate Windows certificate store"") <TAB> if certs: <TAB> <TAB> self.load_verify_locations(cadata=certs) <TAB> return certs",if len ( cert ) == 7 :,"if encoding == ""x509_asn"" :",False,95.22,64.38,,,
"def test_tokenizer_identifier_with_correct_config ( self ) : <TAB> for tokenizer_class in [ BertTokenizer , BertTokenizerFast , AutoTokenizer ] : <TAB> <TAB> tokenizer = tokenizer_class . from_pretrained ( "" wietsedv/bert-base-dutch-cased "" ) <TAB> <TAB> self . assertIsInstance ( tokenizer , ( BertTokenizer , BertTokenizerFast ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( tokenizer . basic_tokenizer . do_lower_case , False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( tokenizer . do_lower_case , False ) <TAB> <TAB> self . assertEqual ( tokenizer . model_max_length , 512 )",if tokenizer . basic_tokenizer :,"if isinstance ( tokenizer , BertTokenizer ) :",False,95.53,70.7,,,
"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB> <TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB> <TAB> if path_id is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> self . lock . acquire ( ) <TAB> <TAB> self . modules [ path_id ] = module <TAB> <TAB> self . lock . release ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB> <TAB> <TAB> self . _relations [ path_id ] = [ ] <TAB> <TAB> <TAB> for package in resolution : <TAB> <TAB> <TAB> <TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB> <TAB> <TAB> self . queue_send . put ( ( path_id , module , False , resolution ) )",if path_id not in self . _relations :,if resolve :,False,95.94,72.95,,,
"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB> <TAB> for base in bases : <TAB> <TAB> <TAB> if hasattr ( base , "" trace "" ) : <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile : <TAB> <TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB> <TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB> <TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs )","if hasattr ( base , ""garbage"" ) :","if hasattr ( base , ""garbage"" ) :",True,100.0,74.55,,,
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_owner_ : <TAB> <TAB> res + = prefix + ( "" owner:  %s \n "" % self . DebugFormatString ( self . owner_ ) ) <TAB> cnt = 0 <TAB> for e in self . entries_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" entries %s  < \n "" % elm ) <TAB> <TAB> res + = e . __str__ ( prefix + "" "" , printElemNumber ) <TAB> <TAB> res + = prefix + "" > \n "" <TAB> <TAB> cnt + = 1 <TAB> return res",if printElemNumber :,if printElemNumber :,True,100.0,74.52,,,
"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB> <TAB> if escaped : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> <TAB> elif c == "" \\ "" : <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" "" . join ( buf ) <TAB> <TAB> else : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) )","elif c == ""\n"" :","elif c == "">"" :",False,97.81,68.77,,,
"def get_batches ( train_nodes , train_labels , batch_size = 64 , shuffle = True ) : <TAB> if shuffle : <TAB> <TAB> random . shuffle ( train_nodes ) <TAB> total = train_nodes . shape [ 0 ] <TAB> for i in range ( 0 , total , batch_size ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cur_nodes = train_nodes [ i : i + batch_size ] <TAB> <TAB> <TAB> cur_labels = train_labels [ cur_nodes ] <TAB> <TAB> <TAB> yield cur_nodes , cur_labels",if i + batch_size < total :,if i + batch_size <= total :,False,98.35,72.86,,,
"def get_batches ( train_nodes , train_labels , batch_size = 64 , shuffle = True ) : <TAB> if shuffle : <TAB> <TAB> random . shuffle ( train_nodes ) <TAB> total = train_nodes . shape [ 0 ] <TAB> for i in range ( 0 , total , batch_size ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cur_nodes = train_nodes [ i : i + batch_size ] <TAB> <TAB> <TAB> cur_labels = train_labels [ cur_nodes ] <TAB> <TAB> <TAB> yield cur_nodes , cur_labels",if i + batch_size < total :,"if splitrow [ 0 ] == ""INFO:"" :",False,92.5,61.82,,,
"def _validate_client_public_key ( self , username , key_data ) : <TAB> """""" Validate a client public key for the specified user """""" <TAB> try : <TAB> <TAB> key = decode_ssh_public_key ( key_data ) <TAB> except KeyImportError : <TAB> <TAB> return None <TAB> options = None <TAB> if self . _client_keys : <TAB> <TAB> options = self . _client_keys . validate ( key , self . _peer_addr ) <TAB> if options is None : <TAB> <TAB> result = self . _owner . validate_public_key ( username , key ) <TAB> <TAB> if asyncio . iscoroutine ( result ) : <TAB> <TAB> <TAB> result = yield from result <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> options = { } <TAB> self . _key_options = options <TAB> return key",if result is None :,if not result :,False,98.1,83.56,,,
"def attach_related_versions ( addons , addon_dict = None ) : <TAB> if addon_dict is None : <TAB> <TAB> addon_dict = { addon . id : addon for addon in addons } <TAB> all_ids = set ( filter ( None , ( addon . _current_version_id for addon in addons ) ) ) <TAB> versions = list ( Version . objects . filter ( id__in = all_ids ) . order_by ( ) ) <TAB> for version in versions : <TAB> <TAB> try : <TAB> <TAB> <TAB> addon = addon_dict [ version . addon_id ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> log . info ( "" Version  %s  has an invalid add-on id. "" % version . id ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> addon . _current_version = version <TAB> <TAB> version . addon = addon",if not addon . _current_version :,if addon . _current_version_id == version . id :,False,95.76,72.02,,,
"def move_view ( obj , evt ) : <TAB> position = obj . GetCurrentCursorPosition ( ) <TAB> for other_axis , axis_number in self . _axis_names . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ipw3d = getattr ( self , "" ipw_3d_ %s "" % other_axis ) <TAB> <TAB> ipw3d . ipw . slice_position = position [ axis_number ]",if other_axis not in position :,if other_axis == axis_name :,False,94.21,71.16,,,
"def func_wrapper ( * args , * * kwargs ) : <TAB> warnings . simplefilter ( "" always "" , DeprecationWarning ) # turn off filter <TAB> for old, new in arg_mapping.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> f""Keyword argument '{old}' has been "" <TAB> <TAB> <TAB> <TAB> f""deprecated in favour of '{new}'. "" <TAB> <TAB> <TAB> <TAB> f""'{old}' will be removed in a future version."", <TAB> <TAB> <TAB> <TAB> category=DeprecationWarning, <TAB> <TAB> <TAB> <TAB> stacklevel=2, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> val = kwargs.pop(old) <TAB> <TAB> <TAB> kwargs[new] = val <TAB> # reset filter <TAB> warnings.simplefilter(""default"", DeprecationWarning) <TAB> return func(*args, **kwargs)",if old != new :,if old in kwargs :,False,98.22,72.71,,,
"def inner_connection_checker ( self , * args , * * kwargs ) : <TAB> LOG . debug ( "" in _connection_checker "" ) <TAB> for attempts in range ( 5 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( self , * args , * * kwargs ) <TAB> <TAB> except exception . VolumeBackendAPIException as e : <TAB> <TAB> <TAB> pattern = re . compile ( r "" .*Session id expired$ "" ) <TAB> <TAB> <TAB> matches = pattern . match ( six . text_type ( e ) ) <TAB> <TAB> <TAB> if matches : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> LOG . debug ( "" Session might have expired. "" ""  Trying to relogin "" ) <TAB> <TAB> <TAB> <TAB> <TAB> self . _login ( ) <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> LOG . error ( "" Re-throwing Exception  %s "" , e ) <TAB> <TAB> <TAB> raise",if len ( matches ) == 0 :,if attempts < 4 :,False,96.81,72.81,,,
"def set ( self , pcount ) : <TAB> """""" Set channel prefetch_count setting. """""" <TAB> if pcount != self . prev : <TAB> <TAB> new_value = pcount <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" QoS: Disabled: prefetch_count exceeds  %r "" , PREFETCH_COUNT_MAX <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> new_value = 0 <TAB> <TAB> logger . debug ( "" basic.qos: prefetch_count-> %s "" , new_value ) <TAB> <TAB> self . callback ( prefetch_count = new_value ) <TAB> <TAB> self . prev = pcount <TAB> return pcount",if new_value > PREFETCH_COUNT_MAX :,if pcount > PREFETCH_COUNT_MAX :,False,97.62,80.42,,,
"def _build_gcs_object_key ( self , key ) : <TAB> if self . platform_specific_separator : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gcs_object_key = os . path . join ( <TAB> <TAB> <TAB> <TAB> self . prefix , self . _convert_key_to_filepath ( key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gcs_object_key = "" / "" . join ( ( self . prefix , self . _convert_key_to_filepath ( key ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> return gcs_object_key",if self . prefix :,if self . prefix :,True,100.0,74.46,,,
"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> if hasattr ( a , name ) : <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> if hasattr ( a , name ) : <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . unop_test ( a , res , expr , name )",if name not in skip :,if name not in skip :,True,100.0,74.65,,,
def isCurveMonotonic ( set_ ) : <TAB> for i in range ( len ( set_ ) - 1 ) : <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # if set_[i][1] > set_[i + 1][1]: <TAB> <TAB> if set_[i][1] >= set_[i + 1][1]: <TAB> <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> <TAB> return False <TAB> return True,if set_ [ i ] [ 0 ] > set_ [ i + 1 ] [ 0 ] :,if set_ [ i ] [ 0 ] >= set_ [ i + 1 ] [ 0 ] :,False,98.86,98.22,,,
"def show_topics ( ) : <TAB> """""" prints all available miscellaneous help topics. """""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os . listdir ( pp ) <TAB> <TAB> for pn in content : <TAB> <TAB> <TAB> if "" . "" in pn : <TAB> <TAB> <TAB> <TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print ( name )",if not os . path . isdir ( pp ) :,if not os . path . isdir ( pp ) :,True,100.0,99.47,,,
"def test_send_error ( self ) : <TAB> allow_transfer_encoding_codes = ( 205 , 304 ) <TAB> for code in ( 101 , 102 , 204 , 205 , 304 ) : <TAB> <TAB> self . con . request ( "" SEND_ERROR "" , "" / {} "" . format ( code ) ) <TAB> <TAB> res = self . con . getresponse ( ) <TAB> <TAB> self . assertEqual ( code , res . status ) <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Content-Length "" ) ) <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Content-Type "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Transfer-Encoding "" ) ) <TAB> <TAB> data = res . read ( ) <TAB> <TAB> self . assertEqual ( b "" "" , data )",if res . status in allow_transfer_encoding_codes :,if code not in allow_transfer_encoding_codes :,False,97.92,73.19,,,
"def _length_hint ( obj ) : <TAB> """""" Returns the length hint of an object. """""" <TAB> try : <TAB> <TAB> return len ( obj ) <TAB> except ( AttributeError , TypeError ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> get_hint = type ( obj ) . __length_hint__ <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> return None <TAB> <TAB> try : <TAB> <TAB> <TAB> hint = get_hint ( obj ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> return None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return hint",if hint is None :,"if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 :",False,91.22,89.38,,,
"def _rmtree ( self , path ) : <TAB> # Essentially a stripped down version of shutil.rmtree. We can't <TAB> # use globals because they may be None'ed out at shutdown. <TAB> for name in self._listdir(path): <TAB> <TAB> fullname = self._path_join(path, name) <TAB> <TAB> try: <TAB> <TAB> <TAB> isdir = self._isdir(fullname) <TAB> <TAB> except self._os_error: <TAB> <TAB> <TAB> isdir = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._rmtree(fullname) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self._remove(fullname) <TAB> <TAB> <TAB> except self._os_error: <TAB> <TAB> <TAB> <TAB> pass <TAB> try: <TAB> <TAB> self._rmdir(path) <TAB> except self._os_error: <TAB> <TAB> pass",if isdir :,if isdir :,True,100.0,74.39,,,
"def get_sources ( self , sources = None ) : <TAB> """""" Returns all sources from this provider. """""" <TAB> self . _load ( ) <TAB> if sources is None : <TAB> <TAB> sources = list ( self . data . keys ( ) ) <TAB> elif not isinstance ( sources , ( list , tuple ) ) : <TAB> <TAB> sources = [ sources ] <TAB> for source in sources : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Invalid data key:  {} . Valid keys are:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> source , "" ,  "" . join ( str ( k ) for k in self . data ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return { k : self . data [ k ] for k in sources }",if not self . data . has_key ( source ) :,if source not in self . data :,False,95.47,80.45,,,
"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB> <TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB> <TAB> if short_has_arg ( opt , shortopts ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not args : <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB> <TAB> <TAB> <TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB> <TAB> <TAB> optarg , optstring = optstring , "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> optarg = "" "" <TAB> <TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args","if optstring == """" :","if optstring == """" :",True,100.0,99.64,,,
"def _sanitize_dict ( self , config_dict , allow_val_change = None , ignore_keys : set = None ) : <TAB> sanitized = { } <TAB> for k , v in six . iteritems ( config_dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> k , v = self . _sanitize ( k , v , allow_val_change ) <TAB> <TAB> sanitized [ k ] = v <TAB> return sanitized",if k in ignore_keys :,if ignore_keys and k in ignore_keys :,False,95.41,71.73,,,
def x ( data ) : <TAB> count = 0 <TAB> while count < 10 : <TAB> <TAB> data . start_example ( SOME_LABEL ) <TAB> <TAB> b = data . draw_bits ( 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> data . stop_example ( discard = not b ) <TAB> data . mark_interesting ( ),if b :,if b :,True,100.0,98.98,,,
"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB> <TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB> <TAB> prompt = "" (R/F)>  "" <TAB> <TAB> answer = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> answer = raw_input ( prompt ) <TAB> <TAB> except NameError : <TAB> <TAB> <TAB> answer = input ( prompt ) <TAB> <TAB> if answer . upper ( ) == "" F "" : <TAB> <TAB> <TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( "" Resuming previous scan "" ) <TAB> <TAB> <TAB> config . resume = True <TAB> return config . resume","if answer == ""R"" :","elif answer . upper ( ) == ""R"" :",False,97.17,72.41,,,
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> elif isinstance ( in_arrays , dict ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> if self . _progress_hook : <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results","if isinstance ( in_arrays , list ) :","if isinstance ( in_arrays , tuple ) :",False,98.9,73.52,,,
"def _send_until_done ( self , data ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . connection . send ( data ) <TAB> <TAB> except OpenSSL . SSL . WantWriteError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise timeout ( ) <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL . SSL . SysCallError as e : <TAB> <TAB> <TAB> raise SocketError ( str ( e ) )",if self . timeout is not None :,"if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) :",False,84.89,65.09,,,
"def _read_jtl_chunk ( self , jtl ) : <TAB> data = jtl . read ( 1024 * 1024 * 10 ) <TAB> if data : <TAB> <TAB> parts = data . rsplit ( "" \n "" , 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ready_chunk = self . buffer + parts [ 0 ] + "" \n "" <TAB> <TAB> <TAB> self . buffer = parts [ 1 ] <TAB> <TAB> <TAB> df = string_to_df ( ready_chunk ) <TAB> <TAB> <TAB> self . stat_queue . put ( df ) <TAB> <TAB> <TAB> return df <TAB> <TAB> else : <TAB> <TAB> <TAB> self . buffer + = parts [ 0 ] <TAB> else : <TAB> <TAB> if self . jmeter_finished : <TAB> <TAB> <TAB> self . agg_finished = True <TAB> <TAB> jtl . readline ( ) <TAB> return None",if len ( parts ) == 2 :,if len ( parts ) > 1 :,False,98.09,73.37,,,
"def __new__ ( mcl , classname , bases , dictionary ) : <TAB> slots = list ( dictionary . get ( "" __slots__ "" , [ ] ) ) <TAB> for getter_name in [ key for key in dictionary if key . startswith ( "" get_ "" ) ] : <TAB> <TAB> name = getter_name <TAB> <TAB> slots . append ( "" __ "" + name ) <TAB> <TAB> getter = dictionary . pop ( getter_name ) <TAB> <TAB> setter = dictionary . get ( setter_name , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del dictionary [ setter_name ] <TAB> <TAB> dictionary [ name ] = property ( getter . setter ) <TAB> <TAB> dictionary [ "" __slots__ "" ] = tuple ( slots ) <TAB> <TAB> return super ( ) . __new__ ( mcl , classname , bases , dictionary )",if getter is None or setter is None :,"if setter is not None and isinstance ( setter , collections . Callable ) :",False,93.99,70.15,,,
"def tex_coords ( self ) : <TAB> """""" Array of texture coordinate data. """""" <TAB> if "" multi_tex_coords "" not in self . domain . attribute_names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> domain = self . domain <TAB> <TAB> <TAB> attribute = domain . attribute_names [ "" tex_coords "" ] <TAB> <TAB> <TAB> self . _tex_coords_cache = attribute . get_region ( <TAB> <TAB> <TAB> <TAB> attribute . buffer , self . start , self . count <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _tex_coords_cache_version = domain . _version <TAB> <TAB> region = self . _tex_coords_cache <TAB> <TAB> region . invalidate ( ) <TAB> <TAB> return region . array <TAB> else : <TAB> <TAB> return None","if self . domain . _version < ""3.0"" :",if self . _tex_coords_cache_version != self . domain . _version :,False,94.15,77.75,,,
"def index ( self , sub , start = 0 ) : <TAB> """""" Returns the index of the closing bracket """""" <TAB> br = "" ([ { < "" [ "" )]}> "" . index ( sub ) ] <TAB> count = 0 <TAB> for i in range ( start , len ( self . string ) ) : <TAB> <TAB> char = self . string [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> elif char == sub : <TAB> <TAB> <TAB> if count > 0 : <TAB> <TAB> <TAB> <TAB> count - = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return i <TAB> err = "" Closing bracket  {!r}  missing in string  {!r} "" . format ( <TAB> <TAB> sub , "" "" . join ( self . original ) <TAB> ) <TAB> raise ParseError ( err )",if char == br :,if char == br :,True,100.0,99.59,,,
"def test_createFile ( self ) : <TAB> text = "" This is a test! "" <TAB> path = tempfile . mktemp ( ) <TAB> try : <TAB> <TAB> koDoc = self . _koDocFromPath ( path , load = False ) <TAB> <TAB> koDoc . buffer = text <TAB> <TAB> koDoc . save ( 0 ) <TAB> <TAB> del koDoc <TAB> <TAB> koDoc2 = self . _koDocFromPath ( path ) <TAB> <TAB> assert koDoc2 . buffer == text <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . unlink ( path ) # clean up",if os . path . exists ( path ) :,if os . path . exists ( path ) :,True,100.0,74.39,,,
"def __editScopeHasEdit ( self , attributeHistory ) : <TAB> with attributeHistory . context : <TAB> <TAB> tweak = GafferScene . EditScopeAlgo . acquireParameterEdit ( <TAB> <TAB> <TAB> attributeHistory . scene . node ( ) , <TAB> <TAB> <TAB> attributeHistory . context [ "" scene:path "" ] , <TAB> <TAB> <TAB> attributeHistory . attributeName , <TAB> <TAB> <TAB> IECoreScene . ShaderNetwork . Parameter ( "" "" , self . __parameter ) , <TAB> <TAB> <TAB> createIfNecessary = False , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> return tweak [ "" enabled "" ] . getValue ( )",if not tweak :,if tweak is None :,False,97.41,72.07,,,
"def mail_migrator ( app , schema_editor ) : <TAB> Event_SettingsStore = app . get_model ( "" pretixbase "" , "" Event_SettingsStore "" ) <TAB> for ss in Event_SettingsStore . objects . filter ( <TAB> <TAB> key__in = [ <TAB> <TAB> <TAB> "" mail_text_order_approved "" , <TAB> <TAB> <TAB> "" mail_text_order_placed "" , <TAB> <TAB> <TAB> "" mail_text_order_placed_require_approval "" , <TAB> <TAB> ] <TAB> ) : <TAB> <TAB> chgd = ss . value . replace ( "" {date} "" , "" {expire_date} "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ss . value = chgd <TAB> <TAB> <TAB> ss . save ( ) <TAB> <TAB> <TAB> cache . delete ( "" hierarkey_ {} _ {} "" . format ( "" event "" , ss . object_id ) )",if chgd . exists ( ) :,if chgd != ss . value :,False,97.38,72.53,,,
"def __get_limits ( self ) : <TAB> dimension = len ( self . __tree . get_root ( ) . data ) <TAB> nodes = self . __get_all_nodes ( ) <TAB> max , min = [ float ( "" -inf "" ) ] * dimension , [ float ( "" +inf "" ) ] * dimension <TAB> for node in nodes : <TAB> <TAB> for d in range ( dimension ) : <TAB> <TAB> <TAB> if max [ d ] < node . data [ d ] : <TAB> <TAB> <TAB> <TAB> max [ d ] = node . data [ d ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> min [ d ] = node . data [ d ] <TAB> return min , max",if min [ d ] > node . data [ d ] :,if min [ d ] > node . data [ d ] :,True,100.0,74.53,,,
"def get_complete_position ( self , context : UserContext ) - > int : <TAB> # Check member prefix pattern. <TAB> for prefix_pattern in convert2list( <TAB> <TAB> self.get_filetype_var(context[""filetype""], ""prefix_patterns"") <TAB> ): <TAB> <TAB> m = re.search(self._object_pattern + prefix_pattern + r""\w*$"", context[""input""]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self._prefix = re.sub(r""\w*$"", """", m.group(0)) <TAB> <TAB> m = re.search(r""\w*$"", context[""input""]) <TAB> <TAB> if m: <TAB> <TAB> <TAB> return m.start() <TAB> return -1",if not m :,"if m is None or prefix_pattern == """" :",False,94.43,65.03,,,
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> if curses : <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False",if colorama :,elif colorama :,False,99.0,73.64,,,
"def setLabelColumnWidth ( self , panel , width ) : <TAB> for child in panel . GetChildren ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size = child . GetSize ( ) <TAB> <TAB> <TAB> size [ 0 ] = width <TAB> <TAB> <TAB> child . SetBestSize ( size )",if child . GetStyle ( ) & wx . PX_LABEL_COLUMN_WIDTH_MASK :,"if isinstance ( child , wx . lib . stattext . GenStaticText ) :",False,81.55,64.74,,,
"def update ( self , other ) : <TAB> if other . M is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . items . update ( other . items ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for i in other . items : <TAB> <TAB> <TAB> <TAB> self . add ( i ) <TAB> <TAB> return <TAB> <IF-STMT> <TAB> <TAB> self . convert ( ) <TAB> self . M = array . array ( "" B "" , list ( map ( max , list ( zip ( self . M , other . M ) ) ) ) )",if self . M is None :,if self . M is None :,True,100.0,74.47,,,
"def on_end_epoch ( self , state ) : <TAB> if self . write_epoch_metrics : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . writer . add_text ( <TAB> <TAB> <TAB> <TAB> "" epoch "" , <TAB> <TAB> <TAB> <TAB> "" <h4>Epoch  {} </h4> "" . format ( state [ torchbearer . EPOCH ] ) <TAB> <TAB> <TAB> <TAB> + self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB> <TAB> <TAB> <TAB> 1 , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . writer . add_text ( <TAB> <TAB> <TAB> <TAB> "" epoch "" , <TAB> <TAB> <TAB> <TAB> self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB> <TAB> <TAB> <TAB> state [ torchbearer . EPOCH ] , <TAB> <TAB> <TAB> )",if self . epoch_metrics_enabled :,if self . visdom :,False,97.47,73.65,,,
"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """""" Check if the conversation is in need for a user message. """""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif e . get ( "" event "" ) == ActionExecuted . type_name : <TAB> <TAB> <TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False","if e . get ( ""event"" ) == ActionExecuted . type_user :","if e . get ( ""event"" ) == UserUttered . type_name :",False,97.13,72.72,,,
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret",if in_port :,if port . port_no == in_port :,False,95.72,71.81,,,
"def next_month ( billing_cycle_anchor : datetime , dt : datetime ) - > datetime : <TAB> estimated_months = round ( ( dt - billing_cycle_anchor ) . days * 12.0 / 365 ) <TAB> for months in range ( max ( estimated_months - 1 , 0 ) , estimated_months + 2 ) : <TAB> <TAB> proposed_next_month = add_months ( billing_cycle_anchor , months ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return proposed_next_month <TAB> raise AssertionError ( <TAB> <TAB> "" Something wrong in next_month calculation with  "" <TAB> <TAB> f "" billing_cycle_anchor:  { billing_cycle_anchor } , dt:  { dt } "" <TAB> )",if proposed_next_month is not None :,if 20 < ( proposed_next_month - dt ) . days < 40 :,False,92.98,69.04,,,
"def wait_complete ( self ) : <TAB> """""" Wait for futures complete done. """""" <TAB> for future in concurrent . futures . as_completed ( self . _futures . keys ( ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> error = future . exception ( ) <TAB> <TAB> except concurrent . futures . CancelledError : <TAB> <TAB> <TAB> break <TAB> <TAB> name = self . _futures [ future ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> err_msg = ' Extracting  "" {0} "" , got:  {1} ' . format ( name , error ) <TAB> <TAB> <TAB> logger . error ( err_msg )",if error :,if error is not None :,False,97.35,94.22,,,
"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB> <TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB> <TAB> if issubclass ( target , mapperlib . Mapper ) : <TAB> <TAB> <TAB> return target <TAB> <TAB> else : <TAB> <TAB> <TAB> mapper = _mapper_or_none ( target ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB> <TAB> return target",if mapper :,if mapper is not None :,False,97.32,71.74,,,
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """""" Convert args into gvariant. """""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> elif isinstance ( arg , ( int , float ) ) : <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> elif isinstance ( arg , str ) : <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( )","if isinstance ( arg , str ) :","if isinstance ( arg , bool ) :",False,98.7,98.61,,,
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> if isinstance ( test , unittest . TestSuite ) : <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if support . match_test ( test ) : <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) )","elif isinstance ( test , unittest . TestSuite ) :","elif isinstance ( test , unittest . TestCase ) :",False,97.54,72.15,,,
def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB> <TAB> if page . relations . disambiguation_links is not None : <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ),if page . relations . disambiguation_links_norm is not None :,if page . relations . disambiguation_links_norm is not None :,True,100.0,99.21,,,
"def test_decode_invalid ( self ) : <TAB> testcases = [ <TAB> <TAB> ( b "" xn--w& "" , "" strict "" , UnicodeError ( ) ) , <TAB> <TAB> ( b "" xn--w& "" , "" ignore "" , "" xn- "" ) , <TAB> ] <TAB> for puny , errors , expected in testcases : <TAB> <TAB> with self . subTest ( puny = puny , errors = errors ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertRaises ( UnicodeError , puny . decode , "" punycode "" , errors ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( puny . decode ( "" punycode "" , errors ) , expected )","if isinstance ( puny , UnicodeError ) :","if isinstance ( expected , Exception ) :",False,97.62,72.85,,,
"def find_globs ( walker , patterns , matches ) : <TAB> for root , dirs , files in walker : <TAB> <TAB> for d in dirs : <TAB> <TAB> <TAB> d = join ( root , d ) <TAB> <TAB> <TAB> for pattern in patterns : <TAB> <TAB> <TAB> <TAB> for p in Path ( d ) . glob ( pattern ) : <TAB> <TAB> <TAB> <TAB> <TAB> matches . add ( str ( p ) ) <TAB> <TAB> sub_files = set ( ) <TAB> <TAB> for p in matches : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> <TAB> <TAB> sub_files . add ( join ( root , f ) ) <TAB> <TAB> matches . update ( sub_files )","if p . endswith ( "".*"" ) :",if root . startswith ( p ) :,False,95.95,64.09,,,
"def parse_stack_trace ( self , it , line ) : <TAB> """""" Iterate over lines and parse stack traces. """""" <TAB> events = [ ] <TAB> stack_traces = [ ] <TAB> while self . stack_trace_re . match ( line ) : <TAB> <TAB> event = self . parse_stack_trace_line ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> events . append ( event ) <TAB> <TAB> stack_traces . append ( line ) <TAB> <TAB> line = get_next ( it ) <TAB> events . reverse ( ) <TAB> return stack_traces , events , line",if event is not None :,if event :,False,97.12,95.43,,,
"def process ( self ) : <TAB> """""" Do processing necessary, storing result in feature. """""" <TAB> summation = 0 # count of all <TAB> histo = self.data[""flat.notes.quarterLengthHistogram""] <TAB> if not histo: <TAB> <TAB> raise NativeFeatureException(""input lacks notes"") <TAB> maxKey = 0 # max found for any one key <TAB> for key in histo: <TAB> <TAB> # all defined keys should be greater than zero, but just in case <TAB> <TAB> if histo[key] > 0: <TAB> <TAB> <TAB> summation += histo[key] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> maxKey = histo[key] <TAB> self.feature.vector[0] = maxKey / summation",if histo [ key ] > maxKey :,if histo [ key ] >= maxKey :,False,98.71,98.23,,,
"def load_resource ( name ) : <TAB> """""" return file contents for files within the package root folder """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return sublime . load_resource ( "" Packages/Markdown Preview/ {0} "" . format ( name ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = os . path . join ( <TAB> <TAB> <TAB> <TAB> sublime . packages_path ( ) , INSTALLED_DIRECTORY , os . path . normpath ( name ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return load_utf8 ( filename ) <TAB> except : <TAB> <TAB> print ( "" Error while load_resource( ' %s ' ) "" % name ) <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> return "" ""","if name . endswith ( "".md"" ) :",if is_ST3 ( ) :,False,95.66,72.65,,,
"def get_password ( self , service , repo_url ) : <TAB> if self . is_unlocked : <TAB> <TAB> asyncio . set_event_loop ( asyncio . new_event_loop ( ) ) <TAB> <TAB> collection = secretstorage . get_default_collection ( self . connection ) <TAB> <TAB> attributes = { "" application "" : "" Vorta "" , "" service "" : service , "" repo_url "" : repo_url } <TAB> <TAB> items = list ( collection . search_items ( attributes ) ) <TAB> <TAB> logger . debug ( "" Found  %i  passwords matching repo URL. "" , len ( items ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return items [ 0 ] . get_secret ( ) . decode ( "" utf-8 "" ) <TAB> return None",if len ( items ) == 1 :,if len ( items ) > 0 :,False,97.64,73.15,,,
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> if fname == "" output "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res",if os . path . isdir ( p ) :,if os . path . isdir ( p ) :,True,100.0,74.53,,,
"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB> <TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if nic not in out : <TAB> <TAB> <TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic )","if nic == ""all"" :","if ""pseudo-interface"" in nic . replace ( "" "" , ""-"" ) . lower ( ) :",False,88.91,64.47,,,
"def vexop_to_simop ( op , extended = True , fp = True ) : <TAB> res = operations . get ( op ) <TAB> if res is None and extended : <TAB> <TAB> attrs = op_attrs ( op ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB> <TAB> res = SimIROp ( op , * * attrs ) <TAB> if res is None : <TAB> <TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB> if res . _float and not fp : <TAB> <TAB> raise UnsupportedIROpError ( "" Floating point support disabled "" ) <TAB> return res",if attrs is None :,if attrs is None :,True,100.0,74.48,,,
"def rule_builder_add_value ( self , value , screenshot_name = None ) : <TAB> rule_builder = self . components . rule_builder <TAB> rule_builder . menu_button_column . wait_for_and_click ( ) <TAB> with self . rule_builder_rule_editor ( "" add-column-value "" ) as editor_element : <TAB> <TAB> filter_input = editor_element . find_element_by_css_selector ( "" input[type= ' text ' ] "" ) <TAB> <TAB> filter_input . clear ( ) <TAB> <TAB> filter_input . send_keys ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . screenshot ( screenshot_name )",if screenshot_name :,if screenshot_name :,True,100.0,74.25,,,
"def make_open_socket ( self ) : <TAB> s = socket . socket ( ) <TAB> try : <TAB> <TAB> s . bind ( DEFAULT_BIND_ADDR_TUPLE ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Windows and linux (with psutil) doesn't show as open until <TAB> <TAB> <TAB> # we call listen (linux with lsof accepts either) <TAB> <TAB> <TAB> s.listen(1) <TAB> <TAB> self.assert_open(s, s.fileno()) <TAB> except: <TAB> <TAB> s.close() <TAB> <TAB> s = None <TAB> <TAB> raise <TAB> return s","if sys . platform == ""win32"" :",if WIN or greentest . LINUX :,False,94.6,62.08,,,
"def handle_ray_task_error ( e ) : <TAB> for s in e . traceback_str . split ( "" \n "" ) [ : : - 1 ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> raise getattr ( builtins , s . split ( "" : "" ) [ 0 ] ) ( "" "" . join ( s . split ( "" : "" ) [ 1 : ] ) ) <TAB> <TAB> <TAB> except AttributeError as att_err : <TAB> <TAB> <TAB> <TAB> if "" module "" in str ( att_err ) and builtins . __name__ in str ( att_err ) : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise att_err <TAB> raise e","if s . startswith ( ""ray"" ) :","if ""Error"" in s or ""Exception"" in s :",False,94.76,67.71,,,
"def compare_multiple_events ( i , expected_results , actual_results ) : <TAB> events_in_a_row = [ ] <TAB> j = i <TAB> while j < len ( expected_results ) and isinstance ( <TAB> <TAB> actual_results [ j ] , actual_results [ i ] . __class__ <TAB> ) : <TAB> <TAB> events_in_a_row . append ( actual_results [ j ] ) <TAB> <TAB> j + = 1 <TAB> message = "" "" <TAB> for event in events_in_a_row : <TAB> <TAB> for k in range ( i , j ) : <TAB> <TAB> <TAB> passed , message = compare_events ( expected_results [ k ] , event ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> expected_results [ k ] = None <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> return i , False , message <TAB> return j , True , "" """,if passed :,if passed :,True,100.0,74.57,,,
"def ListSubscriptions ( self , params ) : <TAB> queryreturn = sqlQuery ( """""" SELECT label, address, enabled FROM subscriptions """""" ) <TAB> data = ' { "" subscriptions "" :[ ' <TAB> for row in queryreturn : <TAB> <TAB> label , address , enabled = row <TAB> <TAB> label = shared . fixPotentiallyInvalidUTF8Data ( label ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data + = "" , "" <TAB> <TAB> data + = json . dumps ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" label "" : label . encode ( "" base64 "" ) , <TAB> <TAB> <TAB> <TAB> "" address "" : address , <TAB> <TAB> <TAB> <TAB> "" enabled "" : enabled == 1 , <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> indent = 4 , <TAB> <TAB> <TAB> separators = ( "" , "" , "" :  "" ) , <TAB> <TAB> ) <TAB> data + = "" ]} "" <TAB> return data",if label :,if len ( data ) > 20 :,False,97.1,82.54,,,
"def compile ( self , args ) : <TAB> compiled_args = { } <TAB> for key , value in six . iteritems ( args ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> compiled_args [ key ] = str ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> compiled_args [ key ] = sjson_dumps ( value ) <TAB> return self . _minified_code % compiled_args","if isinstance ( value , six . string_types ) :",if key in self . clean_args :,False,90.19,68.52,,,
"def insert ( self , pack_id , data ) : <TAB> if ( pack_id not in self . queue ) and pack_id > self . begin_id : <TAB> <TAB> self . queue [ pack_id ] = PacketInfo ( data ) <TAB> <TAB> if self . end_id == pack_id : <TAB> <TAB> <TAB> self . end_id = pack_id + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> eid = self . end_id <TAB> <TAB> <TAB> while eid < pack_id : <TAB> <TAB> <TAB> <TAB> self . miss_queue . add ( eid ) <TAB> <TAB> <TAB> <TAB> eid + = 1 <TAB> <TAB> <TAB> self . end_id = pack_id + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . miss_queue . remove ( pack_id )",elif self . end_id < pack_id :,elif self . end_id < pack_id :,True,100.0,74.51,,,
"def _target_generator ( self ) : <TAB> # since we do not have predictions yet, so we ignore sampling here <TAB> if self._internal_target_generator is None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> from ....model_zoo.ssd.target import SSDTargetGenerator <TAB> <TAB> self._internal_target_generator = SSDTargetGenerator( <TAB> <TAB> <TAB> iou_thresh=self._iou_thresh, <TAB> <TAB> <TAB> stds=self._box_norm, <TAB> <TAB> <TAB> negative_mining_ratio=-1, <TAB> <TAB> <TAB> **self._kwargs <TAB> <TAB> ) <TAB> <TAB> return self._internal_target_generator <TAB> else: <TAB> <TAB> return self._internal_target_generator",if self . _box_norm is None :,if self . _anchors_none :,False,97.09,72.0,,,
"def test_heapsort ( self ) : <TAB> # Exercise everything with repeated heapsort checks <TAB> for trial in range(100): <TAB> <TAB> size = random.randrange(50) <TAB> <TAB> data = [random.randrange(25) for i in range(size)] <TAB> <TAB> <IF-STMT> # Half of the time, use heapify <TAB> <TAB> <TAB> heap = data[:] <TAB> <TAB> <TAB> self.module.heapify(heap) <TAB> <TAB> else: # The rest of the time, use heappush <TAB> <TAB> <TAB> heap = [] <TAB> <TAB> <TAB> for item in data: <TAB> <TAB> <TAB> <TAB> self.module.heappush(heap, item) <TAB> <TAB> heap_sorted = [self.module.heappop(heap) for i in range(size)] <TAB> <TAB> self.assertEqual(heap_sorted, sorted(data))",if trial == 0 :,if trial & 1 :,False,98.03,72.66,,,
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> if timeout is None : <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> if code == TERMINATE : <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode",if res == _subprocess . WAIT_OBJECT_0 :,if res == _subprocess . WAIT_OBJECT_0 :,True,100.0,74.5,,,
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed",elif value == False :,elif value is None :,False,97.96,72.96,,,
"def isnotsurplus ( self , item : T ) - > bool : <TAB> if not self . matchers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . mismatch_description . append_text ( <TAB> <TAB> <TAB> <TAB> "" not matched:  "" <TAB> <TAB> <TAB> ) . append_description_of ( item ) <TAB> <TAB> return False <TAB> return True",if self . mismatch_description :,if self . mismatch_description :,True,100.0,73.99,,,
"def resolve_env_secrets ( config , environ ) : <TAB> """""" Create copy that recursively replaces  { "" $env "" :  "" NAME "" } with values from environ """""" <TAB> if isinstance ( config , dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB> <TAB> elif list ( config . keys ( ) ) == [ "" $file "" ] : <TAB> <TAB> <TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key : resolve_env_secrets ( value , environ ) <TAB> <TAB> <TAB> <TAB> for key , value in config . items ( ) <TAB> <TAB> <TAB> } <TAB> elif isinstance ( config , list ) : <TAB> <TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB> <TAB> return config","if list ( config . keys ( ) ) == [ ""$env"" ] :","if list ( config . keys ( ) ) == [ ""$env"" ] :",True,100.0,74.66,,,
"def __open__ ( filename , * args , * * kwargs ) : <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> return __realopen__ ( filename , * args , * * kwargs ) <TAB> if not os . path . isabs ( filename ) : <TAB> <TAB> datafilename = __papplet__ . dataPath ( filename ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return __realopen__ ( datafilename , * args , * * kwargs ) <TAB> <TAB> sketchfilename = __papplet__ . sketchPath ( filename ) <TAB> if os . path . isfile ( sketchfilename ) : <TAB> <TAB> return __realopen__ ( sketchfilename , * args , * * kwargs ) <TAB> # Fail naturally <TAB> return __realopen__(filename, *args, **kwargs)",if os . path . isfile ( datafilename ) :,if os . path . isfile ( datafilename ) :,True,100.0,74.52,,,
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ),if self . _completed . is_set ( ) :,if self . block :,False,95.98,82.11,,,
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> if config is None : <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> if defaults is None : <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass",if error_on_path :,if error_on_path :,True,100.0,74.6,,,
"def structured_dot_grad ( sparse_A , dense_B , ga ) : <TAB> if sparse_A . type . format in ( "" csc "" , "" csr "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sdgcsx = sdg_csc <TAB> <TAB> <TAB> CSx = CSC <TAB> <TAB> else : <TAB> <TAB> <TAB> sdgcsx = sdg_csr <TAB> <TAB> <TAB> CSx = CSR <TAB> <TAB> g_A_data = sdgcsx ( csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , dense_B , ga ) <TAB> <TAB> return CSx ( <TAB> <TAB> <TAB> g_A_data , csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , csm_shape ( sparse_A ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise NotImplementedError ( )","if sparse_A . type . format == ""csr"" :","if sparse_A . type . format == ""csc"" :",False,98.9,73.47,,,
"def step_async ( self , actions ) : <TAB> listify = True <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> listify = False <TAB> except TypeError : <TAB> <TAB> pass <TAB> if not listify : <TAB> <TAB> self . actions = actions <TAB> else : <TAB> <TAB> assert ( <TAB> <TAB> <TAB> self . num_envs == 1 <TAB> <TAB> ) , f "" actions  { actions }  is either not a list or has a wrong size - cannot match to  { self . num_envs }  environments "" <TAB> <TAB> self . actions = [ actions ]","if actions == [ ""list"" , ""list_async"" ] :",if len ( actions ) == self . num_envs :,False,91.31,61.98,,,
"def tempFailureRetry ( func , * args , * * kwargs ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( * args , * * kwargs ) <TAB> <TAB> except ( os . error , IOError ) as ex : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise",if ex . errno == errno . EAGAIN :,if ex . errno == errno . EINTR :,False,97.86,72.5,,,
"def test_learning_always_changes_generation ( chars , order ) : <TAB> learner = LStar ( lambda s : len ( s ) == 1 and s [ 0 ] in chars ) <TAB> for c in order : <TAB> <TAB> prev = learner . generation <TAB> <TAB> s = bytes ( [ c ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> learner . learn ( s ) <TAB> <TAB> <TAB> assert learner . generation > prev",if len ( s ) > 1 :,if learner . dfa . matches ( s ) != learner . member ( s ) :,False,87.11,66.05,,,
"def test_costs_5D_noisy_names ( signal_bkps_5D_noisy , cost_name ) : <TAB> signal , bkps = signal_bkps_5D_noisy <TAB> cost = cost_factory ( cost_name ) <TAB> cost . fit ( signal ) <TAB> cost . error ( 0 , 100 ) <TAB> cost . error ( 100 , signal . shape [ 0 ] ) <TAB> cost . error ( 10 , 50 ) <TAB> cost . sum_of_costs ( bkps ) <TAB> with pytest . raises ( NotEnoughPoints ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cost . min_size = 4 <TAB> <TAB> <TAB> cost . error ( 1 , 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cost . error ( 1 , 2 )","if cost_name == ""cosine"" :","if cost_name == ""cosine"" :",True,100.0,74.44,,,
"def remove_empty_dirs ( dirname ) : <TAB> logger . debug ( "" remove_empty_dirs  ' %s ' "" % ( dirname ) ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dirname = dirname . encode ( "" utf-8 "" ) <TAB> <TAB> os . removedirs ( dirname ) <TAB> <TAB> logger . debug ( "" remove_empty_dirs  ' %s '  done "" % ( dirname ) ) <TAB> except OSError as exc : # Python >2.5 <TAB> <TAB> if exc.errno == errno.ENOTEMPTY: <TAB> <TAB> <TAB> logger.debug(""remove_empty_dirs '%s' not empty"" % (dirname)) <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> except Exception as e: <TAB> <TAB> logger.exception(e) <TAB> <TAB> logger.error(""remove_empty_dirs exception: "" + dirname) <TAB> <TAB> raise e","if isinstance ( dirname , str ) :","if not isinstance ( dirname , str ) :",False,98.98,73.42,,,
"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if feat is not None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB> <TAB> <TAB> feat = f <TAB> if feat is None : <TAB> <TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name )",if f . name == name :,"if self . _return_feature ( f ) and hasattr ( f , name ) :",False,87.7,67.26,,,
"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB> <TAB> occupied = False <TAB> <TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB> <TAB> <TAB> if strategy == self : <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot ( <TAB> <TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> )",if occupied :,if not occupied :,False,98.7,73.44,,,
"def __deepcopy__ ( self , memo ) : <TAB> cls = self . __class__ <TAB> result = cls . __new__ ( cls ) <TAB> memo [ id ( self ) ] = result <TAB> for key , value in self . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( result , key , copy . copy ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( result , key , copy . deepcopy ( value , memo ) ) <TAB> return result","if isinstance ( value , dict ) :",if key in cls . dynamic_methods :,False,94.07,70.61,,,
def restore_forward ( model ) : <TAB> for child in model . children ( ) : <TAB> <TAB> # leaf node <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> child.forward = child.old_forward <TAB> <TAB> <TAB> child.old_forward = None <TAB> <TAB> else: <TAB> <TAB> <TAB> restore_forward(child),if child . forward is None :,"if is_leaf ( child ) and hasattr ( child , ""old_forward"" ) :",False,83.31,44.16,,,
"def add ( self , obj , allow_duplicates = False ) : <TAB> if allow_duplicates or obj not in self . _constants : <TAB> <TAB> self . _constant_pool . append ( obj ) <TAB> <TAB> self . _constants [ obj ] = len ( self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _constant_pool . append ( None )",if obj in self . _constant_pool :,"if obj . __class__ in ( Double , Long ) :",False,88.17,67.8,,,
"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] : # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l.lower().find(""copyright"") <TAB> <TAB> if idx < 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l[idx + 9 :].strip() <TAB> <TAB> if not copyright: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise(copyright) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ret.add(copyright) <TAB> return ret","if not copyright . find ( ""notices"" ) :","if not copyright . find ( ""200"" ) >= 0 and not copyright . find ( ""199"" ) >= 0 :",False,91.74,63.14,,,
"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB> <TAB> context . next_indent = len ( text ) <TAB> <TAB> if context . next_indent < context . indent : <TAB> <TAB> <TAB> while context . next_indent < context . indent : <TAB> <TAB> <TAB> <TAB> context . indent = context . indent_stack . pop ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> extra = text [ context . indent : ] <TAB> <TAB> <TAB> <TAB> text = text [ : context . indent ] <TAB> else : <TAB> <TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB> <TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB> <TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( )",if context . next_indent == context . indent :,if context . next_indent > context . indent :,False,98.64,73.93,,,
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> if not cmd . stdout . strip ( ) : <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )",if log_cmd . run ( ) :,"if log_cmd . check ( f""docker logs for {self.path.k8s}"" ) :",False,93.38,69.34,,,
"def nodes ( self ) : <TAB> if not self . _nodes : <TAB> <TAB> nodes = self . cluster_group . instances ( ) <TAB> <TAB> self . _nodes = [ ] <TAB> <TAB> master = self . master_node <TAB> <TAB> nodeid = 1 <TAB> <TAB> for node in nodes : <TAB> <TAB> <TAB> if node . state not in [ "" pending "" , "" running "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _nodes . insert ( 0 , master ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _nodes . append ( Node ( node , self . key_location , "" node %.3d "" % nodeid ) ) <TAB> <TAB> <TAB> nodeid + = 1 <TAB> else : <TAB> <TAB> for node in self . _nodes : <TAB> <TAB> <TAB> log . debug ( "" refreshing instance  %s "" % node . id ) <TAB> <TAB> <TAB> node . update ( ) <TAB> return self . _nodes",if node . master != master :,if node . id == master . id :,False,97.62,72.94,,,
"def match ( cls , agent_name , guid , uri , media = None ) : <TAB> # Retrieve `Agent` for provided `guid` <TAB> agent = Agents.get(agent_name) <TAB> if agent is None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # First occurrence of unsupported agent <TAB> <TAB> <TAB> log.warn(""Unsupported metadata agent: %s"" % agent_name) <TAB> <TAB> <TAB> # Mark unsupported agent as ""seen"" <TAB> <TAB> <TAB> unsupported_agents[agent_name] = True <TAB> <TAB> <TAB> return False <TAB> <TAB> # Duplicate occurrence of unsupported agent <TAB> <TAB> log.warn( <TAB> <TAB> <TAB> ""Unsupported metadata agent: %s"" % agent_name, extra={""duplicate"": True} <TAB> <TAB> ) <TAB> <TAB> return False <TAB> # Fill `guid` with details from agent <TAB> return agent.fill(guid, uri, media)",if agent_name in unsupported_agents :,if agent_name not in unsupported_agents :,False,98.99,73.34,,,
"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB> <TAB> randomNode = Gaffer . Random ( ) <TAB> <TAB> parentNode . addChild ( randomNode ) <TAB> <TAB> if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) : <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode )","if isinstance ( plug , Gaffer . ColorPlug ) :","elif isinstance ( plug , Gaffer . Color3fPlug ) :",False,96.82,72.22,,,
"def post_arrow ( self , arr : pa . Table , graph_type : str , opts : str = "" "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> sub_path = f "" api/v2/upload/datasets/ { dataset_id } / { graph_type } /arrow "" <TAB> try : <TAB> <TAB> resp = self . post_arrow_generic ( sub_path , tok , arr , opts ) <TAB> <TAB> out = resp . json ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" No success indicator in server response "" ) <TAB> <TAB> return out <TAB> except Exception as e : <TAB> <TAB> logger . error ( "" Failed to post arrow to  %s "" , sub_path , exc_info = True ) <TAB> <TAB> raise e",if resp . status_code == 404 :,"if not ( ""success"" in out ) or not out [ ""success"" ] :",False,91.98,65.55,,,
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """""" Return XML element converting dicts recursively. """""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> elif isinstance ( val , MutableMapping ) : <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if tag == "" config "" : <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem","if isinstance ( val , MutableLayer ) :","if tag == ""layers"" :",False,96.94,76.5,,,
"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB> <TAB> node = self . path . find_dir ( dir ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not node in lst : <TAB> <TAB> <TAB> lst . append ( node ) <TAB> <TAB> self . bld_incpaths_lst . append ( node )",if not node :,if not node :,True,100.0,74.34,,,
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> if isinstance ( val , compat . string_types ) : <TAB> <TAB> <TAB> return "" %s "" % val <TAB> <TAB> elif val < 1024 * * 2 : <TAB> <TAB> <TAB> return "" %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return "" %s "" % val",elif val < 1024 * * 3 :,elif val < 1024 ** 3 :,False,100.0,73.63,,,
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """""" cache hidden states into memory. """""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> if prev_mem is None : <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem",if reuse_len is not None :,if reuse_len is not None and reuse_len > 0 :,False,96.4,95.05,,,
"def GROUP_CONCAT ( builder , distinct , expr , sep = None ) : <TAB> assert distinct in ( None , True , False ) <TAB> result = distinct and "" GROUP_CONCAT(DISTINCT  "" or "" GROUP_CONCAT( "" , builder ( expr ) <TAB> if sep is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = result , ""  SEPARATOR  "" , builder ( sep ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = result , "" ,  "" , builder ( sep ) <TAB> return result , "" ) """,if result . endswith ( sep ) :,"if builder . provider . dialect == ""MySQL"" :",False,91.91,66.49,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> self . custom_fields = [ ] <TAB> self . obj_type = ContentType . objects . get_for_model ( self . model ) <TAB> # Add all applicable CustomFields to the form <TAB> custom_fields = CustomField.objects.filter(content_types=self.obj_type) <TAB> for cf in custom_fields: <TAB> <TAB> # Annotate non-required custom fields as nullable <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.nullable_fields.append(cf.name) <TAB> <TAB> self.fields[cf.name] = cf.to_form_field( <TAB> <TAB> <TAB> set_initial=False, enforce_required=False <TAB> <TAB> ) <TAB> <TAB> # Annotate this as a custom field <TAB> <TAB> self.custom_fields.append(cf.name)",if cf . required :,if not cf . required :,False,98.96,73.15,,,
"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if possible_child_hash not in self . items : <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash",if self . items [ possible_child_hash ] . previous_hash != self . get_last ( item_hash ) :,if possible_child_hash == item_hash :,False,86.17,68.15,,,
"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB> <TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB> <TAB> <TAB> <TAB> if not self . use_parallel_executor : <TAB> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) )",if self . unordered :,if self . use_parallel_executor and not self . use_double_buffer :,False,93.49,71.76,,,
"def add_cells ( self , cells ) : <TAB> for cell in cells : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> id = len ( self . cell_id_map ) <TAB> <TAB> <TAB> self . cell_id_map [ cell ] = id <TAB> <TAB> <TAB> self . id_cell_map [ id ] = cell",if cell not in self . cell_id_map :,if cell not in self . cell_id_map :,True,100.0,73.92,,,
"def _verify_out ( marker = "" >> "" ) : <TAB> if shared : <TAB> <TAB> self . assertIn ( "" libapp_lib.dylib "" , self . client . out ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIn ( "" libapp_lib.a "" , self . client . out ) <TAB> <TAB> else : # Incremental build not the same msg <TAB> <TAB> <TAB> self.assertIn(""Built target app_lib"", self.client.out) <TAB> out = str(self.client.out).splitlines() <TAB> for k, v in vals.items(): <TAB> <TAB> self.assertIn(""%s %s: %s"" % (marker, k, v), out)",if shared :,"if marker == "">>"" :",False,95.56,68.06,,,
"def Visit_expr ( self , node ) : # pylint: disable=invalid-name <TAB> # expr ::= xor_expr ('|' xor_expr)* <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""xor"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""|"" :",False,97.61,71.16,,,
"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB> <TAB> after = self . after . id if self . after else None <TAB> <TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB> <TAB> if not data : <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.limit = 0 # terminate loop <TAB> <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB> <TAB> for element in reversed(data): <TAB> <TAB> <TAB> await self.members.put(self.create_member(element))",if len ( data ) > 1 :,if len ( data ) < 1000 :,False,98.26,72.72,,,
"def assert_warns ( expected ) : <TAB> with warnings . catch_warnings ( record = True ) as w : <TAB> <TAB> warnings . simplefilter ( "" always "" ) <TAB> <TAB> yield <TAB> # Python 2 does not raise warnings multiple times from the same stack <TAB> # frame. <TAB> if sys.version_info >= (3, 0): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> exc_name = expected.__name__ <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> exc_name = str(expected) <TAB> <TAB> <TAB> raise AssertionError(""%s not triggerred"" % exc_name)",if expected is not None :,"if not any ( isinstance ( m . message , expected ) for m in w ) :",False,91.2,66.37,,,
"def __init__ ( self , measures ) : <TAB> """""" Constructs a ContingencyMeasures given a NgramAssocMeasures class """""" <TAB> self . __class__ . __name__ = "" Contingency "" + measures . __class__ . __name__ <TAB> for k in dir ( measures ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> v = getattr ( measures , k ) <TAB> <TAB> if not k . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> v = self . _make_contingency_fn ( measures , v ) <TAB> <TAB> setattr ( self , k , v )","if k . startswith ( ""_"" ) :","if k . startswith ( ""__"" ) :",False,98.95,98.18,,,
"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB> <TAB> start = event == ""start"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> omitted_kws += 1 <TAB> <TAB> if not omitted_kws: <TAB> <TAB> <TAB> yield event, elem <TAB> <TAB> elif not start: <TAB> <TAB> <TAB> elem.clear() <TAB> <TAB> if omit and not start: <TAB> <TAB> <TAB> omitted_kws -= 1","if elem . tag == ""kw"" and elem . get ( ""type"" ) != ""teardown"" :",if omit and start :,False,88.89,64.75,,,
"def read_block ( buffer , i ) : <TAB> offset = i * BLOCK_LENGTH % config . CAPTURE_BUFFER <TAB> while True : <TAB> <TAB> if buffer [ offset ] == BLOCK_MARKER . END : <TAB> <TAB> <TAB> return None <TAB> <TAB> while buffer [ offset ] == BLOCK_MARKER . WRITE : <TAB> <TAB> <TAB> time . sleep ( SHORT_SENSOR_SLEEP_TIME ) <TAB> <TAB> buffer [ offset ] = BLOCK_MARKER . READ <TAB> <TAB> buffer . seek ( offset + 1 ) <TAB> <TAB> length = struct . unpack ( "" =H "" , buffer . read ( 2 ) ) [ 0 ] <TAB> <TAB> retval = buffer . read ( length ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> buffer [ offset ] = BLOCK_MARKER . NOP <TAB> return retval",if retval == 0 :,if buffer [ offset ] == BLOCK_MARKER . READ :,False,94.58,71.29,,,
def _start ( self ) : <TAB> try : <TAB> <TAB> instance_info = self . _get_instance_info ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _multipass_cmd . start ( instance_name = self . instance_name ) <TAB> except errors . ProviderInfoError as instance_error : <TAB> <TAB> # Until we have proper multipass error codes to know if this <TAB> <TAB> # was a communication error we should keep this error tracking <TAB> <TAB> # and generation here. <TAB> <TAB> raise errors.ProviderInstanceNotFoundError( <TAB> <TAB> <TAB> instance_name=self.instance_name <TAB> <TAB> ) from instance_error,if instance_info . is_multipass :,if not instance_info . is_running ( ) :,False,95.97,91.96,,,
"def _river_driver ( self ) : <TAB> if self . _cached_river_driver : <TAB> <TAB> return self . _cached_river_driver <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _cached_river_driver = MsSqlDriver ( <TAB> <TAB> <TAB> <TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _cached_river_driver = OrmDriver ( <TAB> <TAB> <TAB> <TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _cached_river_driver",if self . is_sql :,if app_config . IS_MSSQL :,False,95.92,72.07,,,
"def __LazyMap__ ( self , attr ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> debug_attr_print ( <TAB> <TAB> <TAB> <TAB> "" %s .__LazyMap__( %s ) added something "" % ( self . _username_ , attr ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return 1 <TAB> except AttributeError : <TAB> <TAB> return 0",if attr in self . _lazy_map_attrs :,if self . _LazyAddAttr_ ( attr ) :,False,92.12,68.84,,,
"def prepare ( self , data = None , user = None ) : <TAB> """""" Prepare activation for execution. """""" <TAB> super ( ManagedStartViewActivation , self ) . prepare . original ( ) <TAB> self . task . owner = user <TAB> management_form_class = self . get_management_form_class ( ) <TAB> self . management_form = management_form_class ( data = data , instance = self . task ) <TAB> if data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise FlowRuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Activation metadata is broken  {} "" . format ( self . management_form . errors ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . task = self . management_form . save ( commit = False )",if self . management_form . errors :,if not self . management_form . is_valid ( ) :,False,95.42,77.93,,,
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> if self . __Token : <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList : <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",if ReplacedLine :,if not RegionSizeGuid :,False,97.65,72.0,,,
"def _get_completion ( self , document ) : <TAB> try : <TAB> <TAB> completion_header = document . xpath ( "" //div[@id= ' complete_day ' ] "" ) [ 0 ] <TAB> <TAB> completion_message = completion_header . getchildren ( ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif "" day_complete_message "" in completion_message . classes : <TAB> <TAB> <TAB> return True <TAB> except IndexError : <TAB> <TAB> return False # Who knows, probably not my diary.","if ""day_complete_header"" in completion_message . classes :","if ""day_incomplete_message"" in completion_message . classes :",False,97.24,72.89,,,
"def run ( self ) : <TAB> DISPATCH_SYNC = components . interfaces . nsIEventTarget . DISPATCH_SYNC <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> for match in findlib2 . find_all_matches ( self . regex , self . text ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> self . target . dispatch ( lambda : self . callback ( match ) , DISPATCH_SYNC ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self . target . dispatch ( lambda : self . callback ( None ) , DISPATCH_SYNC ) <TAB> finally : <TAB> <TAB> self . callback = None <TAB> <TAB> self . target = None",if self . callback is None :,if self . _stopped :,False,93.62,70.62,,,
"def to_key ( literal_or_identifier ) : <TAB> """""" returns string representation of this object """""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k )","elif isinstance ( k , str ) :","elif ""regex"" in literal_or_identifier :",False,95.72,94.39,,,
"def process_image_pre_creation ( sender , instance : Image , * * kwargs ) : <TAB> # FIXME(winkidney): May have issue on determining if it <TAB> # is created or not <TAB> if instance.pk is not None: <TAB> <TAB> return <TAB> for plugin in _plugin_instances: <TAB> <TAB> process_fn = getattr(plugin, ""process_image_pre_creation"", None) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> process_fn( <TAB> <TAB> <TAB> <TAB> django_settings=settings, <TAB> <TAB> <TAB> <TAB> image_instance=instance, <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> logging.exception( <TAB> <TAB> <TAB> <TAB> ""Error occurs while trying to access plugin's pin_pre_save "" <TAB> <TAB> <TAB> <TAB> ""for plugin %s"" % plugin <TAB> <TAB> <TAB> )",if process_fn is None :,if process_fn is None :,True,100.0,74.49,,,
"def check_screenshots ( self ) : <TAB> # If we arrive here, there have not been any failures yet <TAB> if self.interactive: <TAB> <TAB> self._commit_screenshots() <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._validate_screenshots() <TAB> <TAB> <TAB> # Always commit the screenshots here. They can be used for the next test run. <TAB> <TAB> <TAB> # If reference screenshots were already present and there was a mismatch, it should <TAB> <TAB> <TAB> # have failed above. <TAB> <TAB> <TAB> self._commit_screenshots() <TAB> <TAB> elif self.allow_missing_screenshots: <TAB> <TAB> <TAB> warnings.warn(""No committed reference screenshots available. Ignoring."") <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail( <TAB> <TAB> <TAB> <TAB> ""No committed reference screenshots available. Run interactive first."" <TAB> <TAB> <TAB> )",if self . allow_screenshots :,if self . _has_reference_screenshots ( ) :,False,96.61,72.65,,,
"def on_task_abort ( self , task , config ) : <TAB> if "" abort "" in config : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" sending abort notification "" ) <TAB> <TAB> self . send_notification ( <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" title "" ] , <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" message "" ] , <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" via "" ] , <TAB> <TAB> <TAB> template_renderer = task . render , <TAB> <TAB> )","if task . status == ""closed"" :",if task . silent_abort :,False,95.41,69.45,,,
"def block_users ( self , user_ids ) : <TAB> broken_items = [ ] <TAB> self . logger . info ( "" Going to block  %d  users. "" % len ( user_ids ) ) <TAB> for user_id in tqdm ( user_ids ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . error_delay ( ) <TAB> <TAB> <TAB> broken_items = user_ids [ user_ids . index ( user_id ) : ] <TAB> <TAB> <TAB> break <TAB> self . logger . info ( "" DONE: Total blocked  %d  users. "" % self . total [ "" blocks "" ] ) <TAB> return broken_items",if user_id in user_ids :,if not self . block ( user_id ) :,False,94.64,70.41,,,
"def find_widget_by_id ( self , id , parent = None ) : <TAB> """""" Recursively searches for widget with specified ID """""" <TAB> if parent == None : <TAB> <TAB> if id in self : <TAB> <TAB> <TAB> return self [ id ] # Do things fast if possible <TAB> <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <TAB> <TAB> if hasattr(c, ""get_id""): <TAB> <TAB> <TAB> if c.get_id() == id: <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance(c, Gtk.Container): <TAB> <TAB> <TAB> r = self.find_widget_by_id(id, c) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",if r :,if not r is None :,False,97.7,71.68,,,
"def addClasses ( self , name ) : <TAB> # Result: void - None <TAB> # In: name: string <TAB> for n in name.split(): <TAB> <TAB> try: <TAB> <TAB> <TAB> k, method = n.split(""."") <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> k = n <TAB> <TAB> <TAB> method = None <TAB> <TAB> self.classes[k] = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.methods.setdefault(k, {})[method] = 1",if method is not None :,if method is not None :,True,100.0,74.14,,,
"def Read ( self , lex_mode ) : <TAB> while True : <TAB> <TAB> t = self . _Read ( lex_mode ) <TAB> <TAB> self . was_line_cont = t . id == Id . Ignored_LineCont <TAB> <TAB> # TODO: Change to ALL IGNORED types, once you have SPACE_TOK. This means <TAB> <TAB> # we don't have to handle them in the VS_1/VS_2/etc. states. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> # log('Read() Returning %s', t) <TAB> return t",if t . id in Id . IGNORED_Types :,if t . id != Id . Ignored_LineCont :,False,95.13,71.54,,,
"def _dir_guildfile ( dir , ctx ) : <TAB> from guild import guildfile <TAB> try : <TAB> <TAB> return guildfile . for_dir ( dir ) <TAB> except guildfile . NoModels : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> help_suffix = ""  or  ' %s '  for help "" % click_util . cmd_help ( ctx ) <TAB> <TAB> else : <TAB> <TAB> <TAB> help_suffix = "" "" <TAB> <TAB> cli . error ( <TAB> <TAB> <TAB> "" %s  does not contain a Guild file (guild.yml) \n "" <TAB> <TAB> <TAB> "" Try specifying a project path or package name %s . "" <TAB> <TAB> <TAB> % ( cwd_desc ( dir ) , help_suffix ) <TAB> <TAB> ) <TAB> except guildfile . GuildfileError as e : <TAB> <TAB> cli . error ( str ( e ) )","if ctx . get_option ( ""help"" ) :",if ctx :,False,95.44,68.12,,,
"def check_response ( self , response ) : <TAB> """""" Specialized version of check_response(). """""" <TAB> for line in response : <TAB> <TAB> # Skip blank lines: <TAB> <TAB> if not line.strip(): <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB> <TAB> <TAB> raise BadLogin(line) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))","if line . startswith ( b""User"" ) :","if line . startswith ( b""OK"" ) :",False,98.5,97.44,,,
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> if username not in self._ignore_users: <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)",if response . stat_mode == rdf_client . StatEntry . ST_MODE :,if stat . S_ISDIR ( int ( response . st_mode ) ) :,False,93.45,70.06,,,
"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB> <TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB> <TAB> spk = uttid <TAB> if not self . reverse : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = np . add ( x , self . bias [ spk ] ) <TAB> <TAB> if self . norm_vars : <TAB> <TAB> <TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB> <TAB> if self . norm_vars : <TAB> <TAB> <TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x",if self . reverse :,if self . norm_means :,False,95.9,72.96,,,
"def hasFixtures ( self , ctx_callback = None ) : <TAB> context = self . context <TAB> if context is None : <TAB> <TAB> return False <TAB> if self . implementsAnyFixture ( context , ctx_callback = ctx_callback ) : <TAB> <TAB> return True <TAB> # My context doesn't have any, but its ancestors might <TAB> factory = self.factory <TAB> if factory: <TAB> <TAB> ancestors = factory.context.get(self, []) <TAB> <TAB> for ancestor in ancestors: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if ancestor . hasFixtures ( ctx_callback = ctx_callback ) :,"if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :",False,95.86,70.96,,,
def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB> <TAB> btn = self.radioButtons[moduleID] <TAB> <TAB> if moduleID == active: <TAB> <TAB> <TAB> btn.SetValue(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.SetValue(False) <TAB> <TAB> if self.demoModules.Exists(moduleID): <TAB> <TAB> <TAB> btn.Enable(True) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.Enable(False) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(False),if active == self . demoModules . GetActiveID ( ) :,if moduleID == modModified :,False,90.89,91.94,,,
"def ignore_proxy_host ( self ) : <TAB> """""" Check if self.host is in the $no_proxy ignore list. """""" <TAB> if urllib . proxy_bypass ( self . host ) : <TAB> <TAB> return True <TAB> no_proxy = os . environ . get ( "" no_proxy "" ) <TAB> if no_proxy : <TAB> <TAB> entries = [ parse_host_port ( x ) for x in no_proxy . split ( "" , "" ) ] <TAB> <TAB> for host , port in entries : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if host . startswith ( self . host ) and port != 0 :,if host . lower ( ) == self . host and port == self . port :,False,92.17,90.74,,,
"def run ( self , _ ) : <TAB> view = self . view <TAB> if not view . settings ( ) . get ( "" terminus_view "" ) : <TAB> <TAB> return <TAB> terminal = Terminal . from_id ( view . id ( ) ) <TAB> if terminal : <TAB> <TAB> terminal . close ( ) <TAB> <TAB> panel_name = terminal . panel_name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> window = panel_window ( view ) <TAB> <TAB> <TAB> if window : <TAB> <TAB> <TAB> <TAB> window . destroy_output_panel ( panel_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> view . close ( )",if panel_name :,if panel_name :,True,100.0,74.4,,,
"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB> <TAB> elif isinstance ( node , addnodes . start_of_file ) : <TAB> <TAB> <TAB> return node [ "" docname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> node = node . parent <TAB> return None # never reached here. only for type hinting","if isinstance ( node , addnodes . start_of_file ) :","if isinstance ( node , nodes . document ) :",False,94.03,72.01,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.14,,,
"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB> <TAB> if self . has_gender_differences : <TAB> <TAB> <TAB> elements = path_elements + [ "" female "" ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> el <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict )",if self . species_id not in self . gender_differences :,if strict :,False,88.02,69.88,,,
"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB> <TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB> <TAB> <TAB> self . _cancel_editing ( ) <TAB> <TAB> elif event . GetKeyCode ( ) == wx . WXK_RETURN : <TAB> <TAB> <TAB> self . _update_value ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_SPACE :,elif event . GetKeyCode ( ) == wx . WXK_DELETE :,False,98.68,73.48,,,
"def sync_up_to_new_location ( self , worker_ip ) : <TAB> if worker_ip != self . worker_ip : <TAB> <TAB> logger . debug ( "" Setting new worker IP to  %s "" , worker_ip ) <TAB> <TAB> self . set_worker_ip ( worker_ip ) <TAB> <TAB> self . reset ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( "" Sync up to new location skipped. This should not occur. "" ) <TAB> else : <TAB> <TAB> logger . warning ( "" Sync attempted to same IP  %s . "" , worker_ip )",if self . sync_state . is_set ( ) :,if not self . sync_up ( ) :,False,95.03,71.51,,,
"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB> <TAB> "" torrent "" : "" "" , <TAB> <TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB> <TAB> data = self . session . get ( url ) . text <TAB> <TAB> with bs4_parser ( data ) as html : <TAB> <TAB> <TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for download in downloads . findAll ( "" a "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> link = download [ "" href "" ] <TAB> <TAB> <TAB> <TAB> <TAB> if link . startswith ( "" magnet "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" magnet "" ] = link <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return links [ download_type ]",if downloads :,if downloads :,True,100.0,74.68,,,
"def force_ipv4 ( self , * args ) : <TAB> """""" only ipv4 localhost in /etc/hosts """""" <TAB> logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB> lines = [ ] <TAB> for line in open ( self . etc_hosts ( ) ) : <TAB> <TAB> if "" ::1 "" in line : <TAB> <TAB> <TAB> newline = re . sub ( "" \\ slocalhost \\ s "" , "" "" , line ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB> <TAB> <TAB> <TAB> line = newline <TAB> <TAB> lines . append ( line ) <TAB> f = open ( self . etc_hosts ( ) , "" w "" ) <TAB> for line in lines : <TAB> <TAB> f . write ( line ) <TAB> f . close ( )","if newline . find ( ""\n"" ) != - 1 :",if line != newline :,False,94.81,94.87,,,
"def prepare ( self ) : <TAB> # Maybe the brok is a old daemon one or was already prepared <TAB> # if so, the data is already ok <TAB> if hasattr(self, ""prepared"") and not self.prepared: <TAB> <TAB> self.data = SafeUnpickler.loads(self.data) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.data[""instance_id""] = self.instance_id <TAB> self.prepared = True",if self . instance_id :,"if hasattr ( self , ""instance_id"" ) :",False,91.76,62.42,,,
"def _test_compute_q0 ( self ) : <TAB> # Stub code to search a logq space and figure out logq0 by eyeballing <TAB> # results. This code does not run with the tests. Remove underscore to run. <TAB> sigma = 15 <TAB> order = 250 <TAB> logqs = np.arange(-290, -270, 1) <TAB> count = 0 <TAB> for logq in logqs: <TAB> <TAB> count += 1 <TAB> <TAB> sys.stdout.write( <TAB> <TAB> <TAB> ""\t%0.5g: %0.10g"" % (logq, pate.rdp_gaussian(logq, sigma, order)) <TAB> <TAB> ) <TAB> <TAB> sys.stdout.flush() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print("""")",if count > 0 :,if count % 5 == 0 :,False,97.14,72.03,,,
"def valid_fieldnames ( fieldnames ) : <TAB> """""" check if fieldnames are valid """""" <TAB> for fieldname in fieldnames : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> elif fieldname in fieldname_map and fieldname_map [ fieldname ] == "" source "" : <TAB> <TAB> <TAB> return True <TAB> return False",if fieldname in fieldname_map and fieldname in fieldname_map [ fieldname ] :,"if fieldname in canonical_field_names and fieldname == ""source"" :",False,87.98,63.57,,,
"def ns_provide ( self , id_ ) : <TAB> global controllers , layouts <TAB> if id_ == "" _leo_viewrendered "" : <TAB> <TAB> c = self . c <TAB> <TAB> vr = controllers . get ( c . hash ( ) ) or ViewRenderedController ( c ) <TAB> <TAB> h = c . hash ( ) <TAB> <TAB> controllers [ h ] = vr <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> layouts [ h ] = c . db . get ( "" viewrendered_default_layouts "" , ( None , None ) ) <TAB> <TAB> # return ViewRenderedController(self.c) <TAB> <TAB> return vr",if h in layouts :,if not layouts . get ( h ) :,False,95.02,70.6,,,
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> if config is None : <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass",if defaults is None :,if defaults is None :,True,100.0,74.6,,,
"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB> <TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB> <TAB> for k , v in q . items ( ) : <TAB> <TAB> <TAB> if k not in query : <TAB> <TAB> <TAB> <TAB> query [ k ] = { } <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query[k] = v <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> query[k].update(v) <TAB> return query","if isinstance ( v , dict ) :","if isinstance ( v , list ) :",False,98.74,73.4,,,
"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB> <TAB> self . data . append ( data ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> passon = b "" "" <TAB> <TAB> if data : <TAB> <TAB> <TAB> self . data . append ( data ) <TAB> return passon",if self . size :,if self . size :,True,100.0,74.39,,,
"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB> <TAB> if mode == "" append "" : <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . append ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB> <TAB> core . config . globalVariables [ name ] = data","elif mode == ""add"" :","elif mode == ""add"" :",True,100.0,74.2,,,
"def vi_pos_back_short ( line , index = 0 , count = 1 ) : <TAB> line = vi_list ( line ) <TAB> try : <TAB> <TAB> for i in range ( count ) : <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> while vi_is_space ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> in_word = vi_is_word ( line [ index ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> while vi_is_word ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> while not vi_is_word_or_space ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> return index + 1 <TAB> except IndexError : <TAB> <TAB> return 0",if in_word :,if in_word :,True,100.0,74.56,,,
"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB> <TAB> example = list ( example ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for key , max_len in len_map . items ( ) : <TAB> <TAB> <TAB> <TAB> example_len = example [ key ] . shape <TAB> <TAB> <TAB> <TAB> if example_len > max_len : <TAB> <TAB> <TAB> <TAB> <TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB> <TAB> yield tuple ( example )",if len_map :,if len_map is not None :,False,97.19,71.51,,,
"def decorate ( f ) : <TAB> # call-signature of f is exposed via __wrapped__. <TAB> # we want it to mimic Obj.__init__ <TAB> f.__wrapped__ = Obj.__init__ <TAB> f._uses_signature = Obj <TAB> # Supplement the docstring of f with information from Obj <TAB> if Obj.__doc__: <TAB> <TAB> doclines = Obj.__doc__.splitlines() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> doc = f.__doc__ + ""\n"".join(doclines[1:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> doc = ""\n"".join(doclines) <TAB> <TAB> try: <TAB> <TAB> <TAB> f.__doc__ = doc <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> # __doc__ is not modifiable for classes in Python < 3.3 <TAB> <TAB> <TAB> pass <TAB> return f","if doclines [ 0 ] == ""__doc__"" :",if f . __doc__ :,False,95.83,64.93,,,
"def IncrementErrorCount ( self , category ) : <TAB> """""" Bumps the module ' s error statistic. """""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB> <TAB> if self . counting != "" detailed "" : <TAB> <TAB> <TAB> category = category . split ( "" / "" ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . errors_by_category [ category ] = 0 <TAB> <TAB> self . errors_by_category [ category ] + = 1",if category not in self . errors_by_category :,if category not in self . errors_by_category :,True,100.0,99.37,,,
"def _delete_fields ( self , data ) : <TAB> data = self . _del ( <TAB> <TAB> data , [ "" speaker_ids "" , "" track_id "" , "" microlocation_id "" , "" session_type_id "" ] <TAB> ) <TAB> # convert datetime fields <TAB> for _ in [""start_time_tz"", ""end_time_tz""]: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data[_] = SESSION_POST[_[0:-3]].from_str(data[_]) <TAB> <TAB> <TAB> data[_[0:-3]] = data.pop(_) <TAB> return data",if _ in SESSION_POST :,if _ in data :,False,97.31,72.35,,,
"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB> <TAB> if char in char_set : <TAB> <TAB> <TAB> letters + = char <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> strings . append ( letters ) <TAB> <TAB> <TAB> letters = "" "" <TAB> <TAB> <TAB> count = 0 <TAB> <IF-STMT> <TAB> <TAB> strings . append ( letters ) <TAB> return strings",if count > threshold :,if count > threshold :,True,100.0,74.4,,,
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """""" Check if the function argument list has a dictionary as an arg. """""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> if token . value == "" { "" : <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token . OpensScope ( ) : <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False","if token . value == ""}"" :",if token . ClosesScope ( ) :,False,96.5,76.75,,,
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","elif mode == ""key"" :","elif s . startswith ( ""Proc-Type"" ) and ""ENCRYPTED"" in s :",False,94.44,69.25,,,
"def main ( self ) : <TAB> self . model . clear ( ) <TAB> self . callman . unregister_all ( ) <TAB> active_handle = self . get_active ( "" Person "" ) <TAB> if active_handle : <TAB> <TAB> active = self . dbstate . db . get_person_from_handle ( active_handle ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . callman . register_obj ( active ) <TAB> <TAB> <TAB> self . display_citations ( active ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . set_has_data ( False ) <TAB> else : <TAB> <TAB> self . set_has_data ( False )",if active :,if active :,True,100.0,74.37,,,
"def _validate ( self ) - > None : <TAB> # Paren validation and such <TAB> super(Tuple, self)._validate() <TAB> if len(self.elements) == 0: <TAB> <TAB> <IF-STMT> # assumes len(lpar) == len(rpar), via superclass <TAB> <TAB> <TAB> raise CSTValidationError( <TAB> <TAB> <TAB> <TAB> ""A zero-length tuple must be wrapped in parentheses."" <TAB> <TAB> <TAB> )",if self . _is_sequence ( ) :,if len ( self . lpar ) == 0 :,False,92.35,67.47,,,
"def _session_from_arg ( self , session_obj , lock_type = None ) : <TAB> if not isinstance ( session_obj , self . ISession ) : <TAB> <TAB> vm = self . _machine_from_arg ( session_obj ) <TAB> <TAB> lock_type = lock_type or self . LockType . null <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return vm . create_session ( lock_type ) <TAB> <TAB> return None <TAB> return session_obj",if vm :,if vm :,True,100.0,74.11,,,
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not private and name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot : <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls",if meth is not inspect . __init__ :,"if name != ""__init__"" :",False,94.59,64.41,,,
"def pdb ( message = "" "" ) : <TAB> """""" Fall into pdb. """""" <TAB> import pdb # Required: we have just defined pdb as a function! <TAB> if app and not app.useIpython: <TAB> <TAB> # from leo.core.leoQt import QtCore <TAB> <TAB> # This is more portable. <TAB> <TAB> try: <TAB> <TAB> <TAB> import PyQt5.QtCore as QtCore <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> import PyQt4.QtCore as QtCore <TAB> <TAB> <TAB> except ImportError: <TAB> <TAB> <TAB> <TAB> QtCore = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # pylint: disable=no-member <TAB> <TAB> <TAB> QtCore.pyqtRemoveInputHook() <TAB> if message: <TAB> <TAB> print(message) <TAB> pdb.set_trace()",if QtCore :,if QtCore :,True,100.0,74.46,,,
"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """""" return (bucket_name, prefix) for all s3 logging targets """""" <TAB> for b in buckets : <TAB> <TAB> if b . get ( "" Logging "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB> <TAB> if not self_log and b [ "" Name "" ] . startswith ( "" cf-templates- "" ) : <TAB> <TAB> <TAB> yield ( b [ "" Name "" ] , "" "" )","if ""TargetBucket"" in b [ ""Logging"" ] :",if self_log :,False,94.63,70.16,,,
"def prepare_fields ( self ) : <TAB> # See clean() <TAB> for k, v in self.fields.items(): <TAB> <TAB> v._required = v.required <TAB> <TAB> v.required = False <TAB> <TAB> v.widget.is_required = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v._required = v.one_required <TAB> <TAB> <TAB> v.one_required = False <TAB> <TAB> <TAB> v.widget.enabled_locales = self.locales",if v . one_required :,"if isinstance ( v , I18nFormField ) :",False,94.79,67.91,,,
"def __pack__ ( self ) : <TAB> new_values = [ ] <TAB> for i in xrange ( len ( self . __unpacked_data_elms__ ) ) : <TAB> <TAB> for key in self . __keys__ [ i ] : <TAB> <TAB> <TAB> new_val = getattr ( self , key ) <TAB> <TAB> <TAB> old_val = self . __unpacked_data_elms__ [ i ] <TAB> <TAB> <TAB> # In the case of Unions, when the first changed value <TAB> <TAB> <TAB> # is picked the loop is exited <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_values.append(new_val) <TAB> return struct.pack(self.__format__, *new_values)",if new_val != old_val :,if new_val != old_val :,True,100.0,74.4,,,
"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB> <TAB> main_vault_directory = os . path . join ( <TAB> <TAB> <TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB> <TAB> <TAB> <TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB> <TAB> <TAB> <TAB> <TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if cred : <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found . append ( cred ) <TAB> return pwd_found",if os . path . exists ( main_vault_directory ) :,if os . path . exists ( main_vault_directory ) :,True,100.0,74.56,,,
"def on_revision_plugin_revision_pre_save ( * * kwargs ) : <TAB> instance = kwargs [ "" instance "" ] <TAB> if kwargs . get ( "" created "" , False ) : <TAB> <TAB> update_previous_revision = ( <TAB> <TAB> <TAB> not instance . previous_revision <TAB> <TAB> <TAB> and instance . plugin <TAB> <TAB> <TAB> and instance . plugin . current_revision <TAB> <TAB> <TAB> and instance . plugin . current_revision != instance <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> instance . previous_revision = instance . plugin . current_revision <TAB> if not instance . revision_number : <TAB> <TAB> try : <TAB> <TAB> <TAB> previous_revision = instance . plugin . revision_set . latest ( ) <TAB> <TAB> <TAB> instance . revision_number = previous_revision . revision_number + 1 <TAB> <TAB> except RevisionPluginRevision . DoesNotExist : <TAB> <TAB> <TAB> instance . revision_number = 1",if update_previous_revision :,if update_previous_revision :,True,100.0,74.56,,,
"def __setattr__ ( self , name , value ) : <TAB> super ( ) . __setattr__ ( name , value ) <TAB> field = self . _fields . get ( name ) <TAB> if field : <TAB> <TAB> self . check_field_type ( field , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( f "" cannot set immutable  { name }  on  { self !r} "" )",if field . immutable :,if name in self . __ast_frozen_fields__ :,False,87.5,69.76,,,
"def _check_for_req_data ( data ) : <TAB> required_args = [ "" columns "" ] <TAB> for arg in required_args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True , make_json_response ( <TAB> <TAB> <TAB> <TAB> status = 400 , <TAB> <TAB> <TAB> <TAB> success = 0 , <TAB> <TAB> <TAB> <TAB> errormsg = gettext ( "" Could not find required parameter ( {} ). "" ) . format ( arg ) , <TAB> <TAB> <TAB> ) <TAB> return False , "" """,if arg in data :,"if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) :",False,84.08,62.08,,,
"def train_dict ( self , triples ) : <TAB> """""" Train a dict lemmatizer given training (word, pos, lemma) triples. """""" <TAB> # accumulate counter <TAB> ctr = Counter() <TAB> ctr.update([(p[0], p[1], p[2]) for p in triples]) <TAB> # find the most frequent mappings <TAB> for p, _ in ctr.most_common(): <TAB> <TAB> w, pos, l = p <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.composite_dict[(w, pos)] = l <TAB> <TAB> if w not in self.word_dict: <TAB> <TAB> <TAB> self.word_dict[w] = l <TAB> return","if ( w , pos ) not in self . composite_dict :","if ( w , pos ) not in self . composite_dict :",True,100.0,74.34,,,
"def render ( type_ , obj , context ) : <TAB> if type_ == "" foreign_key "" : <TAB> <TAB> return None <TAB> if type_ == "" column "" : <TAB> <TAB> if obj . name == "" y "" : <TAB> <TAB> <TAB> return None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" col( %s ) "" % obj . name <TAB> if type_ == "" type "" and isinstance ( obj , MySpecialType ) : <TAB> <TAB> context . imports . add ( "" from mypackage import MySpecialType "" ) <TAB> <TAB> return "" MySpecialType() "" <TAB> return "" render: %s "" % type_","elif obj . name == ""y"" :","elif obj . name == ""q"" :",False,98.68,73.49,,,
"def test_knows_when_stepping_back_possible ( self ) : <TAB> iterator = bidirectional_iterator . BidirectionalIterator ( [ 0 , 1 , 2 , 3 ] ) <TAB> commands = [ 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ] <TAB> command_count = 0 <TAB> results = [ ] <TAB> for _ in iterator : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> iterator . step_back_on_next_iteration ( ) <TAB> <TAB> results . append ( iterator . can_step_back ( ) ) <TAB> <TAB> command_count + = 1 <TAB> assert results == [ False , True , False , True , True , True , False , True , True , True ]",if command_count % 2 == 0 :,if commands [ command_count ] :,False,95.6,72.17,,,
"def flask_debug_true ( context ) : <TAB> if context . is_module_imported_like ( "" flask "" ) : <TAB> <TAB> if context . call_function_name_qual . endswith ( "" .run "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return bandit . Issue ( <TAB> <TAB> <TAB> <TAB> <TAB> severity = bandit . HIGH , <TAB> <TAB> <TAB> <TAB> <TAB> confidence = bandit . MEDIUM , <TAB> <TAB> <TAB> <TAB> <TAB> text = "" A Flask app appears to be run with debug=True,  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" which exposes the Werkzeug debugger and allows  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" the execution of arbitrary code. "" , <TAB> <TAB> <TAB> <TAB> <TAB> lineno = context . get_lineno_for_call_arg ( "" debug "" ) , <TAB> <TAB> <TAB> <TAB> )","if context . call_function_name_qual . endswith ( "".run"" ) :","if context . check_call_arg_value ( ""debug"" , ""True"" ) :",False,94.92,69.08,,,
"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . _should_meta_profile : <TAB> <TAB> end_time = timezone . now ( ) <TAB> <TAB> exception_raised = exc_type is not None <TAB> <TAB> if exception_raised : <TAB> <TAB> <TAB> Logger . error ( <TAB> <TAB> <TAB> <TAB> "" Exception when performing meta profiling, dumping trace below "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> traceback . print_exception ( exc_type , exc_val , exc_tb ) <TAB> <TAB> request = getattr ( DataCollector ( ) . local , "" request "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> curr = request . meta_time or 0 <TAB> <TAB> <TAB> request . meta_time = curr + _time_taken ( self . start_time , end_time )",if request :,if request :,True,100.0,74.5,,,
"def get_job_offer ( ja_list ) : <TAB> ja_joff_map = { } <TAB> offers = frappe . get_all ( <TAB> <TAB> "" Job Offer "" , <TAB> <TAB> filters = [ [ "" job_applicant "" , "" IN "" , ja_list ] ] , <TAB> <TAB> fields = [ "" name "" , "" job_applicant "" , "" status "" , "" offer_date "" , "" designation "" ] , <TAB> ) <TAB> for offer in offers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ja_joff_map [ offer . job_applicant ] = [ offer ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ja_joff_map [ offer . job_applicant ] . append ( offer ) <TAB> return ja_joff_map",if offer . job_applicant not in ja_joff_map :,if offer . job_applicant not in ja_joff_map . keys ( ) :,False,97.34,72.32,,,
"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return t [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> for part in t : <TAB> <TAB> <TAB> <TAB> res = self . _get_deepest ( part ) <TAB> <TAB> <TAB> <TAB> if res : <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None",if len ( t ) == 1 :,if len ( t ) == 1 :,True,100.0,74.26,,,
"def test_main ( self ) : <TAB> root = os . path . dirname ( mutagen . __path__ [ 0 ] ) <TAB> skip = [ os . path . join ( root , "" docs "" ) , os . path . join ( root , "" venv "" ) ] <TAB> for dirpath , dirnames , filenames in os . walk ( root ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> if filename . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> <TAB> path = os . path . join ( dirpath , filename ) <TAB> <TAB> <TAB> <TAB> self . _check_encoding ( path )",if dirpath . startswith ( skip ) :,if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) :,False,88.89,67.23,,,
"def xview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB> <TAB> value = float ( value ) <TAB> if mode is None : <TAB> <TAB> return self . hsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB> <TAB> frameWidth = self . innerframe . winfo_reqwidth ( ) <TAB> <TAB> self . _startX = value * float ( frameWidth ) <TAB> else : # mode == 'scroll' <TAB> <TAB> clipperWidth = self._clipper.winfo_width() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> jump = int(clipperWidth * self._jfraction) <TAB> <TAB> else: <TAB> <TAB> <TAB> jump = clipperWidth <TAB> <TAB> self._startX = self._startX + value * jump <TAB> self.reposition()",if self . _jfraction is not None :,"if units == ""units"" :",False,96.09,65.44,,,
"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB> <TAB> DEFAULT_DOMAIN_PATH , <TAB> <TAB> DEFAULT_STORIES_FILE , <TAB> <TAB> tmpdir . strpath , <TAB> <TAB> interpreter = RegexInterpreter ( ) , <TAB> <TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB> <TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if type ( policy ) == FormPolicy : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 2 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 5",if policy . featurizer :,"if hasattr ( policy . featurizer , ""max_history"" ) :",False,94.82,64.37,,,
"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> compare_entry = compare_entry . lower ( ) <TAB> <TAB> <TAB> compare_base = compare_base . lower ( ) <TAB> <TAB> if self . compare_entries ( compare_entry , compare_base ) : <TAB> <TAB> <TAB> if entry not in sugg : <TAB> <TAB> <TAB> <TAB> sugg . append ( entry ) <TAB> return sugg","if isinstance ( compare_entry , str ) :",if self . settings . get ( IGNORE_CASE_SETTING ) :,False,93.06,70.18,,,
"def marker_expr ( remaining ) : <TAB> if remaining and remaining [ 0 ] == "" ( "" : <TAB> <TAB> result , remaining = marker ( remaining [ 1 : ] . lstrip ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise SyntaxError ( "" unterminated parenthesis:  %s "" % remaining ) <TAB> <TAB> remaining = remaining [ 1 : ] . lstrip ( ) <TAB> else : <TAB> <TAB> lhs , remaining = marker_var ( remaining ) <TAB> <TAB> while remaining : <TAB> <TAB> <TAB> m = MARKER_OP . match ( remaining ) <TAB> <TAB> <TAB> if not m : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> op = m . groups ( ) [ 0 ] <TAB> <TAB> <TAB> remaining = remaining [ m . end ( ) : ] <TAB> <TAB> <TAB> rhs , remaining = marker_var ( remaining ) <TAB> <TAB> <TAB> lhs = { "" op "" : op , "" lhs "" : lhs , "" rhs "" : rhs } <TAB> <TAB> result = lhs <TAB> return result , remaining","if remaining [ 0 ] == "")"" :","if remaining [ 0 ] != "")"" :",False,99.1,73.99,,,
"def __repr__ ( self ) : <TAB> """""" Dump the class data in the format of a .netrc file. """""" <TAB> rep = "" "" <TAB> for host in self . hosts . keys ( ) : <TAB> <TAB> attrs = self . hosts [ host ] <TAB> <TAB> rep = rep + "" machine  "" + host + "" \n \t login  "" + repr ( attrs [ 0 ] ) + "" \n "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rep = rep + "" account  "" + repr ( attrs [ 1 ] ) <TAB> <TAB> rep = rep + "" \t password  "" + repr ( attrs [ 2 ] ) + "" \n "" <TAB> for macro in self . macros . keys ( ) : <TAB> <TAB> rep = rep + "" macdef  "" + macro + "" \n "" <TAB> <TAB> for line in self . macros [ macro ] : <TAB> <TAB> <TAB> rep = rep + line <TAB> <TAB> rep = rep + "" \n "" <TAB> return rep",if attrs [ 1 ] :,if attrs [ 1 ] :,True,100.0,74.65,,,
"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB> <TAB> id_ = required_key ( item , "" id "" ) <TAB> <TAB> controls_ids = required_key ( item , "" controls "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if controls_ids != "" all "" : <TAB> <TAB> <TAB> <TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> id_ = id_ , controls = str ( controls_ids ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError ( msg ) <TAB> <TAB> self . policies [ id_ ] = controls_ids","if id_ != ""all"" :","if not isinstance ( controls_ids , list ) :",False,94.98,65.7,,,
"def __set__ ( self , obj , value ) : # noqa <TAB> if ( <TAB> <TAB> value is not None <TAB> <TAB> and self.field._currency_field.null <TAB> <TAB> and not isinstance(value, MONEY_CLASSES + (Decimal,)) <TAB> ): <TAB> <TAB> # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB> <TAB> raise ValueError(""Missing currency value"") <TAB> if isinstance(value, BaseExpression): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = self.prepare_value(obj, value.value) <TAB> <TAB> elif not isinstance(value, Func): <TAB> <TAB> <TAB> validate_money_expression(obj, value) <TAB> <TAB> <TAB> prepare_expression(value) <TAB> else: <TAB> <TAB> value = self.prepare_value(obj, value) <TAB> obj.__dict__[self.field.name] = value",if value . value is not None :,"if isinstance ( value , Value ) :",False,97.08,71.13,,,
"def Children ( self ) : <TAB> """""" Returns a list of all of this object ' s owned (strong) children. """""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB> <TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not is_list : <TAB> <TAB> <TAB> <TAB> children . append ( self . _properties [ property ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> children . extend ( self . _properties [ property ] ) <TAB> return children",if is_strong :,if is_strong and property in self . _properties :,False,95.13,91.88,,,
"def next_item ( self , direction ) : <TAB> """""" Selects next menu item, based on self._direction """""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> start = 0",if i == 0 :,if start < 0 :,False,98.4,98.39,,,
"def setup_displace ( self ) : <TAB> self . displace_mod = None <TAB> self . displace_strength = 0.020 <TAB> for mod in self . obj . modifiers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . displace_mod = mod <TAB> <TAB> <TAB> self . displace_strength = mod . strength <TAB> if not self . displace_mod : <TAB> <TAB> bpy . ops . object . modifier_add ( type = "" DISPLACE "" ) <TAB> <TAB> self . displace_mod = self . obj . modifiers [ - 1 ] <TAB> <TAB> self . displace_mod . show_expanded = False <TAB> <TAB> self . displace_mod . strength = self . displace_strength <TAB> <TAB> self . displace_mod . show_render = False <TAB> <TAB> self . displace_mod . show_viewport = False","if mod . type == ""DISPLACE"" :","if mod . type == ""DISPLACE"" :",True,100.0,74.52,,,
"def set_json_body ( cls , request_builder ) : <TAB> old_body = request_builder . info . pop ( "" data "" , { } ) <TAB> if isinstance ( old_body , abc . Mapping ) : <TAB> <TAB> body = request_builder . info . setdefault ( "" json "" , { } ) <TAB> <TAB> for path in old_body : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cls . _sequence_path_resolver ( path , old_body [ path ] , body ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> body [ path ] = old_body [ path ] <TAB> else : <TAB> <TAB> request_builder . info . setdefault ( "" json "" , old_body )","if isinstance ( old_body [ path ] , abc . Mapping ) :","if isinstance ( path , tuple ) :",False,94.56,71.88,,,
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" DBLL "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,True,100.0,74.46,,,
"def test_prefix_lm ( self ) : <TAB> num_tries = 100 <TAB> original = "" This is a long test with lots of words to see if it works ok. "" <TAB> dataset = tf . data . Dataset . from_tensor_slices ( { "" text "" : [ original ] * num_tries } ) <TAB> dataset = prep . prefix_lm ( dataset ) <TAB> for data in test_utils . dataset_as_text ( dataset ) : <TAB> <TAB> inputs = data [ "" inputs "" ] . replace ( "" prefix:  "" , "" "" ) <TAB> <TAB> targets = data [ "" targets "" ] <TAB> <TAB> reconstructed = "" "" . join ( inputs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> reconstructed + = "" "" <TAB> <TAB> reconstructed + = "" "" . join ( targets ) <TAB> <TAB> self . assertEqual ( reconstructed , original )",if targets :,if inputs :,False,98.8,73.73,,,
"def leading_whitespace ( self , inputstring ) : <TAB> """""" Get leading whitespace. """""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB> <TAB> if c in legal_indent_chars : <TAB> <TAB> <TAB> leading_ws . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . indchar = c <TAB> <TAB> elif c != self . indchar : <TAB> <TAB> <TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws )","if c == ""\t"" :",if self . indchar is None :,False,95.31,90.54,,,
"def __init__ ( self , text ) : <TAB> self . mappings = { } <TAB> self . attributes = collections . defaultdict ( set ) <TAB> for stanza in _ParseTextProperties ( text ) : <TAB> <TAB> processor_id , single_values , multiple_values = self . _ParseStanza ( stanza ) <TAB> <TAB> if processor_id is None : # can be 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging.warn(""Processor id %s seen twice in %s"", processor_id, text) <TAB> <TAB> <TAB> continue <TAB> <TAB> self.mappings[processor_id] = single_values <TAB> <TAB> for key, value in multiple_values.items(): <TAB> <TAB> <TAB> self.attributes[key].add(value)",if processor_id in self . mappings :,if processor_id in self . mappings :,True,100.0,74.42,,,
"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> elif self . wait_counter < self . wait_cntr_max : <TAB> <TAB> <TAB> self . wait_counter + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB> <TAB> <TAB> <TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( self . poll_period )",if self . wait_counter == 0 :,if chunk is not None :,False,95.65,71.62,,,
"def download ( self , prefetch = False ) : <TAB> while self . running : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ( path , start , end ) = self . prefetch_queue . get ( <TAB> <TAB> <TAB> <TAB> <TAB> True , 1 <TAB> <TAB> <TAB> <TAB> ) # 1 second time-out <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> (path, start, end) = self.download_queue.get( <TAB> <TAB> <TAB> <TAB> <TAB> True, 1 <TAB> <TAB> <TAB> <TAB> ) # 1 second time-out <TAB> <TAB> <TAB> self.download_data(path, start, end) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.prefetch_queue.task_done() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.download_queue.task_done() <TAB> <TAB> except Queue.Empty: <TAB> <TAB> <TAB> pass",if prefetch :,if prefetch :,True,100.0,74.49,,,
"def process_messages ( self , found_files , messages ) : <TAB> for message in messages : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message . to_absolute_path ( self . config . workdir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> message . to_relative_path ( self . config . workdir ) <TAB> if self . config . blending : <TAB> <TAB> messages = blender . blend ( messages ) <TAB> filepaths = found_files . iter_module_paths ( abspath = False ) <TAB> return postfilter . filter_messages ( filepaths , self . config . workdir , messages )",if self . config . include_base :,if self . config . absolute_paths :,False,97.2,73.12,,,
"def set_indentation_params ( self , ispythonsource , guess = 1 ) : <TAB> if guess and ispythonsource : <TAB> <TAB> i = self . guess_indent ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . indentwidth = i <TAB> <TAB> if self . indentwidth != self . tabwidth : <TAB> <TAB> <TAB> self . usetabs = 0 <TAB> self . editwin . set_tabwidth ( self . tabwidth )",if i > self . indentwidth :,if 2 <= i <= 8 :,False,92.58,69.94,,,
"def to_tree ( self , tagname = None , value = None , namespace = None ) : <TAB> namespace = getattr ( self , "" namespace "" , namespace ) <TAB> if value is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tagname = "" { %s } %s "" % ( namespace , tagname ) <TAB> <TAB> el = Element ( tagname ) <TAB> <TAB> el . text = safe_string ( value ) <TAB> <TAB> return el",if namespace :,if namespace is not None :,False,96.09,71.16,,,
"def execute ( self , argv : List ) - > bool : <TAB> if not argv : <TAB> <TAB> print ( "" ERROR: You must give at least one module to download. "" ) <TAB> <TAB> return False <TAB> for _arg in argv : <TAB> <TAB> result = module_server . search_module ( _arg ) <TAB> <TAB> CacheUpdater ( "" hub_download "" , _arg ) . start ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> url = result [ 0 ] [ "" url "" ] <TAB> <TAB> <TAB> with log . ProgressBar ( "" Download  {} "" . format ( url ) ) as bar : <TAB> <TAB> <TAB> <TAB> for file , ds , ts in utils . download_with_progress ( url ) : <TAB> <TAB> <TAB> <TAB> <TAB> bar . update ( float ( ds ) / ts ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" ERROR: Could not find a HubModule named  {} "" . format ( _arg ) ) <TAB> return True",if result :,if result :,True,100.0,74.64,,,
"def visit_type_type ( self , t : TypeType ) - > ProperType : <TAB> if isinstance ( self . s , TypeType ) : <TAB> <TAB> typ = self . meet ( t . item , self . s . item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> typ = TypeType . make_normalized ( typ , line = t . line ) <TAB> <TAB> return typ <TAB> elif isinstance ( self . s , Instance ) and self . s . type . fullname == "" builtins.type "" : <TAB> <TAB> return t <TAB> elif isinstance ( self . s , CallableType ) : <TAB> <TAB> return self . meet ( t , self . s ) <TAB> else : <TAB> <TAB> return self . default ( self . s )",if typ . is_normalized ( ) :,"if not isinstance ( typ , NoneType ) :",False,96.19,71.93,,,
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . name ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,True,100.0,74.38,,,
"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB> <TAB> <TAB> except GObject.GError as ge: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB> <TAB> theme = Gtk.IconTheme() <TAB> <TAB> if theme.has_icon(icon_name): <TAB> <TAB> <TAB> return theme.load_icon(icon_name, 24, 0)",if os . path . isabs ( self . icon ) :,if os . path . exists ( self . icon ) :,False,98.88,73.04,,,
"def setup_logger ( ) : <TAB> """""" Set up logger and add stdout handler """""" <TAB> logging . setLoggerClass ( IPDLogger ) <TAB> logger = logging . getLogger ( "" icloudpd "" ) <TAB> has_stdout_handler = False <TAB> for handler in logger . handlers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> has_stdout_handler = True <TAB> if not has_stdout_handler : <TAB> <TAB> formatter = logging . Formatter ( <TAB> <TAB> <TAB> fmt = "" %(asctime)s %(levelname)-8s %(message)s "" , datefmt = "" % Y- % m- %d % H: % M: % S "" <TAB> <TAB> ) <TAB> <TAB> stdout_handler = logging . StreamHandler ( stream = sys . stdout ) <TAB> <TAB> stdout_handler . setFormatter ( formatter ) <TAB> <TAB> stdout_handler . name = "" stdoutLogger "" <TAB> <TAB> logger . addHandler ( stdout_handler ) <TAB> return logger","if handler . name == ""stdoutLogger"" :","if handler . name == ""stdoutLogger"" :",True,100.0,99.56,,,
"def process_extra_fields ( self ) : <TAB> if self . instance . pk is not None : <TAB> <TAB> if self . cleaned_data . get ( "" initialize "" , None ) : <TAB> <TAB> <TAB> self . instance . initialize ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . instance . update_from_templates ( )","if self . cleaned_data . get ( ""update"" , None ) :","if self . cleaned_data . get ( ""update"" , None ) or not self . instance . stores . count ( ) :",False,89.2,66.41,,,
"def testFunctions ( self ) : <TAB> from zim . formats . wiki import match_url , is_url <TAB> for input , input_is_url , tail in self . examples : <TAB> <TAB> if input_is_url : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , input [ : - len ( tail ) ] ) <TAB> <TAB> <TAB> <TAB> self . assertFalse ( is_url ( input ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , input ) <TAB> <TAB> <TAB> <TAB> self . assertTrue ( is_url ( input ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , None ) <TAB> <TAB> <TAB> self . assertFalse ( is_url ( input ) )",if tail :,if tail :,True,100.0,74.54,,,
"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB> <TAB> username = user [ 0 ] <TAB> <TAB> settings = user [ 1 ] <TAB> <TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB> <TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" joined "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB> <TAB> <TAB> elif "" left "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . removeUser ( username ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _client . userlist . modUser ( username , room , file_ )",if username :,"if ""event"" in settings :",False,97.17,70.39,,,
"def restoreTerminals ( self , state ) : <TAB> for name in list ( self . terminals . keys ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . removeTerminal ( name ) <TAB> for name , opts in state . items ( ) : <TAB> <TAB> if name in self . terminals : <TAB> <TAB> <TAB> term = self [ name ] <TAB> <TAB> <TAB> term . setOpts ( * * opts ) <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> opts = strDict ( opts ) <TAB> <TAB> <TAB> self . addTerminal ( name , * * opts ) <TAB> <TAB> except : <TAB> <TAB> <TAB> printExc ( "" Error restoring terminal  %s  ( %s ): "" % ( str ( name ) , str ( opts ) ) )",if name in state :,if name not in state :,False,98.78,73.56,,,
"def htmlify ( path , text ) : <TAB> fname = os . path . basename ( path ) <TAB> if any ( ( fnmatch . fnmatchcase ( fname , p ) for p in _patterns ) ) : <TAB> <TAB> # Get file_id, skip if not in database <TAB> <TAB> sql = ""SELECT files.id FROM files WHERE path = ? LIMIT 1"" <TAB> <TAB> row = _conn.execute(sql, (path,)).fetchone() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ClangHtmlifier(_tree, _conn, path, text, row[0]) <TAB> return None",if row :,if row :,True,100.0,74.29,,,
"def autoformat_filter_conv2d ( fsize , in_depth , out_depth ) : <TAB> if isinstance ( fsize , int ) : <TAB> <TAB> return [ fsize , fsize , in_depth , out_depth ] <TAB> elif isinstance ( fsize , ( tuple , list , tf . TensorShape ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ fsize [ 0 ] , fsize [ 1 ] , in_depth , out_depth ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" filter length error:  "" <TAB> <TAB> <TAB> <TAB> + str ( len ( fsize ) ) <TAB> <TAB> <TAB> <TAB> + "" , only a length of 2 is supported. "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" filter format error:  "" + str ( type ( fsize ) ) )",if len ( fsize ) == 2 :,if len ( fsize ) == 2 :,True,100.0,74.58,,,
"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if count : <TAB> <TAB> <TAB> <TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new + = bytes ( [ cur ] ) <TAB> return new","if cur == b""#"" :",if not cur :,False,94.2,65.04,,,
"def is_clean ( self ) : <TAB> acceptable_statuses = { "" external "" , "" unversioned "" } <TAB> root = self . _capture_output ( "" status "" , "" --quiet "" ) <TAB> for elem in root . findall ( "" ./target/entry "" ) : <TAB> <TAB> status = elem . find ( "" ./wc-status "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> log . debug ( "" Path  %s  is  %s "" , elem . get ( "" path "" ) , status . get ( "" item "" ) ) <TAB> <TAB> return False <TAB> return True","if status . get ( ""item"" ) not in acceptable_statuses :","if status . get ( ""item"" , None ) in acceptable_statuses :",False,97.36,72.45,,,
"def process ( self , body , message ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> ' Received an unexpected type  "" %s ""  for payload. ' % type ( body ) <TAB> <TAB> <TAB> ) <TAB> <TAB> response = self . _handler . pre_ack_process ( body ) <TAB> <TAB> self . _dispatcher . dispatch ( self . _process_message , response ) <TAB> except : <TAB> <TAB> LOG . exception ( "" %s  failed to process message:  %s "" , self . __class__ . __name__ , body ) <TAB> finally : <TAB> <TAB> # At this point we will always ack a message. <TAB> <TAB> message.ack()","if not isinstance ( body , ( Message , Message ) ) :","if not isinstance ( body , self . _handler . message_type ) :",False,95.39,72.0,,,
"def page_file ( self , page ) : <TAB> try : <TAB> <TAB> page = self . notebook . get_page ( page ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return page . source <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> except PageNotFoundError : <TAB> <TAB> return None",if page . is_file ( ) :,"if hasattr ( page , ""source"" ) and isinstance ( page . source , File ) :",False,83.53,54.64,,,
"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif silhouette < = best_silhouette : <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a , best_silhouette , best_k",if a > best_a :,if best_silhouette is None :,False,95.89,70.99,,,
"def _cancel_tasks_for_partitions ( self , to_cancel_partitions ) : <TAB> # type: (Iterable[str]) -> None <TAB> with self._lock: <TAB> <TAB> _LOGGER.debug( <TAB> <TAB> <TAB> ""EventProcessor %r tries to cancel partitions %r"", <TAB> <TAB> <TAB> self._id, <TAB> <TAB> <TAB> to_cancel_partitions, <TAB> <TAB> ) <TAB> <TAB> for partition_id in to_cancel_partitions: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self._consumers[partition_id].stop = True <TAB> <TAB> <TAB> <TAB> _LOGGER.info( <TAB> <TAB> <TAB> <TAB> <TAB> ""EventProcessor %r has cancelled partition %r"", <TAB> <TAB> <TAB> <TAB> <TAB> self._id, <TAB> <TAB> <TAB> <TAB> <TAB> partition_id, <TAB> <TAB> <TAB> <TAB> )",if partition_id in self . _consumers :,if partition_id in self . _consumers :,True,100.0,74.35,,,
"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else : <TAB> <TAB> <TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB> <TAB> return None <TAB> elif len ( result ) == 1 : <TAB> <TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB> <TAB> solids = [ p . item for p in result ] <TAB> <TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB> <TAB> if refine : <TAB> <TAB> <TAB> solid = solid . removeSplitter ( ) <TAB> <TAB> return solid","if source == ""intersection"" :",if result is None :,False,96.38,64.38,,,
"def geli_detach ( self , pool , clear = False ) : <TAB> failed = 0 <TAB> for ed in self . middleware . call_sync ( <TAB> <TAB> "" datastore.query "" , <TAB> <TAB> "" storage.encrypteddisk "" , <TAB> <TAB> [ ( "" encrypted_volume "" , "" = "" , pool [ "" id "" ] ) ] , <TAB> ) : <TAB> <TAB> dev = ed [ "" encrypted_provider "" ] <TAB> <TAB> try : <TAB> <TAB> <TAB> self . geli_detach_single ( dev ) <TAB> <TAB> except Exception as ee : <TAB> <TAB> <TAB> self . logger . warn ( str ( ee ) ) <TAB> <TAB> <TAB> failed + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . geli_clear ( dev ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> self . logger . warn ( "" Failed to clear  %s :  %s "" , dev , e ) <TAB> return failed",if clear :,if clear :,True,100.0,74.62,,,
def compute_lengths ( batch_sizes ) : <TAB> tmp_batch_sizes = np . copy ( batch_sizes ) <TAB> lengths = [ ] <TAB> while True : <TAB> <TAB> c = np . count_nonzero ( tmp_batch_sizes > 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> lengths . append ( c ) <TAB> <TAB> tmp_batch_sizes = np . array ( [ b - 1 for b in tmp_batch_sizes ] ) <TAB> return np . array ( lengths ),if c == 0 :,if c == 0 :,True,100.0,99.24,,,
"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flatten_items . append ( b "" "" ) <TAB> <TAB> elif isinstance ( item , bytes ) : <TAB> <TAB> <TAB> flatten_items . append ( item ) <TAB> <TAB> elif isinstance ( item , int ) : <TAB> <TAB> <TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB> <TAB> elif isinstance ( item , list ) : <TAB> <TAB> <TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items )","if isinstance ( item , str ) :",if item is None :,False,96.13,71.63,,,
"def update ( self , new_config ) : <TAB> jsonschema . validate ( new_config , self . schema ) <TAB> config = { } <TAB> for k , v in new_config . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> config [ k ] = self [ k ] <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ k ] = v <TAB> self . _config = config <TAB> self . changed ( )","if isinstance ( self [ k ] , dict ) :","if k in self . schema . get ( ""secret"" , [ ] ) and v == SECRET_PLACEHOLDER :",False,83.42,56.7,,,
"def _encode_numpy ( values , uniques = None , encode = False , check_unknown = True ) : <TAB> # only used in _encode below, see docstring there for details <TAB> if uniques is None: <TAB> <TAB> if encode: <TAB> <TAB> <TAB> uniques, encoded = np.unique(values, return_inverse=True) <TAB> <TAB> <TAB> return uniques, encoded <TAB> <TAB> else: <TAB> <TAB> <TAB> # unique sorts <TAB> <TAB> <TAB> return np.unique(values) <TAB> if encode: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> diff = _encode_check_unknown(values, uniques) <TAB> <TAB> <TAB> if diff: <TAB> <TAB> <TAB> <TAB> raise ValueError(""y contains previously unseen labels: %s"" % str(diff)) <TAB> <TAB> encoded = np.searchsorted(uniques, values) <TAB> <TAB> return uniques, encoded <TAB> else: <TAB> <TAB> return uniques",if check_unknown :,if check_unknown :,True,100.0,74.49,,,
"def restore_dtype_and_merge ( arr , input_dtype ) : <TAB> if isinstance ( arr , list ) : <TAB> <TAB> arr = [ restore_dtype_and_merge ( arr_i , input_dtype ) for arr_i in arr ] <TAB> <TAB> shapes = [ arr_i . shape for arr_i in arr ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> arr = np . array ( arr ) <TAB> if ia . is_np_array ( arr ) : <TAB> <TAB> arr = iadt . restore_dtypes_ ( arr , input_dtype ) <TAB> return arr",if shapes == [ ] :,if len ( set ( shapes ) ) == 1 :,False,93.16,69.1,,,
"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB> <TAB> if diff_min is not None and diff_min != 0 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d","if expanded [ 0 ] [ 0 ] == ""*"" :",if is_prev :,False,92.47,63.22,,,
"def _populate_tree ( self , element , d ) : <TAB> """""" Populates an etree with attributes & elements, given a dict. """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v )","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.6,,,
"def __createItemAttribute ( self , item , function , preload ) : <TAB> """""" Create the new widget, add it, and remove the old one """""" <TAB> try : <TAB> <TAB> self . __stack . addWidget ( function ( item , preload ) ) <TAB> <TAB> # Remove the widget <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> oldWidget = self.__stack.widget(0) <TAB> <TAB> <TAB> self.__stack.removeWidget(oldWidget) <TAB> <TAB> <TAB> oldWidget.setParent(QtWidgets.QWidget()) <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __stack . widget ( 0 ) is not None :,if self . __stack . count ( ) > 1 :,False,95.6,95.25,,,
"def __createItemAttribute ( self , item , function , preload ) : <TAB> """""" Create the new widget, add it, and remove the old one """""" <TAB> try : <TAB> <TAB> self . __stack . addWidget ( function ( item , preload ) ) <TAB> <TAB> # Remove the widget <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> oldWidget = self.__stack.widget(0) <TAB> <TAB> <TAB> self.__stack.removeWidget(oldWidget) <TAB> <TAB> <TAB> oldWidget.setParent(QtWidgets.QWidget()) <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __stack . widget ( 0 ) is not None :,"if url . startswith ( ""https://"" ) :",False,92.45,93.87,,,
"def __createItemAttribute ( self , item , function , preload ) : <TAB> """""" Create the new widget, add it, and remove the old one """""" <TAB> try : <TAB> <TAB> self . __stack . addWidget ( function ( item , preload ) ) <TAB> <TAB> # Remove the widget <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> oldWidget = self.__stack.widget(0) <TAB> <TAB> <TAB> self.__stack.removeWidget(oldWidget) <TAB> <TAB> <TAB> oldWidget.setParent(QtWidgets.QWidget()) <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if self . __stack . widget ( 0 ) is not None :,"if isinstance ( o , Iterable )",False,91.77,93.44,,,
"def ensemble ( self , pairs , other_preds ) : <TAB> """""" Ensemble the dict with statistical model predictions. """""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> if ( w , pos ) in self . composite_dict : <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> elif w in self . word_dict : <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas",elif pred == self . word_dict :,if lemma is None :,False,95.21,91.88,,,
"def replace_to_6hex ( color ) : <TAB> """""" Validate and replace 3hex colors to 6hex ones. """""" <TAB> if match ( r "" ^#(?:[0-9a-fA-F] {3} ) { 1,2}$ "" , color ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> color = "" # {0} {0} {1} {1} {2} {2} "" . format ( color [ 1 ] , color [ 2 ] , color [ 3 ] ) <TAB> <TAB> return color <TAB> else : <TAB> <TAB> exit ( _ ( "" Invalid color  {} "" ) . format ( color ) )","if color [ 0 ] == ""#3"" :",if len ( color ) == 4 :,False,93.48,70.87,,,
"def computeMachineName ( self ) : <TAB> """""" Return the name of the current machine, i.e, HOSTNAME. """""" <TAB> # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB> # to give the machine-specific setting name. <TAB> # How can this be worth doing?? <TAB> try: <TAB> <TAB> import os <TAB> <TAB> name = os.getenv(""HOSTNAME"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = os.getenv(""COMPUTERNAME"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> import socket <TAB> <TAB> <TAB> name = socket.gethostname() <TAB> except Exception: <TAB> <TAB> name = """" <TAB> return name","if name == ""leoSettings.leo"" :",if not name :,False,90.42,70.04,,,
"def _git_dirty_working_directory ( q , include_untracked ) : <TAB> try : <TAB> <TAB> cmd = [ "" git "" , "" status "" , "" --porcelain "" ] <TAB> <TAB> if include_untracked : <TAB> <TAB> <TAB> cmd + = [ "" --untracked-files=normal "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> cmd + = [ "" --untracked-files=no "" ] <TAB> <TAB> status = _run_git_cmd ( cmd ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> q . put ( bool ( status ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> q . put ( None ) <TAB> except ( subprocess . CalledProcessError , OSError , FileNotFoundError ) : <TAB> <TAB> q . put ( None )",if status :,if status is not None :,False,97.68,72.19,,,
"def runAndWaitWork ( server , work ) : <TAB> work . touch ( ) <TAB> thr = threading . Thread ( target = workThread , args = ( server , work ) ) <TAB> thr . setDaemon ( True ) <TAB> thr . start ( ) <TAB> # Wait around for done or timeout <TAB> while True: <TAB> <TAB> if work.isTimedOut(): <TAB> <TAB> <TAB> break <TAB> <TAB> # If the thread is done, lets get out. <TAB> <TAB> if not thr.isAlive(): <TAB> <TAB> <TAB> break <TAB> <TAB> # If our parent, or some thread closes stdin, <TAB> <TAB> # time to pack up and go. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(2)",if thr . isAlive ( ) :,if sys . stdin . closed :,False,96.84,71.97,,,
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> if DEBUG_COMM : <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise",if ignore_non_errors and is_non_errors ( e ) :,if ignore_non_errors and is_noerr ( e ) :,False,98.05,73.61,,,
"def PrintHeader ( self ) : # print the header array <TAB> if self.draw == False: <TAB> <TAB> return <TAB> for val in self.parent.header: <TAB> <TAB> self.SetPrintFont(val[""Font""]) <TAB> <TAB> header_indent = val[""Indent""] * self.pwidth <TAB> <TAB> text = val[""Text""] <TAB> <TAB> htype = val[""Type""] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> addtext = self.GetDate() <TAB> <TAB> elif htype == ""Date & Time"": <TAB> <TAB> <TAB> addtext = self.GetDateTime() <TAB> <TAB> else: <TAB> <TAB> <TAB> addtext = """" <TAB> <TAB> self.OutTextPageWidth( <TAB> <TAB> <TAB> text + addtext, self.pheader_margin, val[""Align""], header_indent, True <TAB> <TAB> )","if htype == ""Date"" :","if htype == ""Date"" :",True,100.0,99.35,,,
"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB> <TAB> if result is None : <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else : <TAB> <TAB> <TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB> <TAB> return None <TAB> elif len ( result ) == 1 : <TAB> <TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB> <TAB> solids = [ p . item for p in result ] <TAB> <TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> solid = solid . removeSplitter ( ) <TAB> <TAB> return solid",if refine :,if refine :,True,100.0,74.56,,,
"def captured_updateNode ( self , context ) : <TAB> if not self . updating_name_from_pointer : <TAB> <TAB> font_datablock = self . get_bpy_data_from_name ( self . fontname , bpy . data . fonts ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . font_pointer = font_datablock <TAB> <TAB> <TAB> updateNode ( self , context )",if font_datablock :,if font_datablock :,True,100.0,73.85,,,
"def __add__ ( self , other ) : <TAB> if isinstance ( other , Vector2 ) : <TAB> <TAB> # Vector + Vector -> Vector <TAB> <TAB> # Vector + Point -> Point <TAB> <TAB> # Point + Point -> Vector <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _class = Vector2 <TAB> <TAB> else: <TAB> <TAB> <TAB> _class = Point2 <TAB> <TAB> return _class(self.x + other.x, self.y + other.y) <TAB> else: <TAB> <TAB> assert hasattr(other, ""__len__"") and len(other) == 2 <TAB> <TAB> return Vector2(self.x + other[0], self.y + other[1])",if self . __class__ is other . __class__ :,if self . __class__ is other . __class__ :,True,100.0,74.35,,,
"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """""" Take a nested dict and return a flat dict of setting values. """""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setting_values . update ( <TAB> <TAB> <TAB> <TAB> self . _flatten_settings_from_form ( <TAB> <TAB> <TAB> <TAB> <TAB> settings , field , form_values [ field . _name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif field . _name in settings : <TAB> <TAB> <TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values",if field . _name in form_values :,"if isinstance ( field , _ContainerMixin ) :",False,95.8,94.13,,,
"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> if hasattr(a, ""includedirs""): <TAB> <TAB> <TAB> a = a.includedirs <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidArguments( <TAB> <TAB> <TAB> <TAB> ""Include directory to be added is not an include directory object."" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids.append(a) <TAB> self.include_dirs += ids","if not isinstance ( a , ( list , tuple ) ) :","if not isinstance ( a , IncludeDirs ) :",False,95.97,71.62,,,
"def _clip_array ( array , config ) : <TAB> if "" threshold "" in config . keys ( ) : <TAB> <TAB> threshold = config [ "" threshold "" ] <TAB> else : <TAB> <TAB> abs_array = np . max ( np . abs ( array ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return array <TAB> <TAB> threshold = np . percentile ( np . abs ( array ) , 99.99 ) <TAB> return np . clip ( array , - threshold , threshold )",if abs_array < 0.5 :,if abs_array < 1.0 :,False,97.96,72.91,,,
def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield from dfs ( w ) <TAB> <TAB> elif w not in identified : <TAB> <TAB> <TAB> while index [ w ] < boundaries [ - 1 ] : <TAB> <TAB> <TAB> <TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB> <TAB> boundaries . pop ( ) <TAB> <TAB> scc = set ( stack [ index [ v ] : ] ) <TAB> <TAB> del stack [ index [ v ] : ] <TAB> <TAB> identified . update ( scc ) <TAB> <TAB> yield scc,if w in edges :,if w not in index :,False,98.04,98.19,,,
"def create_balancer ( <TAB> self , name , members , protocol = "" http "" , port = 80 , algorithm = DEFAULT_ALGORITHM ) : <TAB> balancer = self . ex_create_balancer_nowait ( name , members , protocol , port , algorithm ) <TAB> timeout = 60 * 20 <TAB> waittime = 0 <TAB> interval = 2 * 15 <TAB> if balancer . id is not None : <TAB> <TAB> return balancer <TAB> else : <TAB> <TAB> while waittime < timeout : <TAB> <TAB> <TAB> balancers = self . list_balancers ( ) <TAB> <TAB> <TAB> for i in balancers : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> waittime + = interval <TAB> <TAB> <TAB> time . sleep ( interval ) <TAB> raise Exception ( "" Failed to get id "" )",if i . id is not None :,if i . name == balancer . name and i . id is not None :,False,95.94,71.87,,,
"def handle ( self , scope : Scope , receive : Receive , send : Send ) - > None : <TAB> if self . methods and scope [ "" method "" ] not in self . methods : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise HTTPException ( status_code = 405 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = PlainTextResponse ( "" Method Not Allowed "" , status_code = 405 ) <TAB> <TAB> await response ( scope , receive , send ) <TAB> else : <TAB> <TAB> await self . app ( scope , receive , send )","if scope [ ""method"" ] in self . methods :","if ""app"" in scope :",False,92.75,71.4,,,
"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB> if isinstance(d, tuple) and len(d) == 2: <TAB> <TAB> <TAB> result.append((d[0], None, d[1])) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.append(d) <TAB> return result","elif isinstance ( d , str ) and d [ 0 ] == ""0"" and d [ 1 ] == ""0"" :","elif isinstance ( d , basestring ) :",False,82.3,57.75,,,
"def register_adapters ( ) : <TAB> global adapters_registered <TAB> if adapters_registered is True : <TAB> <TAB> return <TAB> try : <TAB> <TAB> import pkg_resources <TAB> <TAB> packageDir = pkg_resources . resource_filename ( "" pyamf "" , "" adapters "" ) <TAB> except : <TAB> <TAB> packageDir = os . path . dirname ( __file__ ) <TAB> for f in glob . glob ( os . path . join ( packageDir , "" *.py "" ) ) : <TAB> <TAB> mod = os . path . basename ( f ) . split ( os . path . extsep , 1 ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> register_adapter ( mod [ 1 : ] . replace ( "" _ "" , "" . "" ) , PackageImporter ( mod ) ) <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> pass <TAB> adapters_registered = True","if mod == ""__init__"" :","if mod == ""__init__"" or not mod . startswith ( ""_"" ) :",False,95.48,68.06,,,
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> if module is None or not hasattr ( module , attr ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr ( module , "" aliases "" ) : <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( )",if alias not in excluded_aliases :,if alias not in excluded_aliases :,True,100.0,74.63,,,
"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB> <TAB> if item . has_variations : <TAB> <TAB> <TAB> if not any ( var . item == item for var in variations ) : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",if not item . has_event :,if event != item . event :,False,97.06,72.13,,,
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return element <TAB> <TAB> if element [ 3 ] and element [ 4 ] : <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> if not isinstance ( i , int ) : <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx",if element [ 0 ] and element [ 1 ] == num :,if idx == num :,False,94.3,71.46,,,
"def check ( chip , xeddb , chipdb ) : <TAB> all_inst = [ ] <TAB> undoc = [ ] <TAB> for inst in xeddb . recs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if inst . undocumented : <TAB> <TAB> <TAB> <TAB> undoc . append ( inst ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> all_inst . append ( inst ) <TAB> return ( all_inst , undoc )","if isinstance ( inst , chipdb . VIRT_XEDDB ) :",if inst . isa_set in chipdb [ chip ] :,False,91.66,68.58,,,
"def get_all_topic_src_files ( self ) : <TAB> """""" Retrieves the file paths of all the topics in directory """""" <TAB> topic_full_paths = [ ] <TAB> topic_names = os . listdir ( self . topic_dir ) <TAB> for topic_name in topic_names : <TAB> <TAB> # Do not try to load hidden files. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> topic_full_path = os.path.join(self.topic_dir, topic_name) <TAB> <TAB> <TAB> # Ignore the JSON Index as it is stored with topic files. <TAB> <TAB> <TAB> if topic_full_path != self.index_file: <TAB> <TAB> <TAB> <TAB> topic_full_paths.append(topic_full_path) <TAB> return topic_full_paths","if not os . path . isfile ( os . path . join ( self . topic_dir , topic_name ) ) :","if not topic_name . startswith ( ""."" ) :",False,90.72,93.78,,,
"def _get_element ( dom_msi , tag_name , name = None , id_ = None ) : <TAB> """""" Get a xml element defined on Product. """""" <TAB> product = dom_msi . getElementsByTagName ( "" Product "" ) [ 0 ] <TAB> elements = product . getElementsByTagName ( tag_name ) <TAB> for element in elements : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> element . getAttribute ( "" Name "" ) == name <TAB> <TAB> <TAB> <TAB> and element . getAttribute ( "" Id "" ) == id_ <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return element <TAB> <TAB> elif id_ : <TAB> <TAB> <TAB> if element . getAttribute ( "" Id "" ) == id_ : <TAB> <TAB> <TAB> <TAB> return element",if name :,if name and id_ :,False,97.96,96.63,,,
"def __init__ ( self , * models ) : <TAB> super ( ) . __init__ ( ) <TAB> self . models = ModuleList ( models ) <TAB> for m in models : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs) "" <TAB> <TAB> <TAB> ) <TAB> self . likelihood = LikelihoodList ( * [ m . likelihood for m in models ] )",if m . likelihood is None :,"if not hasattr ( m , ""likelihood"" ) :",False,92.48,62.66,,,
"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as fileobj : <TAB> <TAB> <TAB> header = fileobj . read ( 4 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> fileobj . read ( 1 ) # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj.read(1) <TAB> <TAB> <TAB> <TAB> if binascii.hexlify(ftype) == oxlitype: <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError: <TAB> <TAB> return False",if header == 0x00 :,"if header == b""OXLI"" :",False,96.77,66.17,,,
"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB> <TAB> key = str ( k ) <TAB> <TAB> if "" / "" not in key : <TAB> <TAB> <TAB> key + = "" /tcp "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result","if isinstance ( v , ( list , tuple ) ) :","if isinstance ( v , list ) :",False,96.12,72.31,,,
"def input_data ( self ) : <TAB> gen = self . config . generator <TAB> # don't try running the generator if we specify an output file explicitly, <TAB> # otherwise generator may segfault and we end up returning the output file anyway <TAB> if gen and (not self.config[""out""] or not self.config[""in""]): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._run_generator(gen, args=self.config.generator_args) <TAB> <TAB> if self._generated[0]: <TAB> <TAB> <TAB> return self._generated[0] <TAB> # in file is optional <TAB> return ( <TAB> <TAB> self._normalize(self.problem.problem_data[self.config[""in""]]) <TAB> <TAB> if self.config[""in""] <TAB> <TAB> else b"""" <TAB> )",if self . config . generator :,if self . _generated is None :,False,97.54,71.84,,,
"def __new__ ( cls , * tasks , * * kwargs ) : <TAB> # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB> if not kwargs and tasks: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tasks = tasks[0] if len(tasks) == 1 else tasks <TAB> <TAB> <TAB> return reduce(operator.or_, tasks) <TAB> return super(chain, cls).__new__(cls, *tasks, **kwargs)","if isinstance ( tasks , tuple ) :",if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) :,False,88.51,65.51,,,
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> if file_sources_as_dict is not None : <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources is None :,if file_sources is None :,True,100.0,74.52,,,
"def InitializeColours ( self ) : <TAB> """""" Initializes the 16 custom colours in :class:`CustomPanel`. """""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB> <TAB> c = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _customColours [ i ] = wx . WHITE <TAB> <TAB> if c == curr : <TAB> <TAB> <TAB> self . _colourSelection = i",if c == curr :,if c . IsOk ( ) :,False,96.79,93.82,,,
"def convert_obj_into_marshallable ( self , obj ) : <TAB> if isinstance ( obj , self . marshalable_types ) : <TAB> <TAB> return obj <TAB> if isinstance ( obj , array . array ) : <TAB> <TAB> if obj . typecode == "" c "" : <TAB> <TAB> <TAB> return obj . tostring ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return obj . tounicode ( ) <TAB> <TAB> return obj . tolist ( ) <TAB> return self . class_to_dict ( obj )","elif obj . typecode == ""b"" :","if obj . typecode == ""u"" :",False,96.31,71.27,,,
"def run ( self ) : <TAB> self . run_command ( "" egg_info "" ) <TAB> from glob import glob <TAB> for pattern in self . match : <TAB> <TAB> pattern = self . distribution . get_name ( ) + "" * "" + pattern <TAB> <TAB> files = glob ( os . path . join ( self . dist_dir , pattern ) ) <TAB> <TAB> files = [ ( os . path . getmtime ( f ) , f ) for f in files ] <TAB> <TAB> files . sort ( ) <TAB> <TAB> files . reverse ( ) <TAB> <TAB> log . info ( "" %d  file(s) matching  %s "" , len ( files ) , pattern ) <TAB> <TAB> files = files [ self . keep : ] <TAB> <TAB> for ( t , f ) in files : <TAB> <TAB> <TAB> log . info ( "" Deleting  %s "" , f ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . unlink ( f )",if os . path . exists ( f ) :,if not self . dry_run :,False,96.29,72.5,,,
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> if token . token_type == TOKEN_TEXT : <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars",elif token . token_type == TOKEN_VAR :,elif token . token_type == TOKEN_VAR :,True,100.0,74.38,,,
"def _handle_raise ( self , values , is_NAs , origins ) : <TAB> for is_NA , origin in zip ( is_NAs , origins ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> "" Missing values detected. If you want rows with missing  "" <TAB> <TAB> <TAB> <TAB> "" values to be automatically deleted in a list-wise  "" <TAB> <TAB> <TAB> <TAB> "" manner (not recommended), please set dropna=True in  "" <TAB> <TAB> <TAB> <TAB> "" the Bambi Model initialization. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise PatsyError ( msg , origin ) <TAB> return values","if not is_NA and not self . _is_na_set ( values , is_NA ) :",if np . any ( is_NA ) :,False,90.88,70.94,,,
"def add_node_data ( node_array , ntwk ) : <TAB> node_ntwk = nx . Graph ( ) <TAB> newdata = { } <TAB> for idx , data in ntwk . nodes ( data = True ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newdata [ "" value "" ] = node_array [ int ( idx ) - 1 ] <TAB> <TAB> <TAB> data . update ( newdata ) <TAB> <TAB> <TAB> node_ntwk . add_node ( int ( idx ) , * * data ) <TAB> return node_ntwk",if int ( idx ) > 0 :,if not int ( idx ) == 0 :,False,95.68,71.46,,,
"def safe_parse_date ( date_hdr ) : <TAB> """""" Parse a Date: or Received: header into a unix timestamp. """""" <TAB> try : <TAB> <TAB> if "" ; "" in date_hdr : <TAB> <TAB> <TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB> <TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB> <TAB> return None",if msg_ts < 0 :,if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) :,False,87.46,60.56,,,
"def _route_db ( self , model , * * hints ) : <TAB> chosen_db = None <TAB> for router in self . routers : <TAB> <TAB> try : <TAB> <TAB> <TAB> method = getattr ( router , action ) <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> # If the router doesn't have a method, skip to the next one. <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> chosen_db = method(model, **hints) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return chosen_db <TAB> try: <TAB> <TAB> return hints[""instance""]._state.db or DEFAULT_DB_ALIAS <TAB> except KeyError: <TAB> <TAB> return DEFAULT_DB_ALIAS",if chosen_db :,if chosen_db :,True,100.0,74.4,,,
"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB> <TAB> if not ignore_first_level : <TAB> <TAB> <TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB> <TAB> <TAB> res . extend ( keys ) <TAB> <TAB> for key in struct : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB> <TAB> for item in struct : <TAB> <TAB> <TAB> res . extend ( get_keys ( item ) ) <TAB> return res",if key in IGNORED_FIRST_LEVEL :,if key in IGNORED_KEYS :,False,98.17,73.82,,,
"def launch_app ( self , fs_id ) : <TAB> if fs_id in self . app_infos : <TAB> <TAB> row = self . get_row_by_fsid ( fs_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> app_info = self . app_infos [ fs_id ] <TAB> <TAB> filepath = os . path . join ( row [ SAVEDIR_COL ] , row [ SAVENAME_COL ] ) <TAB> <TAB> gfile = Gio . File . new_for_path ( filepath ) <TAB> <TAB> app_info . launch ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> gfile , <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> None , <TAB> <TAB> ) <TAB> <TAB> self . app_infos . pop ( fs_id , None )",if row [ SAVEDIR_COL ] == fs_id :,if not row :,False,94.63,72.15,,,
"def create_skipfile ( files_changed , skipfile ) : <TAB> # File is likely to contain some garbage values at start, <TAB> # only the corresponding json should be parsed. <TAB> json_pattern = re.compile(r""^\{.*\}"") <TAB> for line in files_changed.readlines(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for filename in json.loads(line): <TAB> <TAB> <TAB> <TAB> if ""/COMMIT_MSG"" in filename: <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> skipfile.write(""+*/%s\n"" % filename) <TAB> skipfile.write(""-*\n"")",if json_pattern . match ( line ) :,"if re . match ( json_pattern , line ) :",False,96.56,70.64,,,
"def zscore ( self , client , request , N ) : <TAB> check_input ( request , N != 2 ) <TAB> key = request [ 1 ] <TAB> db = client . db <TAB> value = db . get ( key ) <TAB> if value is None : <TAB> <TAB> client . reply_bulk ( None ) <TAB> elif not isinstance ( value , self . zset_type ) : <TAB> <TAB> client . reply_wrongtype ( ) <TAB> else : <TAB> <TAB> score = value . score ( request [ 2 ] , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> score = str ( score ) . encode ( "" utf-8 "" ) <TAB> <TAB> client . reply_bulk ( score )","if isinstance ( score , bytes ) :",if score is not None :,False,95.91,71.66,,,
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> if isinstance ( test , unittest . TestSuite ) : <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> elif isinstance ( test , unittest . TestCase ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) )","if test . name ( ) == ""test"" :",if support . match_test ( test ) :,False,90.11,60.41,,,
"def Run ( self ) : <TAB> """""" The main run method of the client. """""" <TAB> for thread in self . _threads . values ( ) : <TAB> <TAB> thread . start ( ) <TAB> logging . info ( START_STRING ) <TAB> while True : <TAB> <TAB> dead_threads = [ tn for ( tn , t ) in self . _threads . items ( ) if not t . isAlive ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise FatalError ( <TAB> <TAB> <TAB> <TAB> "" These threads are dead:  %r . Shutting down... "" % dead_threads <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 10 )",if dead_threads :,if dead_threads :,True,100.0,99.45,,,
"def _slice_queryset ( queryset , order_by , per_page , start ) : <TAB> page_len = int ( per_page ) + 1 <TAB> if start : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filter_name = "" %s __lte "" % order_by [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> filter_name = "" %s __gte "" % order_by <TAB> <TAB> return queryset . filter ( * * { filter_name : start } ) [ : page_len ] <TAB> return queryset [ : page_len ]","if order_by . startswith ( ""_"" ) :","if order_by . startswith ( ""-"" ) :",False,98.37,72.92,,,
"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB> <TAB> for _ in XRANGE ( 10 ) : <TAB> <TAB> <TAB> t1 = timer ( ) <TAB> <TAB> <TAB> t2 = timer ( ) <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt < = 0.0 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if precision is not None : <TAB> <TAB> <TAB> precision = min ( precision , dt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points + = 1 <TAB> <TAB> previous = timer ( ) <TAB> return precision",if dt <= 0.0 :,if 0 < dt :,False,98.11,73.28,,,
"def findWorkingDir ( ) : <TAB> frozen = getattr ( sys , "" frozen "" , "" "" ) <TAB> if not frozen : <TAB> <TAB> path = os . path . dirname ( __file__ ) <TAB> elif frozen in ( "" dll "" , "" console_exe "" , "" windows_exe "" , "" macosx_app "" ) : <TAB> <TAB> path = os . path . dirname ( <TAB> <TAB> <TAB> os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) ) <TAB> <TAB> ) <TAB> elif frozen : # needed for PyInstaller <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = getattr(sys, ""_MEIPASS"", """") # --onefile <TAB> <TAB> else: <TAB> <TAB> <TAB> path = os.path.dirname(sys.executable) # --onedir <TAB> else: <TAB> <TAB> path = """" <TAB> return path","if hasattr ( sys , ""_MEIPASS"" ) :","if getattr ( sys , ""_MEIPASS"" , """" ) is not None :",False,95.63,65.22,,,
"def CreateDataType ( vmodlName , wsdlName , parent , version , props ) : <TAB> with _lazyLock : <TAB> <TAB> dic = [ vmodlName , wsdlName , parent , version , props ] <TAB> <TAB> names = vmodlName . split ( "" . "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vmodlName = "" . "" . join ( name [ 0 ] . lower ( ) + name [ 1 : ] for name in names ) <TAB> <TAB> _AddToDependencyMap ( names ) <TAB> <TAB> typeNs = GetWsdlNamespace ( version ) <TAB> <TAB> _dataDefMap [ vmodlName ] = dic <TAB> <TAB> _wsdlDefMap [ ( typeNs , wsdlName ) ] = dic <TAB> <TAB> _wsdlTypeMapNSs . add ( typeNs )",if names :,if _allowCapitalizedNames :,False,97.89,73.44,,,
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)",if username not in knowledge_base . users :,if username not in self . _ignore_users :,False,97.41,72.71,,,
"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB> <TAB> if letter == "" < "" : <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "" > "" : <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if letter == "" "" : <TAB> <TAB> <TAB> <TAB> letter = "" _ "" <TAB> <TAB> <TAB> question + = letter . lower ( ) <TAB> return question",if not skip :,"if letter . isalnum ( ) or letter == "" "" :",False,92.66,65.05,,,
"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB> <TAB> for line in lines : <TAB> <TAB> <TAB> if gap : <TAB> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> <TAB> self . process ( line ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0",if self . _gap and self . _process_line ( line ) :,if not is_command ( line ) :,False,90.67,70.39,,,
"def _get ( self , domain ) : <TAB> with self . lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> record = self . cache [ domain ] <TAB> <TAB> <TAB> time_now = time . time ( ) <TAB> <TAB> <TAB> if time_now - record [ "" update "" ] > self . ttl : <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> record = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record",if record is None :,if not record :,False,97.81,72.82,,,
"def gen_constant_folding ( cw ) : <TAB> types = [ "" Int32 "" , "" Double "" , "" BigInteger "" , "" Complex "" ] <TAB> for cur_type in types : <TAB> <TAB> cw . enter_block ( "" if (constLeft.Value.GetType() == typeof( %s )) "" % ( cur_type , ) ) <TAB> <TAB> cw . enter_block ( "" switch (_op) "" ) <TAB> <TAB> for op in ops : <TAB> <TAB> <TAB> gen = getattr ( op , "" genConstantFolding "" , None ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> gen ( cw , cur_type ) <TAB> <TAB> cw . exit_block ( ) <TAB> <TAB> cw . exit_block ( )",if gen :,if gen is not None :,False,97.66,72.13,,,
"def unreferenced_dummy ( self ) : <TAB> for g , base in zip ( self . evgroups , self . evbases ) : <TAB> <TAB> for ind , j in enumerate ( g ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> debug_print ( <TAB> <TAB> <TAB> <TAB> <TAB> "" replacing unreferenced  %d %s  with dummy "" % ( ( base + ind ) , g [ ind ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> g [ ind ] = "" dummy "" <TAB> <TAB> <TAB> <TAB> self . evnum [ base + ind ] = "" dummy """,if j == base :,if not self . indexobj [ base + ind ] :,False,94.03,69.84,,,
"def handle_signature ( self , sig : str , signode : desc_signature ) - > Tuple [ str , str ] : <TAB> for cls in self . __class__ . __mro__ : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" PyDecoratorMixin is deprecated.  "" <TAB> <TAB> <TAB> <TAB> "" Please check the implementation of  %s "" % cls , <TAB> <TAB> <TAB> <TAB> RemovedInSphinx50Warning , <TAB> <TAB> <TAB> <TAB> stacklevel = 2 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> "" PyDecoratorMixin is deprecated "" , RemovedInSphinx50Warning , stacklevel = 2 <TAB> <TAB> ) <TAB> ret = super ( ) . handle_signature ( sig , signode ) # type: ignore <TAB> signode.insert(0, addnodes.desc_addname(""@"", ""@"")) <TAB> return ret",if cls . __name__ == sig :,"if cls . __name__ != ""DirectiveAdapter"" :",False,97.61,69.39,,,
"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB> <TAB> path . responses . append ( response ) <TAB> <TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB> <TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> n + = 1 <TAB> <TAB> if n > max_next : <TAB> <TAB> <TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB> <TAB> response = requests . get ( src , stream = True )",if not src :,if not src :,True,100.0,74.6,,,
"def ordered_indices ( self ) : <TAB> with data_utils . numpy_seed ( self . seed , self . epoch ) : <TAB> <TAB> # Used to store the order of indices of each dataset to use <TAB> <TAB> indices = [ <TAB> <TAB> <TAB> np.random.permutation(len(dataset)) for dataset in self.datasets.values() <TAB> <TAB> ] <TAB> <TAB> # Keep track of which samples we've used for each dataset <TAB> <TAB> counters = [0 for _ in self.datasets] <TAB> <TAB> sampled_indices = [ <TAB> <TAB> <TAB> self._sample(indices, counters) for _ in range(self.total_num_instances) <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sampled_indices.sort(key=lambda i: self.num_tokens(i)) <TAB> <TAB> return np.array(sampled_indices, dtype=np.int64)",if self . num_tokens > 0 :,if self . sort_indices :,False,97.4,72.85,,,
"def _build_columns ( self ) : <TAB> self . columns = [ Column ( ) for col in self . keys ] <TAB> for row in self : <TAB> <TAB> for ( col_idx , col_val ) in enumerate ( row ) : <TAB> <TAB> <TAB> col = self . columns [ col_idx ] <TAB> <TAB> <TAB> col . append ( col_val ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> col . is_quantity = False <TAB> for ( idx , key_name ) in enumerate ( self . keys ) : <TAB> <TAB> self . columns [ idx ] . name = key_name <TAB> self . x = Column ( ) <TAB> self . ys = [ ]",if col . is_quantity :,if ( col_val is not None ) and ( not is_quantity ( col_val ) ) :,False,89.75,68.24,,,
"def tearDown ( self ) : <TAB> subprocess_list = self . subprocess_list <TAB> processes = subprocess_list . processes <TAB> self . schedule . reset ( ) <TAB> del self . schedule <TAB> for proc in processes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = True ) <TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB> <TAB> for proc in processes : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = False ) <TAB> <TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB> <TAB> log . warning ( "" Processes left running:  %s "" , processes )",if proc . pid != 0 :,if proc . is_alive ( ) :,False,94.4,71.54,,,
"def colorNetwork ( cls , network , nodesInNetwork , nodeByID = None ) : <TAB> for node in nodesInNetwork : <TAB> <TAB> node . use_custom_color = True <TAB> <TAB> neededCopies = sum ( socket . execution . neededCopies for socket in node . outputs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> color = ( 0.7 , 0.9 , 0.7 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> color = ( 1.0 , 0.3 , 0.3 ) <TAB> <TAB> node . color = color",if neededCopies > 0 :,if neededCopies == 0 :,False,97.18,72.86,,,
"def _init_warmup_scheduler ( self , optimizer , states ) : <TAB> updates_so_far = states . get ( "" number_training_updates "" , 0 ) <TAB> if self . warmup_updates > 0 and ( <TAB> <TAB> updates_so_far < = self . warmup_updates or self . hard_reset <TAB> ) : <TAB> <TAB> self . warmup_scheduler = optim . lr_scheduler . LambdaLR ( optimizer , self . _warmup_lr ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . warmup_scheduler . load_state_dict ( states [ "" warmup_scheduler "" ] ) <TAB> else : <TAB> <TAB> self . warmup_scheduler = None","if ""warmup_scheduler"" in states :","if states . get ( ""warmup_scheduler"" ) :",False,95.51,70.92,,,
"def inner ( self , * iargs , * * ikwargs ) : <TAB> try : <TAB> <TAB> return getattr ( super ( VEXResilienceMixin , self ) , func ) ( * iargs , * * ikwargs ) <TAB> except excs as e : <TAB> <TAB> for exc , handler in zip ( excs , handlers ) : <TAB> <TAB> <TAB> if isinstance ( e , exc ) : <TAB> <TAB> <TAB> <TAB> v = getattr ( self , handler ) ( * iargs , * * ikwargs ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> assert False , "" this should be unreachable if Python is working correctly """,if v is None :,if v is raiseme :,False,98.61,73.54,,,
"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB> <TAB> if data [ "" items "" ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = len ( data ) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . context [ "" total "" ] = 0 <TAB> <TAB> <TAB> data = { "" items "" : [ ] } <TAB> <TAB> return data [ "" items "" ] <TAB> return data","if data [ ""total"" ] == 0 :","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) :",False,92.7,65.46,,,
"def __subclasscheck__ ( self , cls ) : <TAB> if self . __origin__ is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" Parameterized generics cannot be used with class  "" "" or instance checks "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return False <TAB> if self is Generic : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" Class  %r  cannot be used with class  "" "" or instance checks "" % self <TAB> <TAB> ) <TAB> return super ( ) . __subclasscheck__ ( cls )",if self is Parameterized :,"if sys . _getframe ( 1 ) . f_globals [ ""__name__"" ] not in [ ""abc"" , ""functools"" ] :",False,81.56,62.34,,,
"def __subclasscheck__ ( self , cls ) : <TAB> if self . __origin__ is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" Parameterized generics cannot be used with class  "" "" or instance checks "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return False <TAB> if self is Generic : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" Class  %r  cannot be used with class  "" "" or instance checks "" % self <TAB> <TAB> ) <TAB> return super ( ) . __subclasscheck__ ( cls )",if self is Parameterized :,"if version . startswith ( ""pypy"" )",False,94.14,66.43,,,
"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> tasks = self . tasks . tasks # is a group <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> tasks = self.tasks <TAB> <TAB> if len(tasks): <TAB> <TAB> <TAB> app = tasks[0]._app <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> app = body._app <TAB> return app if app is not None else current_app",elif body :,if app is None and body is not None :,False,93.3,67.73,,,
"def logic ( ) : <TAB> for v in [ True , False , None , 0 , True , None , None , 1 ] : <TAB> <TAB> yield clk . posedge <TAB> <TAB> xd . next = v <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yd . next = zd . next = None <TAB> <TAB> elif v : <TAB> <TAB> <TAB> yd . next = zd . next = 11 <TAB> <TAB> else : <TAB> <TAB> <TAB> yd . next = zd . next = 0",if v :,if v is None :,False,97.31,72.18,,,
"def run ( self ) : <TAB> eid = self . start_episode ( ) <TAB> obs = self . env . reset ( ) <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> action = self . env . action_space . sample ( ) <TAB> <TAB> <TAB> self . log_action ( eid , obs , action ) <TAB> <TAB> else : <TAB> <TAB> <TAB> action = self . get_action ( eid , obs ) <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> self . log_returns ( eid , reward , info = info ) <TAB> <TAB> if done : <TAB> <TAB> <TAB> self . end_episode ( eid , obs ) <TAB> <TAB> <TAB> obs = self . env . reset ( ) <TAB> <TAB> <TAB> eid = self . start_episode ( )",if self . env . action_space :,if random . random ( ) < self . off_pol_frac :,False,94.3,71.53,,,
"def tearDown ( self ) : <TAB> os . chdir ( self . orig_working_dir ) <TAB> sys . argv = self . orig_argv <TAB> sys . stdout = self . orig_stdout <TAB> sys . stderr = self . orig_stderr <TAB> for dirname in [ "" lv_LV "" , "" ja_JP "" ] : <TAB> <TAB> locale_dir = os . path . join ( self . datadir , "" project "" , "" i18n "" , dirname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutil . rmtree ( locale_dir )",if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,True,100.0,74.33,,,
"def sentry_set_scope ( process_context , entity , project , email = None , url = None ) : <TAB> # Using GLOBAL_HUB means these tags will persist between threads. <TAB> # Normally there is one hub per thread. <TAB> with sentry_sdk.hub.GLOBAL_HUB.configure_scope() as scope: <TAB> <TAB> scope.set_tag(""process_context"", process_context) <TAB> <TAB> scope.set_tag(""entity"", entity) <TAB> <TAB> scope.set_tag(""project"", project) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scope.user = {""email"": email} <TAB> <TAB> if url: <TAB> <TAB> <TAB> scope.set_tag(""url"", url)",if email :,if email :,True,100.0,74.19,,,
"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if c . getYAxis ( ) == Y_AXIS : <TAB> <TAB> <TAB> nPoints = c . getNPoints ( ) <TAB> <TAB> <TAB> for j in range ( nPoints ) : <TAB> <TAB> <TAB> <TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB> <TAB> return Double . NaN <TAB> return result",if c . getYAxis ( ) == X_AXIS :,if not c . isVisible ( ) :,False,94.76,71.87,,,
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" link "" and ( "" rel "" , "" icon "" ) in attrs or ( "" rel "" , "" shortcut icon "" ) in attrs : <TAB> <TAB> href = None <TAB> <TAB> icon_type = None <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> if attr == "" href "" : <TAB> <TAB> <TAB> <TAB> href = value <TAB> <TAB> <TAB> elif attr == "" type "" : <TAB> <TAB> <TAB> <TAB> icon_type = value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> mimetype = extension_to_mimetype ( href . rpartition ( "" . "" ) [ 2 ] ) <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> icon_type = mimetype <TAB> <TAB> <TAB> if icon_type : <TAB> <TAB> <TAB> <TAB> self . icons . append ( ( href , icon_type ) )","elif attr == ""mime-type"" :",if href :,False,97.12,69.99,,,
"def get_version ( version_file = STATIC_VERSION_FILE ) : <TAB> version_info = get_static_version_info ( version_file ) <TAB> version = version_info [ "" version "" ] <TAB> if version == "" __use_git__ "" : <TAB> <TAB> version = get_version_from_git ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> version = get_version_from_git_archive ( version_info ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> version = Version ( "" unknown "" , None , None ) <TAB> <TAB> return pep440_format ( version ) <TAB> else : <TAB> <TAB> return version","elif version == ""unknown"" :",if not version :,False,90.83,62.55,,,
"def _Sleep ( self , seconds ) : <TAB> if threading . current_thread ( ) is not self . _worker_thread : <TAB> <TAB> return self . _original_sleep ( seconds ) <TAB> self . _time + = seconds <TAB> self . _budget - = seconds <TAB> while self . _budget < 0 : <TAB> <TAB> self . _worker_thread_turn . clear ( ) <TAB> <TAB> self . _owner_thread_turn . set ( ) <TAB> <TAB> self . _worker_thread_turn . wait ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise FakeTimeline . _WorkerThreadExit ( )",if self . _owner_thread_turn . is_alive ( ) :,if self . _worker_thread_done :,False,93.37,72.05,,,
"def validate_attributes ( self ) : <TAB> if not ( self . has_variants or self . variant_of ) : <TAB> <TAB> return <TAB> if not self . variant_based_on : <TAB> <TAB> self . variant_based_on = "" Item Attribute "" <TAB> if self . variant_based_on == "" Item Attribute "" : <TAB> <TAB> attributes = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Attribute table is mandatory "" ) ) <TAB> <TAB> for d in self . attributes : <TAB> <TAB> <TAB> if d . attribute in attributes : <TAB> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Attribute  {0}  selected multiple times in Attributes Table "" <TAB> <TAB> <TAB> <TAB> <TAB> ) . format ( d . attribute ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attributes . append ( d . attribute )",if not self . attributes :,if not self . attributes :,True,100.0,74.63,,,
"def check_digest_auth ( user , passwd ) : <TAB> """""" Check user authentication using HTTP Digest auth """""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB> <TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB> <TAB> if not credentails : <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response ( <TAB> <TAB> <TAB> credentails , <TAB> <TAB> <TAB> passwd , <TAB> <TAB> <TAB> dict ( <TAB> <TAB> <TAB> <TAB> uri = request . script_root + request . path , <TAB> <TAB> <TAB> <TAB> body = request . data , <TAB> <TAB> <TAB> <TAB> method = request . method , <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if response_hash == user :,"if credentails . get ( ""response"" ) == response_hash :",False,94.99,91.71,,,
"def _get_index_type ( return_index_type , ctx ) : <TAB> if return_index_type is None : # pragma: no cover <TAB> <TAB> if ctx.running_mode == RunningMode.local: <TAB> <TAB> <TAB> return_index_type = ""object"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return_index_type = ""filename"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return_index_type = ""bytes"" <TAB> return return_index_type",elif ctx . running_mode == RunningMode . local :,elif ctx . running_mode == RunningMode . local_cluster :,False,97.52,71.84,,,
"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB> <TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB> <TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB> <TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB> <TAB> if not isinstance ( handler , handlers . ResourceWatchingHandler ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield handler","elif isinstance ( handler , handlers . SimpleRegistry ) :","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) :",False,90.82,67.79,,,
"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB> <TAB> if completed_process . stderr is not None : <TAB> <TAB> <TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB> <TAB> if raise_error : <TAB> <TAB> <TAB> raise PipxError ( <TAB> <TAB> <TAB> <TAB> f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" )",if completed_process . stdout is not None :,if completed_process . stdout is not None :,True,100.0,74.61,,,
"def __pow__ ( self , power ) : <TAB> if power == 1 : <TAB> <TAB> return self <TAB> if power == - 1 : <TAB> <TAB> # HACK: break cycle <TAB> <TAB> from cirq.devices import line_qubit <TAB> <TAB> decomposed = protocols.decompose_once_with_qubits( <TAB> <TAB> <TAB> self, qubits=line_qubit.LineQid.for_gate(self), default=None <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> inverse_decomposed = protocols.inverse(decomposed, None) <TAB> <TAB> if inverse_decomposed is None: <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> return _InverseCompositeGate(self) <TAB> return NotImplemented",if decomposed is None :,if decomposed is None :,True,100.0,74.33,,,
"def tearDown ( self ) : <TAB> """""" Close the application after tests """""" <TAB> # set it back to it's old position so not to annoy users :-) <TAB> self.old_pos = self.dlg.rectangle <TAB> # close the application <TAB> self.dlg.menu_select(""File->Exit"") <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.app.UntitledNotepad[""Do&n't Save""].click() <TAB> <TAB> <TAB> self.app.UntitledNotepad.wait_not(""visible"") <TAB> except Exception: <TAB> <TAB> pass <TAB> finally: <TAB> <TAB> self.app.kill()","if self . app . UntitledNotepad [ ""Do&n"" ] . exists ( ) :","if self . app . UntitledNotepad [ ""Do&n't Save"" ] . exists ( ) :",False,98.11,71.99,,,
"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> <IF-STMT> <TAB> <TAB> if log : <TAB> <TAB> <TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB> <TAB> proc . terminate ( ) <TAB> <TAB> timeout_time = time . time ( ) + timeout <TAB> <TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB> <TAB> <TAB> time . sleep ( 0.02 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if log : <TAB> <TAB> <TAB> <TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB> <TAB> <TAB> proc . kill ( ) <TAB> return proc . returncode",if proc . returncode == 0 :,if proc . poll ( ) is None :,False,93.51,69.45,,,
"def validate ( self , detection , expectation ) : <TAB> config = SigmaConfiguration ( ) <TAB> self . basic_rule [ "" detection "" ] = detection <TAB> with patch ( "" yaml.safe_load_all "" , return_value = [ self . basic_rule ] ) : <TAB> <TAB> parser = SigmaCollectionParser ( "" any sigma io "" , config , None ) <TAB> <TAB> backend = SQLiteBackend ( config , self . table ) <TAB> <TAB> assert len ( parser . parsers ) == 1 <TAB> <TAB> for p in parser . parsers : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( expectation , backend . generate ( p ) ) <TAB> <TAB> <TAB> elif isinstance ( expectation , Exception ) : <TAB> <TAB> <TAB> <TAB> self . assertRaises ( type ( expectation ) , backend . generate , p )","if isinstance ( expectation , str ) :","if isinstance ( expectation , str ) :",True,100.0,74.57,,,
"def makelist ( d ) : <TAB> """""" Convert d into a list if all the keys of d are integers. """""" <TAB> if isinstance ( d , dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ makelist ( d [ k ] ) for k in sorted ( d , key = int ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return web . storage ( ( k , makelist ( v ) ) for k , v in d . items ( ) ) <TAB> else : <TAB> <TAB> return d","if isinstance ( d , list ) :",if all ( isint ( k ) for k in d ) :,False,92.18,66.06,,,
"def __share_local_dir ( self , lpath , rpath , fast ) : <TAB> result = const . ENoError <TAB> for walk in self . __walk_normal_file ( lpath ) : <TAB> <TAB> ( dirpath , dirnames , filenames ) = walk <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> rpart = os . path . relpath ( dirpath , lpath ) <TAB> <TAB> <TAB> if rpart == "" . "" : <TAB> <TAB> <TAB> <TAB> rpart = "" "" <TAB> <TAB> <TAB> subr = self . __share_local_file ( <TAB> <TAB> <TAB> <TAB> joinpath ( dirpath , filename ) , <TAB> <TAB> <TAB> <TAB> posixpath . join ( rpath , rpart , filename ) , <TAB> <TAB> <TAB> <TAB> fast , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result = subr <TAB> return result",if subr is not const . ENoError :,if subr != const . ENoError :,False,98.58,73.53,,,
"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser.values[condfield] <TAB> <TAB> <TAB> for condvalue in self.conditions[condfield]: <TAB> <TAB> <TAB> <TAB> if condvalue in rulefieldvalues: <TAB> <TAB> <TAB> <TAB> <TAB> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",if condfield in sigmaparser . values :,if condfield in sigmaparser . values :,True,100.0,74.07,,,
"def _wrapped_view ( request , * args , * * kwargs ) : <TAB> # based on authority/decorators.py <TAB> user = request.user <TAB> if user.is_authenticated(): <TAB> <TAB> obj = _resolve_lookup(obj_lookup, kwargs) <TAB> <TAB> perm_obj = _resolve_lookup(perm_obj_lookup, kwargs) <TAB> <TAB> granted = access.has_perm_or_owns(user, perm, obj, perm_obj, owner_attr) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return view_func(request, *args, **kwargs) <TAB> # In all other cases, permission denied <TAB> return HttpResponseForbidden()",if granted :,if granted or user . has_perm ( perm ) :,False,94.03,68.38,,,
"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB> <TAB> earlier_part = earlier [ "" part "" ] <TAB> <TAB> earlier_step = earlier [ "" step "" ] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not found : <TAB> <TAB> <TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB> <TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint )","if current [ ""part"" ] == earlier_part :","if earlier_part == current [ ""part"" ] and earlier_step == current [ ""step"" ] :",False,92.84,65.65,,,
"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB> <TAB> if self . named_windows [ wnd_name ] == 0 : <TAB> <TAB> <TAB> self . named_windows [ wnd_name ] = 1 <TAB> <TAB> <TAB> self . on_create_window ( wnd_name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . capture_mouse ( wnd_name ) <TAB> <TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB> <TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" )",elif self . named_windows [ wnd_name ] == 1 :,if wnd_name in self . capture_mouse_windows :,False,93.33,70.03,,,
"def readlines ( self , hint = None ) : <TAB> # Again, allow hint but ignore <TAB> body = self._get_body() <TAB> rest = body[self.position :] <TAB> self.position = len(body) <TAB> result = [] <TAB> while 1: <TAB> <TAB> next = rest.find(""\r\n"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.append(rest) <TAB> <TAB> <TAB> break <TAB> <TAB> result.append(rest[: next + 2]) <TAB> <TAB> rest = rest[next + 2 :] <TAB> return result",if next < 0 :,if next == - 1 :,False,96.61,71.19,,,
"def __lt__ ( self , other ) : <TAB> olen = len ( other ) <TAB> for i in range ( olen ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> c = self [ i ] < other [ i ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> # self must be shorter <TAB> <TAB> <TAB> return True <TAB> <TAB> if c: <TAB> <TAB> <TAB> return c <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return len(self) < olen",if i >= olen :,elif other [ i ] < self [ i ] :,False,92.49,68.22,,,
"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB> <TAB> if user and social . user != user : <TAB> <TAB> <TAB> msg = "" This account is already in use. "" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> user = social . user <TAB> return { <TAB> <TAB> "" social "" : social , <TAB> <TAB> "" user "" : user , <TAB> <TAB> "" is_new "" : user is None , <TAB> <TAB> "" new_association "" : social is None , <TAB> }",if user is None :,elif not user :,False,97.35,72.56,,,
"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB> <TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB> <TAB> self . utexc = True <TAB> else : <TAB> <TAB> if self . utexc is False : <TAB> <TAB> <TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . utexc [ indices ] = True",if indices :,if self . utexc is not True :,False,94.34,70.25,,,
"def destination ( self , type , name , arglist ) : <TAB> classname = "" ResFunction "" <TAB> listname = "" functions "" <TAB> if arglist : <TAB> <TAB> t , n , m = arglist [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> classname = "" ResMethod "" <TAB> <TAB> <TAB> listname = "" resmethods "" <TAB> return classname , listname","if t == ""ResFunction"" and m == ""ResMethod"" :","if t == ""Handle"" and m == ""InMode"" :",False,95.17,70.61,,,
"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB> <TAB> self . view . sel ( ) . add ( r ) <TAB> <TAB> if register : <TAB> <TAB> <TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> if register : <TAB> <TAB> text = "" "" . join ( to_store ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = text + "" \n "" <TAB> <TAB> state = State ( self . view ) <TAB> <TAB> state . registers [ register ] = [ text ]",if self . view . sel ( ) . count ( ) > 0 :,"if not text . endswith ( ""\n"" ) :",False,92.77,64.68,,,
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> if self . _pos < start : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> if stop is not None and self . _pos > stop : <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( )",if start is None and self . _pos >= stop :,elif self . _pos == start :,False,95.39,71.76,,,
"def start ( self ) : <TAB> self . on_config_change ( ) <TAB> self . start_config_watch ( ) <TAB> try : <TAB> <TAB> if self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" tcp "" ] . lower ( ) == "" on "" : <TAB> <TAB> <TAB> self . startTCP ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . startUDP ( ) <TAB> except socket . error as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutdown ( <TAB> <TAB> <TAB> <TAB> "" \n [DNS] Unable to start DNS server on port  {} : port already in use "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" port "" ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if e . errno == errno . EADDRINUSE :,"if ""Address already in use"" in e :",False,96.03,68.77,,,
"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB> <TAB> if other not in self . ignoreExprs : <TAB> <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self",if self . expr is not None :,if self . expr is not None :,True,100.0,74.48,,,
"def test_relative_deploy_path_override ( ) : <TAB> s = Site ( TEST_SITE_ROOT ) <TAB> s . load ( ) <TAB> res = s . content . resource_from_relative_path ( <TAB> <TAB> "" blog/2010/december/merry-christmas.html "" <TAB> ) <TAB> res . relative_deploy_path = "" blog/2010/december/happy-holidays.html "" <TAB> for page in s . content . walk_resources ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert page . relative_deploy_path == "" blog/2010/december/happy-holidays.html "" <TAB> <TAB> else : <TAB> <TAB> <TAB> assert page . relative_deploy_path == Folder ( page . relative_path )",if page . is_dir :,if res . source_file == page . source_file :,False,93.49,70.24,,,
"def _parser ( cls , buf ) : <TAB> tlvs = [ ] <TAB> while buf : <TAB> <TAB> tlv_type = LLDPBasicTLV . get_type ( buf ) <TAB> <TAB> tlv = cls . _tlv_parsers [ tlv_type ] ( buf ) <TAB> <TAB> tlvs . append ( tlv ) <TAB> <TAB> offset = LLDP_TLV_SIZE + tlv . len <TAB> <TAB> buf = buf [ offset : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> assert len ( buf ) > 0 <TAB> lldp_pkt = cls ( tlvs ) <TAB> assert lldp_pkt . _tlvs_len_valid ( ) <TAB> assert lldp_pkt . _tlvs_valid ( ) <TAB> return lldp_pkt , None , buf",if not tlvs :,if tlv . tlv_type == LLDP_TLV_END :,False,93.07,71.71,,,
"def _do_pull ( self , repo , pull_kwargs , silent , ignore_pull_failures ) : <TAB> try : <TAB> <TAB> output = self . client . pull ( repo , * * pull_kwargs ) <TAB> <TAB> if silent : <TAB> <TAB> <TAB> with open ( os . devnull , "" w "" ) as devnull : <TAB> <TAB> <TAB> <TAB> yield from stream_output ( output , devnull ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from stream_output ( output , sys . stdout ) <TAB> except ( StreamOutputError , NotFound ) as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> log . error ( str ( e ) )",if ignore_pull_failures :,if not ignore_pull_failures :,False,98.71,73.33,,,
def _collect_bytecode ( ordered_code ) : <TAB> bytecode_blocks = [ ] <TAB> stack = [ ordered_code ] <TAB> while stack : <TAB> <TAB> code = stack . pop ( ) <TAB> <TAB> bytecode_blocks . append ( code . co_code ) <TAB> <TAB> for const in code . co_consts : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> stack . append ( const ) <TAB> return bytecode_blocks,if const . co_code == ordered_code :,"if isinstance ( const , blocks . OrderedCode ) :",False,91.28,54.41,,,
"def displayhook ( value ) : <TAB> if value is None : <TAB> <TAB> return <TAB> builtins = modules [ "" builtins "" ] <TAB> # Set '_' to None to avoid recursion <TAB> builtins._ = None <TAB> text = repr(value) <TAB> try: <TAB> <TAB> local_stdout = stdout <TAB> except NameError as e: <TAB> <TAB> raise RuntimeError(""lost sys.stdout"") from e <TAB> try: <TAB> <TAB> local_stdout.write(text) <TAB> except UnicodeEncodeError: <TAB> <TAB> bytes = text.encode(local_stdout.encoding, ""backslashreplace"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> local_stdout.buffer.write(bytes) <TAB> <TAB> else: <TAB> <TAB> <TAB> text = bytes.decode(local_stdout.encoding, ""strict"") <TAB> <TAB> <TAB> local_stdout.write(text) <TAB> local_stdout.write(""\n"") <TAB> builtins._ = value",if PY3 :,"if hasattr ( local_stdout , ""buffer"" ) :",False,95.51,67.1,,,
"def displayhook ( value ) : <TAB> if value is None : <TAB> <TAB> return <TAB> builtins = modules [ "" builtins "" ] <TAB> # Set '_' to None to avoid recursion <TAB> builtins._ = None <TAB> text = repr(value) <TAB> try: <TAB> <TAB> local_stdout = stdout <TAB> except NameError as e: <TAB> <TAB> raise RuntimeError(""lost sys.stdout"") from e <TAB> try: <TAB> <TAB> local_stdout.write(text) <TAB> except UnicodeEncodeError: <TAB> <TAB> bytes = text.encode(local_stdout.encoding, ""backslashreplace"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> local_stdout.buffer.write(bytes) <TAB> <TAB> else: <TAB> <TAB> <TAB> text = bytes.decode(local_stdout.encoding, ""strict"") <TAB> <TAB> <TAB> local_stdout.write(text) <TAB> local_stdout.write(""\n"") <TAB> builtins._ = value",if PY3 :,"elif line . startswith ( ""FAIL:"" ) and prev_line and prev_line . startswith ( ""="" ) :",False,89.96,63.15,,,
"def _flush ( self ) : <TAB> if self . _data : <TAB> <TAB> if self . _last is not None : <TAB> <TAB> <TAB> text = "" "" . join ( self . _data ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> assert self . _last . tail is None , "" internal error (tail) "" <TAB> <TAB> <TAB> <TAB> self . _last . tail = text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert self . _last . text is None , "" internal error (text) "" <TAB> <TAB> <TAB> <TAB> self . _last . text = text <TAB> <TAB> self . _data = [ ]",if self . tail is None :,if self . _tail :,False,97.74,72.98,,,
"def write ( self , chunk ) : <TAB> consumer = self . _current_consumer <TAB> server_side = consumer . server_side <TAB> if server_side : <TAB> <TAB> server_side . data_received ( chunk ) <TAB> else : <TAB> <TAB> consumer . message + = chunk <TAB> <TAB> assert consumer . in_parser . execute ( chunk , len ( chunk ) ) == len ( chunk ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> consumer . finished ( )",if self . _is_finished :,if consumer . in_parser . is_message_complete ( ) :,False,89.96,69.3,,,
"def _api_change_cat ( name , output , kwargs ) : <TAB> """""" API: accepts output, value(=nzo_id), value2(=category) """""" <TAB> value = kwargs . get ( "" value "" ) <TAB> value2 = kwargs . get ( "" value2 "" ) <TAB> if value and value2 : <TAB> <TAB> nzo_id = value <TAB> <TAB> cat = value2 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cat = None <TAB> <TAB> result = sabnzbd . NzbQueue . change_cat ( nzo_id , cat ) <TAB> <TAB> return report ( output , keyword = "" status "" , data = bool ( result > 0 ) ) <TAB> else : <TAB> <TAB> return report ( output , _MSG_NO_VALUE )","if cat == ""category"" :","if cat == ""None"" :",False,98.69,97.0,,,
"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB> <TAB> occupied = False <TAB> <TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not occupied : <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot ( <TAB> <TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> )",if strategy == self . strategy :,if strategy == self :,False,98.2,73.56,,,
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> if key in LoggerFactory . schedule_logger_dict : <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id )",if delete :,if delete :,True,100.0,74.59,,,
"def quick_load ( tool_file , async_load = True ) : <TAB> try : <TAB> <TAB> tool = self . load_tool ( tool_file , tool_cache_data_dir ) <TAB> <TAB> self . __add_tool ( tool , load_panel_dict , elems ) <TAB> <TAB> # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB> <TAB> key = ""tool_%s"" % str(tool.id) <TAB> <TAB> integrated_elems[key] = tool <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._load_tool_panel() <TAB> <TAB> <TAB> self._save_integrated_tool_panel() <TAB> <TAB> return tool.id <TAB> except Exception: <TAB> <TAB> log.exception(""Failed to load potential tool %s."", tool_file) <TAB> <TAB> return None",if async_load :,if async_load :,True,100.0,74.39,,,
"def _get_default_ordering ( self ) : <TAB> try : <TAB> <TAB> ordering = super ( DocumentChangeList , self ) . _get_default_ordering ( ) <TAB> except AttributeError : <TAB> <TAB> ordering = [ ] <TAB> <TAB> if self . model_admin . ordering : <TAB> <TAB> <TAB> ordering = self . model_admin . ordering <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ordering = self . lookup_opts . ordering <TAB> return ordering",elif self . lookup_opts . ordering :,elif self . lookup_opts . ordering :,True,100.0,74.15,,,
"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB> <TAB> self . __storage ( None ) , <TAB> <TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB> <TAB> for b in s : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name not in u : <TAB> <TAB> <TAB> <TAB> result . append ( b . name ) <TAB> <TAB> <TAB> <TAB> u . add ( b . name ) <TAB> return result",if b . is_persistent and b . is_persistent :,if persistent is not None and b . persistent != persistent :,False,95.51,70.56,,,
"def common_check_get_messages_query ( <TAB> self , query_params : Dict [ str , object ] , expected : str ) - > None : <TAB> user_profile = self . example_user ( "" hamlet "" ) <TAB> request = POSTRequestMock ( query_params , user_profile ) <TAB> with queries_captured ( ) as queries : <TAB> <TAB> get_messages_backend ( request , user_profile ) <TAB> for query in queries : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sql = str ( query [ "" sql "" ] ) . replace ( ""  /* get_messages */ "" , "" "" ) <TAB> <TAB> <TAB> self . assertEqual ( sql , expected ) <TAB> <TAB> <TAB> return <TAB> raise AssertionError ( "" get_messages query not found "" )","if query [ ""sql"" ] :","if ""/* get_messages */"" in query [ ""sql"" ] :",False,94.32,68.71,,,
"def _activate_only_current_top_active ( ) : <TAB> for i in range ( 0 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> current_sequence ( ) . tracks [ i ] . active = True <TAB> <TAB> else : <TAB> <TAB> <TAB> current_sequence ( ) . tracks [ i ] . active = False <TAB> gui . tline_column . widget . queue_draw ( )",if current_sequence ( ) . tracks [ i ] . active :,if i == current_sequence ( ) . get_first_active_track ( ) . id :,False,87.76,68.61,,,
"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB> <TAB> if postdata != { } : <TAB> <TAB> <TAB> f = urllib . urlopen ( url , postdata ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = urllib . urlopen ( url ) <TAB> <TAB> response = f . read ( ) <TAB> except : <TAB> <TAB> import traceback <TAB> <TAB> import logging , sys <TAB> <TAB> cla , exc , tb = sys . exc_info ( ) <TAB> <TAB> logging . error ( url ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . error ( "" with post data "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . error ( "" without post data "" ) <TAB> <TAB> logging . error ( exc . args ) <TAB> <TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB> <TAB> response = "" "" <TAB> return response","if cla . request . method == ""POST"" :",if postdata :,False,95.48,67.2,,,
"def frequent_thread_switches ( ) : <TAB> """""" Make concurrency bugs more likely to manifest. """""" <TAB> interval = None <TAB> <IF-STMT> <TAB> <TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval )",if interval is None :,"if not sys . platform . startswith ( ""java"" ) :",False,89.15,62.8,,,
"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB> <TAB> f = queue . popleft ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if block_end : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( None ) <TAB> <TAB> <TAB> for gf in f . filters : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( gf ) <TAB> <TAB> yield f",if f . block_end :,"if f is not None and f . type in ( ""or"" , ""and"" , ""not"" ) :",False,84.2,58.96,,,
"def smartsplit ( code ) : <TAB> """""" Split `code` at  ""  symbol, only if it is not escaped. """""" <TAB> strings = [ ] <TAB> pos = 0 <TAB> while pos < len ( code ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> word = "" "" # new word <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> while pos < len(code): <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if code[pos] == ""\\"": <TAB> <TAB> <TAB> <TAB> <TAB> word += ""\\"" <TAB> <TAB> <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> <TAB> word += code[pos] <TAB> <TAB> <TAB> <TAB> pos += 1 <TAB> <TAB> <TAB> strings.append('""%s""' % word) <TAB> <TAB> pos += 1 <TAB> return strings","if code [ pos ] == ""\\"" :","if code [ pos ] == '""' :",False,96.41,64.45,,,
"def get_folder_content ( cls , name ) : <TAB> """""" Return (folders, files) for the given folder in the root dir. """""" <TAB> folders = set ( ) <TAB> files = set ( ) <TAB> for path in cls . LAYOUT : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> parts = path . split ( "" / "" ) <TAB> <TAB> if len ( parts ) == 2 : <TAB> <TAB> <TAB> files . add ( parts [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> folders . add ( parts [ 1 ] ) <TAB> folders = list ( folders ) <TAB> folders . sort ( ) <TAB> files = list ( files ) <TAB> files . sort ( ) <TAB> return ( folders , files )",if not path . startswith ( name ) :,"if not path . startswith ( name + ""/"" ) :",False,97.34,96.44,,,
"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _tail <TAB> <TAB> node = self . _root <TAB> <TAB> level = self . _shift <TAB> <TAB> while level > 0 : <TAB> <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> <TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB> <TAB> <TAB> level - = 5 <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" )",if self . _tail :,if i >= self . tailoff ( ) :,False,95.13,71.28,,,
"def __or__ ( self , other ) - > "" MultiVector "" : <TAB> r """""" ``self | other``, the inner product :math:`M  \ cdot N` """""" <TAB> other , mv = self . _checkOther ( other ) <TAB> if mv : <TAB> <TAB> newValue = self . layout . imt_func ( self . value , other . value ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> obj = self . __array__ ( ) <TAB> <TAB> <TAB> return obj | other <TAB> <TAB> # l * M = M * l = 0 for scalar l <TAB> <TAB> return self._newMV(dtype=np.result_type(self.value.dtype, other)) <TAB> return self._newMV(newValue)",if self . __array__ is not None :,"if isinstance ( other , np . ndarray ) :",False,94.49,92.29,,,
"def __or__ ( self , other ) - > "" MultiVector "" : <TAB> r """""" ``self | other``, the inner product :math:`M  \ cdot N` """""" <TAB> other , mv = self . _checkOther ( other ) <TAB> if mv : <TAB> <TAB> newValue = self . layout . imt_func ( self . value , other . value ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> obj = self . __array__ ( ) <TAB> <TAB> <TAB> return obj | other <TAB> <TAB> # l * M = M * l = 0 for scalar l <TAB> <TAB> return self._newMV(dtype=np.result_type(self.value.dtype, other)) <TAB> return self._newMV(newValue)",if self . __array__ is not None :,"elif statusline == ""added:"" :",False,93.88,72.76,,,
"def write ( self , timestamps , actualValues , predictedValues , predictionStep = 1 ) : <TAB> assert len ( timestamps ) == len ( actualValues ) == len ( predictedValues ) <TAB> for index in range ( len ( self . names ) ) : <TAB> <TAB> timestamp = timestamps [ index ] <TAB> <TAB> actual = actualValues [ index ] <TAB> <TAB> prediction = predictedValues [ index ] <TAB> <TAB> writer = self . outputWriters [ index ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> outputRow = [ timestamp , actual , prediction ] <TAB> <TAB> <TAB> writer . writerow ( outputRow ) <TAB> <TAB> <TAB> self . lineCounts [ index ] + = 1",if self . lineCounts [ index ] < predictionStep :,if timestamp is not None :,False,94.32,70.97,,,
"def clean ( self ) : <TAB> """""" Delete old files in  "" tmp "" . """""" <TAB> now = time . time ( ) <TAB> for entry in os . listdir ( os . path . join ( self . _path , "" tmp "" ) ) : <TAB> <TAB> path = os . path . join ( self . _path , "" tmp "" , entry ) <TAB> <TAB> <IF-STMT> # 60 * 60 * 36 <TAB> <TAB> <TAB> os.remove(path)",if time . time ( ) - now > 60 * 60 * 60 :,if now - os . path . getatime ( path ) > 129600 :,False,89.57,86.6,,,
"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB> <TAB> stdout = None <TAB> <TAB> try : <TAB> <TAB> <TAB> stdout , stderr = Popen ( <TAB> <TAB> <TAB> <TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB> <TAB> <TAB> <TAB> stdout = PIPE , <TAB> <TAB> <TAB> <TAB> stderr = PIPE , <TAB> <TAB> <TAB> ) . communicate ( ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for line in stdout . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> if len ( line ) == 2 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info",if stdout :,if stdout :,True,100.0,74.65,,,
"def add ( meta_list , info_list = None ) : <TAB> if not info_list : <TAB> <TAB> info_list = meta_list <TAB> if not isinstance ( meta_list , ( list , tuple ) ) : <TAB> <TAB> meta_list = ( meta_list , ) <TAB> if not isinstance ( info_list , ( list , tuple ) ) : <TAB> <TAB> info_list = ( info_list , ) <TAB> for info_f in info_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for meta_f in meta_list : <TAB> <TAB> <TAB> <TAB> metadata [ meta_f ] = info [ info_f ] <TAB> <TAB> <TAB> break",if info_f not in metadata :,if info . get ( info_f ) is not None :,False,94.61,69.64,,,
"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log_r_term = model_site [ "" log_prob "" ] <TAB> <TAB> <TAB> if not model_site [ "" is_observed "" ] : <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB> <TAB> <TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r","if ""log_prob"" in model_site :","if model_site [ ""type"" ] == ""sample"" :",False,93.92,66.75,,,
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> if prog . match ( line ) : <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None",if not line :,if not line or not line [ 0 ] . isspace ( ) :,False,95.55,71.2,,,
"def build_iterator ( data , infinite = True ) : <TAB> """""" Build the iterator for inputs. """""" <TAB> index = 0 <TAB> size = len ( data [ 0 ] ) <TAB> while True : <TAB> <TAB> if index + batch_size > size : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> index = 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield data [ 0 ] [ index : index + batch_size ] , data [ 1 ] [ index : index + batch_size ] <TAB> <TAB> index + = batch_size",if infinite :,if infinite :,True,100.0,99.38,,,
"def checkall ( g , bg , dst_nodes , include_dst_in_src = True ) : <TAB> for etype in g . etypes : <TAB> <TAB> ntype = g . to_canonical_etype ( etype ) [ 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> check ( g , bg , ntype , etype , dst_nodes [ ntype ] , include_dst_in_src ) <TAB> <TAB> else : <TAB> <TAB> <TAB> check ( g , bg , ntype , etype , None , include_dst_in_src )",if ntype in dst_nodes :,if dst_nodes is not None and ntype in dst_nodes :,False,93.96,69.96,,,
"def minimalBases ( classes ) : <TAB> """""" Reduce a list of base classes to its ordered minimum equivalent """""" <TAB> if not __python3 : # pragma: no cover <TAB> <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB> <TAB> for n in classes: <TAB> <TAB> <TAB> if issubclass(n, m) and m is not n: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> candidates.remove(m) # ensure that we're later in the list <TAB> <TAB> <TAB> candidates.append(m) <TAB> return candidates",if m not in candidates :,if m in candidates :,False,98.77,73.62,,,
"def __keep_songs_enable ( self , enabled ) : <TAB> config . set ( "" memory "" , "" queue_keep_songs "" , enabled ) <TAB> if enabled : <TAB> <TAB> self . queue . set_first_column_type ( CurrentColumn ) <TAB> else : <TAB> <TAB> for col in self . queue . get_columns ( ) : <TAB> <TAB> <TAB> # Remove the CurrentColum if it exists <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.queue.set_first_column_type(None) <TAB> <TAB> <TAB> <TAB> break",if col . type == CurrentColumn :,"if isinstance ( col , CurrentColumn ) :",False,95.48,70.12,,,
"def outlineView_heightOfRowByItem_ ( self , tree , item ) - > float : <TAB> default_row_height = self . rowHeight <TAB> if item is self : <TAB> <TAB> return default_row_height <TAB> heights = [ default_row_height ] <TAB> for column in self . tableColumns : <TAB> <TAB> value = getattr ( item . attrs [ "" node "" ] , str ( column . identifier ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # if the cell value is a widget, use its height <TAB> <TAB> <TAB> heights.append(value._impl.native.intrinsicContentSize().height) <TAB> return max(heights)","if isinstance ( value , Widget ) :","if isinstance ( value , toga . Widget ) :",False,97.88,72.61,,,
"def condition ( self ) : <TAB> if self . __condition is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self.__condition = self.flat_conditions[0] <TAB> <TAB> elif len(self.flat_conditions) == 0: <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self.__condition = lambda _: True <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition",if len ( self . flat_conditions ) == 1 :,if len ( self . flat_conditions ) == 1 :,True,100.0,74.35,,,
"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB> <TAB> return 0 <TAB> while True : <TAB> <TAB> b = f . read ( block_size ) <TAB> <TAB> if not b : <TAB> <TAB> <TAB> return f . tell ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1",if b . index ( delimiter ) < len ( b ) :,elif delimiter in b :,False,90.86,69.45,,,
"def serialize ( self , name = None ) : <TAB> data = super ( SimpleText , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> data [ "" content "" ] = self . content <TAB> if self . width : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidWidthException ( self . width ) <TAB> <TAB> data [ "" inputOptions "" ] = { } <TAB> <TAB> data [ "" width "" ] = self . width <TAB> return data","if self . width not in [ ""100%"" , ""101"" ] :","if self . width not in [ 100 , 50 , 33 , 25 ] :",False,93.24,65.57,,,
"def inference ( self ) : <TAB> self . attention_weight_dim = self . input_dims [ 0 ] [ - 1 ] <TAB> if self . keep_dim : <TAB> <TAB> self . output_dim = copy . deepcopy ( self . input_dims [ 0 ] ) <TAB> else : <TAB> <TAB> self . output_dim = [ ] <TAB> <TAB> for idx , dim in enumerate ( self . input_dims [ 0 ] ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . output_dim . append ( dim ) <TAB> super ( <TAB> <TAB> LinearAttentionConf , self <TAB> ) . inference ( ) # PUT THIS LINE AT THE END OF inference()",if idx > 0 :,if idx != len ( self . input_dims [ 0 ] ) - 2 :,False,91.09,69.2,,,
"def __delete_hook ( self , rpc ) : <TAB> try : <TAB> <TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB> <TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB> <TAB> if status == MemcacheDeleteResponse . DELETED : <TAB> <TAB> <TAB> result . append ( DELETE_SUCCESSFUL ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( DELETE_ITEM_MISSING ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result",elif status == MemcacheDeleteResponse . Missing :,elif status == MemcacheDeleteResponse . NOT_FOUND :,False,97.34,73.09,,,
def identify_page_at_cursor ( self ) : <TAB> for region in self . view . sel ( ) : <TAB> <TAB> text_on_cursor = None <TAB> <TAB> pos = region . begin ( ) <TAB> <TAB> scope_region = self . view . extract_scope ( pos ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text_on_cursor = self . view . substr ( scope_region ) <TAB> <TAB> <TAB> return text_on_cursor . strip ( string . punctuation ) <TAB> return None,if scope_region :,if not scope_region . empty ( ) :,False,94.17,73.93,,,
"def from_elem ( cls , parent , when_elem ) : <TAB> """""" Loads the proper when by attributes of elem """""" <TAB> when_value = when_elem . get ( "" value "" , None ) <TAB> <IF-STMT> <TAB> <TAB> return ValueToolOutputActionConditionalWhen ( parent , when_elem , when_value ) <TAB> else : <TAB> <TAB> when_value = when_elem . get ( "" datatype_isinstance "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return DatatypeIsInstanceToolOutputActionConditionalWhen ( <TAB> <TAB> <TAB> <TAB> parent , when_elem , when_value <TAB> <TAB> <TAB> ) <TAB> raise TypeError ( "" When type not implemented "" )",if when_value :,if when_value is not None :,False,94.88,65.26,,,
"def test_insert_entity_empty_string_rk ( <TAB> self , tables_cosmos_account_name , tables_primary_cosmos_account_key ) : <TAB> # Arrange <TAB> await self._set_up(tables_cosmos_account_name, tables_primary_cosmos_account_key) <TAB> try: <TAB> <TAB> entity = {""PartitionKey"": ""pk"", ""RowKey"": """"} <TAB> <TAB> # Act <TAB> <TAB> with pytest.raises(HttpResponseError): <TAB> <TAB> <TAB> await self.table.create_entity(entity=entity) <TAB> <TAB> <TAB> # Assert <TAB> <TAB> # assert resp is None <TAB> finally: <TAB> <TAB> await self._tear_down() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sleep(SLEEP_DELAY)",if self . is_live :,if self . is_live :,True,100.0,99.13,,,
"def provider_uris ( self ) : <TAB> login_urls = { } <TAB> continue_url = self . request . get ( "" continue_url "" ) <TAB> for provider in self . provider_info : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> login_url = self . uri_for ( <TAB> <TAB> <TAB> <TAB> "" social-login "" , provider_name = provider , continue_url = continue_url <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> login_url = self . uri_for ( "" social-login "" , provider_name = provider ) <TAB> <TAB> login_urls [ provider ] = login_url <TAB> return login_urls",if continue_url :,if continue_url :,True,100.0,74.34,,,
"def provider_uris ( self ) : <TAB> login_urls = { } <TAB> continue_url = self . request . get ( "" continue_url "" ) <TAB> for provider in self . provider_info : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> login_url = self . uri_for ( <TAB> <TAB> <TAB> <TAB> "" social-login "" , provider_name = provider , continue_url = continue_url <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> login_url = self . uri_for ( "" social-login "" , provider_name = provider ) <TAB> <TAB> login_urls [ provider ] = login_url <TAB> return login_urls",if continue_url :,"if isinstance ( name , str )",False,95.77,70.7,,,
"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB> <TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB> <TAB> <TAB> uri = self . request . path + "" / "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )",if self . request . query :,if self . request . query :,True,100.0,74.5,,,
"def subword_map_by_joiner ( subwords , marker = SubwordMarker . JOINER ) : <TAB> """""" Return word id for each subword token (annotate by joiner). """""" <TAB> flags = [ 0 ] * len ( subwords ) <TAB> for i , tok in enumerate ( subwords ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flags [ i ] = 1 <TAB> <TAB> if tok . startswith ( marker ) : <TAB> <TAB> <TAB> assert i > = 1 and flags [ i - 1 ] != 1 , "" Sentence ` {} ` not correct! "" . format ( <TAB> <TAB> <TAB> <TAB> "" "" . join ( subwords ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> flags [ i - 1 ] = 1 <TAB> marker_acc = list ( accumulate ( [ 0 ] + flags [ : - 1 ] ) ) <TAB> word_group = [ ( i - maker_sofar ) for i , maker_sofar in enumerate ( marker_acc ) ] <TAB> return word_group",if tok . startswith ( marker ) :,if tok . endswith ( marker ) :,False,99.0,97.89,,,
"def next_item ( self , direction ) : <TAB> """""" Selects next menu item, based on self._direction """""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",if i >= len ( self . items ) :,if self . select ( i ) :,False,97.08,97.52,,,
"def get_config ( cls ) : <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = {} <TAB> # Try to get iflytek_yuyin config from config <TAB> profile_path = dingdangpath.config(""profile.yml"") <TAB> if os.path.exists(profile_path): <TAB> <TAB> with open(profile_path, ""r"") as f: <TAB> <TAB> <TAB> profile = yaml.safe_load(f) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if ""vid"" in profile[""iflytek_yuyin""]: <TAB> <TAB> <TAB> <TAB> <TAB> config[""vid""] = profile[""iflytek_yuyin""][""vid""] <TAB> return config","if ""iflytek_yuyin"" in profile :","if ""iflytek_yuyin"" in profile :",True,100.0,74.25,,,
"def get_signed_in_user ( test_case ) : <TAB> playback = not ( test_case . is_live or test_case . in_recording ) <TAB> if playback : <TAB> <TAB> return MOCKED_USER_NAME <TAB> else : <TAB> <TAB> account_info = test_case . cmd ( "" account show "" ) . get_output_in_json ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return account_info [ "" user "" ] [ "" name "" ] <TAB> return None","if account_info [ ""user"" ] :","if account_info [ ""user"" ] [ ""type"" ] != ""servicePrincipal"" :",False,91.81,66.18,,,
"def rename_project ( self , project , new_name ) : <TAB> """""" Rename project, update the related projects if necessary """""" <TAB> old_name = project . name <TAB> for proj in self . projects : <TAB> <TAB> relproj = proj . get_related_projects ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> relproj [ relproj . index ( old_name ) ] = new_name <TAB> <TAB> <TAB> proj . set_related_projects ( relproj ) <TAB> project . rename ( new_name ) <TAB> self . save ( )",if old_name in relproj :,if old_name in relproj :,True,100.0,99.27,,,
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None : <TAB> <TAB> <TAB> return True <TAB> <TAB> if len ( a ) != b . len : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if a . ptr != b . ptr :,if a . ptr == b . ptr :,False,98.94,73.77,,,
"def parse_variable ( self ) : <TAB> begin = self . _pos <TAB> while True : <TAB> <TAB> ch = self . read ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ScriptVariable ( self . _text [ begin : self . _pos - 1 ] ) <TAB> <TAB> elif ch is None : <TAB> <TAB> <TAB> self . __raise_eof ( ) <TAB> <TAB> elif not isidentif ( ch ) and ch != "" : "" : <TAB> <TAB> <TAB> self . __raise_char ( ch )","if isidentif ( ch ) and ch != ""\n"" :","if ch == ""%"" :",False,92.28,63.92,,,
"def h_file ( self ) : <TAB> filename = self . abspath ( ) <TAB> st = os . stat ( filename ) <TAB> cache = self . ctx . hashes_md5_tstamp <TAB> if filename in cache and cache [ filename ] [ 0 ] == st . st_mtime : <TAB> <TAB> return cache [ filename ] [ 1 ] <TAB> if STRONGEST : <TAB> <TAB> ret = Utils . h_file ( filename ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IOError ( "" Not a file "" ) <TAB> <TAB> ret = Utils . md5 ( str ( ( st . st_mtime , st . st_size ) ) . encode ( ) ) . digest ( ) <TAB> cache [ filename ] = ( st . st_mtime , ret ) <TAB> return ret",if not os . path . isfile ( filename ) :,if stat . S_ISDIR ( st [ stat . ST_MODE ] ) :,False,92.79,70.98,,,
"def add_widgets ( self , * widgets_or_spacings ) : <TAB> """""" Add widgets/spacing to dialog vertical layout """""" <TAB> layout = self . layout ( ) <TAB> for widget_or_spacing in widgets_or_spacings : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> layout . addSpacing ( widget_or_spacing ) <TAB> <TAB> else : <TAB> <TAB> <TAB> layout . addWidget ( widget_or_spacing )",if widget_or_spacing is not None :,"if isinstance ( widget_or_spacing , int ) :",False,93.33,89.75,,,
"def _str_index ( self ) : <TAB> idx = self [ "" index "" ] <TAB> out = [ ] <TAB> if len ( idx ) == 0 : <TAB> <TAB> return out <TAB> out + = [ "" .. index::  %s "" % idx . get ( "" default "" , "" "" ) ] <TAB> for section , references in idx . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif section == "" refguide "" : <TAB> <TAB> <TAB> out + = [ "" single:  %s "" % ( "" ,  "" . join ( references ) ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> out + = [ ""  %s :  %s "" % ( section , "" , "" . join ( references ) ) ] <TAB> return out","if section == ""default"" :","if section == ""default"" :",True,100.0,74.56,,,
"def dictify_CPPDEFINES ( env ) : <TAB> cppdefines = env . get ( "" CPPDEFINES "" , { } ) <TAB> if cppdefines is None : <TAB> <TAB> return { } <TAB> if SCons . Util . is_Sequence ( cppdefines ) : <TAB> <TAB> result = { } <TAB> <TAB> for c in cppdefines : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ c [ 0 ] ] = c [ 1 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result [ c ] = None <TAB> <TAB> return result <TAB> if not SCons . Util . is_Dict ( cppdefines ) : <TAB> <TAB> return { cppdefines : None } <TAB> return cppdefines","if c [ 0 ] in [ ""CPPDEFINES"" , ""CPPDEFINES"" , ""CPPDEFINES"" ] :",if SCons . Util . is_Sequence ( c ) :,False,90.29,61.91,,,
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> if c == "" & "" and not decode : <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> elif c == "" - "" and decode : <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )","elif c == ""-"" :",elif decode :,False,97.36,70.16,,,
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed","if not isinstance ( v , Shape ) :",if not Placeholder . check_resolved ( v . size ) :,False,94.81,71.07,,,
"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB> <TAB> if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ "" v "" ] ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1","elif op_reg ( op ) and op . oc2 in [ ""g"" , ""v"" ] :",elif op_gprv ( op ) :,False,88.55,61.29,,,
"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """""" Return standard location of genome directories. """""" <TAB> if galaxy_dir : <TAB> <TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB> <TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB> <TAB> if seq_file and os . path . exists ( seq_file ) : <TAB> <TAB> <TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB> <TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return gdirs [ 0 ]",if gdirs and os . path . exists ( os . path . dirname ( os . path . dirname ( gdirs [ 0 ] ) ) :,if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) :,False,92.93,84.19,,,
"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB> <TAB> line = line and line . strip ( ) <TAB> <TAB> if not line or line . startswith ( "" - "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line . split ( ) <TAB> <TAB> for module in line_modules : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB> <TAB> <TAB> module_parts = module . split ( "" / "" ) <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len ( module_parts ) == 2 : <TAB> <TAB> <TAB> <TAB> module_version = module_parts [ 1 ] <TAB> <TAB> <TAB> module_name = module_parts [ 0 ] <TAB> <TAB> <TAB> yield module_name , module_version",if module . endswith ( self . default_indicator ) :,if module . endswith ( self . default_indicator ) :,True,100.0,74.63,,,
"def save ( self ) : <TAB> updates = self . cinder_obj_get_changes ( ) <TAB> if updates : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> metadata = updates . pop ( "" metadata "" , None ) <TAB> <TAB> <TAB> self . metadata = db . backup_metadata_update ( <TAB> <TAB> <TAB> <TAB> self . _context , self . id , metadata , True <TAB> <TAB> <TAB> ) <TAB> <TAB> updates . pop ( "" parent "" , None ) <TAB> <TAB> db . backup_update ( self . _context , self . id , updates ) <TAB> self . obj_reset_changes ( )","if ""metadata"" in updates :","if ""metadata"" in updates :",True,100.0,74.39,,,
"def test_set_tag ( association_obj , sagemaker_session ) : <TAB> tag = { "" Key "" : "" foo "" , "" Value "" : "" bar "" } <TAB> association_obj . set_tag ( tag ) <TAB> while True : <TAB> <TAB> actual_tags = sagemaker_session . sagemaker_client . list_tags ( <TAB> <TAB> <TAB> ResourceArn = association_obj . source_arn <TAB> <TAB> ) [ "" Tags "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( 5 ) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len(actual_tags) > 0 <TAB> assert actual_tags[0] == tag",if actual_tags [ 0 ] == tag :,if actual_tags :,False,96.25,72.79,,,
"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> "" flush "" , <TAB> <TAB> "" write "" , <TAB> <TAB> "" writelines "" , <TAB> ] : <TAB> <TAB> if not hasattr ( wsgi_errors , method ) : <TAB> <TAB> <TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB> <TAB> if error_msg : <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ]","elif not callable ( wsgi_errors . getattr ( method , None ) ) :","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :",False,94.77,70.7,,,
"def current_dict ( cursor_offset , line ) : <TAB> """""" If in dictionary completion, return the dict that should be used """""" <TAB> for m in current_dict_re . finditer ( line ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return LinePart ( m . start ( 1 ) , m . end ( 1 ) , m . group ( 1 ) ) <TAB> return None",if m . start ( 1 ) <= cursor_offset and m . end ( 1 ) >= cursor_offset :,if m . start ( 2 ) <= cursor_offset and m . end ( 2 ) >= cursor_offset :,False,95.71,71.28,,,
"def show_file_browser ( self ) : <TAB> """""" Show/hide the file browser. """""" <TAB> if self . show_file_browser_action . isChecked ( ) : <TAB> <TAB> sizes = self . panel . sizes ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sizes [ 0 ] = sum ( sizes ) / / 4 <TAB> <TAB> <TAB> self . panel . setSizes ( sizes ) <TAB> <TAB> self . file_browser . show ( ) <TAB> else : <TAB> <TAB> self . file_browser . hide ( )",if self . show_file_browser_action . isChecked ( ) :,if sizes [ 0 ] == 0 :,False,90.42,88.73,,,
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . nameEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,True,100.0,74.38,,,
"def prepend ( self , value ) : <TAB> """""" prepend value to nodes """""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> if len ( root ) > 0 : <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self","if tag . text == """" :",if not tag . text :,False,96.83,49.88,,,
"def getLabel ( self , address = None ) : <TAB> if address is None : <TAB> <TAB> address = self . address <TAB> label = address <TAB> if shared . config . has_section ( address ) : <TAB> <TAB> label = shared . config . get ( address , "" label "" ) <TAB> queryreturn = sqlQuery ( """""" select label from addressbook where address=? """""" , address ) <TAB> <IF-STMT> <TAB> <TAB> for row in queryreturn : <TAB> <TAB> <TAB> ( label , ) = row <TAB> else : <TAB> <TAB> queryreturn = sqlQuery ( <TAB> <TAB> <TAB> """""" select label from subscriptions where address=? """""" , address <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for row in queryreturn : <TAB> <TAB> <TAB> <TAB> ( label , ) = row <TAB> return label",if queryreturn :,if queryreturn != [ ] :,False,95.07,92.41,,,
"def _parse ( self , engine ) : <TAB> """""" Parse the layer. """""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if ""momentum"" in self . args :","if ""momentum"" in self . args :",True,100.0,99.61,,,
"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB> <TAB> new_kwargs = dict ( kwargs ) <TAB> <TAB> if "" encoding "" in new_kwargs : <TAB> <TAB> <TAB> del new_kwargs [ "" encoding "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs )","if ""errors"" in new_kwargs :","if ""errors"" in kwargs :",False,97.13,72.62,,,
"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB> <TAB> if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] : <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( ) # Remove the current form. if it is at the end of the list <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self.setNextForm( <TAB> <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop() <TAB> <TAB> <TAB> ) # Switch to the previous form if one exists <TAB> except IndexError: <TAB> <TAB> self.setNextForm(backup)",if self . _FORM_VISIT_LIST [ - 1 ] == self . _FORM_VISIT_LIST [ - 1 ] :,if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM :,False,90.57,70.25,,,
"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB> <TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB> <TAB> <TAB> if current_word : <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [ char ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current_word . append ( char ) <TAB> if current_word : <TAB> <TAB> yield current_word","elif not self . keep_blank_chars and char [ ""text"" ] . isspace ( ) :","elif current_word and self . char_begins_new_word ( current_word , char ) :",False,90.93,61.25,,,
"def get ( self ) : <TAB> """""" return a secret by name """""" <TAB> results = self . _get ( "" secrets "" , self . name ) <TAB> results [ "" decoded "" ] = { } <TAB> results [ "" exists "" ] = False <TAB> if results [ "" returncode "" ] == 0 and results [ "" results "" ] [ 0 ] : <TAB> <TAB> results [ "" exists "" ] = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" data "" in results [ "" results "" ] [ 0 ] : <TAB> <TAB> <TAB> <TAB> for sname , value in results [ "" results "" ] [ 0 ] [ "" data "" ] . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> results [ "" decoded "" ] [ sname ] = base64 . b64decode ( value ) <TAB> if results [ "" returncode "" ] != 0 and ' "" %s ""  not found ' % self . name in results [ "" stderr "" ] : <TAB> <TAB> results [ "" returncode "" ] = 0 <TAB> return results","if results [ ""exists"" ] :",if self . decode :,False,97.06,70.81,,,
"def insert_use ( self , edit ) : <TAB> if self . is_first_use ( ) : <TAB> <TAB> for location in [ r "" ^ \ s*namespace \ s+[ \ w \\ ]+[; { ] "" , r "" < \ ?php "" ] : <TAB> <TAB> <TAB> inserted = self . insert_first_use ( location , edit ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> self . insert_use_among_others ( edit )",if inserted :,if inserted :,True,100.0,74.22,,,
"def _new_rsa_key ( spec ) : <TAB> if "" name "" not in spec : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ( head , tail ) = os . path . split ( spec [ "" key "" ] ) <TAB> <TAB> <TAB> spec [ "" path "" ] = head <TAB> <TAB> <TAB> spec [ "" name "" ] = tail <TAB> <TAB> else : <TAB> <TAB> <TAB> spec [ "" name "" ] = spec [ "" key "" ] <TAB> return rsa_init ( spec )","if spec [ ""key"" ] . endswith ( "".rsa"" ) :","if ""/"" in spec [ ""key"" ] :",False,92.69,70.79,,,
"def mimeData ( self , indexes ) : <TAB> if len ( indexes ) == 1 : <TAB> <TAB> index = indexes [ 0 ] <TAB> <TAB> model = song = index . data ( Qt . UserRole ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> model = song . album <TAB> <TAB> <TAB> except ( ProviderIOError , Exception ) : <TAB> <TAB> <TAB> <TAB> model = None <TAB> <TAB> return ModelMimeData ( model )",if model is None :,if index . column ( ) == Column . album :,False,91.49,68.56,,,
"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB> <TAB> if url . endswith ( "" ping "" ) and self . _first_ping : <TAB> <TAB> <TAB> self . _first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ErrorApiResponse ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = app . get ( url , * * kwargs ) <TAB> <TAB> <TAB> return TestingResponse ( response ) <TAB> else : <TAB> <TAB> return requests . get ( url , * * kwargs )","elif url . endswith ( ""error"" ) and self . _first_ping :","elif ""Hello0"" in url and ""1.2.1"" in url and ""v1"" in url :",False,90.8,64.33,,,
"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB> <TAB> if hasattr ( model , "" _create_content_base "" ) : <TAB> <TAB> <TAB> self . validate_base_model ( model ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . validate_content_type ( model )","if hasattr ( model , ""_create_content_type"" ) :","if hasattr ( model , ""_feincms_content_models"" ) :",False,96.56,72.88,,,
"def test_rules_widget ( self ) : <TAB> subreddit = self . reddit . subreddit ( pytest . placeholders . test_subreddit ) <TAB> widgets = subreddit . widgets <TAB> with self . use_cassette ( "" TestSubredditWidgets.fetch_widgets "" ) : <TAB> <TAB> rules = None <TAB> <TAB> for widget in widgets . sidebar : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> rules = widget <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert isinstance ( rules , RulesWidget ) <TAB> <TAB> assert rules == rules <TAB> <TAB> assert rules . id == rules <TAB> <TAB> assert rules . display <TAB> <TAB> assert len ( rules ) > 0 <TAB> <TAB> assert subreddit == rules . subreddit","if isinstance ( widget , RulesWidget ) :","if isinstance ( widget , RulesWidget ) :",True,100.0,74.49,,,
"def __init__ ( self , exception ) : <TAB> message = str ( exception ) <TAB> with contextlib . suppress ( IndexError ) : <TAB> <TAB> underlying_exception = exception . args [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message = ( <TAB> <TAB> <TAB> <TAB> "" maximum retries exceeded trying to reach the store. \n "" <TAB> <TAB> <TAB> <TAB> "" Check your network connection, and check the store  "" <TAB> <TAB> <TAB> <TAB> "" status at  {} "" . format ( _STORE_STATUS_URL ) <TAB> <TAB> <TAB> ) <TAB> super ( ) . __init__ ( message = message )",if underlying_exception . errno == errno . ECONNRESET :,"if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) :",False,93.64,69.63,,,
"def wrapped ( self , request ) : <TAB> try : <TAB> <TAB> return self . _finished <TAB> except AttributeError : <TAB> <TAB> if self . node_ids : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> log . debug ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  is still going to be used, not terminating it.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Still in use on: \n %s "" , <TAB> <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> <TAB> <TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( request ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _finished = True",if self . _finished :,if not request . session . shouldfail and not request . session . shouldstop :,False,94.79,69.85,,,
"def get_min_vertical_scroll ( ) - > int : <TAB> # Make sure that the cursor line is not below the bottom. <TAB> # (Calculate how many lines can be shown between the cursor and the .) <TAB> used_height = 0 <TAB> prev_lineno = ui_content.cursor_position.y <TAB> for lineno in range(ui_content.cursor_position.y, -1, -1): <TAB> <TAB> used_height += get_line_height(lineno) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return prev_lineno <TAB> <TAB> else: <TAB> <TAB> <TAB> prev_lineno = lineno <TAB> return 0",if used_height < min_horizontal_scroll :,if used_height > height - scroll_offsets_bottom :,False,94.91,70.97,,,
"def cookies ( self ) : <TAB> # strip cookie_suffix from all cookies in the request, return result <TAB> cookies = flask.Request.cookies.__get__(self) <TAB> result = {} <TAB> desuffixed = {} <TAB> for key, value in cookies.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> desuffixed[key[: -len(self.cookie_suffix)]] = value <TAB> <TAB> else: <TAB> <TAB> <TAB> result[key] = value <TAB> result.update(desuffixed) <TAB> return result",if key . endswith ( self . cookie_suffix ) :,if key . endswith ( self . cookie_suffix ) :,True,100.0,74.11,,,
"def update_vars ( state1 , state2 ) : <TAB> ops = [ ] <TAB> for name in state1 . _fields : <TAB> <TAB> state1_vs = getattr ( state1 , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ops + = [ <TAB> <TAB> <TAB> <TAB> tf . assign ( _v1 , _v2 ) <TAB> <TAB> <TAB> <TAB> for _v1 , _v2 in zip ( state1_vs , getattr ( state2 , name ) ) <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ops + = [ tf . assign ( state1_vs , getattr ( state2 , name ) ) ] <TAB> return tf . group ( * ops )","if isinstance ( state1_vs , ( list , tuple ) ) :","if isinstance ( state1_vs , list ) :",False,96.66,72.7,,,
"def manifest ( self ) : <TAB> """""" The current manifest dictionary. """""" <TAB> if self . reload : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return { } <TAB> <TAB> mtime = self . getmtime ( self . manifest_path ) <TAB> <TAB> if self . _mtime is None or mtime > self . _mtime : <TAB> <TAB> <TAB> self . _manifest = self . get_manifest ( ) <TAB> <TAB> <TAB> self . _mtime = mtime <TAB> return self . _manifest",if self . _manifest is None :,if not self . exists ( self . manifest_path ) :,False,91.93,73.63,,,
"def csvtitle ( self ) : <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> return ' "" ' + self . name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB> else : <TAB> <TAB> ret = "" "" <TAB> <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> <TAB> ret = ret + ' "" ' + name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" sep "" ] <TAB> <TAB> return ret",if i > 0 :,if i + 1 != len ( self . name ) :,False,93.63,70.87,,,
"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB> <TAB> for dst , src in viewitems ( assignblk ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if final_dst is not None : <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst",if dst == linenb :,"if dst . is_id ( ""IRDst"" ) :",False,94.18,64.42,,,
"def _ProcessName ( self , name , dependencies ) : <TAB> """""" Retrieve a module name from a node name. """""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if module_name in dependencies : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] . add ( base_name ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] = { base_name } <TAB> <TAB> else : <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging.warning(""Empty package name: %s"", name)",if base_name :,if module_name :,False,99.05,73.75,,,
"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB> <TAB> if i == "" [ "" : <TAB> <TAB> <TAB> m = - 1 <TAB> <TAB> <TAB> aas . append ( "" "" ) <TAB> <TAB> elif i == "" ] "" : <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == - 1 : <TAB> <TAB> <TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> aas . append ( i ) <TAB> return aas",elif m == 1 :,elif m == 0 :,False,98.62,73.28,,,
"def logic ( ) : <TAB> count = intbv ( 0 , min = 0 , max = MAXVAL + 1 ) <TAB> while True : <TAB> <TAB> yield clock . posedge , reset . posedge <TAB> <TAB> if reset == 1 : <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> flag . next = 0 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> flag . next = 1 <TAB> <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> count + = 1",if reset == 2 :,if count == MAXVAL :,False,97.17,72.36,,,
"def logic ( ) : <TAB> count = intbv ( 0 , min = 0 , max = MAXVAL + 1 ) <TAB> while True : <TAB> <TAB> yield clock . posedge , reset . posedge <TAB> <TAB> if reset == 1 : <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> flag . next = 0 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> flag . next = 1 <TAB> <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> count + = 1",if reset == 2 :,if hkey . startswith ( k [ : - 1 ] ) :,False,92.83,68.93,,,
"def optimize_models ( args , use_cuda , models ) : <TAB> """""" Optimize ensemble for generation """""" <TAB> for model in models : <TAB> <TAB> model . make_generation_fast_ ( <TAB> <TAB> <TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB> <TAB> <TAB> need_attn = args . print_alignment , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> model . half ( ) <TAB> <TAB> if use_cuda : <TAB> <TAB> <TAB> model . cuda ( )",if args . use_half :,if args . fp16 :,False,97.13,97.78,,,
"def _Dynamic_Rollback ( self , transaction , transaction_response ) : <TAB> txid = transaction . handle ( ) <TAB> self . __local_tx_lock . acquire ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise apiproxy_errors . ApplicationError ( <TAB> <TAB> <TAB> <TAB> datastore_pb . Error . BAD_REQUEST , "" Transaction  %d  not found. "" % ( txid , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> txdata = self . __transactions [ txid ] <TAB> <TAB> assert ( <TAB> <TAB> <TAB> txdata . thread_id == thread . get_ident ( ) <TAB> <TAB> ) , "" Transactions are single-threaded. "" <TAB> <TAB> del self . __transactions [ txid ] <TAB> finally : <TAB> <TAB> self . __local_tx_lock . release ( )",if txid not in self . __transactions :,if txid not in self . __transactions :,True,100.0,74.51,,,
"def get_job_dirs ( path ) : <TAB> regex = re . compile ( "" [1-9][0-9]*- "" ) <TAB> jobdirs = [ ] <TAB> for d in os . listdir ( path ) : <TAB> <TAB> # skip directories not matching the job result dir pattern <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os.path.join(options.resultsdir, d) <TAB> <TAB> if os.path.isdir(d) and not os.path.exists(os.path.join(d, PUBLISH_FLAGFILE)): <TAB> <TAB> <TAB> jobdirs.append(d) <TAB> return jobdirs",if regex . match ( d ) :,if not regex . match ( d ) :,False,98.53,72.53,,,
"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB> <TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB> <TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB> <TAB> if node : <TAB> <TAB> <TAB> node . functions = list ( functions ) <TAB> <TAB> <TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB> <TAB> functions . append ( type ( node ) . __name__ ) <TAB> <TAB> for f in node . next_functions : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB> <TAB> <TAB> <TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB> <TAB> for t in node . saved_tensors : <TAB> <TAB> <TAB> traverse ( t )","if hasattr ( f [ 0 ] , ""__name__"" ) :",if f [ 0 ] :,False,95.11,68.15,,,
"def get_all_snap_points ( self , forts ) : <TAB> points = [ ] <TAB> radius = Constants . MAX_DISTANCE_FORT_IS_REACHABLE <TAB> for i in range ( 0 , len ( forts ) ) : <TAB> <TAB> for j in range ( i + 1 , len ( forts ) ) : <TAB> <TAB> <TAB> c1 , c2 = self . get_enclosing_circles ( forts [ i ] , forts [ j ] , radius ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> points . append ( ( c1 , c2 , forts [ i ] , forts [ j ] ) ) <TAB> return points",if c1 != c2 :,if c1 and c2 :,False,97.77,73.08,,,
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if not isinstance ( grandchild , minidom . Element ) :","if not isinstance ( grandchild , minidom . Element ) :",True,100.0,74.56,,,
"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB> <TAB> if ch == "" "" : <TAB> <TAB> <TAB> w + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return w","elif ch == ""\t"" :","elif ch == ""\t"" :",True,100.0,74.13,,,
"def test_avg_group_by ( self ) : <TAB> ret = ( <TAB> <TAB> await Book . annotate ( avg = Avg ( "" rating "" ) ) <TAB> <TAB> . group_by ( "" author_id "" ) <TAB> <TAB> . values ( "" author_id "" , "" avg "" ) <TAB> ) <TAB> for item in ret : <TAB> <TAB> author_id = item . get ( "" author_id "" ) <TAB> <TAB> avg = item . get ( "" avg "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( avg , 4.5 ) <TAB> <TAB> elif author_id == self . a2 . pk : <TAB> <TAB> <TAB> self . assertEqual ( avg , 2.0 )",if author_id == self . a1 . pk :,if author_id == self . a1 . pk :,True,100.0,74.48,,,
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> if not expiration . tzinfo : <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )",if stored_session :,if stored_session :,True,100.0,74.56,,,
"def one_line_description ( self ) : <TAB> MAX_LINE_LENGTH = 120 <TAB> desc = util . remove_html_tags ( self . description or "" "" ) <TAB> desc = re . sub ( "" \ s+ "" , "" "" , desc ) . strip ( ) <TAB> if not desc : <TAB> <TAB> return _ ( "" No description available "" ) <TAB> else : <TAB> <TAB> # Decode the description to avoid gPodder bug 1277 <TAB> <TAB> desc = util.convert_bytes(desc).strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return desc[:MAX_LINE_LENGTH] + ""..."" <TAB> <TAB> else: <TAB> <TAB> <TAB> return desc",if len ( desc ) > MAX_LINE_LENGTH :,if len ( desc ) > MAX_LINE_LENGTH :,True,100.0,74.4,,,
"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB> <TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB> <TAB> self . tag . append ( node ) <TAB> <TAB> name = getattr ( node , "" name "" , None ) <TAB> <TAB> if name is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> handler ( node )",if handler :,if handler :,True,100.0,74.52,,,
def get_supported_period_type_map ( cls ) : <TAB> if cls . supported_period_map is None : <TAB> <TAB> cls . supported_period_map = { } <TAB> <TAB> cls . supported_period_map . update ( cls . period_type_map ) <TAB> <TAB> try : <TAB> <TAB> <TAB> from dateutil import relativedelta <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cls . supported_period_map . update ( cls . optional_period_type_map ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass <TAB> return cls . supported_period_map,if relativedelta . is_relative_period ( cls . period_type_map ) :,if relativedelta is not None :,False,90.78,91.01,,,
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if redo : <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> if self . callback : <TAB> <TAB> <TAB> <TAB> self . callback ( )",if compare_id not in compares_done :,"if self . _decide_whether_to_process ( compare_id , redo , compares_done ) :",False,91.51,70.1,,,
"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB> <TAB> for field_name in field_names : <TAB> <TAB> <TAB> field_name = field_name . lower ( ) <TAB> <TAB> <TAB> if "" : "" in line : <TAB> <TAB> <TAB> <TAB> left , right = line . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> <TAB> left = left . strip ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> right = right . strip ( ) <TAB> <TAB> <TAB> <TAB> if left == field_name and len ( right ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None",if len ( left ) == cant_be_number :,if not right . isdigit ( ) :,False,95.99,72.28,,,
"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB> <TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB> <TAB> if not s . consume ( "" \\ "" ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB> <TAB> <TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> s . expect_re ( _escapes_re ) <TAB> <TAB> <TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res )",elif s . consume_re ( _basicstr_re ) :,if s . consume_re ( _newline_esc_re ) :,False,97.16,72.85,,,
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> if code == ""550"": <TAB> <TAB> <TAB> <TAB> if self.isfile(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise # pragma: no cover",elif self . isdir ( path ) :,if not self . isempty ( path ) :,False,97.74,71.25,,,
"def _normalize_store_path ( self , resource_store ) : <TAB> if resource_store [ "" type "" ] == "" filesystem "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resource_store [ "" base_directory "" ] = os . path . join ( <TAB> <TAB> <TAB> <TAB> self . root_directory , resource_store [ "" base_directory "" ] <TAB> <TAB> <TAB> ) <TAB> return resource_store","if resource_store [ ""base_directory"" ] :","if not os . path . isabs ( resource_store [ ""base_directory"" ] ) :",False,91.29,66.44,,,
"def _apply_nested ( name , val , nested ) : <TAB> parts = name . split ( "" . "" ) <TAB> cur = nested <TAB> for i in range ( 0 , len ( parts ) - 1 ) : <TAB> <TAB> cur = cur . setdefault ( parts [ i ] , { } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conflicts_with = "" . "" . join ( parts [ 0 : i + 1 ] ) <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" %r  cannot be nested: conflicts with  { %r :  %s } "" <TAB> <TAB> <TAB> <TAB> % ( name , conflicts_with , cur ) <TAB> <TAB> <TAB> ) <TAB> cur [ parts [ - 1 ] ] = val",if cur :,"if not isinstance ( cur , dict ) :",False,95.79,71.42,,,
"def build_packages ( targeted_packages , distribution_directory , is_dev_build = False ) : <TAB> # run the build and distribution <TAB> for package_root in targeted_packages: <TAB> <TAB> service_hierarchy = os.path.join(os.path.basename(package_root)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> verify_update_package_requirement(package_root) <TAB> <TAB> print(""Generating Package Using Python {}"".format(sys.version)) <TAB> <TAB> run_check_call( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> sys.executable, <TAB> <TAB> <TAB> <TAB> build_packing_script_location, <TAB> <TAB> <TAB> <TAB> ""--dest"", <TAB> <TAB> <TAB> <TAB> os.path.join(distribution_directory, service_hierarchy), <TAB> <TAB> <TAB> <TAB> package_root, <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> root_dir, <TAB> <TAB> )",if is_dev_build :,if is_dev_build :,True,100.0,74.28,,,
"def resolve_root_node_address ( self , root_node ) : <TAB> if "" [ "" in root_node : <TAB> <TAB> name , numbers = root_node . split ( "" [ "" , maxsplit = 1 ) <TAB> <TAB> number = numbers . split ( "" , "" , maxsplit = 1 ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> number = number . split ( "" - "" ) [ 0 ] <TAB> <TAB> number = re . sub ( "" [^0-9] "" , "" "" , number ) <TAB> <TAB> root_node = name + number <TAB> return root_node","if ""-"" in number :","if ""-"" in number :",True,100.0,74.38,,,
"def _map_args ( maps : dict , * * kwargs ) : <TAB> # maps: key=old name, value= new name <TAB> output = {} <TAB> for name, val in kwargs.items(): <TAB> <TAB> if name in maps: <TAB> <TAB> <TAB> assert isinstance(maps[name], str) <TAB> <TAB> <TAB> output.update({maps[name]: val}) <TAB> <TAB> else: <TAB> <TAB> <TAB> output.update({name: val}) <TAB> for keys in maps.keys(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> return output",if keys in kwargs :,if keys not in output . keys ( ) :,False,95.16,68.97,,,
"def next_item ( self , direction ) : <TAB> """""" Selects next menu item, based on self._direction """""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",if i >= len ( self . items ) :,if i >= len ( self . items ) :,True,100.0,99.59,,,
"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . KEY in function . context : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _explore ( function . entry_point , [ ] ) <TAB> <TAB> <TAB> function . context [ self . KEY ] = True",if self . _is_function_reentrancy ( function ) :,if function . is_implemented :,False,90.29,70.07,,,
"def load_model ( self ) : <TAB> if not os . path . exists ( self . get_filename ( absolute = True ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return { } , { } <TAB> <TAB> error ( <TAB> <TAB> <TAB> "" Model file with pre-trained convolution layers not found. Download it here... "" , <TAB> <TAB> <TAB> "" https://github.com/alexjc/neural-enhance/releases/download/v %s / %s "" <TAB> <TAB> <TAB> % ( __version__ , self . get_filename ( ) ) , <TAB> <TAB> ) <TAB> print ( ""  - Loaded file ` {} ` with trained model. "" . format ( self . get_filename ( ) ) ) <TAB> return pickle . load ( bz2 . open ( self . get_filename ( ) , "" rb "" ) )",if self . get_convolution_layers ( ) is None :,if args . train :,False,94.41,72.23,,,
"def get_nonexisting_check_definition_extends ( definition , indexed_oval_defs ) : <TAB> # TODO: handle multiple levels of referrals. <TAB> # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB> for extdefinition in definition.findall("".//{%s}extend_definition"" % oval_ns): <TAB> <TAB> # Verify each extend_definition in the definition <TAB> <TAB> extdefinitionref = extdefinition.get(""definition_ref"") <TAB> <TAB> # Search the OVAL tree for a definition with the referred ID <TAB> <TAB> referreddefinition = indexed_oval_defs.get(extdefinitionref) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # There is no oval satisfying the extend_definition referal <TAB> <TAB> <TAB> return extdefinitionref <TAB> return None","if referreddefinition and referreddefinition . get ( ""referrals"" ) :",if referreddefinition is None :,False,94.76,64.3,,,
"def pause ( self ) : <TAB> if self . is_playing : <TAB> <TAB> self . state = MusicPlayerState . PAUSED <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _current_player . pause ( ) <TAB> <TAB> self . emit ( "" pause "" , player = self , entry = self . current_entry ) <TAB> <TAB> return <TAB> elif self . is_paused : <TAB> <TAB> return <TAB> raise ValueError ( "" Cannot pause a MusicPlayer in state  %s "" % self . state )",if self . _current_player :,if self . _current_player :,True,100.0,74.29,,,
"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( ) # Remove the current form. if it is at the end of the list <TAB> <TAB> if self._THISFORM.FORM_NAME == self.NEXT_ACTIVE_FORM: <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self.setNextForm( <TAB> <TAB> <TAB> <TAB> self._FORM_VISIT_LIST.pop() <TAB> <TAB> <TAB> ) # Switch to the previous form if one exists <TAB> except IndexError: <TAB> <TAB> self.setNextForm(backup)",if self . _FORM_VISIT_LIST :,if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :,False,92.31,69.01,,,
"def get_expr_referrers ( schema : s_schema . Schema , obj : so . Object ) - > Dict [ so . Object , str ] : <TAB> """""" Return schema referrers with refs in expressions. """""" <TAB> refs = schema . get_referrers_ex ( obj ) <TAB> result = { } <TAB> for ( mcls , fn ) , referrers in refs . items ( ) : <TAB> <TAB> field = mcls . get_field ( fn ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . update ( { ref : fn for ref in referrers } ) <TAB> return result",if field . is_ref :,"if issubclass ( field . type , ( Expression , ExpressionList ) ) :",False,91.51,64.17,,,
"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any ( <TAB> <TAB> <TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB> <TAB> ) <TAB> <TAB> if requires_index : <TAB> <TAB> <TAB> fields . append ( field ) <TAB> return fields",if field . primary_key :,if field . primary_key :,True,100.0,74.19,,,
"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> if not self.orig_prefix: <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> idents = getattr(wrapped, ""ident_values"", None) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = [self._wrap_hash(ident) for ident in idents] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ## <TAB> ident = self.ident <TAB> <TAB> <TAB> ## <TAB> if ident is not None: <TAB> <TAB> <TAB> ## <TAB> <TAB> value = [ident] <TAB> <TAB> self._ident_values = value <TAB> return value",if idents :,if idents :,True,100.0,74.51,,,
"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB> <TAB> node = self . path . find_dir ( dir ) <TAB> <TAB> if not node : <TAB> <TAB> <TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lst . append ( node ) <TAB> <TAB> self . bld_incpaths_lst . append ( node )",if node not in lst :,if not node in lst :,False,97.96,72.7,,,
"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB> <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sabnzbd.add_nzbfile(filename, keep=True)",if os . path . isfile ( filename ) :,if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES :,False,86.78,64.83,,,
"def check ( self , xp , nout ) : <TAB> input = xp . asarray ( self . x ) . astype ( numpy . float32 ) <TAB> with warnings . catch_warnings ( ) : <TAB> <TAB> if self . ignore_warning : <TAB> <TAB> <TAB> warnings . simplefilter ( "" ignore "" , self . ignore_warning ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . check_positive ( xp , self . func , input , self . eps , nout ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . check_negative ( xp , self . func , input , self . eps , nout )",if self . positive :,if self . result :,False,98.36,73.28,,,
"def check ( self , xp , nout ) : <TAB> input = xp . asarray ( self . x ) . astype ( numpy . float32 ) <TAB> with warnings . catch_warnings ( ) : <TAB> <TAB> if self . ignore_warning : <TAB> <TAB> <TAB> warnings . simplefilter ( "" ignore "" , self . ignore_warning ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . check_positive ( xp , self . func , input , self . eps , nout ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . check_negative ( xp , self . func , input , self . eps , nout )",if self . positive :,"if remainder . startswith ( ""://"" ) :",False,92.93,64.45,,,
"def parquet ( tables , data_directory , ignore_missing_dependency , * * params ) : <TAB> try : <TAB> <TAB> import pyarrow as pa # noqa: F401 <TAB> <TAB> import pyarrow.parquet as pq # noqa: F401 <TAB> except ImportError: <TAB> <TAB> msg = ""PyArrow dependency is missing"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger.warning(""Ignored: %s"", msg) <TAB> <TAB> <TAB> return 0 <TAB> <TAB> else: <TAB> <TAB> <TAB> raise click.ClickException(msg) <TAB> data_directory = Path(data_directory) <TAB> for table, df in read_tables(tables, data_directory): <TAB> <TAB> arrow_table = pa.Table.from_pandas(df) <TAB> <TAB> target_path = data_directory / ""{}.parquet"".format(table) <TAB> <TAB> pq.write_table(arrow_table, str(target_path))",if ignore_missing_dependency :,if ignore_missing_dependency :,True,100.0,74.38,,,
"def h2i ( self , pkt , s ) : <TAB> t = ( ) <TAB> if type ( s ) is str : <TAB> <TAB> t = time . strptime ( s ) <TAB> <TAB> t = t [ : 2 ] + t [ 2 : - 3 ] <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y , m , d , h , min , sec , rest , rest , rest = time . gmtime ( time . time ( ) ) <TAB> <TAB> <TAB> t = ( y , m , d , h , min , sec ) <TAB> <TAB> else : <TAB> <TAB> <TAB> t = s <TAB> return t",if self . is_gmtime :,if not s :,False,96.07,72.7,,,
"def filter_episodes ( self , batch , cross_entropy ) : <TAB> """""" Filter the episodes for the cross_entropy method """""" <TAB> accumulated_reward = [ sum ( rewards ) for rewards in batch [ "" rewards "" ] ] <TAB> percentile = cross_entropy * 100 <TAB> reward_bound = np . percentile ( accumulated_reward , percentile ) <TAB> # we save the batch with reward above the bound <TAB> result = {k: [] for k in self.data_keys} <TAB> episode_kept = 0 <TAB> for i in range(len(accumulated_reward)): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k in self.data_keys: <TAB> <TAB> <TAB> <TAB> result[k].append(batch[k][i]) <TAB> <TAB> <TAB> episode_kept += 1 <TAB> return result",if episode_kept < reward_bound :,if accumulated_reward [ i ] >= reward_bound :,False,95.78,96.71,,,
"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB> <TAB> envvar = match . groups ( ) [ 0 ] <TAB> <TAB> if envvar in os . environ : <TAB> <TAB> <TAB> value = os . environ [ envvar ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> <TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB> <TAB> <TAB> <TAB> msg , var , _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> )","if isinstance ( value , bytes ) :",if six . PY2 :,False,97.32,72.89,,,
"def _allocate_nbd ( self ) : <TAB> if not os . path . exists ( "" /sys/block/nbd0 "" ) : <TAB> <TAB> self . error = _ ( "" nbd unavailable: module not loaded "" ) <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> if not self . _DEVICES : <TAB> <TAB> <TAB> # really want to log this info, not raise <TAB> <TAB> <TAB> self.error = _(""No free nbd devices"") <TAB> <TAB> <TAB> return None <TAB> <TAB> device = self._DEVICES.pop() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return device",if device is None :,"if not os . path . exists ( ""/sys/block/%s/pid"" % os . path . basename ( device ) ) :",False,84.31,60.91,,,
"def _expand_deps_java_generation ( self ) : <TAB> """""" Ensure that all multilingual dependencies such as proto_library generate java code. """""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB> <TAB> k = queue . popleft ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> keys . add ( k ) <TAB> <TAB> <TAB> dep = self . target_database [ k ] <TAB> <TAB> <TAB> if "" generate_java "" in dep . attr : # Has this attribute <TAB> <TAB> <TAB> <TAB> dep.attr[""generate_java""] = True <TAB> <TAB> <TAB> <TAB> queue.extend(dep.deps)",if k not in keys :,if k not in keys :,True,100.0,99.41,,,
"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB> <TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB> <TAB> if isinstance ( fstyle , basestring ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> key = fstyle [ 2 : - 2 ] <TAB> <TAB> <TAB> <TAB> fstyle = context [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats","if fstyle . endswith ( ""/"" ) :","if fstyle . startswith ( ""%("" ) and fstyle . endswith ( "")s"" ) :",False,94.85,67.57,,,
"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values . remove ( ) <TAB> <TAB> elif operation == "" update "" : <TAB> <TAB> <TAB> old_value , new_value = values <TAB> <TAB> <TAB> if new_value . full_filename != old_value . full_filename : <TAB> <TAB> <TAB> <TAB> os . unlink ( new_value . full_filename ) <TAB> <TAB> <TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( )","if operation == ""delete"" :","if operation == ""insert"" :",False,98.49,72.95,,,
"def _buildOffsets ( offsetDict , localeData , indexStart ) : <TAB> o = indexStart <TAB> for key in localeData : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k in key . split ( "" | "" ) : <TAB> <TAB> <TAB> <TAB> offsetDict [ k ] = o <TAB> <TAB> else : <TAB> <TAB> <TAB> offsetDict [ key ] = o <TAB> <TAB> o + = 1","if ""|"" in key :","if ""|"" in key :",True,100.0,74.14,,,
"def _check_start_pipeline_execution_errors ( <TAB> graphene_info , execution_params , execution_plan ) : <TAB> if execution_params . step_keys : <TAB> <TAB> for step_key in execution_params . step_keys : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise UserFacingGraphQLError ( <TAB> <TAB> <TAB> <TAB> <TAB> graphene_info . schema . type_named ( "" InvalidStepError "" ) ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> invalid_step_key = step_key <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )","if step_key not in graphene_info . schema . fields_named ( ""InvalidStepError"" ) :",if not execution_plan . has_step ( step_key ) :,False,91.07,60.78,,,
"def __setattr__ ( self , option_name , option_value ) : <TAB> if option_name in self . _options : <TAB> <TAB> # type checking <TAB> <TAB> sort = self.OPTIONS[self.arch.name][option_name][0] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._options[option_name] = option_value <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> 'Value for option ""%s"" must be of type %s' % (option_name, sort) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> super(CFGArchOptions, self).__setattr__(option_name, option_value)",if sort in self . _options [ self . arch . name ] [ option_name ] :,"if sort is None or isinstance ( option_value , sort ) :",False,91.44,66.23,,,
"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB> <TAB> quote = True <TAB> else : <TAB> <TAB> for x in self : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote : <TAB> <TAB> pre = post = "" "" <TAB> <TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> if self [ - 1 ] . token_type == "" cfws "" or self [ - 1 ] [ - 1 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB> <TAB> return super ( DisplayName , self ) . value","if x . token_type == ""cfws"" or x [ 0 ] . token_type == ""cfws"" :","if x . token_type == ""quoted-string"" :",False,93.59,69.28,,,
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename . startswith ( os . sep ) : <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> if data : <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories","if isinstance ( filename_data , tuple ) :","if isinstance ( filename_data , list ) :",False,98.89,73.56,,,
"def _evaluateStack ( s ) : <TAB> op = s . pop ( ) <TAB> if op in "" +-*/@^ "" : <TAB> <TAB> op2 = _evaluateStack ( s ) <TAB> <TAB> op1 = _evaluateStack ( s ) <TAB> <TAB> result = opn [ op ] ( op1 , op2 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( result ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return op",if result :,if debug_flag :,False,96.2,72.47,,,
"def reconnect_user ( self , user_id , host_id , server_id ) : <TAB> if host_id == settings . local . host_id : <TAB> <TAB> return <TAB> if server_id and self . server . id != server_id : <TAB> <TAB> return <TAB> for client in self . clients . find ( { "" user_id "" : user_id } ) : <TAB> <TAB> self . clients . update_id ( <TAB> <TAB> <TAB> client [ "" id "" ] , <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" ignore_routes "" : True , <TAB> <TAB> <TAB> } , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . instance . disconnect_wg ( client [ "" id "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . instance_com . client_kill ( client [ "" id "" ] )","if self . instance_com . client_is_wg ( client [ ""id"" ] ) :","if len ( client [ ""id"" ] ) > 32 :",False,94.53,72.24,,,
"def _get_library ( self , name , args ) : <TAB> library_database = self . _library_manager . get_new_connection_to_library_database ( ) <TAB> try : <TAB> <TAB> last_updated = library_database . get_library_last_updated ( name , args ) <TAB> <TAB> if last_updated : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _library_manager . fetch_keywords ( <TAB> <TAB> <TAB> <TAB> <TAB> name , args , self . _libraries_need_refresh_listener <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return library_database . fetch_library_keywords ( name , args ) <TAB> <TAB> return self . _library_manager . get_and_insert_keywords ( name , args ) <TAB> finally : <TAB> <TAB> library_database . close ( )",if last_updated . is_updated ( ) :,if time . time ( ) - last_updated > 10.0 :,False,95.74,70.48,,,
"def get_paths ( self , path , commit ) : <TAB> """""" Return a generator of all filepaths under path at commit. """""" <TAB> _check_path_is_repo_relative ( path ) <TAB> git_path = _get_git_path ( path ) <TAB> tree = self . gl_repo . git_repo [ commit . tree [ git_path ] . id ] <TAB> assert tree . type == pygit2 . GIT_OBJ_TREE <TAB> for tree_entry in tree : <TAB> <TAB> tree_entry_path = os . path . join ( path , tree_entry . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for fp in self . get_paths ( tree_entry_path , commit ) : <TAB> <TAB> <TAB> <TAB> yield fp <TAB> <TAB> else : <TAB> <TAB> <TAB> yield tree_entry_path",if self . is_dir ( tree_entry_path ) :,"if tree_entry . type == ""tree"" :",False,94.75,92.67,,,
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :","if ""exp"" in conf [ ""properties"" ] [ ""attributes"" ] :",True,100.0,74.24,,,
"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB> <TAB> if tag == ""style"": <TAB> <TAB> <TAB> self._wb_parse_context = ""style"" <TAB> <TAB> elif tag == ""script"": <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self._wb_parse_context = ""script""","if tag_attrs [ ""style"" ] :",if self . _allow_js_type ( tag_attrs ) :,False,90.56,62.91,,,
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> if not isinstance ( op_list , list ) : <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> if dictionary . path in paths : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list",if item . path in dictionary_list :,if item is None :,False,96.29,72.28,,,
def preorder ( root ) : <TAB> res = [ ] <TAB> if not root : <TAB> <TAB> return res <TAB> stack = [ ] <TAB> stack . append ( root ) <TAB> while stack : <TAB> <TAB> root = stack . pop ( ) <TAB> <TAB> res . append ( root . val ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stack . append ( root . right ) <TAB> <TAB> if root . left : <TAB> <TAB> <TAB> stack . append ( root . left ) <TAB> return res,if root . right :,if root . right :,True,100.0,99.33,,,
"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB> <TAB> self . context . log . info ( <TAB> <TAB> <TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB> <TAB> ) <TAB> <TAB> subject = self . derived_by_original . get ( <TAB> <TAB> <TAB> exported_python_target , exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB> <TAB> created [ exported_python_target ] = setup_dir <TAB> <TAB> if self . _recursive : <TAB> <TAB> <TAB> for dep in dependencies : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> create ( dep )",if dep not in created :,if is_exported_python_target ( dep ) :,False,95.05,72.21,,,
"def test_array_interface ( self , data ) : <TAB> result = np . array ( data ) <TAB> np . testing . assert_array_equal ( result [ 0 ] , data [ 0 ] ) <TAB> result = np . array ( data , dtype = object ) <TAB> expected = np . array ( list ( data ) , dtype = object ) <TAB> for a1 , a2 in zip ( result , expected ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert np . isnan ( a1 ) and np . isnan ( a2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tm . assert_numpy_array_equal ( a2 , a1 )","if isinstance ( a1 , np . ndarray ) :",if np . isscalar ( a1 ) :,False,95.67,71.92,,,
"def valueChanged ( plug ) : <TAB> changed = plug . getInput ( ) is not None <TAB> if not changed and isinstance ( plug , Gaffer . ValuePlug ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> changed = not Gaffer . NodeAlgo . isSetToUserDefault ( plug ) <TAB> <TAB> else : <TAB> <TAB> <TAB> changed = not plug . isSetToDefault ( ) <TAB> return changed","if plug . getInput ( ) == ""User"" :",if Gaffer . NodeAlgo . hasUserDefault ( plug ) :,False,89.59,60.24,,,
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> <IF-STMT> # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB> if arch is not None: <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB> if exe_data is not None: <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",if version is not None :,if version is not None :,True,100.0,74.5,,,
"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB> <TAB> if isinstance ( value , alias_flag_value ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( name , self . _has_flag ( value . flag ) )","if isinstance ( value , alias_flag_value ) :","if isinstance ( value , flag_value ) :",False,96.66,71.99,,,
"def connect ( self ) : <TAB> self . sock = sockssocket ( ) <TAB> self . sock . setproxy ( * proxy_args ) <TAB> if type ( self . timeout ) in ( int , float ) : <TAB> <TAB> self . sock . settimeout ( self . timeout ) <TAB> self . sock . connect ( ( self . host , self . port ) ) <TAB> if isinstance ( self , compat_http_client . HTTPSConnection ) : <TAB> <TAB> <IF-STMT> # Python > 2.6 <TAB> <TAB> <TAB> self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.sock = ssl.wrap_socket(self.sock)",if self . _context :,"if hasattr ( self , ""_context"" ) :",False,94.79,62.77,,,
"def frequent_thread_switches ( ) : <TAB> """""" Make concurrency bugs more likely to manifest. """""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval )",if interval is not None :,"if hasattr ( sys , ""setswitchinterval"" ) :",False,95.94,70.43,,,
"def vars ( self ) : <TAB> ret = [ ] <TAB> if op . intlist : <TAB> <TAB> varlist = op . intlist <TAB> else : <TAB> <TAB> varlist = self . discover <TAB> <TAB> for name in varlist : <TAB> <TAB> <TAB> if name in ( "" 0 "" , "" 1 "" , "" 2 "" , "" 8 "" , "" CPU0 "" , "" ERR "" , "" LOC "" , "" MIS "" , "" NMI "" ) : <TAB> <TAB> <TAB> <TAB> varlist . remove ( name ) <TAB> <TAB> if not op . full and len ( varlist ) > 3 : <TAB> <TAB> <TAB> varlist = varlist [ - 3 : ] <TAB> for name in varlist : <TAB> <TAB> if name in self . discover : <TAB> <TAB> <TAB> ret . append ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( self . intmap [ name . lower ( ) ] ) <TAB> return ret",elif name . lower ( ) in self . intmap :,elif name . lower ( ) in self . intmap :,True,100.0,74.65,,,
"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB> <TAB> inst . add ( gadget . _gadget ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> count = len ( inst ) <TAB> <TAB> <TAB> toReturn . append ( gadget ) <TAB> <TAB> <TAB> added = True <TAB> <TAB> if callback : <TAB> <TAB> <TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB> <TAB> <TAB> added = False <TAB> return toReturn",if count == len_gadgets :,if len ( inst ) > count :,False,96.19,71.64,,,
"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> if not self.orig_prefix: <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> ident = getattr(wrapped, ""ident"", None) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = self._wrap_hash(ident) <TAB> <TAB> self._ident = value <TAB> return value",if ident is not None :,if ident is not None :,True,100.0,74.35,,,
"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """""" Take a nested dict and return a flat dict of setting values. """""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB> <TAB> if isinstance ( field , _ContainerMixin ) : <TAB> <TAB> <TAB> setting_values . update ( <TAB> <TAB> <TAB> <TAB> self . _flatten_settings_from_form ( <TAB> <TAB> <TAB> <TAB> <TAB> settings , field , form_values [ field . _name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values","elif isinstance ( field , _FormField ) :",elif field . _name in settings :,False,96.26,93.56,,,
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != "" __init__ "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot : <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls",if meth is None :,"if not private and name . startswith ( ""_"" ) :",False,91.49,61.72,,,
"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB> <TAB> while True : <TAB> <TAB> <TAB> b1 = fp1 . read ( bufsize ) <TAB> <TAB> <TAB> b2 = fp2 . read ( bufsize ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> if not b1 : <TAB> <TAB> <TAB> <TAB> return True",if not b1 and not b2 :,if b1 != b2 :,False,96.28,72.0,,,
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> if value : <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args )",if value :,if self . ctl :,False,97.96,72.97,,,
"def check ( self , hyperlinks : Dict [ str , Hyperlink ] ) - > Generator [ CheckResult , None , None ] : <TAB> self . invoke_threads ( ) <TAB> total_links = 0 <TAB> for hyperlink in hyperlinks . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield CheckResult ( <TAB> <TAB> <TAB> <TAB> hyperlink . uri , hyperlink . docname , hyperlink . lineno , "" ignored "" , "" "" , 0 <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . wqueue . put ( CheckRequest ( CHECK_IMMEDIATELY , hyperlink ) , False ) <TAB> <TAB> <TAB> total_links + = 1 <TAB> done = 0 <TAB> while done < total_links : <TAB> <TAB> yield self . rqueue . get ( ) <TAB> <TAB> done + = 1 <TAB> self . shutdown_threads ( )",if hyperlink . is_linked :,if self . is_ignored_uri ( hyperlink . uri ) :,False,94.88,71.74,,,
"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subscriber . _pyroRelease ( ) <TAB> <TAB> if hasattr ( subscriber , "" _pyroUri "" ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> <TAB> proxy . _pyroRelease ( ) <TAB> <TAB> <TAB> <TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . subscribers [ topic ] . discard ( subscriber )","if hasattr ( subscriber , ""_pyroRelease"" ) :","if hasattr ( subscriber , ""_pyroRelease"" ) :",True,100.0,74.46,,,
"def delete_arc ( collection , document , origin , target , type ) : <TAB> directory = collection <TAB> real_dir = real_directory ( directory ) <TAB> mods = ModificationTracker ( ) <TAB> projectconf = ProjectConfiguration ( real_dir ) <TAB> document = path_join ( real_dir , document ) <TAB> with TextAnnotations ( document ) as ann_obj : <TAB> <TAB> # bail as quick as possible if read-only <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AnnotationsIsReadOnlyError(ann_obj.get_document()) <TAB> <TAB> _delete_arc_with_ann(origin, target, type, mods, ann_obj, projectconf) <TAB> <TAB> mods_json = mods.json_response() <TAB> <TAB> mods_json[""annotations""] = _json_from_ann(ann_obj) <TAB> <TAB> return mods_json",if ann_obj . get_document ( ) . is_read_only :,if ann_obj . _read_only :,False,96.16,72.2,,,
"def _select_from ( self , parent_path , is_dir , exists , listdir ) : <TAB> if not is_dir ( parent_path ) : <TAB> <TAB> return <TAB> with _cached ( listdir ) as listdir : <TAB> <TAB> yielded = set ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> successor_select = self . successor . _select_from <TAB> <TAB> <TAB> for starting_point in self . _iterate_directories ( <TAB> <TAB> <TAB> <TAB> parent_path , is_dir , listdir <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> for p in successor_select ( starting_point , is_dir , exists , listdir ) : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield p <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yielded . add ( p ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> yielded . clear ( )",if p not in yielded :,if p not in yielded :,True,100.0,74.56,,,
"def _fractional_part ( self , n , expr , evaluation ) : <TAB> n_sympy = n . to_sympy ( ) <TAB> if n_sympy . is_constant ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> positive_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression ( "" Floor "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - positive_integer_part <TAB> <TAB> else : <TAB> <TAB> <TAB> negative_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression ( "" Ceiling "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - negative_integer_part <TAB> else : <TAB> <TAB> return expr <TAB> return from_python ( result )",if self . _is_positive ( n ) :,if n_sympy >= 0 :,False,95.82,72.25,,,
"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB> <TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB> <TAB> if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> )",if geometry [ 0 ] < - 180 or geometry [ 0 ] < - 180 :,if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 :,False,94.0,70.33,,,
"def get_absolute_path ( self , root , path ) : <TAB> # find the first absolute path that exists <TAB> self.root = self.roots[0] <TAB> for root in self.roots: <TAB> <TAB> abspath = os.path.abspath(os.path.join(root, path)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.root = root # make sure all the other methods in the base class know how to find the file <TAB> <TAB> <TAB> break <TAB> return abspath",if os . path . exists ( abspath ) :,if os . path . exists ( abspath ) :,True,100.0,74.19,,,
"def do_setflow ( self , l = "" "" ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> l = str ( self . flow_slider . GetValue ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l = l . lower ( ) <TAB> <TAB> flow = int ( l ) <TAB> <TAB> if self . p . online : <TAB> <TAB> <TAB> self . p . send_now ( "" M221 S "" + l ) <TAB> <TAB> <TAB> self . log ( _ ( "" Setting print flow factor to  %d %% . "" ) % flow ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logError ( _ ( "" Printer is not online. "" ) ) <TAB> except Exception as x : <TAB> <TAB> self . logError ( _ ( "" You must enter a flow. ( %s ) "" ) % ( repr ( x ) , ) )",if self . flow_slider . HasValue ( ) :,"if not isinstance ( l , str ) or not len ( l ) :",False,94.44,70.5,,,
"def sources ( ) : <TAB> for d in os . listdir ( base ) : <TAB> <TAB> # <TAB> <TAB> if d.startswith('talis'): <TAB> <TAB> # <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if d == ""indcat"": <TAB> <TAB> <TAB> continue <TAB> <TAB> if not os.path.isdir(base + d): <TAB> <TAB> <TAB> continue <TAB> <TAB> yield d","if d . startswith ( ""src"" ) :","if d . endswith ( ""old"" ) :",False,96.62,71.1,,,
"def create_accumulator ( self ) - > tf_metric_accumulators . TFCompilableMetricsAccumulator : <TAB> configs = zip ( self . _metric_configs , self . _loss_configs ) <TAB> padding_options = None <TAB> if self . _eval_config is not None : <TAB> <TAB> model_spec = model_util . get_model_spec ( self . _eval_config , self . _model_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> padding_options = model_spec . padding_options <TAB> return tf_metric_accumulators . TFCompilableMetricsAccumulator ( <TAB> <TAB> padding_options , <TAB> <TAB> [ len ( m ) + len ( l ) for m , l in configs ] , <TAB> <TAB> desired_batch_size = self . _desired_batch_size , <TAB> )",if model_spec . padding_options is not None :,"if model_spec is not None and model_spec . HasField ( ""padding_options"" ) :",False,93.5,61.97,,,
"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB> <TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . expr . resultsName : <TAB> <TAB> <TAB> <TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB> <TAB> <TAB> <TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tokens = [ self . defaultValue ] <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens = [ ] <TAB> return loc , tokens",if self . defaultValue is not None :,if self . defaultValue is not self . __optionalNotMatched :,False,96.61,72.84,,,
"def handleConnection ( self ) : <TAB> # connection handshake <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> self.csock.close() <TAB> except: <TAB> <TAB> ex_t, ex_v, ex_tb = sys.exc_info() <TAB> <TAB> tb = util.formatTraceback(ex_t, ex_v, ex_tb) <TAB> <TAB> log.warning(""error during connect/handshake: %s; %s"", ex_v, ""\n"".join(tb)) <TAB> <TAB> self.csock.close() <TAB> return False",if self . csock . is_alive ( ) :,if self . daemon . _handshake ( self . csock ) :,False,95.23,68.46,,,
"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 : # have a one element wedge <TAB> <TAB> proc = (""first"", ""last"") <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> proc = (""first"", ""last"") # same element can be first and last <TAB> <TAB> elif su.isFirst(innerTarget): <TAB> <TAB> <TAB> proc = (""first"",) <TAB> <TAB> elif su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""last"",) <TAB> <TAB> else: <TAB> <TAB> <TAB> proc = () <TAB> return proc",if su . isFirst ( innerTarget ) :,if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :,False,96.14,70.53,,,
"def get_color_dtype ( data , column_names ) : <TAB> has_color = all ( column in data [ "" points "" ] for column in column_names ) <TAB> if has_color : <TAB> <TAB> color_data_types = [ <TAB> <TAB> <TAB> data [ "" points "" ] [ column_name ] . dtype for column_name in column_names <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> f "" Data types of color values are inconsistent: got  { color_data_types } "" <TAB> <TAB> <TAB> ) <TAB> <TAB> color_data_type = color_data_types [ 0 ] <TAB> else : <TAB> <TAB> color_data_type = None <TAB> return color_data_type",if color_data_types != [ np . float64 for np in color_data_types ] :,if len ( set ( color_data_types ) ) > 1 :,False,91.9,69.76,,,
"def close ( self ) : <TAB> children = [ ] <TAB> for children_part , line_offset , last_line_offset_leaf in self . children_groups : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> _update_positions ( children_part , line_offset , last_line_offset_leaf ) <TAB> <TAB> <TAB> except _PositionUpdatingFinished : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> children + = children_part <TAB> self . tree_node . children = children <TAB> # Reset the parents <TAB> for node in children: <TAB> <TAB> node.parent = self.tree_node",if children_part . is_position ( ) :,if line_offset != 0 :,False,94.25,71.21,,,
"def get_multi ( self , keys , index = None ) : <TAB> with self . _lmdb . begin ( ) as txn : <TAB> <TAB> result = [ ] <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> packed = txn . get ( key . encode ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result . append ( ( key , cbor . loads ( packed ) ) ) <TAB> return result",if packed :,if packed is not None :,False,96.12,71.02,,,
"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB> <TAB> if p [ 0 ] != "" . "" : <TAB> <TAB> <TAB> subp = os . path . join ( pth , p ) <TAB> <TAB> <TAB> p = os . path . join ( prefix , p ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , None ] ) <TAB> return res",if recursive :,if recursive and os . path . isdir ( subp ) :,False,94.61,70.57,,,
"def __schedule ( self , workflow_scheduler_id , workflow_scheduler ) : <TAB> invocation_ids = self . __active_invocation_ids ( workflow_scheduler_id ) <TAB> for invocation_id in invocation_ids : <TAB> <TAB> log . debug ( "" Attempting to schedule workflow invocation [ %s ] "" , invocation_id ) <TAB> <TAB> self . __attempt_schedule ( invocation_id , workflow_scheduler ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return",if self . __is_scheduled ( invocation_id ) :,if not self . monitor_running :,False,90.31,69.46,,,
"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB> <TAB> self . data . append ( data ) <TAB> else : <TAB> <TAB> if self . size : <TAB> <TAB> <TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> passon = b "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . data . append ( data ) <TAB> return passon",if passon :,if data :,False,98.27,73.18,,,
"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB> <TAB> self . data . append ( data ) <TAB> else : <TAB> <TAB> if self . size : <TAB> <TAB> <TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> passon = b "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . data . append ( data ) <TAB> return passon",if passon :,if k,False,97.59,72.92,,,
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> if self . scrolling : <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",if self . scroll_up_rect ( ) . collidepoint ( p ) :,if self . scroll_up_rect ( ) . collidepoint ( p ) :,True,100.0,74.5,,,
"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB> <TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB> <TAB> <TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB> <TAB> if self . _prompt is None : <TAB> <TAB> <TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB> <TAB> choice = data [ "" choice "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return flask . abort ( <TAB> <TAB> <TAB> <TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _answer_prompt ( choice )",if not choice :,"if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) :",False,90.4,68.35,,,
"def register_predictors ( self , model_data_arr ) : <TAB> for integration in self . _get_integrations ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> integration . register_predictors ( model_data_arr ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> f "" There is no connection to  { integration . name } . predictor wouldn ' t be registred. "" <TAB> <TAB> <TAB> )",if integration . connection_to_model ( ) :,if integration . check_connection ( ) :,False,95.34,72.49,,,
"def _pack_shears ( shearData ) : <TAB> shears = list ( ) <TAB> vidxs = list ( ) <TAB> for e_idx , entry in enumerate ( shearData ) : <TAB> <TAB> # Should be 3 entries <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shears.extend([float(""nan""), float(""nan"")]) <TAB> <TAB> <TAB> vidxs.extend([0, 0]) <TAB> <TAB> else: <TAB> <TAB> <TAB> vidx1, vidx2, shear1, shear2 = entry <TAB> <TAB> <TAB> shears.extend([shear1, shear2]) <TAB> <TAB> <TAB> vidxs.extend([vidx1, vidx2]) <TAB> return (np.asarray(shears, dtype=np.float32), np.asarray(vidxs, dtype=np.uint32))",if len ( entry ) == 3 :,if entry is None :,False,96.02,70.31,,,
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> if not fpath . exists ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( data , dict ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id","if inner [ ""name"" ] != cog_name :","if not isinstance ( inner , dict ) :",False,95.53,66.3,,,
"def subFeaName ( m , newNames , state ) : <TAB> try : <TAB> <TAB> int ( m [ 3 ] , 16 ) <TAB> except : <TAB> <TAB> return m [ 0 ] <TAB> name = m [ 2 ] <TAB> if name in newNames : <TAB> <TAB> # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""sub %r => %r"" % (m[0], m[1] + newNames[name] + m[4])) <TAB> <TAB> state[""didChange""] = True <TAB> <TAB> return m[1] + newNames[name] + m[4] <TAB> return m[0]","if state [ ""state"" ] == ""changed"" :","if name == ""uni0402"" :",False,95.12,65.74,,,
"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB> <TAB> if input_array is None : <TAB> <TAB> <TAB> input_array = model . example_input_array <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB> <TAB> <TAB> self . experiment . add_graph ( model , input_array ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> "" Could not log computational graph since the "" <TAB> <TAB> <TAB> <TAB> ""  `model.example_input_array` attribute is not set "" <TAB> <TAB> <TAB> <TAB> ""  or `input_array` was not given "" , <TAB> <TAB> <TAB> <TAB> UserWarning , <TAB> <TAB> <TAB> )","elif isinstance ( input_array , ( list , tuple ) ) :",if input_array is not None :,False,94.8,70.35,,,
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_date_object ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if not event :,if not event . get_place_handle ( ) :,False,95.91,72.13,,,
"def format ( m ) : <TAB> if m > 1000 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( str ( int ( m / 1000 ) ) , "" km "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ( str ( round ( m / 1000 , 1 ) ) , "" km "" ) <TAB> return ( str ( m ) , "" m "" )",if m % 1000 == 0 :,if m % 1000 == 0 :,True,100.0,74.19,,,
"def previous ( self ) : <TAB> try : <TAB> <TAB> idx = _jump_list_index <TAB> <TAB> next_index = idx + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> next_index = 100 <TAB> <TAB> next_index = min ( len ( _jump_list ) - 1 , next_index ) <TAB> <TAB> _jump_list_index = next_index <TAB> <TAB> return _jump_list [ next_index ] <TAB> except ( IndexError , KeyError ) as e : <TAB> <TAB> return None",if next_index > 100 :,if next_index > 100 :,True,100.0,74.17,,,
"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """""" Placeholder docstring """""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name, definition in self.hyperparameter_definitions.items(): <TAB> <TAB> if name not in self.hyperparam_dict: <TAB> <TAB> <TAB> spec = definition[""spec""] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.hyperparam_dict[name] = spec[""DefaultValue""] <TAB> <TAB> <TAB> elif ""IsRequired"" in spec and spec[""IsRequired""]: <TAB> <TAB> <TAB> <TAB> raise ValueError(""Required hyperparameter: %s is not set"" % name)","if ""DefaultValue"" in spec and spec [ ""DefaultValue"" ] :","if ""DefaultValue"" in spec :",False,95.86,72.19,,,
"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB> <TAB> # take action <TAB> <TAB> if self.action_input.selected_index == 0: # Cancel <TAB> <TAB> <TAB> self.back_to_parent() <TAB> <TAB> <IF-STMT> # Apply <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> client.core.get_config().addCallback(self._update_preferences) <TAB> <TAB> elif self.action_input.selected_index == 2: # OK <TAB> <TAB> <TAB> self._apply_prefs() <TAB> <TAB> <TAB> self.back_to_parent()",elif c == util . KEY_ALT :,elif self . action_input . selected_index == 1 :,False,94.35,69.58,,,
"def _split_anonymous_function ( s ) : <TAB> # Regex is not sufficient to handle differences between anonymous <TAB> # functions and YAML encoded lists. We perform a sniff test to see <TAB> # if it might be an anonymous function and then confirm by <TAB> # decoding it as YAML and testing the result. <TAB> if s[:1] == ""["" and s[-1:] == ""]"" and "":"" in s: <TAB> <TAB> try: <TAB> <TAB> <TAB> l = yaml_util.decode_yaml(s) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> return None, s[1:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None, s[1:-1] <TAB> return None","if s [ 0 ] == ""["" and s [ - 1 ] == ""]"" :","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) :",False,89.43,60.51,,,
"def test_source_address ( self ) : <TAB> for addr , is_ipv6 in VALID_SOURCE_ADDRESSES : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( "" No IPv6 support: skipping. "" , NoIPv6Warning ) <TAB> <TAB> <TAB> continue <TAB> <TAB> pool = HTTPConnectionPool ( <TAB> <TAB> <TAB> self . host , self . port , source_address = addr , retries = False <TAB> <TAB> ) <TAB> <TAB> self . addCleanup ( pool . close ) <TAB> <TAB> r = pool . request ( "" GET "" , "" /source_address "" ) <TAB> <TAB> self . assertEqual ( r . data , b ( addr [ 0 ] ) )",if is_ipv6 :,if is_ipv6 and not HAS_IPV6_AND_DNS :,False,94.09,72.13,,,
"def vim_G ( self ) : <TAB> """""" Put the cursor on the last character of the file. """""" <TAB> if self . is_text_wrapper ( self . w ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . do ( "" end-of-buffer-extend-selection "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . do ( "" end-of-buffer "" ) <TAB> <TAB> self . done ( ) <TAB> else : <TAB> <TAB> self . quit ( )",if self . w . read_only :,"if self . state == ""visual"" :",False,94.16,83.99,,,
"def backend_supported ( module , manager , * * kwargs ) : <TAB> if CollectionNodeModule . backend_supported ( module , manager , * * kwargs ) : <TAB> <TAB> if "" tid "" not in kwargs : <TAB> <TAB> <TAB> return True <TAB> <TAB> conn = manager . connection ( did = kwargs [ "" did "" ] ) <TAB> <TAB> template_path = "" partitions/sql/ {0} /# {0} # {1} # "" . format ( <TAB> <TAB> <TAB> manager . server_type , manager . version <TAB> <TAB> ) <TAB> <TAB> SQL = render_template ( <TAB> <TAB> <TAB> "" / "" . join ( [ template_path , "" backend_support.sql "" ] ) , tid = kwargs [ "" tid "" ] <TAB> <TAB> ) <TAB> <TAB> status , res = conn . execute_scalar ( SQL ) <TAB> <TAB> # check if any errors <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return internal_server_error(errormsg=res) <TAB> <TAB> return res",if status != 0 :,if not status :,False,97.98,73.29,,,
"def _get_regex_config ( self , data_asset_name : Optional [ str ] = None ) - > dict : <TAB> regex_config : dict = copy . deepcopy ( self . _default_regex ) <TAB> asset : Optional [ Asset ] = None <TAB> if data_asset_name : <TAB> <TAB> asset = self . _get_asset ( data_asset_name = data_asset_name ) <TAB> if asset is not None : <TAB> <TAB> # Override the defaults <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> regex_config[""pattern""] = asset.pattern <TAB> <TAB> if asset.group_names: <TAB> <TAB> <TAB> regex_config[""group_names""] = asset.group_names <TAB> return regex_config",if asset . pattern :,if asset . pattern :,True,100.0,74.36,,,
"def resolve ( self , other ) : <TAB> if other == ANY_TYPE : <TAB> <TAB> return self <TAB> elif isinstance ( other , ComplexType ) : <TAB> <TAB> f = self . first . resolve ( other . first ) <TAB> <TAB> s = self . second . resolve ( other . second ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ComplexType ( f , s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> elif self == ANY_TYPE : <TAB> <TAB> return other <TAB> else : <TAB> <TAB> return None",if f != s :,if f and s :,False,97.68,72.96,,,
"def collect_pages ( app ) : <TAB> new_images = { } <TAB> for full_path , basename in app . builder . images . iteritems ( ) : <TAB> <TAB> base , ext = os . path . splitext ( full_path ) <TAB> <TAB> retina_path = base + "" @2x "" + ext <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_images [ retina_path ] = app . env . images [ retina_path ] [ 1 ] <TAB> app . builder . images . update ( new_images ) <TAB> return [ ]",if retina_path in app . env . images :,if retina_path in app . env . images :,True,100.0,74.34,,,
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len ( line . strip ( ) ) == 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if linenum == 0 and line [ 0 ] not in ""\t"" :",if not line :,False,94.56,65.63,,,
"def reader ( ) : <TAB> try : <TAB> <TAB> imgs = mp4_loader ( video_path , seg_num , seglen , mode ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" {}  frame length  {}  less than 1. "" . format ( video_path , len ( imgs ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield None , None <TAB> except : <TAB> <TAB> logger . error ( "" Error when loading  {} "" . format ( mp4_path ) ) <TAB> <TAB> yield None , None <TAB> imgs_ret = imgs_transform ( <TAB> <TAB> imgs , mode , seg_num , seglen , short_size , target_size , img_mean , img_std <TAB> ) <TAB> label_ret = video_path <TAB> yield imgs_ret , label_ret",if len ( imgs ) > 1 :,if len ( imgs ) < 1 :,False,98.89,73.59,,,
"def translate_from_sortname ( name , sortname ) : <TAB> """""" ' Translate '  the artist name by reversing the sortname. """""" <TAB> for c in name : <TAB> <TAB> ctg = unicodedata . category ( c ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB> <TAB> <TAB> <TAB> if separator in sortname : <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname . split ( separator ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> parts = [ sortname ] <TAB> <TAB> <TAB> <TAB> separator = "" "" <TAB> <TAB> <TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name",if ctg . startswith ( sortname ) :,"if ctg [ 0 ] == ""L"" and unicodedata . name ( c ) . find ( ""LATIN"" ) == - 1 :",False,89.23,71.55,,,
"def translate_from_sortname ( name , sortname ) : <TAB> """""" ' Translate '  the artist name by reversing the sortname. """""" <TAB> for c in name : <TAB> <TAB> ctg = unicodedata . category ( c ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB> <TAB> <TAB> <TAB> if separator in sortname : <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname . split ( separator ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> parts = [ sortname ] <TAB> <TAB> <TAB> <TAB> separator = "" "" <TAB> <TAB> <TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name",if ctg . startswith ( sortname ) :,"if path [ : 1 ] == ""/"" and path [ 2 : 3 ] == "":"" :",False,90.45,73.3,,,
"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB> <TAB> if t == "" tacotron "" : <TAB> <TAB> <TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = jaconv . normalize ( text ) <TAB> <TAB> elif t == "" vietnamese "" : <TAB> <TAB> <TAB> if vietnamese_cleaners is None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB> <TAB> <TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text","elif t == ""jaconv"" :","elif t == ""jaconv"" :",True,100.0,74.51,,,
"def cb_syncthing_system_data ( self , daemon , mem , cpu , d_failed , d_total ) : <TAB> if self . daemon . get_my_id ( ) in self . devices : <TAB> <TAB> # Update my device display <TAB> <TAB> device = self.devices[self.daemon.get_my_id()] <TAB> <TAB> device[""ram""] = sizeof_fmt(mem) <TAB> <TAB> device[""cpu""] = ""%3.2f%%"" % (cpu) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> device[""announce""] = _(""disabled"") <TAB> <TAB> else: <TAB> <TAB> <TAB> device[""announce""] = ""%s/%s"" % (d_total - d_failed, d_total)",if d_failed == 0 :,if d_total == 0 :,False,98.76,72.65,,,
"def update_kls ( self , sampled_kls ) : <TAB> for i , kl in enumerate ( sampled_kls ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . kl_coeff_val [ i ] * = 0.5 <TAB> <TAB> elif kl > 1.5 * self . kl_target : <TAB> <TAB> <TAB> self . kl_coeff_val [ i ] * = 2.0 <TAB> return self . kl_coeff_val",if kl < 0.5 * self . kl_target :,if kl < self . kl_target / 1.5 :,False,95.59,70.5,,,
"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB> <TAB> f = True <TAB> <TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB> <TAB> <TAB> if self . FindItemAtPosition ( ( r , c ) ) is not None : <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB> <TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB> <TAB> cols2delete = [ x - 1 for x in cols2delete ]",if f :,if f :,True,100.0,74.52,,,
"def get_session ( self ) : <TAB> if self . _session is None : <TAB> <TAB> session = super ( ChildResourceManager , self ) . get_session ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> session = session . get_session_for_resource ( self . resource_type . resource ) <TAB> <TAB> self . _session = session <TAB> return self . _session",if self . resource_type :,if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY :,False,88.31,68.63,,,
"def _get_master_authorized_networks_config ( self , raw_cluster ) : <TAB> if raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) : <TAB> <TAB> config = raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) <TAB> <TAB> config [ "" includes_public_cidr "" ] = False <TAB> <TAB> for block in config [ "" cidrBlocks "" ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> config [ "" includes_public_cidr "" ] = True <TAB> <TAB> return config <TAB> else : <TAB> <TAB> return { "" enabled "" : False , "" cidrBlocks "" : [ ] , "" includes_public_cidr "" : False }","if block . get ( ""enabled"" ) :","if block [ ""cidrBlock"" ] == ""0.0.0.0/0"" :",False,92.61,68.65,,,
"def scan_folder ( folder ) : <TAB> scanned_files = [ ] <TAB> for root , dirs , files in os . walk ( folder ) : <TAB> <TAB> dirs [ : ] = [ d for d in dirs if d != "" __pycache__ "" ] <TAB> <TAB> relative_path = os . path . relpath ( root , folder ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> relative_name = os . path . normpath ( os . path . join ( relative_path , f ) ) . replace ( <TAB> <TAB> <TAB> <TAB> "" \\ "" , "" / "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> scanned_files . append ( relative_name ) <TAB> return sorted ( scanned_files )","if not f . endswith ( "".pycache"" ) :","if f . endswith ( "".pyc"" ) :",False,97.72,72.92,,,
"def read_progress ( self ) : <TAB> while True : <TAB> <TAB> processed_file = self . queue . get ( ) <TAB> <TAB> self . threading_completed . append ( processed_file ) <TAB> <TAB> total_number = len ( self . file_list ) <TAB> <TAB> completed_number = len ( self . threading_completed ) <TAB> <TAB> # Just for the record, this slows down book searching by about 20% <TAB> <TAB> if _progress_emitter: # Skip update in reading mode <TAB> <TAB> <TAB> _progress_emitter.update_progress(completed_number * 100 // total_number) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if self . is_reading :,if total_number == completed_number :,False,94.78,71.99,,,
"def next_instruction_is_function_or_class ( lines ) : <TAB> """""" Is the first non-empty, non-commented line of the cell either a function or a class? """""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if parser . is_quoted ( ) : <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) : # empty line <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False",if i == 0 :,if i > 0 and not lines [ i - 1 ] . strip ( ) :,False,94.4,94.41,,,
def __next__ ( self ) : <TAB> try : <TAB> <TAB> data = next ( self . iter_loader ) <TAB> except StopIteration : <TAB> <TAB> self . _epoch + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _dataloader . sampler . set_epoch ( self . _epoch ) <TAB> <TAB> self . iter_loader = iter ( self . _dataloader ) <TAB> <TAB> data = next ( self . iter_loader ) <TAB> return data,if self . _dataloader . sampler is not None :,"if hasattr ( self . _dataloader . sampler , ""set_epoch"" ) :",False,91.13,51.73,,,
"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB> <TAB> data = zip ( * data ) <TAB> <TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB> <TAB> if dt is not None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB> <TAB> <TAB> elif isinstance ( dt , nd . NDArray ) : <TAB> <TAB> <TAB> <TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB> <TAB> <TAB> <TAB> data_list = [ dt for dt in data if dt is not None ] <TAB> <TAB> <TAB> <TAB> return pad ( data_list )","if isinstance ( dt , dgl . DGLGraph ) :","if isinstance ( dt , dgl . DGLGraph ) :",True,100.0,74.61,,,
"def f ( self , info ) : <TAB> for k in keys : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k2 in list ( info . keys ( ) ) : <TAB> <TAB> <TAB> <TAB> if k ( k2 ) : <TAB> <TAB> <TAB> <TAB> <TAB> info . pop ( k2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> info . pop ( k , None )","if isinstance ( info , dict ) :",if callable ( k ) :,False,94.47,70.65,,,
"def create ( path , binary = False ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> os . makedirs ( os . path . dirname ( path ) , exist_ok = True ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return open ( path , "" wb "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return open ( path , "" w "" , encoding = "" utf-8 "" ) <TAB> <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> <TAB> log ( True , f "" Created  { path }  at attempt  { i + 1 } "" ) <TAB> <TAB> except : <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> else : <TAB> <TAB> raise Error ( f "" Failed to create  { path } "" )",if binary :,if binary :,True,100.0,74.58,,,
"def validate_update ( self , update_query ) : <TAB> structure = DotCollapsedDict ( self . doc_class . structure ) <TAB> for op , fields in update_query . iteritems ( ) : <TAB> <TAB> for field in fields : <TAB> <TAB> <TAB> if op != "" $unset "" and op != "" $rename "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise UpdateQueryError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" ' %s '  not found in  %s ' s structure "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> % ( field , self . doc_class . __name__ ) <TAB> <TAB> <TAB> <TAB> <TAB> )",if field not in structure :,if field not in structure :,True,100.0,74.46,,,
"def check_enums_ATLAS_ISAEXT ( lines ) : <TAB> for i , isaext in enumerate ( ATLAS_ISAEXT ) : <TAB> <TAB> got = lines . pop ( 0 ) . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> expect = "" none: 1 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> expect = "" {0} :  {1} "" . format ( isaext , 1 << i ) <TAB> <TAB> if got != expect : <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" ATLAS_ISAEXT mismatch at position  "" <TAB> <TAB> <TAB> <TAB> + str ( i ) <TAB> <TAB> <TAB> <TAB> + "" : got >> "" <TAB> <TAB> <TAB> <TAB> + got <TAB> <TAB> <TAB> <TAB> + "" <<, expected >> "" <TAB> <TAB> <TAB> <TAB> + expect <TAB> <TAB> <TAB> <TAB> + "" << "" <TAB> <TAB> <TAB> )","if isaext == """" :",if i == 0 :,False,97.84,69.16,,,
"def _test_export_session_csv ( self , test_session = None ) : <TAB> with self . app . test_request_context ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> test_session = SessionFactory ( ) <TAB> <TAB> field_data = export_sessions_csv ( [ test_session ] ) <TAB> <TAB> session_row = field_data [ 1 ] <TAB> <TAB> self . assertEqual ( session_row [ 0 ] , "" example (accepted) "" ) <TAB> <TAB> self . assertEqual ( session_row [ 9 ] , "" accepted "" )",if not test_session :,if not test_session :,True,100.0,74.23,,,
"def get_report_to_platform ( self , args , scan_reports ) : <TAB> if self . bc_api_key : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> repo_id = self . get_repository ( args ) <TAB> <TAB> <TAB> self . setup_bridgecrew_credentials ( <TAB> <TAB> <TAB> <TAB> bc_api_key = self . bc_api_key , repo_id = repo_id <TAB> <TAB> <TAB> ) <TAB> <TAB> if self . is_integration_configured ( ) : <TAB> <TAB> <TAB> self . _upload_run ( args , scan_reports )",if self . is_bridgecrew ( args ) :,if args . directory :,False,94.51,70.71,,,
"def test_fvalue ( self ) : <TAB> if not getattr ( self , "" skip_f "" , False ) : <TAB> <TAB> rtol = getattr ( self , "" rtol "" , 1e-10 ) <TAB> <TAB> assert_allclose ( self . res1 . fvalue , self . res2 . F , rtol = rtol ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # only available with ivreg2 <TAB> <TAB> <TAB> assert_allclose(self.res1.f_pvalue, self.res2.Fp, rtol=rtol) <TAB> else: <TAB> <TAB> raise pytest.skip(""TODO: document why this test is skipped"")","if hasattr ( self , ""ivreg2"" ) :","if hasattr ( self . res2 , ""Fp"" ) :",False,96.36,71.5,,,
"def fix_repeating_arguments ( self ) : <TAB> """""" Fix elements that should accumulate/increment values. """""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self",if type ( e . value ) is not list :,elif type ( e . value ) is not list :,False,99.01,98.28,,,
"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . parent ( ) . touch ( ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB> <TAB> if not node . isdir : <TAB> <TAB> <TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . watcher . emit ( "" created "" , self )",if self . exists ( ) :,if self . watcher :,False,97.06,72.75,,,
"def __init__ ( self , _inf = None , _tzinfos = None ) : <TAB> if _inf : <TAB> <TAB> self . _tzinfos = _tzinfos <TAB> <TAB> self . _utcoffset , self . _dst , self . _tzname = _inf <TAB> else : <TAB> <TAB> _tzinfos = { } <TAB> <TAB> self . _tzinfos = _tzinfos <TAB> <TAB> self . _utcoffset , self . _dst , self . _tzname = self . _transition_info [ 0 ] <TAB> <TAB> _tzinfos [ self . _transition_info [ 0 ] ] = self <TAB> <TAB> for inf in self . _transition_info [ 1 : ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _tzinfos [ inf ] = self . __class__ ( inf , _tzinfos )",if inf not in _tzinfos :,if not _tzinfos . has_key ( inf ) :,False,95.17,71.58,,,
"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with _file . open ( ) as f : <TAB> <TAB> <TAB> <TAB> if comment not in f . read ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB> <TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB> <TAB> for error in errors : <TAB> <TAB> <TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB> <TAB> print ( line [ : - 1 ] ) <TAB> <TAB> assert False","if _file . suffix == "".py"" and _file . suffix in skip_files :","if _file . suffix == "".py"" and _file . name not in skip_files :",False,98.6,73.42,,,
"def http_get ( url , target ) : <TAB> req = requests . get ( url , stream = True ) <TAB> content_length = req . headers . get ( "" Content-Length "" ) <TAB> total = int ( content_length ) if content_length is not None else None <TAB> progress = tqdm ( unit = "" B "" , total = total ) <TAB> with open ( target , "" wb "" ) as target_file : <TAB> <TAB> for chunk in req . iter_content ( chunk_size = 1024 ) : <TAB> <TAB> <TAB> <IF-STMT> # filter out keep-alive new chunks <TAB> <TAB> <TAB> <TAB> progress.update(len(chunk)) <TAB> <TAB> <TAB> <TAB> target_file.write(chunk) <TAB> progress.close()",if chunk :,if chunk :,True,100.0,74.46,,,
"def _elements_to_datasets ( self , elements , level = 0 ) : <TAB> for element in elements : <TAB> <TAB> extra_kwds = { "" identifier_ %d "" % level : element [ "" name "" ] } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for inner_element in self . _elements_to_datasets ( <TAB> <TAB> <TAB> <TAB> element [ "" elements "" ] , level = level + 1 <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> dataset = extra_kwds . copy ( ) <TAB> <TAB> <TAB> <TAB> dataset . update ( inner_element ) <TAB> <TAB> <TAB> <TAB> yield dataset <TAB> <TAB> else : <TAB> <TAB> <TAB> dataset = extra_kwds <TAB> <TAB> <TAB> extra_kwds . update ( element ) <TAB> <TAB> <TAB> yield extra_kwds","if element [ ""elements"" ] :","if ""elements"" in element :",False,97.48,72.57,,,
"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> a [ key ] = value <TAB> <TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB> <TAB> <TAB> update_dict ( a [ key ] , value ) <TAB> <TAB> elif isinstance ( a [ key ] , list ) : <TAB> <TAB> <TAB> a [ key ] . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> a [ key ] = [ a [ key ] , value ]","if isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) :",if key not in a :,False,91.11,70.16,,,
"def scan ( self , targets ) : <TAB> for target in targets : <TAB> <TAB> target . print_infos ( ) <TAB> <TAB> if self . is_interesting ( target ) : <TAB> <TAB> <TAB> self . target [ "" other "" ] . append ( target ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return target <TAB> return None",if self . scan_target ( target ) :,if self . match ( target ) :,False,95.63,72.21,,,
"def printConnections ( switches ) : <TAB> "" Compactly print connected nodes to each switch "" <TAB> for sw in switches : <TAB> <TAB> output ( "" %s :  "" % sw ) <TAB> <TAB> for intf in sw . intfList ( ) : <TAB> <TAB> <TAB> link = intf . link <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> intf1 , intf2 = link . intf1 , link . intf2 <TAB> <TAB> <TAB> <TAB> remote = intf1 if intf1 . node != sw else intf2 <TAB> <TAB> <TAB> <TAB> output ( "" %s ( %s )  "" % ( remote . node , sw . ports [ intf ] ) ) <TAB> <TAB> output ( "" \n "" )",if link . node != sw :,if link :,False,96.43,73.08,,,
"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB> <TAB> pos = pos_list[i] <TAB> <TAB> if pos == ""B"": <TAB> <TAB> <TAB> begin = i <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield sentence[begin : i + 1] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> elif pos == ""S"": <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB> <TAB> yield sentence[nexti:]","elif pos == ""E"" :","elif pos == ""E"" :",True,100.0,74.47,,,
"def check_files ( self , paths = None ) : <TAB> """""" Run all checks on the paths. """""" <TAB> if paths is None : <TAB> <TAB> paths = self . paths <TAB> report = self . options . report <TAB> runner = self . runner <TAB> report . start ( ) <TAB> try : <TAB> <TAB> for path in paths : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . input_dir ( path ) <TAB> <TAB> <TAB> elif not self . excluded ( path ) : <TAB> <TAB> <TAB> <TAB> runner ( path ) <TAB> except KeyboardInterrupt : <TAB> <TAB> print ( "" ... stopped "" ) <TAB> report . stop ( ) <TAB> return report",if self . is_dir ( path ) :,if os . path . isdir ( path ) :,False,96.78,95.45,,,
"def verts_of_loop ( edge_loop ) : <TAB> verts = [ ] <TAB> for e0 , e1 in iter_pairs ( edge_loop , False ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v0 = e0 . shared_vert ( e1 ) <TAB> <TAB> <TAB> verts + = [ e0 . other_vert ( v0 ) , v0 ] <TAB> <TAB> verts + = [ e1 . other_vert ( verts [ - 1 ] ) ] <TAB> if len ( verts ) > 1 and verts [ 0 ] == verts [ - 1 ] : <TAB> <TAB> return verts [ : - 1 ] <TAB> return verts",if e0 != e1 :,if not verts :,False,96.45,72.39,,,
"def generator ( self , data ) : <TAB> for task in data : <TAB> <TAB> # Do we scan everything or just /bin/bash instances? <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for bucket in task.bash_hash_entries(): <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0, <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int(task.p_pid), <TAB> <TAB> <TAB> <TAB> <TAB> str(task.p_comm), <TAB> <TAB> <TAB> <TAB> <TAB> int(bucket.times_found), <TAB> <TAB> <TAB> <TAB> <TAB> str(bucket.key), <TAB> <TAB> <TAB> <TAB> <TAB> str(bucket.data.path), <TAB> <TAB> <TAB> <TAB> ], <TAB> <TAB> <TAB> )",if not task . p_comm :,"if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == ""bash"" ) :",False,91.81,58.72,,,
"def __get_ratio ( self ) : <TAB> """""" Return splitter ratio of the main splitter. """""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB> <TAB> w = free_layout . get_main_splitter ( ) <TAB> <TAB> if w : <TAB> <TAB> <TAB> aList = w . sizes ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> n1 , n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5",if aList :,if len ( aList ) == 2 :,False,96.05,93.78,,,
"def geterrors ( self ) : <TAB> """""" Get all error messages. """""" <TAB> notes = self . getnotes ( origin = "" translator "" ) . split ( "" \n "" ) <TAB> errordict = { } <TAB> for note in notes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error = note . replace ( "" (pofilter)  "" , "" "" ) <TAB> <TAB> <TAB> errorname , errortext = error . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> errordict [ errorname ] = errortext <TAB> return errordict","if note . startswith ( ""pofilter"" ) :","if ""(pofilter) "" in note :",False,94.21,93.65,,,
"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB> <TAB> if d in [ "" . "" , "" .. "" ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB> <TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB> <TAB> attr = self . getattr ( d_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . rename_path ( d_path , d_new_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True )",if attr == new_path :,"if stat . S_ISDIR ( attr [ ""st_mode"" ] ) :",False,93.86,68.3,,,
"def index ( self , url_id : int ) - > FlaskResponse : # pylint: disable=no-self-use <TAB> url = db.session.query(models.Url).get(url_id) <TAB> if url and url.url: <TAB> <TAB> explore_url = ""//superset/explore/?"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> explore_url += f""r={url_id}"" <TAB> <TAB> <TAB> return redirect(explore_url[1:]) <TAB> <TAB> return redirect(url.url[1:]) <TAB> flash(""URL to nowhere..."", ""danger"") <TAB> return redirect(""/"")",if url_id :,if url . url . startswith ( explore_url ) :,False,94.17,66.85,,,
"def testShortCircuit ( self ) : <TAB> """""" Test that creation short-circuits to reuse existing references """""" <TAB> sd = { } <TAB> for s in self . ss : <TAB> <TAB> sd [ s ] = 1 <TAB> for t in self . ts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertTrue ( sd . has_key ( safeRef ( t . x ) ) ) <TAB> <TAB> <TAB> self . assertTrue ( safeRef ( t . x ) in sd ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertTrue ( sd . has_key ( safeRef ( t ) ) ) <TAB> <TAB> <TAB> self . assertTrue ( safeRef ( t ) in sd )","if isinstance ( t , Reference ) :","if hasattr ( t , ""x"" ) :",False,96.07,69.31,,,
"def wrapped ( request , * args , * * kwargs ) : <TAB> if not request . user . is_authenticated ( ) : <TAB> <TAB> request . session [ "" _next "" ] = request . get_full_path ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> redirect_uri = reverse ( <TAB> <TAB> <TAB> <TAB> "" sentry-auth-organization "" , args = [ kwargs [ "" organization_slug "" ] ] <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> redirect_uri = get_login_url ( ) <TAB> <TAB> return HttpResponseRedirect ( redirect_uri ) <TAB> return func ( request , * args , * * kwargs )","if kwargs . get ( ""organization_slug"" ) :","if ""organization_slug"" in kwargs :",False,95.64,71.73,,,
"def read_info ( reader , dump = None ) : <TAB> line_number_table_length = reader . read_u2 ( ) <TAB> <IF-STMT> <TAB> <TAB> reader . debug ( <TAB> <TAB> <TAB> ""  <TAB>  "" * dump , "" Line numbers ( %s  total): "" % line_number_table_length <TAB> <TAB> ) <TAB> line_numbers = [ ] <TAB> for i in range ( 0 , line_number_table_length ) : <TAB> <TAB> start_pc = reader . read_u2 ( ) <TAB> <TAB> line_number = reader . read_u2 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> reader . debug ( ""  <TAB>  "" * ( dump + 1 ) , "" %s :  %s "" % ( start_pc , line_number ) ) <TAB> <TAB> line_numbers . append ( ( start_pc , line_number ) ) <TAB> return LineNumberTable ( line_numbers )",if dump :,if dump is not None :,False,96.2,70.61,,,
"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB> <TAB> for _ in XRANGE ( 10 ) : <TAB> <TAB> <TAB> t1 = timer ( ) <TAB> <TAB> <TAB> t2 = timer ( ) <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB> if 0 < dt : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt < = 0.0 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> precision = min ( precision , dt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points + = 1 <TAB> <TAB> previous = timer ( ) <TAB> return precision",if precision :,if precision is not None :,False,98.3,72.88,,,
def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB> <TAB> <TAB> if self . expr3 is None : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno,if self . expr2 is None :,if self . expr2 is None :,True,100.0,99.44,,,
"def validate_cluster_resource_group ( cmd , namespace ) : <TAB> if namespace . cluster_resource_group is not None : <TAB> <TAB> client = get_mgmt_service_client ( <TAB> <TAB> <TAB> cmd . cli_ctx , ResourceType . MGMT_RESOURCE_RESOURCES <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidArgumentValueError ( <TAB> <TAB> <TAB> <TAB> "" Invalid --cluster-resource-group  ' %s ' : resource group must not exist. "" <TAB> <TAB> <TAB> <TAB> % namespace . cluster_resource_group <TAB> <TAB> <TAB> )",if client . resource_group_exists ( namespace . cluster_resource_group ) :,if client . resource_groups . check_existence ( namespace . cluster_resource_group ) :,False,96.26,71.66,,,
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right",if left == len ( text ) and allowed_chars in text :,if left == 0 :,False,94.99,72.42,,,
"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB> <TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB> <TAB> if len ( set ( lengths ) ) > 1 : <TAB> <TAB> <TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB> <TAB> x_len = lengths [ 0 ] <TAB> else : <TAB> <TAB> x_len = len ( X ) <TAB> if y is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB> <TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y",if x_len != y :,if len ( y ) != x_len :,False,96.3,72.52,,,
"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB> <TAB> if isinstance ( node , HtmlTag ) : <TAB> <TAB> <TAB> if node . tag_type == OPEN_TAG : <TAB> <TAB> <TAB> <TAB> open_tags + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> open_tags - = 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance ( node , HtmlDataFragment ) <TAB> <TAB> <TAB> and node . is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ) : <TAB> <TAB> <TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text",elif node . tag_type == CLOSE_TAG :,elif node . tag_type == CLOSE_TAG :,True,100.0,74.48,,,
"def _get_spyne_type ( cls_name , k , v ) : <TAB> try : <TAB> <TAB> v = NATIVE_MAP . get ( v , v ) <TAB> except TypeError : <TAB> <TAB> return <TAB> try : <TAB> <TAB> subc = issubclass ( v , ModelBase ) or issubclass ( v , SelfReference ) <TAB> except : <TAB> <TAB> subc = False <TAB> if subc : <TAB> <TAB> if issubclass ( v , Array ) and len ( v . _type_info ) != 1 : <TAB> <TAB> <TAB> raise Exception ( "" Invalid Array definition in  %s . %s . "" % ( cls_name , k ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" Please specify the number of dimensions "" ) <TAB> <TAB> return v",if len ( v . _type_info ) != 2 :,"elif issubclass ( v , Point ) and v . Attributes . dim is None :",False,92.79,69.01,,,
"def customize ( cls , * * kwargs ) : <TAB> """""" return a class with some existing attributes customized """""" <TAB> for name , value in kwargs . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TransportError ( <TAB> <TAB> <TAB> <TAB> "" you cannot customize the protected attribute  %s "" % name <TAB> <TAB> <TAB> ) <TAB> <TAB> if not hasattr ( cls , name ) : <TAB> <TAB> <TAB> raise TransportError ( "" Transport has no attribute  %s "" % name ) <TAB> NewSubClass = type ( "" Customized_ {} "" . format ( cls . __name__ ) , ( cls , ) , kwargs ) <TAB> return NewSubClass",if value is not None and value is not None :,"if name in [ ""cookie"" , ""circuit"" , ""upstream"" , ""downstream"" , ""stream"" ] :",False,87.0,78.22,,,
"def test_UNrelativize ( self ) : <TAB> import URIlib <TAB> relative = self . relative + self . full_relativize <TAB> for base , rel , fullpath , common in relative : <TAB> <TAB> URI = uriparse . UnRelativizeURL ( base , rel ) <TAB> <TAB> fullURI = URIlib . URIParser ( URI ) <TAB> <TAB> # We need to canonicalize the result from unrelativize <TAB> <TAB> # compared to the original full path we expect to see. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fullpath = fullpath[:-1] <TAB> <TAB> self.failUnlessSamePath( <TAB> <TAB> <TAB> os.path.normcase(fullURI.path), os.path.normcase(fullpath) <TAB> <TAB> )","if common == ""absolute"" :","if fullpath [ - 1 ] in ( ""/"" , ""\\"" ) :",False,90.83,59.48,,,
"def get_release_info ( file_path = RELEASE_FILE ) : <TAB> RELEASE_TYPE_REGEX = re . compile ( r "" ^[Rr]elease [Tt]ype: (major|minor|patch)$ "" ) <TAB> with open ( file_path , "" r "" ) as f : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> match = RELEASE_TYPE_REGEX . match ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" The file RELEASE.md should start with `Release type`  "" <TAB> <TAB> <TAB> <TAB> "" and specify one of the following values: major, minor or patch. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 ) <TAB> <TAB> type_ = match . group ( 1 ) <TAB> <TAB> changelog = "" "" . join ( [ line for line in f . readlines ( ) ] ) . strip ( ) <TAB> return type_ , changelog",if not match :,if not match :,True,100.0,74.58,,,
"def _get_next_history_entry ( self ) : <TAB> if self . _history : <TAB> <TAB> hist_len = len ( self . _history ) - 1 <TAB> <TAB> self . history_index = min ( hist_len , self . history_index + 1 ) <TAB> <TAB> index = self . history_index <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . history_index + = 1 <TAB> <TAB> return self . _history [ index ] <TAB> return "" """,if self . history_index < hist_len :,if self . history_index == hist_len :,False,97.37,72.57,,,
"def star_op ( self ) : <TAB> """""" Put a  ' * '  op, with special cases for *args. """""" <TAB> val = "" * "" <TAB> if self . paren_level : <TAB> <TAB> i = len ( self . code_list ) - 1 <TAB> <TAB> if self . code_list [ i ] . kind == "" blank "" : <TAB> <TAB> <TAB> i - = 1 <TAB> <TAB> token = self . code_list [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . op_no_blanks ( val ) <TAB> <TAB> elif token . value == "" , "" : <TAB> <TAB> <TAB> self . blank ( ) <TAB> <TAB> <TAB> self . add_token ( "" op-no-blanks "" , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . op ( val ) <TAB> else : <TAB> <TAB> self . op ( val )","if token . value == "","" :","if token . kind == ""lt"" :",False,97.94,96.38,,,
"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if HIDDEN_SETTINGS . search ( k ) : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = "" ******************** "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict","if k . startswith ( ""_"" ) :",if k . isupper ( ) :,False,96.21,65.38,,,
"def nextEditable ( self ) : <TAB> """""" Moves focus of the cursor to the next editable window """""" <TAB> if self . currentEditable is None : <TAB> <TAB> if len ( self . _editableChildren ) : <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei > = len ( self . _editableChildren ) : <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if ref in self . _editableChildren :,if ref in self . _editableChildren :,True,100.0,99.56,,,
"def _handle_dependents_type ( types , type_str , type_name , rel_name , row ) : <TAB> if types [ type_str [ 0 ] ] is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> type_name = "" index "" <TAB> <TAB> <TAB> rel_name = row [ "" indname "" ] + ""  ON  "" + rel_name <TAB> <TAB> elif type_str [ 0 ] == "" o "" : <TAB> <TAB> <TAB> type_name = "" operator "" <TAB> <TAB> <TAB> rel_name = row [ "" relname "" ] <TAB> else : <TAB> <TAB> type_name = types [ type_str [ 0 ] ] <TAB> return type_name , rel_name","if type_str [ 0 ] == ""i"" :","if type_str [ 0 ] == ""i"" :",True,100.0,74.43,,,
"def streamErrorHandler ( self , conn , error ) : <TAB> name , text = "" error "" , error . getData ( ) <TAB> for tag in error . getChildren ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if tag . getName ( ) == "" text "" : <TAB> <TAB> <TAB> <TAB> text = tag . getData ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = tag . getName ( ) <TAB> if name in stream_exceptions . keys ( ) : <TAB> <TAB> exc = stream_exceptions [ name ] <TAB> else : <TAB> <TAB> exc = StreamError <TAB> raise exc ( ( name , text ) )","if isinstance ( tag , StreamError ) :",if tag . getNamespace ( ) == NS_XMPP_STREAMS :,False,92.89,71.33,,,
"def _validate_names ( self , settings : _SettingsType ) - > None : <TAB> """""" Make sure all settings exist. """""" <TAB> unknown = [ ] <TAB> for name in settings : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unknown . append ( name ) <TAB> if unknown : <TAB> <TAB> errors = [ <TAB> <TAB> <TAB> configexc . ConfigErrorDesc ( <TAB> <TAB> <TAB> <TAB> "" While loading options "" , "" Unknown option  {} "" . format ( e ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for e in sorted ( unknown ) <TAB> <TAB> ] <TAB> <TAB> raise configexc . ConfigFileErrors ( "" autoconfig.yml "" , errors )",if name not in unknown :,if name not in configdata . DATA :,False,97.54,96.06,,,
"def can_haz ( self , target , credentials ) : <TAB> """""" Check whether key-values in target are present in credentials. """""" <TAB> # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB> # <TAB> <TAB> <TAB>  string <TAB> for requirement in target: <TAB> <TAB> key, match = requirement.split("":"", 1) <TAB> <TAB> check = credentials.get(key) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> check = [check] <TAB> <TAB> if match in check: <TAB> <TAB> <TAB> return True","if not isinstance ( check , tuple ) :","if check is None or isinstance ( check , basestring ) :",False,94.96,69.36,,,
"def _recursive_fx_apply ( input : dict , fx ) : <TAB> for k , v in input . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = torch . tensor ( v ) <TAB> <TAB> if isinstance ( v , torch . Tensor ) : <TAB> <TAB> <TAB> v = fx ( v . float ( ) ) <TAB> <TAB> <TAB> input [ k ] = v <TAB> <TAB> else : <TAB> <TAB> <TAB> _recursive_fx_apply ( v , fx )","if isinstance ( v , dict ) :","if isinstance ( v , list ) :",False,98.16,72.9,,,
"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse ( ) <TAB> <TAB> elif "" Hello0 "" in url and "" 1.2.1 "" in url and "" v1 "" in url : <TAB> <TAB> <TAB> return ErrorApiResponse ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = app . get ( url , * * kwargs ) <TAB> <TAB> <TAB> return TestingResponse ( response ) <TAB> else : <TAB> <TAB> return requests . get ( url , * * kwargs )",if self . _first_ping :,"if url . endswith ( ""ping"" ) and self . _first_ping :",False,94.41,66.2,,,
"def server_thread_fn ( ) : <TAB> server_ctx = ssl . create_default_context ( ssl . Purpose . CLIENT_AUTH ) <TAB> server_ctx . load_cert_chain ( "" trio-test-1.pem "" ) <TAB> server = server_ctx . wrap_socket ( <TAB> <TAB> server_sock , <TAB> <TAB> server_side = True , <TAB> <TAB> suppress_ragged_eofs = False , <TAB> ) <TAB> while True : <TAB> <TAB> data = server . recv ( 4096 ) <TAB> <TAB> print ( "" server got: "" , data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" server waiting for client to finish everything "" ) <TAB> <TAB> <TAB> client_done . wait ( ) <TAB> <TAB> <TAB> print ( "" server attempting to send back close-notify "" ) <TAB> <TAB> <TAB> server . unwrap ( ) <TAB> <TAB> <TAB> print ( "" server ok "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> server . sendall ( data )",if client_side :,if not data :,False,98.26,73.28,,,
"def find_hostnames ( data ) : <TAB> # sends back an array of hostnames <TAB> hostnames = [] <TAB> for i in re.finditer(hostname_regex, data): <TAB> <TAB> h = string.lower(i.group(1)) <TAB> <TAB> tld = h.split(""."")[-1:][0] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hostnames.append(h) <TAB> return hostnames",if tld in hostnames :,if tld in tlds :,False,97.78,71.1,,,
"def Validate ( self , win ) : <TAB> textCtrl = self . GetWindow ( ) <TAB> text = textCtrl . GetValue ( ) . strip ( ) <TAB> sChar = Character . getInstance ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( _t ( "" You must supply a name for the Character! "" ) ) <TAB> <TAB> elif text in [ x . name for x in sChar . getCharacterList ( ) ] : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> _t ( "" Character name already in use, please choose another. "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> except ValueError as e : <TAB> <TAB> pyfalog . error ( e ) <TAB> <TAB> wx . MessageBox ( "" {} "" . format ( e ) , _t ( "" Error "" ) ) <TAB> <TAB> textCtrl . SetFocus ( ) <TAB> <TAB> return False",if text == sChar . getName ( ) :,if len ( text ) == 0 :,False,96.62,72.53,,,
def get_random_user_agent ( agent_list = UA_CACHE ) : <TAB> if not len ( agent_list ) : <TAB> <TAB> ua_file = file ( UA_FILE ) <TAB> <TAB> for line in ua_file : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> agent_list . append ( line ) <TAB> ua = random . choice ( UA_CACHE ) <TAB> return ua,if line :,if line :,True,100.0,99.1,,,
"def _validate_action_like_for_prefixes ( self , key ) : <TAB> for statement in self . _statements : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( statement [ key ] , string_types ) : <TAB> <TAB> <TAB> <TAB> self . _validate_action_prefix ( statement [ key ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for action in statement [ key ] : <TAB> <TAB> <TAB> <TAB> <TAB> self . _validate_action_prefix ( action )","if isinstance ( statement , dict ) :",if key in statement :,False,95.0,70.42,,,
"def predict ( self , X ) : <TAB> if self . regression : <TAB> <TAB> return self . predict_proba ( X ) <TAB> else : <TAB> <TAB> y_pred = np . argmax ( self . predict_proba ( X ) , axis = 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y_pred = self . enc_ . inverse_transform ( y_pred ) <TAB> <TAB> return y_pred",if self . enc_ :,if self . use_label_encoder :,False,94.42,72.27,,,
"def _threaded_request_tracker ( self , builder ) : <TAB> while True : <TAB> <TAB> event_type = self . _read_q . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> payload = { "" body "" : b "" "" } <TAB> <TAB> request_id = builder . build_record ( event_type , payload , "" "" ) <TAB> <TAB> self . _write_q . put_nowait ( request_id )",if event_type is None :,if event_type is False :,False,97.96,72.15,,,
"def __call__ ( self , value ) : <TAB> try : <TAB> <TAB> super ( EmailValidator , self ) . __call__ ( value ) <TAB> except ValidationError as e : <TAB> <TAB> # Trivial case failed. Try for possible IDN domain-part <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts = value.split(""@"") <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> parts[-1] = parts[-1].encode(""idna"").decode(""ascii"") <TAB> <TAB> <TAB> except UnicodeError: <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> super(EmailValidator, self).__call__(""@"".join(parts)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise","if ""@"" in value :","if value and ""@"" in value :",False,98.37,72.21,,,
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> if self . __Token : <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid : <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",if x == 2 :,elif not IfList :,False,95.7,70.94,,,
"def _arg_with_type ( self ) : <TAB> for t in self . d [ "" Args "" ] : <TAB> <TAB> m = re . search ( "" ([A-Za-z0-9_-]+) \ s { 0,4}( \ (.+ \ )) \ s { 0,4}: "" , t ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . args [ m . group ( 1 ) ] = m . group ( 2 ) <TAB> return self . args",if m :,if m :,True,100.0,74.16,,,
"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [] <TAB> <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <TAB> <TAB> <TAB> if new_id != -1: <TAB> <TAB> <TAB> <TAB> palette.append(self.PALETTE[old_id]) <TAB> <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB> <TAB> else: <TAB> <TAB> <TAB> palette = self.PALETTE <TAB> return palette",if len ( class_names ) > 3 :,if self . PALETTE is None :,False,95.98,70.51,,,
"def Visit_star_expr ( self , node ) : # pylint: disable=invalid-name <TAB> # star_expr ::= '*' expr <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.UNARY_OPERATOR) <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.VARARGS_STAR)","if isinstance ( child , ast . Name ) :","if isinstance ( child , pytree . Leaf ) and child . value == ""*"" :",False,88.65,54.84,,,
"def create_if_compatible ( cls , typ : Type , * , root : "" RootNode "" ) - > Optional [ "" Node "" ] : <TAB> if cls . compatible_types : <TAB> <TAB> target_type : Type = typ <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> target_type = getattr ( typ , "" __origin__ "" , None ) or typ <TAB> <TAB> if cls . _issubclass ( target_type , cls . compatible_types ) : <TAB> <TAB> <TAB> return cls ( typ , root = root ) <TAB> return None","if isinstance ( typ , type ) :",if cls . use_origin :,False,94.65,71.16,,,
"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB> <TAB> tokentype , token = tokens [ i ] <TAB> <TAB> i + = 1 <TAB> <TAB> if tokentype != "" id "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len ( tokens ) <TAB> <TAB> <TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB> <TAB> <TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB> <TAB> <TAB> i + = 2 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token [ 0 ] in "" .0123456789 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token","if token == ""op"" :","if token == """" :",False,99.13,61.09,,,
"def create_config_filepath ( cls , visibility = None ) : <TAB> if cls . is_local ( visibility ) : <TAB> <TAB> # Local to this directory <TAB> <TAB> base_path = os.path.join(""."") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Add it to the current ""./.polyaxon"" <TAB> <TAB> <TAB> base_path = os.path.join(base_path, "".polyaxon"") <TAB> <TAB> <TAB> cls._create_dir(base_path) <TAB> elif cls.CONFIG_PATH: # Custom path <TAB> <TAB> pass <TAB> else: # Handle both global and all cases <TAB> <TAB> base_path = polyaxon_user_path() <TAB> <TAB> cls._create_dir(base_path)",if os . path . isdir ( base_path ) :,if cls . IS_POLYAXON_DIR :,False,94.74,70.47,,,
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 4 :,elif size <= 3 :,False,98.87,73.7,,,
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> elif is_dict . match ( item ) : <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result",if is_dict . match ( item ) :,"if item . endswith ( ""/"" ) :",False,97.19,68.73,,,
"def api_read ( self ) : <TAB> result = { } <TAB> files = [ "" my.cnf "" , "" debian.cnf "" ] <TAB> directory_list = self . exec_payload ( "" mysql_config_directory "" ) [ "" directory "" ] <TAB> for _file in files : <TAB> <TAB> for directory in directory_list : <TAB> <TAB> <TAB> mysql_conf = directory + _file <TAB> <TAB> <TAB> content = self . shell . read ( mysql_conf ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ mysql_conf ] = content <TAB> return result",if content :,if content :,True,100.0,74.31,,,
"def generate ( self , count = 100 ) : <TAB> self . pre_generate ( ) <TAB> counter = iter ( range ( count ) ) <TAB> created = 0 <TAB> while True : <TAB> <TAB> batch = list ( islice ( counter , self . batch_size ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> self . do_generate ( batch , self . batch_size ) <TAB> <TAB> from_size = created <TAB> <TAB> created + = len ( batch ) <TAB> <TAB> print ( "" Generate  %s :  %s - %s "" % ( self . resource , from_size , created ) ) <TAB> self . after_generate ( )",if len ( batch ) == 0 :,if not batch :,False,95.26,72.0,,,
"def _normalize_fields ( self , document , loader ) : <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list(document.keys()): <TAB> <TAB> d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> document[d2] = document[d] <TAB> <TAB> <TAB> del document[d]","if d2 . startswith ( u""/"" ) :",if d != d2 :,False,92.74,87.05,,,
"def _normalize_fields ( self , document , loader ) : <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list(document.keys()): <TAB> <TAB> d2 = loader.expand_url(d, u"""", scoped_id=False, vocab_term=True) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> document[d2] = document[d] <TAB> <TAB> <TAB> del document[d]","if d2 . startswith ( u""/"" ) :","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b"":"" :",False,81.08,71.66,,,
"def __lshift__ ( self , other ) : <TAB> if not self . symbolic and type ( other ) is int : <TAB> <TAB> return RegisterOffset ( <TAB> <TAB> <TAB> self . _bits , self . reg , self . _to_signed ( self . offset << other ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return RegisterOffset ( self . _bits , self . reg , self . offset << other ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return RegisterOffset ( <TAB> <TAB> <TAB> <TAB> self . _bits , <TAB> <TAB> <TAB> <TAB> self . reg , <TAB> <TAB> <TAB> <TAB> ArithmeticExpression ( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression . LShift , <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . offset , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other , <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> )",if self . symbolic :,if self . symbolic :,True,100.0,74.61,,,
"def SaveSettings ( self , force = False ) : <TAB> if self . config is not None : <TAB> <TAB> frame . ShellFrameMixin . SaveSettings ( self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frame . Frame . SaveSettings ( self , self . config ) <TAB> <TAB> <TAB> self . shell . SaveSettings ( self . config )",if force :,if self . autoSaveSettings or force :,False,93.59,69.74,,,
"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB> <TAB> if "" type "" in genename_element . attrib : <TAB> <TAB> <TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB> <TAB> <TAB> <TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB> <TAB> <TAB> <TAB> genename_element . attrib [ "" type "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> append_to_annotations ( ann_key , genename_element . text )","if genename_element . tag == ""seq"" :","if genename_element . attrib [ ""type"" ] == ""primary"" :",False,95.23,67.38,,,
"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB> <TAB> if "" type "" in genename_element . attrib : <TAB> <TAB> <TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB> <TAB> <TAB> <TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB> <TAB> <TAB> <TAB> genename_element . attrib [ "" type "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> append_to_annotations ( ann_key , genename_element . text )","if genename_element . tag == ""seq"" :","if line . startswith ( ""Metadata-Version: "" ) :",False,94.76,70.87,,,
"def get ( self ) : <TAB> """""" If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called. """""" <TAB> if self . _exception is not _NONE : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . value <TAB> <TAB> getcurrent ( ) . throw ( * self . _exception ) # pylint:disable=undefined-variable <TAB> else: <TAB> <TAB> if self.greenlet is not None: <TAB> <TAB> <TAB> raise ConcurrentObjectUseError( <TAB> <TAB> <TAB> <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.greenlet = getcurrent() # pylint:disable=undefined-variable <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.hub.switch() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.greenlet = None",if self . value is not _NONE :,if self . _exception is None :,False,97.5,69.02,,,
"def connect ( self , * args ) : <TAB> """""" connects to the dropbox. args[0] is the username. """""" <TAB> if len ( args ) != 1 : <TAB> <TAB> return "" expected one argument! "" <TAB> try : <TAB> <TAB> dbci = get_dropbox_client ( args [ 0 ] , False , None , None ) <TAB> except Exception as e : <TAB> <TAB> return e . message <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" No Dropbox configured for  ' {u} ' . "" . format ( u = args [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . client = dbci <TAB> <TAB> return True",if dbci is None :,if dbci is None :,True,100.0,99.5,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if ""\n"" in text :","if ""\n"" in text :",True,100.0,74.67,,,
def t ( ret ) : <TAB> with IPDB ( ) as ipdb : <TAB> <TAB> with ipdb . eventqueue ( ) as evq : <TAB> <TAB> <TAB> for msg in evq : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> ret . append ( msg ) <TAB> <TAB> <TAB> <TAB> <TAB> return,"if msg . type in ( ""event"" , ""message"" ) :","if msg . get_attr ( ""IFLA_IFNAME"" ) == ""test1984"" :",False,86.89,68.28,,,
"def check_stmt ( self , stmt ) : <TAB> if is_future ( stmt ) : <TAB> <TAB> for name , asname in stmt . names : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . found [ name ] = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise SyntaxError ( "" future feature  %s  is not defined "" % name ) <TAB> <TAB> stmt . valid_future = 1 <TAB> <TAB> return 1 <TAB> return 0",if asname in self . found :,if name in self . features :,False,96.25,71.35,,,
"def process_pypi_option ( option , option_str , option_value , parser ) : <TAB> if option_str . startswith ( "" --no "" ) : <TAB> <TAB> setattr ( parser . values , option . dest , [ ] ) <TAB> else : <TAB> <TAB> indexes = getattr ( parser . values , option . dest , [ ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> indexes . append ( _PYPI ) <TAB> <TAB> setattr ( parser . values , option . dest , indexes )","if option_value == ""--no"" :",if _PYPI not in indexes :,False,92.78,62.45,,,
"def modify_address ( self , name , address , domain ) : <TAB> if not self . get_entries_by_name ( name , domain ) : <TAB> <TAB> raise exception . NotFound <TAB> infile = open ( self . filename , "" r "" ) <TAB> outfile = tempfile . NamedTemporaryFile ( "" w "" , delete = False ) <TAB> for line in infile : <TAB> <TAB> entry = self . parse_line ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> outfile . write ( <TAB> <TAB> <TAB> <TAB> "" %s  %s  %s \n "" % ( address , self . qualify ( name , domain ) , entry [ "" type "" ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> outfile . write ( line ) <TAB> infile . close ( ) <TAB> outfile . close ( ) <TAB> shutil . move ( outfile . name , self . filename )","if entry [ ""name"" ] == name :","if entry and entry [ ""name"" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) :",False,91.35,68.77,,,
"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB> <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << (i - 1) <TAB> <TAB> if (x & mask) != 0: <TAB> <TAB> <TAB> digit += 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> digit += 2 <TAB> <TAB> quadKey += str(digit) <TAB> return quadKey",if ( y & mask ) != 0 :,if ( y & mask ) != 0 :,True,100.0,74.47,,,
"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> for typ , key in keys : <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> <TAB> <TAB> if _typ == typ and key is _key : <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] = keys",if flag :,if flag :,True,100.0,74.55,,,
"def scan_error ( self ) : <TAB> "" A string describing why the last scan failed, or None if it didn ' t. "" <TAB> self . acquire_lock ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . _load_buf_data_once ( ) <TAB> <TAB> <TAB> except NotFoundInDatabase : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return self . _scan_error_cache <TAB> finally : <TAB> <TAB> self . release_lock ( )",if self . _last_scan_failed :,if self . _scan_error_cache is None :,False,95.45,71.27,,,
"def _query ( self ) : <TAB> if self . _mongo_query is None : <TAB> <TAB> self . _mongo_query = self . _query_obj . to_query ( self . _document ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" _cls "" in self . _mongo_query : <TAB> <TAB> <TAB> <TAB> self . _mongo_query = { "" $and "" : [ self . _cls_query , self . _mongo_query ] } <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _mongo_query . update ( self . _cls_query ) <TAB> return self . _mongo_query",if self . _mongo_query :,if self . _cls_query :,False,98.55,73.05,,,
"def CountButtons ( self ) : <TAB> """""" Returns the number of visible buttons in the docked pane. """""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self . HasCloseButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMaximizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n + = 1 <TAB> return n",if self . HasMinimizeButton ( ) :,if self . HasPinButton ( ) :,False,98.66,97.52,,,
"def testBind ( self ) : <TAB> try : <TAB> <TAB> with socket . socket ( socket . PF_CAN , socket . SOCK_DGRAM , socket . CAN_J1939 ) as s : <TAB> <TAB> <TAB> addr = ( <TAB> <TAB> <TAB> <TAB> self . interface , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_NAME , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_PGN , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_ADDR , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> s . bind ( addr ) <TAB> <TAB> <TAB> self . assertEqual ( s . getsockname ( ) , addr ) <TAB> except OSError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . skipTest ( "" network interface ` %s ` does not exist "" % self . interface ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise",if e . errno == errno . EADDRNOTAVAIL :,if e . errno == errno . ENODEV :,False,98.98,73.69,,,
"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB> <TAB> pos = self . stream . searchBytes ( <TAB> <TAB> <TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB> <TAB> ) # seek forward by at most 1MB <TAB> <TAB> if pos is not None: <TAB> <TAB> <TAB> padsize = pos - self.current_size <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB> <TAB> chunk = Chunk(self, ""chunk[]"") <TAB> <TAB> try: <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk[""content/data""] <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk",if padsize > 1 :,if padsize :,False,98.56,73.52,,,
"def index_modulemd_files ( repo_path ) : <TAB> merger = Modulemd . ModuleIndexMerger ( ) <TAB> for fn in sorted ( os . listdir ( repo_path ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> yaml_path = os . path . join ( repo_path , fn ) <TAB> <TAB> mmd = Modulemd . ModuleIndex ( ) <TAB> <TAB> mmd . update_from_file ( yaml_path , strict = True ) <TAB> <TAB> merger . associate_index ( mmd , 0 ) <TAB> return merger . resolve ( )","if fn . startswith ( ""yaml"" ) :","if not fn . endswith ( "".yaml"" ) :",False,95.26,70.74,,,
"def set_visible ( self , visible = True ) : <TAB> self . _visible = visible <TAB> if self . _nswindow is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Not really sure why on_resize needs to be here, <TAB> <TAB> <TAB> # but it's what pyglet wants. <TAB> <TAB> <TAB> self.dispatch_event(""on_resize"", self._width, self._height) <TAB> <TAB> <TAB> self.dispatch_event(""on_show"") <TAB> <TAB> <TAB> self.dispatch_event(""on_expose"") <TAB> <TAB> <TAB> self._nswindow.makeKeyAndOrderFront_(None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._nswindow.orderOut_(None)",if self . _visible :,if visible :,False,97.75,71.96,,,
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> if self . is_computed ( ) : <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> if self . error ( ) is None : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False",if self . value ( ) is None :,if self . value ( ) is self :,False,99.14,73.94,,,
"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB> <TAB> for key , value in segment . items ( ) : <TAB> <TAB> <TAB> if key == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if key . text == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB> <TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB> <TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB> <TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB> <TAB> raise Exception ( "" Invalid state "" )","elif index_type == ""text"" :","if hasattr ( key , ""text"" ) :",False,96.51,72.13,,,
"def _makeSafeAbsoluteURI ( base , rel = None ) : <TAB> # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB> if not ACCEPTABLE_URI_SCHEMES: <TAB> <TAB> return _urljoin(base, rel or u"""") <TAB> if not base: <TAB> <TAB> return rel or u"""" <TAB> if not rel: <TAB> <TAB> try: <TAB> <TAB> <TAB> scheme = urlparse.urlparse(base)[0] <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> return u"""" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return base <TAB> <TAB> return u"""" <TAB> uri = _urljoin(base, rel) <TAB> if uri.strip().split("":"", 1)[0] not in ACCEPTABLE_URI_SCHEMES: <TAB> <TAB> return u"""" <TAB> return uri",if scheme not in ACCEPTABLE_URI_SCHEMES :,if not scheme or scheme in ACCEPTABLE_URI_SCHEMES :,False,97.75,71.8,,,
"def _write_packet ( self , packet ) : <TAB> # Immediately writes the given packet to the network. The caller must <TAB> # have the write lock acquired before calling this method. <TAB> try: <TAB> <TAB> for listener in self.early_outgoing_packet_listeners: <TAB> <TAB> <TAB> listener.call_packet(packet) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> packet.write(self.socket, self.options.compression_threshold) <TAB> <TAB> else: <TAB> <TAB> <TAB> packet.write(self.socket) <TAB> <TAB> for listener in self.outgoing_packet_listeners: <TAB> <TAB> <TAB> listener.call_packet(packet) <TAB> except IgnorePacket: <TAB> <TAB> pass",if self . options . compression_threshold is not None :,if self . options . compression_enabled :,False,97.18,71.83,,,
"def rangelist_to_set ( rangelist ) : <TAB> result = set ( ) <TAB> if not rangelist : <TAB> <TAB> return result <TAB> for x in rangelist . split ( "" , "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . add ( int ( x ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re . match ( r "" ^( \ d+)-( \ d+)$ "" , x ) <TAB> <TAB> if m : <TAB> <TAB> <TAB> start = int ( m . group ( 1 ) ) <TAB> <TAB> <TAB> end = int ( m . group ( 2 ) ) <TAB> <TAB> <TAB> result . update ( set ( range ( start , end + 1 ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> msg = "" Cannot understand data input:  %s %s "" % ( x , rangelist ) <TAB> <TAB> raise ValueError ( msg ) <TAB> return result","if x . startswith ( ""x-"" ) :","if re . match ( r""^(\d+)$"" , x ) :",False,93.59,72.29,,,
"def test_device_property_logfile_isinstance ( self ) : <TAB> mock = MagicMock ( ) <TAB> with patch ( builtin_string + "" .open "" , mock ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> builtin_file = "" io.TextIOWrapper "" <TAB> <TAB> else : <TAB> <TAB> <TAB> builtin_file = builtin_string + "" .file "" <TAB> <TAB> with patch ( builtin_file , MagicMock ) : <TAB> <TAB> <TAB> handle = open ( "" filename "" , "" r "" ) <TAB> <TAB> <TAB> self . dev . logfile = handle <TAB> <TAB> <TAB> self . assertEqual ( self . dev . logfile , handle )","if sys . platform == ""win32"" :","if sys . version > ""3"" :",False,96.43,72.28,,,
"def _line_ranges ( statements , lines ) : <TAB> """""" Produce a list of ranges for `format_lines`. """""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines [ lidx ] : <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> if not start : <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs",if start and end :,elif start :,False,97.78,86.59,,,
"def reset_parameters ( self ) : <TAB> initialize = layers . get_initializer ( self . _hparams . initializer ) <TAB> if initialize is not None : <TAB> <TAB> # Do not re-initialize LayerNorm modules. <TAB> <TAB> for name, param in self.named_parameters(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> initialize(param)","if isinstance ( param , ( LayerNorm , LayerNorm ) ) :","if name . split ( ""."" ) [ - 1 ] == ""weight"" and ""layer_norm"" not in name :",False,76.5,54.88,,,
"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB> <TAB> RequiredArgumentMissingError , <TAB> <TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB> <TAB> if namespace . by_subscription is not None : <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> if namespace . by_subscription is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" )",if namespace . name is None :,if namespace . name is None :,True,100.0,74.55,,,
"def DeleteDocuments ( self , document_ids , response ) : <TAB> """""" Deletes documents for the given document_ids. """""" <TAB> for document_id in document_ids : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> document = self . _documents [ document_id ] <TAB> <TAB> <TAB> self . _inverted_index . RemoveDocument ( document ) <TAB> <TAB> <TAB> del self . _documents [ document_id ] <TAB> <TAB> delete_status = response . add_status ( ) <TAB> <TAB> delete_status . set_code ( search_service_pb . SearchServiceError . OK )",if document_id in self . _documents :,if document_id in self . _documents :,True,100.0,99.28,,,
"def generate_new_element ( items , prefix , numeric = False ) : <TAB> """""" Creates a random string with prefix, that is not in  ' items '  list. """""" <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> candidate = prefix + generate_random_numeric ( 8 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> candidate = prefix + generate_random_alphanumeric ( 8 ) <TAB> <TAB> if not candidate in items : <TAB> <TAB> <TAB> return candidate <TAB> <TAB> LOG . debug ( "" Random collision on  %s "" % candidate )",if numeric :,if numeric :,True,100.0,99.35,,,
"def generate_text_for_vocab ( self , data_dir , tmp_dir ) : <TAB> for i , sample in enumerate ( <TAB> <TAB> self . generate_samples ( data_dir , tmp_dir , problem . DatasetSplit . TRAIN ) <TAB> ) : <TAB> <TAB> if self . has_inputs : <TAB> <TAB> <TAB> yield sample [ "" inputs "" ] <TAB> <TAB> yield sample [ "" targets "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if i == self . num_samples_for_vocab :,if self . max_samples_for_vocab and ( i + 1 ) >= self . max_samples_for_vocab :,False,86.04,66.09,,,
"def _get_ccp ( config = None , config_path = None , saltenv = "" base "" ) : <TAB> """""" """""" <TAB> if config_path : <TAB> <TAB> config = __salt__ [ "" cp.get_file_str "" ] ( config_path , saltenv = saltenv ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise SaltException ( "" {}  is not available "" . format ( config_path ) ) <TAB> if isinstance ( config , six . string_types ) : <TAB> <TAB> config = config . splitlines ( ) <TAB> ccp = ciscoconfparse . CiscoConfParse ( config ) <TAB> return ccp",if config is None :,if config is False :,False,98.36,95.4,,,
"def rpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB> <TAB> _client . rpush ( key , * vals ) <TAB> else : <TAB> <TAB> pipe = _client . pipeline ( ) <TAB> <TAB> pipe . rpush ( key , * vals ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pipe . ltrim ( key , 0 , cap ) <TAB> <TAB> if ttl : <TAB> <TAB> <TAB> pipe . expire ( key , ttl ) <TAB> <TAB> pipe . execute ( )",if cap :,if cap :,True,100.0,74.46,,,
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","if s . startswith ( ""APNS-Key"" ) :","if mode == ""start"" :",False,96.7,73.01,,,
"def _add_communication_type ( apps , schema_editor , communication_type ) : <TAB> Worker = apps . get_model ( "" orchestra "" , "" Worker "" ) <TAB> CommunicationPreference = apps . get_model ( "" orchestra "" , "" CommunicationPreference "" ) <TAB> for worker in Worker . objects . all ( ) : <TAB> <TAB> ( <TAB> <TAB> <TAB> communication_preference , <TAB> <TAB> <TAB> created , <TAB> <TAB> ) = CommunicationPreference . objects . get_or_create ( <TAB> <TAB> <TAB> worker = worker , communication_type = communication_type <TAB> <TAB> ) <TAB> <TAB> # By default set both Slack and Email notifications to True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> communication_preference.methods.slack = True <TAB> <TAB> <TAB> communication_preference.methods.email = True <TAB> <TAB> communication_preference.save()",if created :,if created :,True,100.0,74.47,,,
"def get_postgresql_driver_name ( ) : <TAB> # pylint: disable=unused-variable <TAB> try: <TAB> <TAB> driver = os.getenv(""CODECHECKER_DB_DRIVER"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return driver <TAB> <TAB> try: <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import psycopg2 <TAB> <TAB> <TAB> return ""psycopg2"" <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import pg8000 <TAB> <TAB> <TAB> return ""pg8000"" <TAB> except Exception as ex: <TAB> <TAB> LOG.error(str(ex)) <TAB> <TAB> LOG.error(""Failed to import psycopg2 or pg8000 module."") <TAB> <TAB> raise",if driver :,if driver :,True,100.0,74.29,,,
"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB> <TAB> if entry is False : <TAB> <TAB> <TAB> continue <TAB> <TAB> code , tags , used , refname = entry <TAB> <TAB> for fullname in list ( used ) : <TAB> <TAB> <TAB> if used [ fullname ] == docname : <TAB> <TAB> <TAB> <TAB> used . pop ( fullname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> modules . pop ( modname )",if modname in modules :,if len ( used ) == 0 :,False,95.09,71.43,,,
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",if value is None :,if not is_iterable ( value ) :,False,96.99,72.6,,,
"def _get_bucket_for_key ( self , key : bytes ) - > Optional [ _DBValueTuple ] : <TAB> dbs : Iterable [ PartitionDB ] <TAB> try : <TAB> <TAB> partition = self . _key_index [ key ] <TAB> <TAB> dbs = [ PartitionDB ( partition , self . _dbs [ partition ] ) ] <TAB> except KeyError : <TAB> <TAB> dbs = cast ( Iterable [ PartitionDB ] , self . _dbs . items ( ) ) <TAB> for partition , db in dbs : <TAB> <TAB> if db . key_may_exist ( key ) [ 0 ] : <TAB> <TAB> <TAB> value = db . get ( key ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _key_index [ key ] = partition <TAB> <TAB> <TAB> <TAB> return _DBValueTuple ( db , value ) <TAB> return None",if value is not None :,if value is not None :,True,100.0,74.56,,,
"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB> <TAB> if self . _process . poll ( ) is None : <TAB> <TAB> <TAB> for _ in range ( 3 ) : <TAB> <TAB> <TAB> <TAB> self . _process . terminate ( ) <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _process . kill ( ) <TAB> <TAB> <TAB> <TAB> self . _process . wait ( ) <TAB> <TAB> <TAB> <TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB> <TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" )",if self . _process . returncode == 0 :,if self . _process . poll ( ) is not None :,False,97.34,72.28,,,
"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB> <TAB> if isinstance ( resultset , dict ) and "" duration "" in resultset : <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> results[""num_passed_states""] += 1 <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> results[""num_failed_states""] += 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results[""runtime""] += resultset[""duration""] <TAB> log.debug(""Parsed state metrics: {}"".format(results)) <TAB> return results","if state == ""pass"" :","if resultset [ ""result"" ] :",False,96.92,72.02,,,
"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB> <TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB> <TAB> if max != - 1 and spaces > max : <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB> <TAB> <TAB> )",if min != - 1 and spaces < min :,elif min != - 1 and spaces < min :,False,98.9,73.6,,,
"def getfileinfo ( name ) : <TAB> finfo = FInfo ( ) <TAB> with io . open ( name , "" rb "" ) as fp : <TAB> <TAB> # Quick check for textfile <TAB> <TAB> data = fp.read(512) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> finfo.Type = ""TEXT"" <TAB> <TAB> fp.seek(0, 2) <TAB> <TAB> dsize = fp.tell() <TAB> dir, file = os.path.split(name) <TAB> file = file.replace("":"", ""-"", 1) <TAB> return file, finfo, dsize, 0","if data == b"""" :",if 0 not in data :,False,95.36,65.48,,,
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """""" Return XML element converting dicts recursively. """""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> if tag == "" layers "" : <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if tag == "" config "" : <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem","elif tag == ""dict"" :","elif isinstance ( val , MutableMapping ) :",False,96.94,79.82,,,
"def _read_bytes ( self , length ) : <TAB> buffer = b "" "" <TAB> while length : <TAB> <TAB> chunk = self . request . recv ( length ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . debug ( "" Connection closed "" ) <TAB> <TAB> <TAB> return False <TAB> <TAB> length - = len ( chunk ) <TAB> <TAB> buffer + = chunk <TAB> return buffer",if not chunk :,"if chunk == b"""" :",False,93.4,53.08,,,
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> if dep_cnt : <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",if not dep_cnts :,if not dep_cnts :,True,100.0,74.43,,,
"def fix_repeating_arguments ( self ) : <TAB> """""" Fix elements that should accumulate/increment values. """""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self",if type ( e ) is list :,if type ( e ) is Argument or type ( e ) is Option and e . argcount :,False,94.58,94.3,,,
"def do_cli ( manager , options ) : <TAB> header = [ "" Name "" , "" Description "" ] <TAB> table_data = [ header ] <TAB> for filter_name , filter in get_filters ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> filter_doc = inspect . getdoc ( filter ) or "" "" <TAB> <TAB> table_data . append ( [ filter_name , filter_doc ] ) <TAB> try : <TAB> <TAB> table = TerminalTable ( options . table_type , table_data ) <TAB> except TerminalTableError as e : <TAB> <TAB> console ( "" ERROR:  %s "" % str ( e ) ) <TAB> else : <TAB> <TAB> console ( table . output )","if filter_name . startswith ( ""filter_"" ) :",if options . name and not options . name in filter_name :,False,93.78,64.78,,,
"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB> <TAB> while True : <TAB> <TAB> <TAB> b1 = fp1 . read ( bufsize ) <TAB> <TAB> <TAB> b2 = fp2 . read ( bufsize ) <TAB> <TAB> <TAB> if b1 != b2 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True",if b1 == b2 :,if not b1 :,False,96.3,72.08,,,
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if not father_handle :,if not father_handle :,True,100.0,74.42,,,
"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB> <TAB> n = ord ( char ) <TAB> <TAB> if 64 < n < 91 : <TAB> <TAB> <TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB> <TAB> result = result + chr ( n ) <TAB> return result",if 97 < n < 126 :,if 96 < n < 123 :,False,96.08,71.65,,,
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> if i == index : <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file . description : <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None","if rval == ""optional"" :",if composite_file . optional :,False,96.76,67.12,,,
"def __str__ ( self ) : <TAB> t = ""  <TAB>  "" <TAB> if self . _name != "" root "" : <TAB> <TAB> r = f "" { t * ( self . _level - 1 ) } { self . _name } : \n "" <TAB> else : <TAB> <TAB> r = "" "" <TAB> level = self . _level <TAB> for i , ( k , v ) in enumerate ( self . _pointer . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r + = f "" { t * ( self . _level ) } { v } \n "" <TAB> <TAB> <TAB> self . _level + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> r + = f "" { t * ( self . _level ) } { k } :  { v }  ( { type ( v ) . __name__ } ) \n "" <TAB> <TAB> self . _level = level <TAB> return r [ : - 1 ]",if i == 0 :,"if isinstance ( v , Config ) :",False,97.0,72.57,,,
"def __get_securitygroups ( vm_ ) : <TAB> vm_securitygroups = config . get_cloud_config_value ( <TAB> <TAB> "" securitygroups "" , vm_ , __opts__ , search_global = False <TAB> ) <TAB> if not vm_securitygroups : <TAB> <TAB> return [ ] <TAB> securitygroups = list_securitygroups ( ) <TAB> for i in range ( len ( vm_securitygroups ) ) : <TAB> <TAB> vm_securitygroups [ i ] = six . text_type ( vm_securitygroups [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise SaltCloudNotFound ( <TAB> <TAB> <TAB> <TAB> "" The specified securitygroups  ' {0} '  could not be found. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> vm_securitygroups [ i ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vm_securitygroups",if i not in securitygroups :,if vm_securitygroups [ i ] not in securitygroups :,False,96.89,72.52,,,
"def assert_walk_snapshot ( <TAB> self , field , filespecs_or_globs , paths , ignore_patterns = None , prepare = None ) : <TAB> with self . mk_project_tree ( ignore_patterns = ignore_patterns ) as project_tree : <TAB> <TAB> scheduler = self . mk_scheduler ( <TAB> <TAB> <TAB> rules = create_fs_rules ( ) , project_tree = project_tree <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> prepare ( project_tree ) <TAB> <TAB> result = self . execute ( scheduler , Snapshot , self . specs ( filespecs_or_globs ) ) [ 0 ] <TAB> <TAB> self . assertEqual ( sorted ( getattr ( result , field ) ) , sorted ( paths ) )",if prepare :,if prepare :,True,100.0,74.42,,,
"def _parse_rowids ( self , rowids ) : <TAB> xploded = [ ] <TAB> rowids = [ x . strip ( ) for x in rowids . split ( "" , "" ) ] <TAB> for rowid in rowids : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> start = int ( rowid . split ( "" - "" ) [ 0 ] . strip ( ) ) <TAB> <TAB> <TAB> <TAB> end = int ( rowid . split ( "" - "" ) [ - 1 ] . strip ( ) ) <TAB> <TAB> <TAB> <TAB> xploded + = range ( start , end + 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> xploded . append ( int ( rowid ) ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> continue <TAB> return sorted ( list ( set ( xploded ) ) )","if rowid . endswith ( ""-start"" ) :","if ""-"" in rowid :",False,96.14,72.65,,,
"def ensemble ( self , pairs , other_preds ) : <TAB> """""" Ensemble the dict with statistical model predictions. """""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> elif w in self . word_dict : <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None : <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas",if w in self . composite_dict :,"if ( w , pos ) in self . composite_dict :",False,97.08,95.55,,,
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add : <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if self . selectedChunks :,if box == self . level . bounds :,False,95.33,71.51,,,
"def _ensure_max_size ( cls , image , max_size , interpolation ) : <TAB> if max_size is not None : <TAB> <TAB> size = max ( image . shape [ 0 ] , image . shape [ 1 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resize_factor = max_size / size <TAB> <TAB> <TAB> new_height = int ( image . shape [ 0 ] * resize_factor ) <TAB> <TAB> <TAB> new_width = int ( image . shape [ 1 ] * resize_factor ) <TAB> <TAB> <TAB> image = ia . imresize_single_image ( <TAB> <TAB> <TAB> <TAB> image , ( new_height , new_width ) , interpolation = interpolation <TAB> <TAB> <TAB> ) <TAB> return image",if size > 0 :,if size > max_size :,False,97.71,73.38,,,
"def _1_0_cloud_ips ( self , method , url , body , headers ) : <TAB> if method == "" GET "" : <TAB> <TAB> return self . test_response ( httplib . OK , self . fixtures . load ( "" list_cloud_ips.json "" ) ) <TAB> elif method == "" POST "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> body = json . loads ( body ) <TAB> <TAB> node = json . loads ( self . fixtures . load ( "" create_cloud_ip.json "" ) ) <TAB> <TAB> if "" reverse_dns "" in body : <TAB> <TAB> <TAB> node [ "" reverse_dns "" ] = body [ "" reverse_dns "" ] <TAB> <TAB> return self . test_response ( httplib . ACCEPTED , json . dumps ( node ) )",if body :,if body :,True,100.0,74.51,,,
"def get_formatted_stats ( self ) : <TAB> """""" Get percentage or number of rar ' s done """""" <TAB> if self . cur_setname and self . cur_setname in self . total_volumes : <TAB> <TAB> # This won't work on obfuscated posts <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""%02d/%02d"" % (self.cur_volume, self.total_volumes[self.cur_setname]) <TAB> return self.cur_volume",if self . cur_volume in self . total_volumes :,if self . total_volumes [ self . cur_setname ] >= self . cur_volume and self . cur_volume :,False,86.69,89.79,,,
"def wdayset ( self , year , month , day ) : <TAB> # We need to handle cross-year weeks here. <TAB> dset = [None] * (self.yearlen + 7) <TAB> i = datetime.date(year, month, day).toordinal() - self.yearordinal <TAB> start = i <TAB> for j in range(7): <TAB> <TAB> dset[i] = i <TAB> <TAB> i += 1 <TAB> <TAB> # if (not (0 <= i < self.yearlen) or <TAB> <TAB> # <TAB> self.wdaymask[i] == self.rrule._wkst): <TAB> <TAB> # This will cross the year boundary, if necessary. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return dset, start, i",if i >= self . yearlen :,if self . wdaymask [ i ] == self . rrule . _wkst :,False,93.25,68.81,,,
"def do_acquire_read_lock ( self , wait = True ) : <TAB> self . condition . acquire ( ) <TAB> try : <TAB> <TAB> # see if a synchronous operation is waiting to start <TAB> <TAB> # or is already running, in which case we wait (or just <TAB> <TAB> # give up and return) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> while self.current_sync_operation is not None: <TAB> <TAB> <TAB> <TAB> self.condition.wait() <TAB> <TAB> else: <TAB> <TAB> <TAB> if self.current_sync_operation is not None: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> self.asynch += 1 <TAB> finally: <TAB> <TAB> self.condition.release() <TAB> if not wait: <TAB> <TAB> return True",if self . asynch == 0 :,if wait :,False,96.58,72.43,,,
"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> if not isinstance(y, (list, tuple)): <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> if len(x) > len(y): <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y","if isinstance ( y , dict ) :","if not isinstance ( y , ( dict , OrderedDict ) ) :",False,96.6,94.56,,,
"def update_forum_nums_topic_post ( modeladmin , request , queryset ) : <TAB> for forum in queryset : <TAB> <TAB> forum . num_topics = forum . count_nums_topic ( ) <TAB> <TAB> forum . num_posts = forum . count_nums_post ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> forum . last_post = forum . topic_set . order_by ( "" -last_reply_on "" ) [ 0 ] . last_post <TAB> <TAB> else : <TAB> <TAB> <TAB> forum . last_post = "" "" <TAB> <TAB> forum . save ( )","if request . POST . get ( ""last_reply_on"" , False ) :",if forum . num_topics :,False,89.77,63.24,,,
"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB> <TAB> if isinstance ( node , nodes . document ) : <TAB> <TAB> <TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return node [ "" docname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> node = node . parent <TAB> return None # never reached here. only for type hinting","elif isinstance ( node , nodes . name ) :","elif isinstance ( node , addnodes . start_of_file ) :",False,93.84,72.01,,,
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> if self . _args . host and self . _args . host == machine . name : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines","if self . _tags_match ( machine . tags , self . tags ) :",if self . locations and machine . location in self . locations :,False,92.07,69.52,,,
"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB> <TAB> if value is True : <TAB> <TAB> <TAB> return [ "" - %s "" % name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if split_single_char_options : <TAB> <TAB> <TAB> <TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB> <TAB> if value is True : <TAB> <TAB> <TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB> <TAB> elif value is not False and value is not None : <TAB> <TAB> <TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ]",elif value is not False :,"elif value not in ( False , None ) :",False,96.82,72.08,,,
"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * "" "" <TAB> if len ( elem ) : <TAB> <TAB> if not elem . text or not elem . text . strip ( ) : <TAB> <TAB> <TAB> elem . text = i + "" "" <TAB> <TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB> <TAB> <TAB> elem . tail = i <TAB> <TAB> for elem in elem : <TAB> <TAB> <TAB> indent ( elem , level + 1 ) <TAB> <TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB> <TAB> <TAB> elem . tail = i <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elem . tail = i",if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,True,100.0,74.62,,,
"def _run_instances_op ( self , op , instance_ids , * * kwargs ) : <TAB> while instance_ids : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . manager . retry ( op , InstanceIds = instance_ids , * * kwargs ) <TAB> <TAB> except ClientError as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> instance_ids . remove ( extract_instance_id ( e ) ) <TAB> <TAB> <TAB> raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""InvalidInstance.NotFound"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""IncorrectInstanceState"" :",False,96.83,72.71,,,
"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB> <TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB> <TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB> <TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB> <TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bomb_count + = 1 <TAB> <TAB> <TAB> if bomb_count > 3 : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> fish . click ( ) <TAB> <TAB> time . sleep ( 2.5 )",if fish is not None :,if fish is bomb :,False,98.51,73.59,,,
"def lineWidth ( self , lw = None ) : <TAB> """""" Set/get width of mesh edges. Same as `lw()`. """""" <TAB> if lw is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOff ( ) <TAB> <TAB> <TAB> self . GetProperty ( ) . SetRepresentationToSurface ( ) <TAB> <TAB> <TAB> return self <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOn ( ) <TAB> <TAB> self . GetProperty ( ) . SetLineWidth ( lw ) <TAB> else : <TAB> <TAB> return self . GetProperty ( ) . GetLineWidth ( ) <TAB> return self",if self . GetProperty ( ) . GetLineWidth ( ) == lw :,if lw == 0 :,False,92.47,68.55,,,
"def lineWidth ( self , lw = None ) : <TAB> """""" Set/get width of mesh edges. Same as `lw()`. """""" <TAB> if lw is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOff ( ) <TAB> <TAB> <TAB> self . GetProperty ( ) . SetRepresentationToSurface ( ) <TAB> <TAB> <TAB> return self <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOn ( ) <TAB> <TAB> self . GetProperty ( ) . SetLineWidth ( lw ) <TAB> else : <TAB> <TAB> return self . GetProperty ( ) . GetLineWidth ( ) <TAB> return self",if self . GetProperty ( ) . GetLineWidth ( ) == lw :,"if value == { ""$type"" : ""timestamp"" } :",False,91.78,66.3,,,
"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB> <TAB> after = self . after . id if self . after else None <TAB> <TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB> if len(data) < 1000: <TAB> <TAB> <TAB> self.limit = 0 # terminate loop <TAB> <TAB> self.after = Object(id=int(data[-1][""user""][""id""])) <TAB> <TAB> for element in reversed(data): <TAB> <TAB> <TAB> await self.members.put(self.create_member(element))",if not data :,if not data :,True,100.0,74.38,,,
"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB> <TAB> extracted = extractor . extract ( <TAB> <TAB> <TAB> page , start_index , end_index , self . template . ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter ( extracted ) : <TAB> <TAB> <TAB> if item : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> item [ u "" _template "" ] = self . template . id <TAB> <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items",if self . template :,"if isinstance ( item , ( ItemProcessor , dict ) ) :",False,93.79,69.63,,,
"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB> <TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB> <TAB> if node_type not in self . available_node_types : <TAB> <TAB> <TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB> <TAB> node_specific_config = self . available_node_types [ node_type ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fields = node_specific_config [ fields_key ] <TAB> return fields",if fields_key in node_specific_config :,if fields_key in node_specific_config :,True,100.0,74.42,,,
"def _write_all ( self , writer ) : <TAB> """""" Writes messages and insert comments here and there. """""" <TAB> # Note: we make no assumptions about the length of original_messages and original_comments <TAB> for msg, comment in zip_longest( <TAB> <TAB> self.original_messages, self.original_comments, fillvalue=None <TAB> ): <TAB> <TAB> # msg and comment might be None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""writing comment: "", comment) <TAB> <TAB> <TAB> writer.log_event(comment) # we already know that this method exists <TAB> <TAB> if msg is not None: <TAB> <TAB> <TAB> print(""writing message: "", msg) <TAB> <TAB> <TAB> writer(msg)",if comment is not None :,if comment is not None :,True,100.0,74.4,,,
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> elif case(1, 2): <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> elif case(3, 4): <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")","if case ( 0 , 1 ) :",if case ( 0 ) :,False,98.02,72.33,,,
"def date_to_format ( value , target_format ) : <TAB> """""" Convert date to specified format """""" <TAB> if target_format == str : <TAB> <TAB> if isinstance ( value , datetime . date ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . time ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB> <TAB> ret = value <TAB> return ret","elif isinstance ( value , datetime . daterange ) :","elif isinstance ( value , datetime . datetime ) :",False,98.62,97.85,,,
"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB> <TAB> if not which ( "" initdb "" ) : <TAB> <TAB> <TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB> <TAB> if not os . environ . get ( "" GALAXY_TEST_AMQP_INTERNAL_CONNECTION "" ) : <TAB> <TAB> <TAB> pytest . skip ( <TAB> <TAB> <TAB> <TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB> <TAB> <TAB> ) <TAB> return request . getfixturevalue ( request . param )","if not which ( ""psycopg2"" ) :",if not psycopg2 :,False,96.55,69.47,,,
"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> <IF-STMT> <TAB> <TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB> <TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB> <TAB> if not os . check_error ( n ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB> <TAB> <TAB> if timeout < 0 : <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB> <TAB> vals = struct . unpack ( epoll_event , s ) <TAB> <TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res",if timeout :,if timeout >= 0 :,False,96.4,72.52,,,
"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """""" This returns the list of plugins in the callback ordered defined from the config. """""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> if name is None: <TAB> <TAB> <TAB> all_plugins += [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name, plugin in self.plugins.items() <TAB> <TAB> <TAB> <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> plugin = self.plugins[name] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> all_plugins.append(plugin) <TAB> return all_plugins",if plugin . is_activated :,if plugin . is_activated :,True,100.0,99.52,,,
"def get_expected_sql ( self ) : <TAB> sql_base_path = path . join ( path . dirname ( path . realpath ( __file__ ) ) , "" sql "" ) <TAB> # Iterate the version mapping directories. <TAB> for version_mapping in get_version_mapping_directories(self.server[""type""]): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> complete_path = path.join(sql_base_path, version_mapping[""name""]) <TAB> <TAB> if not path.exists(complete_path): <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> data_sql = """" <TAB> with open(path.join(complete_path, ""test_sql_output.sql"")) as fp: <TAB> <TAB> data_sql = fp.read() <TAB> return data_sql","if not path . exists ( path . join ( sql_base_path , version_mapping [ ""name"" ] ) ) :","if version_mapping [ ""number"" ] > self . server_information [ ""server_version"" ] :",False,91.11,89.02,,,
"def _validate_headers ( self , headers ) : <TAB> if headers is None : <TAB> <TAB> return headers <TAB> res = { } <TAB> for key , value in headers . items ( ) : <TAB> <TAB> if isinstance ( value , ( int , float ) ) : <TAB> <TAB> <TAB> value = str ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ScriptError ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" message "" : "" headers must be a table "" <TAB> <TAB> <TAB> <TAB> <TAB> ""  with strings as keys and values. "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Header: ` {!r} : {!r} ` is not valid "" . format ( key , value ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> res [ key ] = value <TAB> return res",if key not in self . table :,"if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) :",False,90.79,67.42,,,
"def _get_literal_value ( self , pyval ) : <TAB> if pyval == self . vm . lookup_builtin ( "" builtins.True "" ) : <TAB> <TAB> return True <TAB> elif pyval == self . vm . lookup_builtin ( "" builtins.False "" ) : <TAB> <TAB> return False <TAB> elif isinstance ( pyval , str ) : <TAB> <TAB> prefix , value = parser_constants . STRING_RE . match ( pyval ) . groups ( ) [ : 2 ] <TAB> <TAB> value = value [ 1 : - 1 ] # remove quotation marks <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = compat.bytestring(value) <TAB> <TAB> elif ""u"" in prefix and self.vm.PY2: <TAB> <TAB> <TAB> value = compat.UnicodeType(value) <TAB> <TAB> return value <TAB> else: <TAB> <TAB> return pyval","if ""b"" in prefix and self . vm . PY2 :","if ""b"" in prefix and not self . vm . PY2 :",False,98.89,73.52,,,
"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB> <TAB> self . decode_query_ids ( trans , conditional . left ) <TAB> <TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB> <TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field = self . FIELDS [ left_base ] <TAB> <TAB> <TAB> if field . id_decode : <TAB> <TAB> <TAB> <TAB> conditional . right = trans . security . decode_id ( conditional . right )",if left_base in self . FIELDS :,if left_base in self . FIELDS :,True,100.0,74.42,,,
"def testLastPhrases ( self ) : <TAB> for day in ( 11 , 12 , 13 , 14 , 15 , 16 , 17 ) : <TAB> <TAB> start = datetime . datetime ( 2012 , 11 , day , 9 , 0 , 0 ) <TAB> <TAB> ( yr , mth , dy , _ , _ , _ , wd , yd , isdst ) = start . timetuple ( ) <TAB> <TAB> n = 4 - wd <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n - = 7 <TAB> <TAB> target = start + datetime . timedelta ( days = n ) <TAB> <TAB> self . assertExpectedResult ( <TAB> <TAB> <TAB> self . cal . parse ( "" last friday "" , start . timetuple ( ) ) , <TAB> <TAB> <TAB> ( target . timetuple ( ) , 1 ) , <TAB> <TAB> <TAB> dateOnly = True , <TAB> <TAB> )",if isdst :,if n >= 0 :,False,97.4,73.17,,,
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> if isinstance ( nbChars , int ) : <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> if nbChars [ 1 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )",if nbChars [ 0 ] is not None :,if nbChars [ 0 ] is not None :,True,100.0,74.44,,,
"def getpystone ( ) : <TAB> # Start calculation <TAB> maxpystone = 0 <TAB> # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB> for pyseed in [1000, 2000, 5000, 10000, 20000, 50000, 100000, 200000]: <TAB> <TAB> duration, pystonefloat = pystones(pyseed) <TAB> <TAB> maxpystone = max(maxpystone, int(pystonefloat)) <TAB> <TAB> # Stop when pystone() has been running for at least 0.1 second <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return maxpystone",if duration > 0.1 :,if duration > 0.1 :,True,100.0,74.28,,,
"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <TAB> <TAB> <IF-STMT> # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re.split( <TAB> <TAB> <TAB> <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> if block: <TAB> <TAB> <TAB> <TAB> <TAB> self._queued_io_events.append((block, stream_name))","if part . startswith ( ""CSI"" ) :",if part :,False,96.36,64.31,,,
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB> if len(val) == 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver.needsQuoting(val, True): <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res","if not isinstance ( val , ( str , unicode ) ) :","if not hasattr ( val , ""__len__"" ) :",False,95.44,65.76,,,
"def SetVerbose ( self , level ) : <TAB> """""" Sets the verbose level. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> level = int ( level ) <TAB> <TAB> if ( level > = 0 ) and ( level < = 3 ) : <TAB> <TAB> <TAB> self . _verbose = level <TAB> <TAB> <TAB> return <TAB> except ValueError : <TAB> <TAB> pass <TAB> self . Error ( "" Verbose level ( %s ) must be between 0 and 3 inclusive. "" % level )","if isinstance ( level , int ) :",if type ( level ) != types . IntType :,False,93.31,93.53,,,
"def step ( self ) - > None : <TAB> """""" Performs a single optimization step. """""" <TAB> for group in self . param_groups : <TAB> <TAB> for p in group [ "" params "" ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> p . add_ ( p . grad , alpha = ( - group [ "" lr "" ] * self . num_data ) ) <TAB> return None",if p . grad is None :,if p . grad is None :,True,100.0,74.26,,,
"def fill ( self , values ) : <TAB> if lupa . lua_type ( values ) != "" table "" : <TAB> <TAB> raise ScriptError ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" argument "" : "" values "" , <TAB> <TAB> <TAB> <TAB> "" message "" : "" element:fill values is not a table "" , <TAB> <TAB> <TAB> <TAB> "" splash_method "" : "" fill "" , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> # marking all tables as arrays by default <TAB> for key, value in values.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _mark_table_as_array(self.lua, value) <TAB> values = self.lua.lua2python(values) <TAB> return self.element.fill(values)","if isinstance ( value , ( list , tuple ) ) :","if lupa . lua_type ( value ) == ""table"" :",False,93.98,67.22,,,
"def _gen_repr ( self , buf ) : <TAB> print >> buf , ""  <TAB> def __repr__(self): "" <TAB> if self . argnames : <TAB> <TAB> fmt = COMMA . join ( [ "" %s "" ] * self . nargs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fmt = "" ( %s ) "" % fmt <TAB> <TAB> vals = [ "" repr(self. %s ) "" % name for name in self . argnames ] <TAB> <TAB> vals = COMMA . join ( vals ) <TAB> <TAB> if self . nargs == 1 : <TAB> <TAB> <TAB> vals = vals + "" , "" <TAB> <TAB> print >> buf , '  <TAB> <TAB> return  "" %s ( %s ) "" %%  ( %s ) ' % ( self . name , fmt , vals ) <TAB> else : <TAB> <TAB> print >> buf , '  <TAB> <TAB> return  "" %s () "" ' % self . name",if self . nargs == 2 :,"if ""("" in self . args :",False,96.86,69.49,,,
"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid <TAB> :  "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x_str + = "" "" * len ( label ) <TAB> <TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB> <TAB> <TAB> if i == x [ 0 ] and j == x [ 1 ] : <TAB> <TAB> <TAB> <TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB> <TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str",if self . is_obs_visible ( ) :,if j != - 1 :,False,96.04,72.83,,,
"def get_module_comment ( self , attrname : str ) - > Optional [ List [ str ] ] : <TAB> try : <TAB> <TAB> analyzer = ModuleAnalyzer . for_module ( self . modname ) <TAB> <TAB> analyzer . analyze ( ) <TAB> <TAB> key = ( "" "" , attrname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return list ( analyzer . attr_docs [ key ] ) <TAB> except PycodeError : <TAB> <TAB> pass <TAB> return None",if key in analyzer . attr_docs :,if key in analyzer . attr_docs :,True,100.0,74.25,,,
"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google: <TAB> <TAB> y = (2 ** z - 1) - y <TAB> for i in range(z, 0, -1): <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << (i - 1) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> digit += 1 <TAB> <TAB> if (y & mask) != 0: <TAB> <TAB> <TAB> digit += 2 <TAB> <TAB> quadKey += str(digit) <TAB> return quadKey",if ( x & mask ) != 0 :,if ( x & mask ) != 0 :,True,100.0,74.47,,,
"def test_enumerate ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB> <TAB> for i in range ( 100 ) : <TAB> <TAB> <TAB> await stream . channel . deliver ( message ( key = i , value = i * 4 ) ) <TAB> <TAB> async for i , value in stream . enumerate ( ) : <TAB> <TAB> <TAB> current_event = stream . current_event <TAB> <TAB> <TAB> assert i == current_event . key <TAB> <TAB> <TAB> assert value == i * 4 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty ( stream . channel )",if i == 100 :,if i >= 99 :,False,97.6,72.93,,,
"def print_messages ( self ) : <TAB> output_reports = self . config . get_output_report ( ) <TAB> for report in output_reports : <TAB> <TAB> output_format , output_files = report <TAB> <TAB> self . summary [ "" formatter "" ] = output_format <TAB> <TAB> formatter = FORMATTERS [ output_format ] ( <TAB> <TAB> <TAB> self . summary , self . messages , self . config . profile <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . write_to ( formatter , sys . stdout ) <TAB> <TAB> for output_file in output_files : <TAB> <TAB> <TAB> with open ( output_file , "" w+ "" ) as target : <TAB> <TAB> <TAB> <TAB> self . write_to ( formatter , target )",if self . config . verbose :,if not output_files :,False,96.85,72.32,,,
"def eval_metrics ( self ) : <TAB> for task in self . task_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ACC , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ROUGE_2_F , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ROUGE_L_F , <TAB> <TAB> <TAB> ] <TAB> return [ <TAB> <TAB> metrics . Metrics . ACC , <TAB> <TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB> ]","if task . name == ""metrics"" :","if ""summarize"" in task . name :",False,95.73,71.42,,,
"def _getBuildRequestForBrdict ( self , brdict ) : <TAB> # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB> # for API like 'nextBuild', which operate on BuildRequest objects. <TAB> breq = self.breqCache.get(brdict[""buildrequestid""]) <TAB> if not breq: <TAB> <TAB> breq = yield BuildRequest.fromBrdict(self.master, brdict) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.breqCache[brdict[""buildrequestid""]] = breq <TAB> defer.returnValue(breq)",if breq :,if breq :,True,100.0,74.0,,,
"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB> <TAB> for s in states : <TAB> <TAB> <TAB> ns = state_func ( s ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> split . append ( ns ) <TAB> <TAB> <TAB> elif isinstance ( ns , ( list , tuple , set ) ) : <TAB> <TAB> <TAB> <TAB> split . extend ( ns ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB> <TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB> <TAB> keep = states <TAB> return keep , split","if isinstance ( ns , ( list , tuple , set ) ) :","if isinstance ( ns , SimState ) :",False,96.16,72.58,,,
"def sequence_to_text ( sequence ) : <TAB> """""" Converts a sequence of IDs back to a string """""" <TAB> result = "" "" <TAB> for symbol_id in sequence : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s = _id_to_symbol [ symbol_id ] <TAB> <TAB> <TAB> # Enclose ARPAbet back in curly braces: <TAB> <TAB> <TAB> if len(s) > 1 and s[0] == ""@"": <TAB> <TAB> <TAB> <TAB> s = ""{%s}"" % s[1:] <TAB> <TAB> <TAB> result += s <TAB> return result.replace(""}{"", "" "")",if symbol_id in _id_to_symbol :,if symbol_id in _id_to_symbol :,True,100.0,99.28,,,
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> elif mod_type == imp . PY_COMPILED : <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",if mod_type == imp . PY_COMPILED :,if mod_type == imp . PY_SOURCE :,False,99.04,73.81,,,
"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB> <TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB> <TAB> return detected <TAB> for wafvendor in self . checklist : <TAB> <TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB> <TAB> if self . wafdetections [ wafvendor ] ( self ) : <TAB> <TAB> <TAB> detected . append ( wafvendor ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected",if not findall :,if not findall :,True,100.0,74.46,,,
"def SessionId ( self ) : <TAB> """""" Returns the Session ID of the process """""" <TAB> if self . Session . is_valid ( ) : <TAB> <TAB> process_space = self . get_process_address_space ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return obj . Object ( <TAB> <TAB> <TAB> <TAB> "" _MM_SESSION_SPACE "" , offset = self . Session , vm = process_space <TAB> <TAB> <TAB> ) . SessionId <TAB> return obj . NoneObject ( "" Cannot find process session "" )",if process_space :,if process_space :,True,100.0,99.24,,,
"def _convert_java_pattern_to_python ( pattern ) : <TAB> """""" Convert a replacement pattern from the Java-style `$5` to the Python-style ` \\ 5`. """""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB> <TAB> c = s [ i ] <TAB> <TAB> if c == "" $ "" and s [ i + 1 ] in "" 0123456789 "" : <TAB> <TAB> <TAB> s [ i ] = "" \\ "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s [ i ] = "" "" <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s )","elif c == ""$"" and s [ i + 1 ] in ""0123456789"" :","elif c == ""\\"" and s [ i + 1 ] == ""$"" :",False,96.58,65.34,,,
"def __init__ ( self , coverage ) : <TAB> self . coverage = coverage <TAB> self . config = self . coverage . config <TAB> self . source_paths = set ( ) <TAB> if self . config . source : <TAB> <TAB> for src in self . config . source : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not self . config . relative_files : <TAB> <TAB> <TAB> <TAB> <TAB> src = files . canonical_filename ( src ) <TAB> <TAB> <TAB> <TAB> self . source_paths . add ( src ) <TAB> self . packages = { } <TAB> self . xml_out = None",if src not in self . source_paths :,if os . path . exists ( src ) :,False,94.83,70.53,,,
"def populate_vol_format ( self ) : <TAB> rhel6_file_whitelist = [ "" raw "" , "" qcow2 "" , "" qed "" ] <TAB> model = self . widget ( "" vol-format "" ) . get_model ( ) <TAB> model . clear ( ) <TAB> formats = self . vol_class . formats <TAB> if hasattr ( self . vol_class , "" create_formats "" ) : <TAB> <TAB> formats = getattr ( self . vol_class , "" create_formats "" ) <TAB> if self . vol_class == Storage . FileVolume and not self . conn . rhel6_defaults_caps ( ) : <TAB> <TAB> newfmts = [ ] <TAB> <TAB> for f in rhel6_file_whitelist : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> newfmts . append ( f ) <TAB> <TAB> formats = newfmts <TAB> for f in formats : <TAB> <TAB> model . append ( [ f , f ] )",if f not in formats :,if f in formats :,False,98.91,73.92,,,
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> if file_sources_as_dict is not None : <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> if file_sources is None : <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources","if os . path . exists ( ""file_sources.json"" ) :","if os . path . exists ( ""file_sources.json"" ) :",True,100.0,74.51,,,
"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> if not isinstance(y, (list, tuple)): <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y",if len ( x ) < len ( y ) :,if len ( x ) > len ( y ) :,False,99.03,98.3,,,
"def copy_dicts ( dct ) : <TAB> if "" _remote_data "" in dct : <TAB> <TAB> dsindex = dct [ "" _remote_data "" ] [ "" _content "" ] . dsindex <TAB> <TAB> newdct = dct . copy ( ) <TAB> <TAB> newdct [ "" _remote_data "" ] = { "" _content "" : dsindex } <TAB> <TAB> return list ( newdct . items ( ) ) <TAB> elif "" _data "" in dct : <TAB> <TAB> newdct = dct . copy ( ) <TAB> <TAB> newdata = copy_dicts ( dct [ "" _data "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newdct [ "" _data "" ] = newdata <TAB> <TAB> return list ( newdct . items ( ) ) <TAB> return None",if newdata :,if newdata :,True,100.0,74.5,,,
"def _import_epic_activity ( self , project_data , taiga_epic , epic , options ) : <TAB> offset = 0 <TAB> while True : <TAB> <TAB> activities = self . _client . get ( <TAB> <TAB> <TAB> "" /projects/ {} /epics/ {} /activity "" . format ( <TAB> <TAB> <TAB> <TAB> project_data [ "" id "" ] , <TAB> <TAB> <TAB> <TAB> epic [ "" id "" ] , <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> { "" envelope "" : "" true "" , "" limit "" : 300 , "" offset "" : offset } , <TAB> <TAB> ) <TAB> <TAB> offset + = 300 <TAB> <TAB> for activity in activities [ "" data "" ] : <TAB> <TAB> <TAB> self . _import_activity ( taiga_epic , activity , options ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if not activities :,"if len ( activities [ ""data"" ] ) < 300 :",False,94.9,68.12,,,
"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rel_obj = self . get_obj ( instance ) <TAB> <TAB> <TAB> if rel_obj : <TAB> <TAB> <TAB> <TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB> <TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self",if instance_type :,if self . att_name not in instance . _obj_cache :,False,89.38,67.53,,,
"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB> <TAB> if url . startswith ( "" https:// "" ) : <TAB> <TAB> <TAB> url = url [ 8 : ] <TAB> <TAB> if not url . startswith ( "" http:// "" ) : <TAB> <TAB> <TAB> url = "" http:// "" + url <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> download_playlist ( <TAB> <TAB> <TAB> <TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only )",if playlist :,if playlist :,True,100.0,74.49,,,
"def _mksubs ( self ) : <TAB> self . _subs = { } <TAB> commit_dir = CommitDir ( self , "" .commit "" ) <TAB> self . _subs [ "" .commit "" ] = commit_dir <TAB> tag_dir = TagDir ( self , "" .tag "" ) <TAB> self . _subs [ "" .tag "" ] = tag_dir <TAB> for ( name , sha ) in git . list_refs ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = name [ 11 : ] <TAB> <TAB> <TAB> date = git . rev_get_date ( sha . encode ( "" hex "" ) ) <TAB> <TAB> <TAB> n1 = BranchList ( self , name , sha ) <TAB> <TAB> <TAB> n1 . ctime = n1 . mtime = date <TAB> <TAB> <TAB> self . _subs [ name ] = n1","if name . startswith ( ""HEAD"" ) :","if name . startswith ( ""refs/heads/"" ) :",False,97.47,73.68,,,
"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB> <TAB> rlen = size - len ( ret ) <TAB> <TAB> x = self . fd . read ( rlen ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not shortok : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret + = x <TAB> return ret",if not x :,"if x == b"""" :",False,94.82,54.71,,,
"def remove_indent ( self ) : <TAB> """""" Remove one tab-width of blanks from the previous token. """""" <TAB> w = abs ( self . tab_width ) <TAB> if self . result : <TAB> <TAB> s = self . result [ - 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . result . pop ( ) <TAB> <TAB> <TAB> s = s . replace ( "" \t "" , "" "" * w ) <TAB> <TAB> <TAB> if s . startswith ( "" \n "" ) : <TAB> <TAB> <TAB> <TAB> s2 = s [ 1 : ] <TAB> <TAB> <TAB> <TAB> self . result . append ( "" \n "" + s2 [ : - w ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . result . append ( s [ : - w ] )","if s . startswith ( ""\t"" ) :",if s . isspace ( ) :,False,96.76,73.29,,,
"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB> <TAB> self . _last_updated = time . time ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if kwargs . get ( "" in_place "" , False ) : <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . _last_updated = time . time ( )","if kwargs . get ( ""in_place"" , False ) :","if ""_create_temporary"" in traceback . format_exc ( ) :",False,94.48,71.51,,,
"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB> <TAB> elif act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_COMP_CODES : <TAB> <TAB> <TAB> manual_intervention_nodes . add ( act [ "" id "" ] )","if act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :","if act [ ""type"" ] == ""SubProcess"" :",False,87.97,69.72,,,
"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB> <TAB> return <TAB> if authed ( ) : <TAB> <TAB> user = get_current_user_attrs ( ) <TAB> <TAB> team = get_current_team_attrs ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) <TAB> <TAB> if team and team . banned : <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , <TAB> <TAB> <TAB> <TAB> <TAB> error = "" Your team has been banned from this CTF "" , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> )",if user and user . banned :,if user and user . banned :,True,100.0,74.6,,,
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> if isinstance ( self . _definition , dict ) : <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> if v == "" ANY "" : <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )",elif v in self . _definition :,elif v in self . _definition :,True,100.0,74.65,,,
"def save ( self , learner , file_name ) : <TAB> """""" Save the model to location specified in file_name. """""" <TAB> with open ( file_name , "" wb "" ) as f : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # don't store the large inference cache! <TAB> <TAB> <TAB> learner.inference_cache_, tmp = (None, learner.inference_cache_) <TAB> <TAB> <TAB> pickle.dump(learner, f, -1) <TAB> <TAB> <TAB> learner.inference_cache_ = tmp <TAB> <TAB> else: <TAB> <TAB> <TAB> pickle.dump(learner, f, -1)",if len ( learner . inference_cache_ ) > self . max_inference_cache :,"if hasattr ( learner , ""inference_cache_"" ) :",False,91.66,75.5,,,
"def __init__ ( self , exprs , savelist = False ) : <TAB> super ( ParseExpression , self ) . __init__ ( savelist ) <TAB> if isinstance ( exprs , _generatorType ) : <TAB> <TAB> exprs = list ( exprs ) <TAB> if isinstance ( exprs , basestring ) : <TAB> <TAB> self . exprs = [ ParserElement . _literalStringClass ( exprs ) ] <TAB> elif isinstance ( exprs , collections . Iterable ) : <TAB> <TAB> exprs = list ( exprs ) <TAB> <TAB> # if sequence of strings provided, wrap with Literal <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exprs = map(ParserElement._literalStringClass, exprs) <TAB> <TAB> self.exprs = list(exprs) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> self.exprs = list(exprs) <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> self.exprs = [exprs] <TAB> self.callPreparse = False","if isinstance ( exprs , ( list , tuple ) ) :","if all ( isinstance ( expr , basestring ) for expr in exprs ) :",False,95.2,70.38,,,
"def find ( self , back = False ) : <TAB> flags = 0 <TAB> <IF-STMT> <TAB> <TAB> flags = QTextDocument . FindBackward <TAB> if self . csBox . isChecked ( ) : <TAB> <TAB> flags = flags | QTextDocument . FindCaseSensitively <TAB> text = self . searchEdit . text ( ) <TAB> if not self . findMain ( text , flags ) : <TAB> <TAB> if text in self . editBoxes [ self . ind ] . toPlainText ( ) : <TAB> <TAB> <TAB> cursor = self . editBoxes [ self . ind ] . textCursor ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cursor . movePosition ( QTextCursor . End ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> cursor . movePosition ( QTextCursor . Start ) <TAB> <TAB> <TAB> self . editBoxes [ self . ind ] . setTextCursor ( cursor ) <TAB> <TAB> <TAB> self . findMain ( text , flags )",if back :,if back :,True,100.0,74.61,,,
"def _load_storage ( self ) : <TAB> self . _storage = { } <TAB> for row in self ( "" SELECT object, resource, amount FROM storage "" ) : <TAB> <TAB> ownerid = int ( row [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _storage [ ownerid ] . append ( row [ 1 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _storage [ ownerid ] = [ row [ 1 : ] ]",if ownerid in self . _storage :,if ownerid in self . _storage :,True,100.0,74.28,,,
"def parse_chunked ( self , unreader ) : <TAB> ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB> while size > 0 : <TAB> <TAB> while size > len ( rest ) : <TAB> <TAB> <TAB> size - = len ( rest ) <TAB> <TAB> <TAB> yield rest <TAB> <TAB> <TAB> rest = unreader . read ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise NoMoreData ( ) <TAB> <TAB> yield rest [ : size ] <TAB> <TAB> # Remove \r\n after chunk <TAB> <TAB> rest = rest[size:] <TAB> <TAB> while len(rest) < 2: <TAB> <TAB> <TAB> rest += unreader.read() <TAB> <TAB> if rest[:2] != b""\r\n"": <TAB> <TAB> <TAB> raise ChunkMissingTerminator(rest[:2]) <TAB> <TAB> (size, rest) = self.parse_chunk_size(unreader, data=rest[2:])",if size == 0 :,if not rest :,False,97.91,72.81,,,
"def _augment_batch_ ( self , batch , random_state , parents , hooks ) : <TAB> for column in batch . columns : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for i , cbaoi in enumerate ( column . value ) : <TAB> <TAB> <TAB> <TAB> column . value [ i ] = cbaoi . clip_out_of_image_ ( ) <TAB> return batch","if isinstance ( column , Column ) :","if column . name in [ ""keypoints"" , ""bounding_boxes"" , ""polygons"" , ""line_strings"" ] :",False,76.99,59.48,,,
"def to_nim ( self ) : <TAB> if self . is_pointer == 2 : <TAB> <TAB> s = "" cstringArray "" if self . type == "" GLchar "" else "" ptr pointer "" <TAB> else : <TAB> <TAB> s = self . type <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> default = "" ptr  "" + s <TAB> <TAB> <TAB> s = self . NIM_POINTER_MAP . get ( s , default ) <TAB> return s",if self . is_pointer == 1 :,if self . is_pointer == 1 :,True,100.0,74.23,,,
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> if self . match_function ( path ) : <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> if self . match_function ( file ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file )",if os . path . isfile ( file ) or os . path . islink ( file ) :,if os . path . isfile ( file ) or os . path . islink ( file ) :,True,100.0,74.63,,,
"def remove ( self , event ) : <TAB> try : <TAB> <TAB> self . _events_current_sweep . remove ( event ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert event . in_sweep == True <TAB> <TAB> <TAB> assert event . other . in_sweep == True <TAB> <TAB> <TAB> event . in_sweep = False <TAB> <TAB> <TAB> event . other . in_sweep = False <TAB> <TAB> return True <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert event . in_sweep == False <TAB> <TAB> <TAB> assert event . other . in_sweep == False <TAB> <TAB> return False",if self . _events_current_sweep is not None :,if USE_DEBUG :,False,87.76,69.84,,,
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass","if attrname == ""version"" :","if attrname == ""salt_version"" :",False,98.57,73.78,,,
"def _init_auxiliary_head ( self , auxiliary_head ) : <TAB> """""" Initialize ``auxiliary_head`` """""" <TAB> if auxiliary_head is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . auxiliary_head = nn . ModuleList ( ) <TAB> <TAB> <TAB> for head_cfg in auxiliary_head : <TAB> <TAB> <TAB> <TAB> self . auxiliary_head . append ( builder . build_head ( head_cfg ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . auxiliary_head = builder . build_head ( auxiliary_head )","if isinstance ( auxiliary_head , list ) :","if isinstance ( auxiliary_head , list ) :",True,100.0,99.27,,,
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> if param . name : <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out",if param . type :,if param . type :,True,100.0,74.58,,,
"def _set_handler ( <TAB> self , name , handle = None , obj = None , constructor_args = ( ) , constructor_kwds = { } ) : <TAB> if handle is None : <TAB> <TAB> handle = obj is not None <TAB> if handle : <TAB> <TAB> handler_class = self . handler_classes [ name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newhandler = handler_class ( obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newhandler = handler_class ( * constructor_args , * * constructor_kwds ) <TAB> else : <TAB> <TAB> newhandler = None <TAB> self . _replace_handler ( name , newhandler )","if isinstance ( obj , handler_class ) :",if obj is not None :,False,94.66,71.18,,,
"def _extract_subtitles ( src ) : <TAB> subtitles = { } <TAB> for caption in try_get ( src , lambda x : x [ "" captions "" ] , list ) or [ ] : <TAB> <TAB> subtitle_url = url_or_none ( caption . get ( "" uri "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lang = caption . get ( "" language "" , "" deu "" ) <TAB> <TAB> <TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" url "" : subtitle_url , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return subtitles",if subtitle_url :,if subtitle_url :,True,100.0,74.44,,,
"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB> <TAB> <TAB> res . extend ( keys ) <TAB> <TAB> for key in struct : <TAB> <TAB> <TAB> if key in IGNORED_KEYS : <TAB> <TAB> <TAB> <TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB> <TAB> for item in struct : <TAB> <TAB> <TAB> res . extend ( get_keys ( item ) ) <TAB> return res",if not ignore_first_level :,if not ignore_first_level :,True,100.0,74.61,,,
"def create_dir ( path ) : <TAB> curr_path = None <TAB> for p in path : <TAB> <TAB> if curr_path is None : <TAB> <TAB> <TAB> curr_path = os . path . abspath ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> curr_path = os . path . join ( curr_path , p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . mkdir ( curr_path )",if not os . path . isdir ( curr_path ) :,if not os . path . exists ( curr_path ) :,False,98.0,72.59,,,
"def dataToDumpFile ( dumpFile , data ) : <TAB> try : <TAB> <TAB> dumpFile . write ( data ) <TAB> <TAB> dumpFile . flush ( ) <TAB> except IOError as ex : <TAB> <TAB> if "" No space left "" in getUnicode ( ex ) : <TAB> <TAB> <TAB> errMsg = "" no space left on output device "" <TAB> <TAB> <TAB> logger . error ( errMsg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errMsg = "" permission denied when flushing dump data "" <TAB> <TAB> <TAB> logger . error ( errMsg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> errMsg = ( <TAB> <TAB> <TAB> <TAB> "" error occurred when writing dump data to file ( ' %s ' ) "" % getUnicode ( ex ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> logger . error ( errMsg )","elif ""Permission denied"" in getUnicode ( ex ) :","elif ""Permission denied"" in getUnicode ( ex ) :",True,100.0,74.57,,,
"def elements ( self , top ) : <TAB> res = [ ] <TAB> # try: <TAB> # <TAB> string = ""== %s (%s)"" % (self.name,self.__class__) <TAB> # except AttributeError: <TAB> # <TAB> string = ""== (%s)"" % (self.__class__,) <TAB> # print(string) <TAB> for part in self.parts: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res.append(name_or_ref(part, top)) <TAB> <TAB> else: <TAB> <TAB> <TAB> if isinstance(part, Extension): <TAB> <TAB> <TAB> <TAB> res.append(part.base) <TAB> <TAB> <TAB> res.extend(part.elements(top)) <TAB> return res","if isinstance ( part , NameOrRef ) :","if isinstance ( part , Element ) :",False,98.82,72.74,,,
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> if default . lower ( ) == "" true "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> if type ( default ) == float : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default )","elif default . lower ( ) == ""false"" :","elif default . lower ( ) == ""false"" :",True,100.0,74.66,,,
"def dvmethod ( c , dx , doAST = False ) : <TAB> for m in c . get_methods ( ) : <TAB> <TAB> mx = dx . get_method ( m ) <TAB> <TAB> ms = DvMethod ( mx ) <TAB> <TAB> ms . process ( doAST = doAST ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert ms . get_ast ( ) is not None <TAB> <TAB> <TAB> assert isinstance ( ms . get_ast ( ) , dict ) <TAB> <TAB> <TAB> assert "" body "" in ms . get_ast ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert ms . get_source ( ) is not None",if doAST :,if doAST :,True,100.0,74.46,,,
"def _repr_pretty_ ( self , p , cycle ) : <TAB> if cycle : <TAB> <TAB> return "" {{ ...} "" <TAB> with p . group ( 2 , "" { "" , "" } "" ) : <TAB> <TAB> p . breakable ( "" "" ) <TAB> <TAB> for idx , key in enumerate ( self . _items ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> p . text ( "" , "" ) <TAB> <TAB> <TAB> <TAB> p . breakable ( ) <TAB> <TAB> <TAB> value = self . _items [ key ] <TAB> <TAB> <TAB> p . pretty ( key ) <TAB> <TAB> <TAB> p . text ( "" :  "" ) <TAB> <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> <TAB> value = trimmed_repr ( value ) <TAB> <TAB> <TAB> p . pretty ( value ) <TAB> <TAB> p . breakable ( "" "" )",if idx :,if idx :,True,100.0,74.59,,,
"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB> <TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB> <TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB> <TAB> if "" ~#rating "" in song : <TAB> <TAB> <TAB> del song [ "" ~#rating "" ] <TAB> <TAB> <TAB> reset . append ( song ) <TAB> librarian . changed ( reset )",if dialog is None :,if dialog . run ( ) != Gtk . ResponseType . YES :,False,93.46,70.21,,,
"def get_or_create_place ( self , place_name ) : <TAB> "" Return the requested place object tuple-packed with a new indicator. "" <TAB> LOG . debug ( "" get_or_create_place: looking for:  %s "" , place_name ) <TAB> for place_handle in self . db . iter_place_handles ( ) : <TAB> <TAB> place = self . db . get_place_from_handle ( place_handle ) <TAB> <TAB> place_title = place_displayer . display ( self . db , place ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( 0 , place ) <TAB> place = Place ( ) <TAB> place . set_title ( place_name ) <TAB> place . name = PlaceName ( value = place_name ) <TAB> self . db . add_place ( place , self . trans ) <TAB> return ( 1 , place )",if place_title == place_name :,if place_title == place_name :,True,100.0,74.51,,,
def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if constraint_data . variables is None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> if constraint_data . body . polynomial_degree ( ) == 0 : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,"if isinstance ( constraint_data , LinearConstraint ) :","if isinstance ( constraint_data , LinearCanonicalRepn ) :",False,97.89,72.1,,,
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> if item < 0 : <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> if is_tuple : <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None",if i != idx :,if i < len ( data ) and i > - 1 :,False,95.51,71.1,,,
"def test_case_insensitivity ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB> <TAB> env . set ( "" PYTHONCASEOK "" , "" 1 "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB> <TAB> loader = self . find_module ( ) <TAB> <TAB> self . assertTrue ( hasattr ( loader , "" load_module "" ) )","if ""PYTHONCASEOK"" in env :","if b""PYTHONCASEOK"" not in _bootstrap . _os . environ :",False,89.59,68.63,,,
def field_spec ( self ) : <TAB> <IF-STMT> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . field_spec_ = FieldSpec ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . field_spec_,if self . field_spec_ is None :,if self . field_spec_ is None :,True,100.0,99.11,,,
"def reduce ( self , f , init ) : <TAB> for x in range ( self . _idx , rt . count ( self . _w_array ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return rt . deref ( init ) <TAB> <TAB> init = f . invoke ( [ init , rt . nth ( self . _w_array , rt . wrap ( x ) ) ] ) <TAB> return init",if rt . is_deref ( init ) :,if rt . reduced_QMARK_ ( init ) :,False,95.1,72.67,,,
"def _find ( event : E ) - > None : <TAB> # We first check values after the selected value, then all values. <TAB> values = list(self.values) <TAB> for value in values[self._selected_index + 1 :] + values: <TAB> <TAB> text = fragment_list_to_text(to_formatted_text(value[1])).lower() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._selected_index = self.values.index(value) <TAB> <TAB> <TAB> return",if text in self . values :,if text . startswith ( event . data . lower ( ) ) :,False,91.5,65.27,,,
"def check_permissions ( ) : <TAB> if platform_os ( ) != "" Windows "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( localization . lang_check_permissions [ "" permissions_granted "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( localization . lang_check_permissions [ "" permissions_denied "" ] ) <TAB> <TAB> <TAB> exit ( ) <TAB> else : <TAB> <TAB> print ( localization . lang_check_permissions [ "" windows_warning "" ] ) <TAB> <TAB> exit ( )","if localization . lang_check_permissions [ ""permissions_denied"" ] == ""true"" :",if getuid ( ) == 0 :,False,87.36,64.68,,,
"def _ProcessName ( self , name , dependencies ) : <TAB> """""" Retrieve a module name from a node name. """""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB> <TAB> if module_name : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] . add ( base_name ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] = { base_name } <TAB> <TAB> else : <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging.warning(""Empty package name: %s"", name)",if module_name in dependencies :,if module_name in dependencies :,True,100.0,74.58,,,
"def _load_db ( self ) : <TAB> try : <TAB> <TAB> with open ( self . db ) as db : <TAB> <TAB> <TAB> content = db . read ( 8 ) <TAB> <TAB> <TAB> db . seek ( 0 ) <TAB> <TAB> <TAB> if content == ( "" Salted__ "" ) : <TAB> <TAB> <TAB> <TAB> data = StringIO ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . encryptor . decrypt ( db , data ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json . loads ( data . getvalue ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return json . load ( db ) <TAB> except : <TAB> <TAB> return { "" creds "" : [ ] }",if self . encryptor :,if self . encryptor :,True,100.0,74.63,,,
"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB> <TAB> context_for_subcon = context <TAB> <TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB> <TAB> <TAB> context_for_subcon = context . __copy__ ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context_for_subcon ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> except ConstructError as ex : <TAB> <TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj",if subobj is None :,"if self . predicate ( subobj , context ) :",False,95.12,70.48,,,
"def is_active_for_user ( self , user ) : <TAB> is_active = super ( AbstractUserFlag , self ) . is_active_for_user ( user ) <TAB> if is_active : <TAB> <TAB> return is_active <TAB> user_ids = self . _get_user_ids ( ) <TAB> if hasattr ( user , "" pk "" ) and user . pk in user_ids : <TAB> <TAB> return True <TAB> if hasattr ( user , "" groups "" ) : <TAB> <TAB> group_ids = self . _get_group_ids ( ) <TAB> <TAB> if group_ids : <TAB> <TAB> <TAB> user_groups = set ( user . groups . all ( ) . values_list ( "" pk "" , flat = True ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return None",if user_groups and user . groups . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all ( ) . all,if group_ids . intersection ( user_groups ) :,False,68.58,62.23,,,
"def lookup_member ( self , member_name ) : <TAB> document_choices = self . choices or [ ] <TAB> for document_choice in document_choices : <TAB> <TAB> doc_and_subclasses = [ document_choice ] + document_choice . __subclasses__ ( ) <TAB> <TAB> for doc_type in doc_and_subclasses : <TAB> <TAB> <TAB> field = doc_type . _fields . get ( member_name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return field",if field :,if field :,True,100.0,74.1,,,
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> if not father_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if not mother_handle :,if not mother_handle :,True,100.0,74.42,,,
"def init_weights ( self ) : <TAB> for m in self . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Linear ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 ) <TAB> <TAB> if isinstance ( m , nn . Conv3d ) : <TAB> <TAB> <TAB> xavier_init ( m , distribution = "" uniform "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> constant_init ( m , 1 )","if isinstance ( m , nn . Linear ) :","if isinstance ( m , nn . BatchNorm3d ) :",False,97.96,72.78,,,
"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn <TAB> <TAB> elif step_num < 30000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 10 <TAB> <TAB> elif step_num < 35000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 100 <TAB> <TAB> else : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB> <TAB> fd [ model . lrn_rate ] = lrn_rate",if step_num < 20000 :,if step_num < hparams . lrn_step :,False,96.95,72.54,,,
"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB> <TAB> if is_push_data_token ( token ) : <TAB> <TAB> <TAB> yield DataToken ( read_data ( token , source ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Token ( token ) <TAB> <TAB> token = source . read_uint8 ( )",elif is_push_small_integer_token ( token ) :,elif is_small_integer ( token ) :,False,95.65,72.75,,,
"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB> <TAB> if is_push_data_token ( token ) : <TAB> <TAB> <TAB> yield DataToken ( read_data ( token , source ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Token ( token ) <TAB> <TAB> token = source . read_uint8 ( )",elif is_push_small_integer_token ( token ) :,"if restr == { ""essential"" : True } :",False,89.95,60.17,,,
"def _helpSlot ( self , * args ) : <TAB> help_text = "" Filters are applied to packets in both direction. \n \n "" <TAB> filter_nb = 0 <TAB> for filter in self . _filters : <TAB> <TAB> help_text + = "" {} :  {} "" . format ( filter [ "" name "" ] , filter [ "" description "" ] ) <TAB> <TAB> filter_nb + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> help_text + = "" \n \n "" <TAB> QtWidgets . QMessageBox . information ( self , "" Help for filters "" , help_text )",if filter_nb > 0 :,if len ( self . _filters ) != filter_nb :,False,92.3,70.16,,,
"def find_user_theme ( self , name : str ) - > Theme : <TAB> """""" Find a theme named as *name* from latex_theme_path. """""" <TAB> for theme_path in self . theme_paths : <TAB> <TAB> config_path = path . join ( theme_path , name , "" theme.conf "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return UserTheme ( name , config_path ) <TAB> <TAB> <TAB> except ThemeError as exc : <TAB> <TAB> <TAB> <TAB> logger . warning ( exc ) <TAB> return None",if path . exists ( config_path ) :,if path . isfile ( config_path ) :,False,98.47,98.05,,,
"def decompress ( self , value ) : <TAB> if value : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value . country_code and value . national_number : <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> "" + %d "" % value . country_code , <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number ( value ) , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ]",if self . is_valid_number ( value ) :,if type ( value ) == PhoneNumber :,False,93.97,71.13,,,
"def update_prevdoc_status ( self , flag ) : <TAB> for quotation in list ( set ( [ d . prevdoc_docname for d in self . get ( "" items "" ) ] ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> doc = frappe . get_doc ( "" Quotation "" , quotation ) <TAB> <TAB> <TAB> if doc . docstatus == 2 : <TAB> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Quotation  {0}  is cancelled "" ) . format ( quotation ) ) <TAB> <TAB> <TAB> doc . set_status ( update = True ) <TAB> <TAB> <TAB> doc . update_opportunity ( )",if flag :,if quotation :,False,98.42,73.25,,,
"def map ( item ) : <TAB> if item . deleted : <TAB> <TAB> return <TAB> exploration = exp_fetchers . get_exploration_from_model ( item ) <TAB> for state_name , state in exploration . states . items ( ) : <TAB> <TAB> hints_length = len ( state . interaction . hints ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exp_and_state_key = "" %s %s "" % ( item . id , state_name . encode ( "" utf-8 "" ) ) <TAB> <TAB> <TAB> yield ( python_utils . UNICODE ( hints_length ) , exp_and_state_key )",if hints_length > 0 :,if hints_length > 0 :,True,100.0,74.33,,,
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> if self . _args . host and self . _args . host == machine . name : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . locations and machine . location in self . locations : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines",elif self . _args . port and self . _args . port == machine . port :,"if self . tags and self . _tags_match ( machine . tags , self . tags ) :",False,89.34,66.9,,,
"def _ripple_trim_compositors_move ( self , delta ) : <TAB> comp_ids = self . multi_data . moved_compositors_destroy_ids <TAB> tracks_compositors = _get_tracks_compositors_list ( ) <TAB> track_moved = self . multi_data . track_affected <TAB> for i in range ( 1 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB> <TAB> if not track_moved [ i - 1 ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> track_comps = tracks_compositors [ i - 1 ] <TAB> <TAB> for comp in track_comps : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> comp . move ( delta )",if comp . id in comp_ids :,if comp . destroy_id in comp_ids :,False,98.12,73.17,,,
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> elif "" error "" in line : <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError","elif ""status"" in line and line [ ""status"" ] . strip ( ) :","elif ""status"" in line :",False,92.44,68.27,,,
"def create_keyfile ( self , keyfile , size = 64 , force = False ) : <TAB> if force or not os . path . exists ( keyfile ) : <TAB> <TAB> keypath = os . path . dirname ( keyfile ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( keypath ) <TAB> <TAB> subprocess . run ( <TAB> <TAB> <TAB> [ "" dd "" , "" if=/dev/random "" , f "" of= { keyfile } "" , f "" bs= { size } "" , "" count=1 "" ] , <TAB> <TAB> <TAB> check = True , <TAB> <TAB> <TAB> stdout = subprocess . DEVNULL , <TAB> <TAB> <TAB> stderr = subprocess . DEVNULL , <TAB> <TAB> )",if not os . path . exists ( keypath ) :,if not os . path . exists ( keypath ) :,True,100.0,74.51,,,
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res","elif self . op == ""*"" :","elif self . op == ""*"" :",True,100.0,74.66,,,
"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB> <TAB> if - delta < expr . get_float_value ( ) < delta : <TAB> <TAB> <TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB> <TAB> real , imag = expr . real , expr . imag <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> real = Integer ( 0 ) <TAB> <TAB> if - delta < imag . get_float_value ( ) < delta : <TAB> <TAB> <TAB> imag = Integer ( 0 ) <TAB> <TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB> <TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr",if - delta < real . get_float_value ( ) < delta :,if - delta < real . get_float_value ( ) < delta :,True,100.0,74.63,,,
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> if file_sources is None : <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources",if file_sources_as_dict :,if file_sources_as_dict is not None :,False,98.17,72.35,,,
"def _get_sort_map ( tags ) : <TAB> """""" See TAG_TO_SORT """""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if tag . user : <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> if tag . internal : <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts","if tag . sort_type == ""user"" :",if tag . has_sort :,False,94.04,72.42,,,
"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB> <TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <TAB> <TAB> if not name in self.option_values: <TAB> <TAB> <TAB> self.option_values[name] = default",if key not in self . options :,if not key in self . options :,False,98.6,73.37,,,
"def modify_bottle_params ( self , output_stride = None ) : <TAB> if output_stride is not None and output_stride % 2 != 0 : <TAB> <TAB> raise Exception ( "" output stride must to be even number "" ) <TAB> if output_stride is None : <TAB> <TAB> return <TAB> else : <TAB> <TAB> stride = 2 <TAB> <TAB> for i , _cfg in enumerate ( self . cfg ) : <TAB> <TAB> <TAB> stride = stride * _cfg [ - 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB> <TAB> self . cfg [ i ] [ - 1 ] = s",if _cfg [ - 1 ] == output_stride :,if stride > output_stride :,False,94.82,72.1,,,
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret","elif isinstance ( value , list ) :",elif is_iterable ( value ) :,False,97.84,73.15,,,
"def make_shares ( self , plaintext ) : <TAB> share_arrays = [ ] <TAB> for i , p in enumerate ( plaintext ) : <TAB> <TAB> share_array = self . make_byte_shares ( p ) <TAB> <TAB> for sa in share_array : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> share_arrays . append ( array . array ( "" H "" ) ) <TAB> <TAB> <TAB> current_share_array = sa <TAB> <TAB> <TAB> current_share_array . append ( sa ) <TAB> return share_arrays",if i % 2 :,if i == 0 :,False,96.94,72.18,,,
"def make_shares ( self , plaintext ) : <TAB> share_arrays = [ ] <TAB> for i , p in enumerate ( plaintext ) : <TAB> <TAB> share_array = self . make_byte_shares ( p ) <TAB> <TAB> for sa in share_array : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> share_arrays . append ( array . array ( "" H "" ) ) <TAB> <TAB> <TAB> current_share_array = sa <TAB> <TAB> <TAB> current_share_array . append ( sa ) <TAB> return share_arrays",if i % 2 :,"if name [ : 2 ] == ""__"" and name [ - 2 : ] == ""__"" :",False,84.39,59.67,,,
"def __repr__ ( self ) : <TAB> try : <TAB> <TAB> if self . _semlock . _is_mine ( ) : <TAB> <TAB> <TAB> name = current_process ( ) . name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> name + = "" | "" + threading . current_thread ( ) . name <TAB> <TAB> elif self . _semlock . _get_value ( ) == 1 : <TAB> <TAB> <TAB> name = "" None "" <TAB> <TAB> elif self . _semlock . _count ( ) > 0 : <TAB> <TAB> <TAB> name = "" SomeOtherThread "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = "" SomeOtherProcess "" <TAB> except Exception : <TAB> <TAB> name = "" unknown "" <TAB> return "" <Lock(owner= %s )> "" % name",elif self . _semlock . _is_thread ( ) :,"if threading . current_thread ( ) . name != ""MainThread"" :",False,94.08,67.09,,,
"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB> <TAB> elif scroll_if_editing : <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets )",if self . _my_widgets :,if not self . editing :,False,95.37,71.58,,,
"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB> <TAB> if dep . repo is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep . repo . repos : <TAB> <TAB> <TAB> if repo . from_config : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) )",if dep . repo . is_dir :,"if not isinstance ( dep . repo , WarehouseBaseRepo ) :",False,94.51,70.4,,,
"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB> <TAB> if dep . repo is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep . repo . repos : <TAB> <TAB> <TAB> if repo . from_config : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) )",if dep . repo . is_dir :,"if name [ : 1 ] == ""_"" :",False,93.19,62.39,,,
"def out ( parent , attr , indent = 0 ) : <TAB> val = getattr ( parent , attr ) <TAB> prefix = "" %s %s : "" % ( "" "" * indent , attr . replace ( "" _ "" , "" - "" ) ) <TAB> if val is None : <TAB> <TAB> cli . out ( prefix ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = [ flag_util . encode_flag_val ( c . value ) for c in val ] <TAB> <TAB> cli . out ( "" %s %s "" % ( prefix , flag_util . encode_flag_val ( val ) ) )","if isinstance ( val , ( list , tuple ) ) :","if attr == ""choices"" :",False,92.87,67.17,,,
"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB> <TAB> x = cand . creator <TAB> <TAB> if x is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB> <TAB> fan_out[x] += 1",if x . rank != fan_out [ x ] :,if x not in fan_out :,False,93.0,68.82,,,
"def task_tree_lines ( task = None ) : <TAB> if task is None : <TAB> <TAB> task = current_root_task ( ) <TAB> rendered_children = [ ] <TAB> nurseries = list ( task . child_nurseries ) <TAB> while nurseries : <TAB> <TAB> nursery = nurseries . pop ( ) <TAB> <TAB> nursery_children = _rendered_nursery_children ( nursery ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nested = _render_subtree ( "" (nested nursery) "" , rendered_children ) <TAB> <TAB> <TAB> nursery_children . append ( nested ) <TAB> <TAB> rendered_children = nursery_children <TAB> return _render_subtree ( task . name , rendered_children )",if nursery_children :,if rendered_children :,False,98.59,73.1,,,
"def lock_workspace ( build_dir ) : <TAB> _BUILDING_LOCK_FILE = "" .blade.building.lock "" <TAB> lock_file_fd , ret_code = lock_file ( os . path . join ( build_dir , _BUILDING_LOCK_FILE ) ) <TAB> if lock_file_fd == - 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> console . fatal ( "" There is already an active building in current workspace. "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> console . fatal ( "" Lock exception, please try it later. "" ) <TAB> return lock_file_fd",if ret_code == 1 :,if ret_code == errno . EAGAIN :,False,97.16,71.77,,,
"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB> <TAB> self . assertIn ( "" bbox "" , feature ) <TAB> <TAB> fid = feature [ "" id "" ] <TAB> <TAB> if fid == 1 : <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( )",elif fid == 2 :,elif fid == 2 :,True,100.0,74.64,,,
"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <TAB> <TAB> if normalize: <TAB> <TAB> <TAB> V = normalize_rays(V, lattice) <TAB> <TAB> if check: <TAB> <TAB> <TAB> R = PointCollection(V, lattice) <TAB> <TAB> <TAB> V = PointCollection(V, lattice) <TAB> <TAB> <TAB> d = lattice.dimension() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> ""virtual rays must be linearly "" <TAB> <TAB> <TAB> <TAB> <TAB> ""independent and with other rays span the ambient space."" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if d > 1 :,if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d :,False,89.07,64.77,,,
"def search_host ( self , search_string ) : <TAB> results = [ ] <TAB> for host_entry in self . config_data : <TAB> <TAB> if host_entry . get ( "" type "" ) != "" entry "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if host_entry . get ( "" host "" ) == "" * "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> searchable_information = host_entry . get ( "" host "" ) <TAB> <TAB> for key , value in six . iteritems ( host_entry . get ( "" options "" ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = "" "" . join ( value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> value = str ( value ) <TAB> <TAB> <TAB> searchable_information + = "" "" + value <TAB> <TAB> if search_string in searchable_information : <TAB> <TAB> <TAB> results . append ( host_entry ) <TAB> return results","if isinstance ( value , list ) :","if isinstance ( value , list ) :",True,100.0,74.63,,,
"def test_async_iterator ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB> <TAB> for i in range ( 100 ) : <TAB> <TAB> <TAB> await stream . channel . deliver ( message ( key = i , value = i ) ) <TAB> <TAB> received = 0 <TAB> <TAB> async for value in stream : <TAB> <TAB> <TAB> assert value == received <TAB> <TAB> <TAB> received + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty ( stream . channel )",if received >= 100 :,if received >= 100 :,True,100.0,74.39,,,
"def has_google_credentials ( ) : <TAB> global _HAS_GOOGLE_CREDENTIALS <TAB> if _HAS_GOOGLE_CREDENTIALS is None : <TAB> <TAB> provider = Provider ( "" google "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = False <TAB> <TAB> else : <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = True <TAB> return _HAS_GOOGLE_CREDENTIALS",if provider . is_available ( ) :,if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None :,False,82.66,62.22,,,
"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB> <TAB> a = self . _d . getTime ( ) <TAB> <TAB> b = other . _d . getTime ( ) <TAB> <TAB> if a < b : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 0 <TAB> else : <TAB> <TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1",elif a > b :,elif a == b :,False,97.37,72.94,,,
"def validate_weight ( self , weight ) : <TAB> try : <TAB> <TAB> add_acl_to_obj ( self . context [ "" user_acl "" ] , self . category ) <TAB> except AttributeError : <TAB> <TAB> return weight # don't validate weight further if category failed <TAB> if weight > self.category.acl.get(""can_pin_threads"", 0): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _( <TAB> <TAB> <TAB> <TAB> <TAB> ""You don't have permission to pin threads globally "" <TAB> <TAB> <TAB> <TAB> <TAB> ""in this category."" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""You don't have permission to pin threads in this category."") <TAB> <TAB> <TAB> ) <TAB> return weight","if self . category . acl . get ( ""can_pin_threads"" , True ) :",if weight == 2 :,False,92.87,66.77,,,
"def effective ( line ) : <TAB> for b in line : <TAB> <TAB> if not b . cond : <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> val = 5 <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if b . ignore : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> b . ignore - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return ( b , True ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> return ( b , False ) <TAB> return",if val < 0 :,if val :,False,98.28,73.25,,,
"def wheelEvent ( self , event ) : <TAB> """""" Handle a wheel event. """""" <TAB> if QtCore . Qt . ControlModifier & event . modifiers ( ) : <TAB> <TAB> d = { "" c "" : self . leo_c } <TAB> <TAB> if isQt5 : <TAB> <TAB> <TAB> point = event . angleDelta ( ) <TAB> <TAB> <TAB> delta = point . y ( ) or point . x ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> delta = event . delta ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> zoom_out ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> zoom_in ( d ) <TAB> <TAB> event . accept ( ) <TAB> <TAB> return <TAB> QtWidgets . QTextBrowser . wheelEvent ( self , event )",if delta > 0 :,if delta < 0 :,False,98.78,98.58,,,
"def test_evname_in_mp_events_testcases ( ) : <TAB> ok = True <TAB> for evname in ins . mp_events : <TAB> <TAB> if evname == "" version "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> for i , args in enumerate ( ins . mp_events [ evname ] [ "" test_cases "" ] ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> msg = "" Error, for evname  %s  the testase # %d  does not match evname "" <TAB> <TAB> <TAB> <TAB> print ( msg % ( evname , i ) ) <TAB> <TAB> <TAB> <TAB> ok = False <TAB> if ok : <TAB> <TAB> print ( "" test_evname_in_mp_events_testcases: passed "" )",if args [ 0 ] != evname :,if evname != args [ 0 ] :,False,97.49,72.52,,,
"def check_database ( ) : <TAB> if len ( EmailAddress . objects . all ( ) ) > 0 : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" Are you sure you want to wipe the existing development database and reseed it? (Y/N) "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> destroy_database ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return True",if EmailAddress . objects . filter ( seed = True ) . exists ( ) :,"if raw_input ( ) . lower ( ) == ""y"" :",False,90.05,60.83,,,
"def _get_requested_databases ( self ) : <TAB> """""" Returns a list of databases requested, not including ignored dbs """""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB> <TAB> for requested_namespace in self . _requested_namespaces : <TAB> <TAB> <TAB> if requested_namespace [ 0 ] is "" * "" : <TAB> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases",if requested_namespace [ 0 ] not in self . _ignored_databases :,elif requested_namespace [ 0 ] not in IGNORE_DBS :,False,94.52,94.78,,,
"def decorated ( self , * args , * * kwargs ) : <TAB> start_time = time . perf_counter ( ) <TAB> stderr = "" "" <TAB> saved_exception = None <TAB> try : <TAB> <TAB> yield from fn ( self , * args , * * kwargs ) <TAB> except GitSavvyError as e : <TAB> <TAB> stderr = e . stderr <TAB> <TAB> saved_exception = e <TAB> finally : <TAB> <TAB> end_time = time . perf_counter ( ) <TAB> <TAB> util . debug . log_git ( args , None , "" <SNIP> "" , stderr , end_time - start_time ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise saved_exception from None",if saved_exception :,if saved_exception :,True,100.0,74.45,,,
"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """""" Check the warning is suppressed or not. """""" <TAB> if type is None : <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings : <TAB> <TAB> if "" . "" in warning_type : <TAB> <TAB> <TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target , subtarget = warning_type , None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == "" * "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if target == type :,if target == type :,True,100.0,99.6,,,
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> if j == - 1 : <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return r",if len ( r ) == 1 :,"if reply == ""!done"" :",False,96.92,67.11,,,
"def encrypt ( self , plaintext ) : <TAB> encrypted = [ ] <TAB> for p in _string_to_bytes ( plaintext ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _remaining_block = self . _aes . encrypt ( self . _last_precipherblock ) <TAB> <TAB> <TAB> self . _last_precipherblock = [ ] <TAB> <TAB> precipherbyte = self . _remaining_block . pop ( 0 ) <TAB> <TAB> self . _last_precipherblock . append ( precipherbyte ) <TAB> <TAB> cipherbyte = p ^ precipherbyte <TAB> <TAB> encrypted . append ( cipherbyte ) <TAB> return _bytes_to_string ( encrypted )",if self . _last_precipherblock :,if len ( self . _remaining_block ) == 0 :,False,93.01,70.14,,,
"def find_symbol ( self , r , globally = False ) : <TAB> query = self . view . substr ( self . view . word ( r ) ) <TAB> fname = self . view . file_name ( ) . replace ( "" \\ "" , "" / "" ) <TAB> locations = self . view . window ( ) . lookup_symbol_in_index ( query ) <TAB> if not locations : <TAB> <TAB> return <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> location = [ hit [ 2 ] for hit in locations if fname . endswith ( hit [ 1 ] ) ] [ 0 ] <TAB> <TAB> <TAB> return location [ 0 ] - 1 , location [ 1 ] - 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> # TODO: There might be many symbols with the same name. <TAB> <TAB> <TAB> return locations[0] <TAB> except IndexError: <TAB> <TAB> return",if globally :,if not globally :,False,98.88,73.71,,,
"def __getslice__ ( self , i , j ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # handle the case where the right bound is unspecified <TAB> <TAB> <TAB> j = len(self) <TAB> <TAB> if i < 0 or j < 0: <TAB> <TAB> <TAB> raise dns.exception.FormError <TAB> <TAB> # If it's not an empty slice, access left and right bounds <TAB> <TAB> # to make sure they're valid <TAB> <TAB> if i != j: <TAB> <TAB> <TAB> super(WireData, self).__getitem__(i) <TAB> <TAB> <TAB> super(WireData, self).__getitem__(j - 1) <TAB> <TAB> return WireData(super(WireData, self).__getslice__(i, j)) <TAB> except IndexError: <TAB> <TAB> raise dns.exception.FormError",if j == - 1 :,if j == sys . maxint :,False,98.07,72.42,,,
"def main ( ) : <TAB> r = redis . StrictRedis ( ) <TAB> curr_memory = prev_memory = r . info ( ) [ "" used_memory "" ] <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Delta Memory :  %d , Total Memory :  %d "" <TAB> <TAB> <TAB> <TAB> % ( ( curr_memory - prev_memory ) , curr_memory ) <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> prev_memory = curr_memory <TAB> <TAB> curr_memory = r . info ( ) [ "" used_memory "" ]",if curr_memory > prev_memory :,if prev_memory != curr_memory :,False,97.06,72.43,,,
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> if self . _flags [ fname ] == 1 : <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if output == input : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if fname not in self . _flags :,if fname not in self . _flags :,True,100.0,74.64,,,
"def urls ( self , version = None ) : <TAB> """""" Returns all URLS that are mapped to this interface """""" <TAB> urls = [ ] <TAB> for _base_url , routes in self . api . http . routes . items ( ) : <TAB> <TAB> for url , methods in routes . items ( ) : <TAB> <TAB> <TAB> for _method , versions in methods . items ( ) : <TAB> <TAB> <TAB> <TAB> for interface_version , interface in versions . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not url in urls : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> urls . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ( "" /v {0} "" . format ( version ) if version else "" "" ) + url <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return urls",if interface_version == _base_url :,if interface_version == version and interface == self :,False,97.21,96.12,,,
"def _handle_data ( self , text ) : <TAB> if self . _translate : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _data . append ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _translate = False <TAB> <TAB> <TAB> self . _data = [ ] <TAB> <TAB> <TAB> self . _comments = [ ]",if self . _translate_text :,"if not text . startswith ( ""gtk-"" ) :",False,90.75,59.28,,,
"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB> <TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB> <TAB> if not self . dry_run : <TAB> <TAB> <TAB> os . chmod ( dirpath , mode )",if not self . _is_dir_supported ( dirpath ) :,if os . path . islink ( dirpath ) :,False,92.53,70.95,,,
"def language ( self ) : <TAB> if self . lang_data : <TAB> <TAB> lang_data = [ s if s != "" None "" else None for s in self . lang_data ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return Language ( lang_data [ 0 ] , country = lang_data [ 1 ] , script = lang_data [ 2 ] )",if lang_data :,if lang_data [ 0 ] :,False,95.27,70.76,,,
"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB> <TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB> <TAB> for col in range(0, nCol, 2): <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if col + 2 == nCol: <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)",if col == nCol :,"if not self . layout . itemAt ( row , col ) :",False,94.54,69.75,,,
"def align_comments ( tlist ) : <TAB> tidx , token = tlist . token_next_by ( i = sql . Comment ) <TAB> while token : <TAB> <TAB> pidx , prev_ = tlist . token_prev ( tidx ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tlist . group_tokens ( sql . TokenList , pidx , tidx , extend = True ) <TAB> <TAB> <TAB> tidx = pidx <TAB> <TAB> tidx , token = tlist . token_next_by ( i = sql . Comment , idx = tidx )",if prev_ is sql . Comment :,"if isinstance ( prev_ , sql . TokenList ) :",False,93.37,69.79,,,
"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB> <TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB> <TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB> <TAB> if params [ "" Attributes "" ] != 0 : <TAB> <TAB> <TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB> <TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params [ "" Data "" ] != 0 : <TAB> <TAB> <TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND",if read_len > 0 :,if read_len < len ( var ) :,False,97.11,72.46,,,
"def _PromptMySQL ( self , config ) : <TAB> """""" Prompts the MySQL configuration, retrying if the configuration is invalid. """""" <TAB> while True : <TAB> <TAB> self . _PromptMySQLOnce ( config ) <TAB> <TAB> if self . _CheckMySQLConnection ( ) : <TAB> <TAB> <TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ConfigInitError ( )",if retry :,if not retry :,False,98.63,97.48,,,
"def split_long_line_with_indent ( line , max_per_line , indent ) : <TAB> """""" Split the `line` so that it doesn ' t go over `max_per_line` and adds `indent` to new lines. """""" <TAB> words = line . split ( "" "" ) <TAB> lines = [ ] <TAB> current_line = words [ 0 ] <TAB> for word in words [ 1 : ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lines . append ( current_line ) <TAB> <TAB> <TAB> current_line = "" "" * indent + word <TAB> <TAB> else : <TAB> <TAB> <TAB> current_line = f "" { current_line } { word } "" <TAB> lines . append ( current_line ) <TAB> return "" \n "" . join ( lines )",if max_per_line and len ( word ) > max_per_line :,"if len ( f""{current_line} {word}"" ) > max_per_line :",False,94.2,72.48,,,
"def gen_cli ( docs_dir ) : <TAB> with open ( os . path . join ( docs_dir , "" CLI_template.md "" ) , "" r "" ) as cli_temp_file : <TAB> <TAB> temp_lines = cli_temp_file . readlines ( ) <TAB> lines = [ ] <TAB> for line in temp_lines : <TAB> <TAB> matched = re . match ( r "" { onnx-tf.*} "" , line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> command = matched . string . strip ( ) [ 1 : - 1 ] <TAB> <TAB> <TAB> output = subprocess . check_output ( command . split ( "" "" ) ) . decode ( "" UTF-8 "" ) <TAB> <TAB> <TAB> lines . append ( output ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lines . append ( line ) <TAB> with open ( os . path . join ( docs_dir , "" CLI.md "" ) , "" w "" ) as cli_file : <TAB> <TAB> cli_file . writelines ( lines )",if matched :,if matched :,True,100.0,74.61,,,
"def read ( self , size = None ) : <TAB> if size == 0 : <TAB> <TAB> return "" "" <TAB> data = list ( ) <TAB> while size is None or size > 0 : <TAB> <TAB> line = self . readline ( size or - 1 ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size - = len ( line ) <TAB> <TAB> data . append ( line ) <TAB> return "" "" . join ( data )",if size is not None and len ( line ) > size :,if size is not None :,False,93.98,71.91,,,
"def _get_format_and_pattern ( file_path ) : <TAB> file_path = Path ( file_path ) <TAB> with file_path . open ( ) as f : <TAB> <TAB> first_line = f . readline ( ) . strip ( ) <TAB> <TAB> match = re . match ( r "" format *: *(.+) "" , first_line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" gztar "" , first_line , 1 <TAB> <TAB> return match . group ( 1 ) , f . readline ( ) . strip ( ) , 2",if match is None :,if match is None :,True,100.0,74.32,,,
"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if os . path . isfile ( file ) : <TAB> <TAB> <TAB> <TAB> os . unlink ( file ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( file ) <TAB> <TAB> except Exception as error : <TAB> <TAB> <TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB> <TAB> <TAB> sys . exit ( 1 )",elif os . path . isdir ( file ) :,elif os . path . isdir ( file ) :,True,100.0,74.5,,,
"def _test_forever ( self , tests ) : <TAB> while True : <TAB> <TAB> for test_name in tests : <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB> if self . bad : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return",if self . bad_forever :,if self . ns . fail_env_changed and self . environment_changed :,False,86.42,66.3,,,
"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB> <TAB> if line . startswith ( "" #include "" ) or line . startswith ( "" %i nclude "" ) : <TAB> <TAB> <TAB> line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ]","if line . startswith ( ""#dependency"" ) :","if not ( ""<"" in line or line in dep ) :",False,92.83,62.14,,,
"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB> <TAB> with db_transaction ( ) : <TAB> <TAB> <TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> key . name = name <TAB> <TAB> <TAB> if metadata is not None : <TAB> <TAB> <TAB> <TAB> key . metadata . update ( metadata ) <TAB> <TAB> <TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB> <TAB> raise ServiceKeyDoesNotExist",if name is not None :,if name is not None :,True,100.0,74.44,,,
"def range ( self , dimension , data_range = True , dimension_range = True ) : <TAB> if self . nodes and dimension in self . nodes . dimensions ( ) : <TAB> <TAB> node_range = self . nodes . range ( dimension , data_range , dimension_range ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path_range = self . _edgepaths . range ( dimension , data_range , dimension_range ) <TAB> <TAB> <TAB> return max_range ( [ node_range , path_range ] ) <TAB> <TAB> return node_range <TAB> return super ( Graph , self ) . range ( dimension , data_range , dimension_range )",if self . _edgepaths :,if self . _edgepaths :,True,100.0,74.41,,,
"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB> <TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB> <TAB> if verbose == True : <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> return <TAB> while True : <TAB> <TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB> <TAB> if sock in r : <TAB> <TAB> <TAB> data = sock . recv ( 1024 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan . send ( data ) <TAB> <TAB> if chan in r : <TAB> <TAB> <TAB> data = chan . recv ( 1024 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( )",if not data :,if len ( data ) == 0 :,False,93.96,70.69,,,
"def output_layer ( self , features , * * kwargs ) : <TAB> """""" Project features to the vocabulary size. """""" <TAB> if self . adaptive_softmax is None : <TAB> <TAB> # project back to size of vocabulary <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return F.linear(features, self.embed_tokens.weight) <TAB> <TAB> else: <TAB> <TAB> <TAB> return F.linear(features, self.embed_out) <TAB> else: <TAB> <TAB> return features",if self . embed_tokens is not None :,if self . share_input_output_embed :,False,94.17,96.15,,,
"def generate ( self , dest , vars ) : <TAB> util . ensure_dir ( dest ) <TAB> for relpath , src , template in self . _file_templates : <TAB> <TAB> file_dest = os . path . join ( dest , relpath ) <TAB> <TAB> util . ensure_dir ( os . path . dirname ( file_dest ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutil . copyfile ( src , file_dest ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _render_template ( template , vars , file_dest )",if os . path . isfile ( src ) :,if template is None :,False,93.42,70.21,,,
"def _py_matching_callback ( self , context , result , sender , device ) : <TAB> d = HIDDevice . get_device ( c_void_p ( device ) ) <TAB> if d not in self . devices : <TAB> <TAB> self . devices . add ( d ) <TAB> <TAB> for x in self . matching_observers : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> x . device_discovered ( d )",if x . device_discovered ( d ) :,"if hasattr ( x , ""device_discovered"" ) :",False,92.78,61.85,,,
"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB> <TAB> new_kwargs = dict ( kwargs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del new_kwargs [ "" encoding "" ] <TAB> <TAB> if "" errors "" in kwargs : <TAB> <TAB> <TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs )","if ""encoding"" in kwargs :","if ""encoding"" in new_kwargs :",False,97.09,72.62,,,
"def Set ( self , attr , value ) : <TAB> hook = getattr ( self , "" _set_ %s "" % attr , None ) <TAB> if hook : <TAB> <TAB> # If there is a set hook we must use the context manager. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Can only update attribute %s using the context manager."" % attr <TAB> <TAB> <TAB> ) <TAB> <TAB> if attr not in self._pending_hooks: <TAB> <TAB> <TAB> self._pending_hooks.append(attr) <TAB> <TAB> self._pending_parameters[attr] = value <TAB> else: <TAB> <TAB> super(Configuration, self).Set(attr, value)","if not getattr ( self , ""_context_manager"" , None ) :",if self . _lock > 0 :,False,92.66,63.62,,,
"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB> <TAB> name = f . get_basename ( ) <TAB> <TAB> if name . endswith ( "" .mod "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = name [ 0 : - 11 ] <TAB> <TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 )","if name . endswith ( "".model"" ) :","if name . endswith ( "".sccprofile"" ) :",False,98.44,73.27,,,
"def get_eval_task ( self , worker_id ) : <TAB> """""" Return next evaluation (task_id, Task) tuple """""" <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - 1 , None <TAB> <TAB> self . _task_id + = 1 <TAB> <TAB> task = self . _eval_todo . pop ( ) <TAB> <TAB> self . _doing [ self . _task_id ] = ( worker_id , task , time . time ( ) ) <TAB> <TAB> return self . _task_id , task",if self . _eval_todo is None :,if not self . _eval_todo :,False,96.68,88.61,,,
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not cmd . stdout . strip ( ) : <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )",if cmd . check ( ) :,"if not cmd . check ( f""docker check for {self.path.k8s}"" ) :",False,93.05,68.99,,,
"def disjoined ( data ) : <TAB> # create marginalized distributions and multiple them together <TAB> data_disjoined = None <TAB> dim = len(data.shape) <TAB> for d in range(dim): <TAB> <TAB> axes = list(range(dim)) <TAB> <TAB> axes.remove(d) <TAB> <TAB> data1d = multisum(data, axes) <TAB> <TAB> shape = [1 for k in range(dim)] <TAB> <TAB> shape[d] = len(data1d) <TAB> <TAB> data1d = data1d.reshape(tuple(shape)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data_disjoined = data1d <TAB> <TAB> else: <TAB> <TAB> <TAB> data_disjoined = data_disjoined * data1d <TAB> return data_disjoined",if data_disjoined is None :,if d == 0 :,False,96.69,71.78,,,
"def safe_repr ( val ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # We special case dicts to have a sorted repr. This makes testing <TAB> <TAB> <TAB> # significantly easier <TAB> <TAB> <TAB> val = _obj_with_safe_repr(val) <TAB> <TAB> ret = repr(val) <TAB> <TAB> if six.PY2: <TAB> <TAB> <TAB> ret = ret.decode(""utf-8"") <TAB> except UnicodeEncodeError: <TAB> <TAB> ret = red(""a %r that cannot be represented"" % type(val)) <TAB> else: <TAB> <TAB> ret = green(ret) <TAB> return ret","if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",True,100.0,74.27,,,
"def wrapper ( * args , * * kwargs ) : <TAB> resp = view_func ( * args , * * kwargs ) <TAB> if isinstance ( resp , dict ) : <TAB> <TAB> ctx_params = request . environ . get ( "" webrec.template_params "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resp . update ( ctx_params ) <TAB> <TAB> template = self . jinja_env . jinja_env . get_or_select_template ( template_name ) <TAB> <TAB> return template . render ( * * resp ) <TAB> else : <TAB> <TAB> return resp",if ctx_params :,if ctx_params :,True,100.0,74.31,,,
"def post ( self , request , * args , * * kwargs ) : <TAB> contact_id = kwargs . get ( "" pk "" ) <TAB> self . object = get_object_or_404 ( Contact , id = contact_id ) <TAB> if ( <TAB> <TAB> self . request . user . role != "" ADMIN "" <TAB> <TAB> and not self . request . user . is_superuser <TAB> <TAB> and self . request . user != self . object . created_by <TAB> ) or self . object . company != self . request . company : <TAB> <TAB> raise PermissionDenied <TAB> else : <TAB> <TAB> if self . object . address_id : <TAB> <TAB> <TAB> self . object . address . delete ( ) <TAB> <TAB> self . object . delete ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return JsonResponse ( { "" error "" : False } ) <TAB> <TAB> return redirect ( "" contacts:list "" )",if self . object . delete_success :,if self . request . is_ajax ( ) :,False,96.68,72.77,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if ""<"" in text :","if ""<"" in text :",True,100.0,74.67,,,
"def everythingIsUnicode ( d ) : <TAB> """""" Takes a dictionary, recursively verifies that every value is unicode """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True",if not everythingIsUnicode ( v ) :,if not everythingIsUnicode ( v ) :,True,100.0,74.59,,,
"def fill ( self ) : <TAB> try : <TAB> <TAB> while ( <TAB> <TAB> <TAB> not self . stopping . wait ( self . sample_wait ) <TAB> <TAB> <TAB> and len ( self . queue ) < self . queue . maxlen <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . queue . append ( self . parent . _read ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . parent . _fire_events ( ) <TAB> <TAB> self . full . set ( ) <TAB> <TAB> while not self . stopping . wait ( self . sample_wait ) : <TAB> <TAB> <TAB> self . queue . append ( self . parent . _read ( ) ) <TAB> <TAB> <TAB> if isinstance ( self . parent , EventsMixin ) : <TAB> <TAB> <TAB> <TAB> self . parent . _fire_events ( ) <TAB> except ReferenceError : <TAB> <TAB> # Parent is dead; time to die! <TAB> <TAB> pass","if isinstance ( self . parent , EventsMixin ) :","if self . partial and isinstance ( self . parent , EventsMixin ) :",False,97.92,72.96,,,
"def _SetListviewTextItems ( self , items ) : <TAB> self . listview . DeleteAllItems ( ) <TAB> index = - 1 <TAB> for item in items : <TAB> <TAB> index = self . listview . InsertItem ( index + 1 , item [ 0 ] ) <TAB> <TAB> data = item [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = "" "" <TAB> <TAB> self . listview . SetItemText ( index , 1 , data )","if data == """" :",if data is None :,False,95.05,63.29,,,
"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB> <TAB> request . uri = request . uri . replace ( old , new ) <TAB> <TAB> if is_text_payload ( request ) and request . body : <TAB> <TAB> <TAB> body = six . ensure_str ( request . body ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> request . body = body . replace ( old , new ) <TAB> return request",if body :,if old in body :,False,97.23,72.06,,,
"def serialize ( cls , value , * args , * * kwargs ) : <TAB> if value is None : <TAB> <TAB> return "" "" <TAB> value_as_string = six . text_type ( value ) <TAB> if SHOULD_NOT_USE_LOCALE : <TAB> <TAB> return value_as_string <TAB> else : <TAB> <TAB> grouping = kwargs . get ( "" grouping "" , None ) <TAB> <TAB> has_decimal_places = value_as_string . find ( "" . "" ) != - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> string_format = "" %d "" <TAB> <TAB> else : <TAB> <TAB> <TAB> decimal_places = len ( value_as_string . split ( "" . "" ) [ 1 ] ) <TAB> <TAB> <TAB> string_format = "" % . {} f "" . format ( decimal_places ) <TAB> <TAB> return locale . format ( string_format , value , grouping = grouping )",if has_decimal_places :,if not has_decimal_places :,False,98.96,73.57,,,
"def review_link ( request , path_obj ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if check_permission ( "" translate "" , request ) : <TAB> <TAB> <TAB> <TAB> text = _ ( "" Review Suggestions "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> text = _ ( "" View Suggestions "" ) <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> "" href "" : dispatch . translate ( <TAB> <TAB> <TAB> <TAB> <TAB> request , path_obj . pootle_path , matchnames = [ "" hassuggestion "" ] <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> "" text "" : text , <TAB> <TAB> <TAB> } <TAB> except IOError : <TAB> <TAB> pass",if path_obj . pootle_path :,if path_obj . has_suggestions ( ) :,False,97.21,72.72,,,
"def _migrate_key ( self , key ) : <TAB> """""" migrate key from old .dat file """""" <TAB> key_path = os . path . join ( self . home_path , "" keys.dat "" ) <TAB> if os . path . exists ( key_path ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> key_data = json . loads ( open ( key_path , "" rb "" ) . read ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . add_key ( key , key_data . get ( key ) ) <TAB> <TAB> except : <TAB> <TAB> <TAB> self . error ( f "" Corrupt key file. Manual migration of  ' { key } '  required. "" )",if key_data . get ( key ) :,if key_data . get ( key ) :,True,100.0,99.48,,,
"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB> <TAB> backref = callback . backref <TAB> <TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB> <TAB> if root_objs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> root_objs = [ root_objs ] <TAB> <TAB> <TAB> with session . no_autoflush : <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs : <TAB> <TAB> <TAB> <TAB> <TAB> if root_obj : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self . get_callback_args ( root_obj , callback ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args","if not isinstance ( root_objs , list ) :","if not isinstance ( root_objs , Iterable ) :",False,99.01,73.6,,,
"def GetDefFile ( self , gyp_to_build_path ) : <TAB> """""" Returns the .def file from sources, if any. Otherwise returns None. """""" <TAB> spec = self . spec <TAB> if spec [ "" type "" ] in ( "" shared_library "" , "" loadable_module "" , "" executable "" ) : <TAB> <TAB> def_files = [ s for s in spec . get ( "" sources "" , [ ] ) if s . endswith ( "" .def "" ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return gyp_to_build_path ( def_files [ 0 ] ) <TAB> <TAB> elif len ( def_files ) > 1 : <TAB> <TAB> <TAB> raise Exception ( "" Multiple .def files "" ) <TAB> return None",if len ( def_files ) == 1 :,if len ( def_files ) == 1 :,True,100.0,99.51,,,
"def _validate_gallery ( images ) : <TAB> for image in images : <TAB> <TAB> image_path = image . get ( "" image_path "" , "" "" ) <TAB> <TAB> if image_path : <TAB> <TAB> <TAB> if not isfile ( image_path ) : <TAB> <TAB> <TAB> <TAB> raise TypeError ( f "" { image_path !r}  is not a valid image path. "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise TypeError ( "" ' image_path '  is required. "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( "" Caption must be 180 characters or less. "" )","if len ( image . get ( ""caption"" ) ) < 180 :","if not len ( image . get ( ""caption"" , """" ) ) <= 180 :",False,95.11,60.04,,,
"def VType ( self ) : <TAB> if "" DW_AT_type "" in self . attributes : <TAB> <TAB> target = self . types [ self . type_id ] <TAB> <TAB> target_type = target . VType ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> target_type = [ target_type , None ] <TAB> <TAB> return [ "" Pointer "" , dict ( target = target_type [ 0 ] , target_args = target_type [ 1 ] ) ] <TAB> return [ "" Pointer "" , dict ( target = "" Void "" ) ]","if not isinstance ( target_type , tuple ) :","if not isinstance ( target_type , list ) :",False,98.25,73.1,,,
"def addInPlace ( self , value1 , value2 ) : <TAB> for group in value2 : <TAB> <TAB> for key in value2 [ group ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value1 [ group ] [ key ] = value2 [ group ] [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> value1 [ group ] [ key ] + = value2 [ group ] [ key ] <TAB> return value1",if key not in value1 :,if key not in value1 [ group ] :,False,96.22,71.69,,,
"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB> <TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB> <TAB> for k , v in q . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> query [ k ] = { } <TAB> <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query[k] = v <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> query[k].update(v) <TAB> return query",if k not in query :,if k not in query :,True,100.0,74.47,,,
"def _handled_eventtype ( self , eventtype , handler ) : <TAB> if eventtype not in known_events : <TAB> <TAB> log . error ( ' The event  "" %s ""  is not known ' , eventtype ) <TAB> <TAB> return False <TAB> if known_events [ eventtype ] . __module__ . startswith ( "" deluge.event "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> log . error ( <TAB> <TAB> <TAB> "" You cannot register custom notification providers  "" <TAB> <TAB> <TAB> "" for built-in event types. "" <TAB> <TAB> ) <TAB> <TAB> return False <TAB> return True",if handler ( known_events [ eventtype ] ) :,if handler . __self__ is self :,False,94.6,71.34,,,
"def get_ax_arg ( uri ) : <TAB> if not ax_ns : <TAB> <TAB> return u "" "" <TAB> prefix = "" openid. "" + ax_ns + "" .type. "" <TAB> ax_name = None <TAB> for name , values in self . request . arguments . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> part = name [ len ( prefix ) : ] <TAB> <TAB> <TAB> ax_name = "" openid. "" + ax_ns + "" .value. "" + part <TAB> <TAB> <TAB> break <TAB> if not ax_name : <TAB> <TAB> return u "" "" <TAB> return self . get_argument ( ax_name , u "" "" )",if name . startswith ( prefix ) and values [ 0 ] == uri :,if values [ - 1 ] == uri and name . startswith ( prefix ) :,False,95.5,71.02,,,
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB> <TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self . strip : <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace ( value ) <TAB> <TAB> <TAB> <TAB> url = self . process_attr ( value ) <TAB> <TAB> <TAB> <TAB> link = Link ( url = url ) <TAB> <TAB> <TAB> <TAB> self . links . append ( link ) <TAB> <TAB> <TAB> <TAB> self . current_link = link","if attr == ""href"" :",if self . scan_attr ( attr ) :,False,95.64,64.9,,,
"def test_long_steadystate_queue_popright ( self ) : <TAB> for size in ( 0 , 1 , 2 , 100 , 1000 ) : <TAB> <TAB> d = deque ( reversed ( range ( size ) ) ) <TAB> <TAB> append , pop = d . appendleft , d . pop <TAB> <TAB> for i in range ( size , BIG ) : <TAB> <TAB> <TAB> append ( i ) <TAB> <TAB> <TAB> x = pop ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( x , i - size ) <TAB> <TAB> self . assertEqual ( list ( reversed ( list ( d ) ) ) , list ( range ( BIG - size , BIG ) ) )",if x != i - size :,if x != i - size :,True,100.0,74.5,,,
"def _update_read ( self ) : <TAB> """""" Update state when there is read event """""" <TAB> try : <TAB> <TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . on_message ( msg ) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self.close() <TAB> except socket.error as err: <TAB> <TAB> if err.args[0] in (errno.EAGAIN, errno.EWOULDBLOCK): <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> self.on_error(err) <TAB> return False",if msg :,if msg :,True,100.0,99.34,,,
"def prepend ( self , value ) : <TAB> """""" prepend value to nodes """""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> if not tag . text : <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self",if root :,if len ( root ) > 0 :,False,96.67,88.27,,,
"def cmp ( self , other ) : <TAB> v_is_ptr = not isinstance ( self , CTypesGenericPrimitive ) <TAB> w_is_ptr = isinstance ( other , CTypesData ) and not isinstance ( <TAB> <TAB> other , CTypesGenericPrimitive <TAB> ) <TAB> if v_is_ptr and w_is_ptr : <TAB> <TAB> return cmpfunc ( self . _convert_to_address ( None ) , other . _convert_to_address ( None ) ) <TAB> elif v_is_ptr or w_is_ptr : <TAB> <TAB> return NotImplemented <TAB> else : <TAB> <TAB> if isinstance ( self , CTypesGenericPrimitive ) : <TAB> <TAB> <TAB> self = self . _value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> other = other . _value <TAB> <TAB> return cmpfunc ( self , other )","if isinstance ( other , CTypesGenericPrimitive ) :","if isinstance ( other , CTypesGenericPrimitive ) :",True,100.0,74.5,,,
"def get_external_addresses ( self , label = None ) - > List [ str ] : <TAB> result = [ ] <TAB> for c in self . _conf [ "" pools "" ] . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if label == c [ "" label "" ] : <TAB> <TAB> <TAB> <TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB> return result","if label is not None and c [ ""label"" ] != label :",if label is not None :,False,92.5,67.05,,,
"def coerce_text ( v ) : <TAB> if not isinstance ( v , basestring_ ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attr = "" __unicode__ "" <TAB> <TAB> else : <TAB> <TAB> <TAB> attr = "" __str__ "" <TAB> <TAB> if hasattr ( v , attr ) : <TAB> <TAB> <TAB> return unicode ( v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return bytes ( v ) <TAB> return v",if PY2 :,if sys . version_info [ 0 ] < 3 :,False,91.42,68.51,,,
"def check_localhost ( self ) : <TAB> """""" Warn if any socket_host is  ' localhost ' . See #711. """""" <TAB> for k , v in cherrypy . config . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" The use of  ' localhost '  as a socket host can  "" <TAB> <TAB> <TAB> <TAB> "" cause problems on newer systems, since  "" <TAB> <TAB> <TAB> <TAB> "" ' localhost '  can map to either an IPv4 or an  "" <TAB> <TAB> <TAB> <TAB> "" IPv6 address. You should use  ' 127.0.0.1 ' "" <TAB> <TAB> <TAB> <TAB> "" or  ' [::1] '  instead. "" <TAB> <TAB> <TAB> )","if k == ""socket_host"" :","if k == ""server.socket_host"" and v == ""localhost"" :",False,94.64,94.52,,,
"def add_songs ( self , filenames , library ) : <TAB> changed = [ ] <TAB> for i in range ( len ( self ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> song = library [ self . _list [ i ] ] <TAB> <TAB> <TAB> self . _list [ i ] = song <TAB> <TAB> <TAB> changed . append ( song ) <TAB> if changed : <TAB> <TAB> self . _emit_changed ( changed , msg = "" add "" ) <TAB> return bool ( changed )",if self . _list [ i ] in filenames :,"if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames :",False,92.03,68.9,,,
"def _expand_deps_java_generation ( self ) : <TAB> """""" Ensure that all multilingual dependencies such as proto_library generate java code. """""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB> <TAB> k = queue . popleft ( ) <TAB> <TAB> if k not in keys : <TAB> <TAB> <TAB> keys . add ( k ) <TAB> <TAB> <TAB> dep = self . target_database [ k ] <TAB> <TAB> <TAB> <IF-STMT> # Has this attribute <TAB> <TAB> <TAB> <TAB> dep.attr[""generate_java""] = True <TAB> <TAB> <TAB> <TAB> queue.extend(dep.deps)","if dep . attr [ ""java_generation"" ] :","if ""generate_java"" in dep . attr :",False,95.22,70.65,,,
"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB> <TAB> opts = dict ( ) <TAB> <TAB> opts [ "" type "" ] = "" episode "" <TAB> <TAB> result = guessit ( name , options = opts ) <TAB> <TAB> res = dict ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" episode "" ] = 0 <TAB> <TAB> if "" season "" in result : <TAB> <TAB> <TAB> res [ "" season "" ] = result [ "" season "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" season "" ] = 0 <TAB> <TAB> if "" subtitle_language "" in result : <TAB> <TAB> <TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB> <TAB> return jsonify ( data = res ) <TAB> else : <TAB> <TAB> return "" "" , 400","if ""episode"" in result :","if ""episode"" in result :",True,100.0,74.67,,,
def _get_error_file ( self ) - > Optional [ str ] : <TAB> error_file = None <TAB> min_timestamp = sys . maxsize <TAB> for replicas in self . role_replicas . values ( ) : <TAB> <TAB> for replica in replicas : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> mtime = os . path . getmtime ( replica . error_file ) <TAB> <TAB> <TAB> if mtime < min_timestamp : <TAB> <TAB> <TAB> <TAB> min_timestamp = mtime <TAB> <TAB> <TAB> <TAB> error_file = replica . error_file <TAB> return error_file,if replica . error_file is None :,if not os . path . exists ( replica . error_file ) :,False,93.9,90.52,,,
"def findChapterNameForPosition ( self , p ) : <TAB> """""" Return the name of a chapter containing p or None if p does not exist. """""" <TAB> cc , c = self , self . c <TAB> if not p or not c . positionExists ( p ) : <TAB> <TAB> return None <TAB> for name in cc . chaptersDict : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> theChapter = cc . chaptersDict . get ( name ) <TAB> <TAB> <TAB> if theChapter . positionIsInChapter ( p ) : <TAB> <TAB> <TAB> <TAB> return name <TAB> return "" main """,if name . startswith ( p ) :,"if name != ""main"" :",False,95.58,72.08,,,
"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB> <TAB> f_path = os . path . join ( folder , f ) <TAB> <TAB> if os . path . isfile ( f_path ) : <TAB> <TAB> <TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . remove ( f_path )",if extension in file_extensions :,if extension in file_extensions :,True,100.0,74.2,,,
"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB> <TAB> f_path = os . path . join ( folder , f ) <TAB> <TAB> if os . path . isfile ( f_path ) : <TAB> <TAB> <TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . remove ( f_path )",if extension in file_extensions :,if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) :,False,81.09,61.77,,,
"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell ( <TAB> critical_suite_with_citations , empty_data_context ) : <TAB> obs = SuiteEditNotebookRenderer . from_data_context ( empty_data_context ) . render ( <TAB> <TAB> critical_suite_with_citations , { "" path "" : "" ./foo/data "" } <TAB> ) <TAB> assert isinstance ( obs , dict ) <TAB> found_expected = False <TAB> for cell in obs [ "" cells "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source_code = cell [ "" source "" ] <TAB> <TAB> <TAB> if ' batch_kwargs =  { "" path "" :  "" ../.././foo/data "" } ' in source_code : <TAB> <TAB> <TAB> <TAB> found_expected = True <TAB> <TAB> <TAB> <TAB> break <TAB> assert found_expected","if cell [ ""cell_type"" ] == ""code"" :","if cell [ ""cell_type"" ] == ""code"" :",True,100.0,74.46,,,
"def _get_file ( self ) : <TAB> if self . _file is None : <TAB> <TAB> self . _file = SpooledTemporaryFile ( <TAB> <TAB> <TAB> max_size = self . _storage . max_memory_size , <TAB> <TAB> <TAB> suffix = "" .S3Boto3StorageFile "" , <TAB> <TAB> <TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB> <TAB> ) <TAB> <TAB> if "" r "" in self . _mode : <TAB> <TAB> <TAB> self . _is_dirty = False <TAB> <TAB> <TAB> self . obj . download_fileobj ( self . _file ) <TAB> <TAB> <TAB> self . _file . seek ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file",if self . _storage . gzip :,"if self . _storage . gzip and self . obj . content_encoding == ""gzip"" :",False,93.96,66.25,,,
"def _get_file ( self ) : <TAB> if self . _file is None : <TAB> <TAB> self . _file = SpooledTemporaryFile ( <TAB> <TAB> <TAB> max_size = self . _storage . max_memory_size , <TAB> <TAB> <TAB> suffix = "" .S3Boto3StorageFile "" , <TAB> <TAB> <TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB> <TAB> ) <TAB> <TAB> if "" r "" in self . _mode : <TAB> <TAB> <TAB> self . _is_dirty = False <TAB> <TAB> <TAB> self . obj . download_fileobj ( self . _file ) <TAB> <TAB> <TAB> self . _file . seek ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file",if self . _storage . gzip :,"if "":"" in f_str :",False,96.45,67.43,,,
"def update_completion ( self ) : <TAB> """""" Update completion model with exist tags """""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if orig_text [ - 1 ] not in ( "" , "" , "" "" ) : <TAB> <TAB> <TAB> <TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB> <TAB> <TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB> <TAB> self . completer_model . setStringList ( tags )",if tag in orig_text :,"if "","" in orig_text :",False,98.19,70.4,,,
"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB> <TAB> name = path . name <TAB> <TAB> if name == "" __pycache__ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB> <TAB> elif path . is_dir ( ) and "" . "" not in name : <TAB> <TAB> <TAB> names . add ( name ) <TAB> if packages : <TAB> <TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB> <TAB> if len ( names & packages ) == len ( packages ) : <TAB> <TAB> <TAB> return packages <TAB> return names","if path . is_file ( ) and ""."" not in name :","if name . endswith ( "".py"" ) :",False,94.32,71.99,,,
"def get_cloud_credential ( self ) : <TAB> """""" Return the credential which is directly tied to the inventory source type. """""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if cred . kind == self . source . replace ( "" ec2 "" , "" aws "" ) : <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred.credential_type.kind != ""vault"": <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential",if self . source :,if self . source in CLOUD_PROVIDERS :,False,97.34,96.08,,,
"def newickize ( clade ) : <TAB> """""" Convert a node tree to a Newick tree string, recursively. """""" <TAB> label = clade . name or "" "" <TAB> if label : <TAB> <TAB> unquoted_label = re . match ( token_dict [ "" unquoted node label "" ] , label ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> label = "" ' %s ' "" % label . replace ( "" \\ "" , "" \\ \\ "" ) . replace ( "" ' "" , "" \\ ' "" ) <TAB> if clade . is_terminal ( ) : # terminal <TAB> <TAB> return label + make_info_string(clade, terminal=True) <TAB> else: <TAB> <TAB> subtrees = (newickize(sub) for sub in clade) <TAB> <TAB> return ""(%s)%s"" % ("","".join(subtrees), label + make_info_string(clade))",if unquoted_label :,if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) :,False,91.02,68.04,,,
"def __iter__ ( self ) : <TAB> for name , value in self . _vars . store . data . items ( ) : <TAB> <TAB> source = self . _sources [ name ] <TAB> <TAB> prefix = self . _get_prefix ( value ) <TAB> <TAB> name = u "" {0} {{ {1} }} "" . format ( prefix , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ArgumentInfo ( name , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield VariableInfo ( name , value , source )",if self . _vars . store . is_argument :,if source == self . ARGUMENT_SOURCE :,False,92.95,70.92,,,
"def filepath_enumerate ( paths ) : <TAB> """""" Enumerate the file paths of all subfiles of the list of paths """""" <TAB> out = [ ] <TAB> for path in paths : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for root , dirs , files in os . walk ( path ) : <TAB> <TAB> <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( os . path . normpath ( os . path . join ( root , name ) ) ) <TAB> return out",if os . path . isdir ( path ) :,if os . path . isfile ( path ) :,False,98.46,98.35,,,
"def del_ ( self , key ) : <TAB> hash_ = self . hash ( key ) <TAB> node_ = self . _table [ hash_ ] <TAB> pre_node = None <TAB> while node_ is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if pre_node is None : <TAB> <TAB> <TAB> <TAB> self . _table [ hash_ ] = node_ . next <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> pre_node . next = node_ . next <TAB> <TAB> <TAB> self . _len - = 1 <TAB> <TAB> pre_node = node_ <TAB> <TAB> node_ = node_ . next",if node_ . key == key :,if node_ . key == key :,True,100.0,74.41,,,
"def _recurse ( self , base_path , rel_source , rel_zip ) : <TAB> submodules_path = Path ( base_path ) / "" submodules "" <TAB> if not submodules_path . is_dir ( ) : <TAB> <TAB> return <TAB> for submodule in submodules_path . iterdir ( ) : <TAB> <TAB> source_path = submodule / rel_source <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> output_path = submodule / rel_zip <TAB> <TAB> self . _build_lambdas ( source_path , output_path ) <TAB> <TAB> self . _recurse ( submodule , rel_source , rel_zip )",if not source_path . is_dir ( ) :,if not source_path . is_dir ( ) :,True,100.0,74.35,,,
"def find_test_functions ( collections ) : <TAB> if not isinstance ( collections , list ) : <TAB> <TAB> collections = [ collections ] <TAB> functions = [ ] <TAB> for collection in collections : <TAB> <TAB> if not isinstance ( collection , dict ) : <TAB> <TAB> <TAB> collection = vars ( collection ) <TAB> <TAB> keys = collection . keys ( ) <TAB> <TAB> keys . sort ( ) <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> value = collection [ key ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> functions . append ( value ) <TAB> return functions","if isinstance ( value , Function ) :","if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",False,92.25,61.26,,,
"def __init__ ( <TAB> self , <TAB> classifier , <TAB> layer_name = None , <TAB> transpose = None , <TAB> distance = None , <TAB> copy_weights = True , ) : <TAB> super ( ) . __init__ ( ) <TAB> self . copy_weights = copy_weights <TAB> ### set layer weights ### <TAB> if layer_name is not None: <TAB> <TAB> self.set_weights(getattr(classifier, layer_name)) <TAB> else: <TAB> <TAB> for x in self.possible_layer_names: <TAB> <TAB> <TAB> layer = getattr(classifier, x, None) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.set_weights(layer) <TAB> <TAB> <TAB> <TAB> break <TAB> ### set distance measure ### <TAB> self.distance = classifier.distance if distance is None else distance <TAB> self.transpose = transpose",if layer is not None :,if layer is not None :,True,100.0,74.49,,,
def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB> <TAB> if len ( self . _tail_data ) < self . _base_number : <TAB> <TAB> <TAB> self . _tail_data + = data <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield self . _tail_data <TAB> <TAB> <TAB> self . _tail_data = [ ],if len ( self . _tail_data ) == self . _base_number :,if len ( self . _tail_data ) == self . _base_number :,True,100.0,99.09,,,
"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB> <TAB> for setting , edge in self . Conflicts : <TAB> <TAB> <TAB> answer = self . AskUser ( self . Setting , setting ) <TAB> <TAB> <TAB> if answer == Gtk . ResponseType . YES : <TAB> <TAB> <TAB> <TAB> value = setting . Value . split ( "" | "" ) <TAB> <TAB> <TAB> <TAB> value . remove ( edge ) <TAB> <TAB> <TAB> <TAB> setting . Value = "" | "" . join ( value ) <TAB> <TAB> <TAB> <TAB> if updater : <TAB> <TAB> <TAB> <TAB> <TAB> updater . UpdateSetting ( setting ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if answer == Gtk . ResponseType . NO :,if answer == Gtk . ResponseType . NO :,True,100.0,74.54,,,
"def _post_process_ttl ( zone ) : <TAB> for name in zone : <TAB> <TAB> for record_type in zone [ name ] : <TAB> <TAB> <TAB> records = zone [ name ] [ record_type ] <TAB> <TAB> <TAB> if isinstance ( records , list ) : <TAB> <TAB> <TAB> <TAB> ttl = min ( [ x [ "" ttl "" ] for x in records ] ) <TAB> <TAB> <TAB> <TAB> for record in records : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Using lowest TTL  {}  for the record set. Ignoring value  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ttl , record [ "" ttl "" ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> record [ "" ttl "" ] = ttl","if record [ ""ttl"" ] < ttl :","if record [ ""ttl"" ] != ttl :",False,98.83,73.86,,,
"def __init__ ( self , cmds , env , cleanup = [ ] ) : <TAB> self . handle = None <TAB> self . cmds = cmds <TAB> self . env = env <TAB> if cleanup : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cleanup = [ cleanup ] <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cleanup = [ c for c in cleanup if callable ( c ) ] <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> cleanup = [ ] <TAB> self . cleanup = cleanup","if isinstance ( cleanup , ( list , tuple ) ) :",if callable ( cleanup ) :,False,93.87,71.11,,,
"def _parse_data_of_birth ( cls , data_of_birth_string ) : <TAB> if data_of_birth_string : <TAB> <TAB> format = "" % m/ %d / % Y "" <TAB> <TAB> try : <TAB> <TAB> <TAB> parsed_date = datetime . datetime . strptime ( data_of_birth_string , format ) <TAB> <TAB> <TAB> return parsed_date <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> # Facebook sometimes provides a partial date format <TAB> <TAB> <TAB> # ie 04/07 (ignore those) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise","if ""YYYY-MM-DD"" in format and ""YYYY-MM-DD"" in format :","if data_of_birth_string . count ( ""/"" ) != 1 :",False,90.21,62.28,,,
"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB> <TAB> var = d . upper ( ) <TAB> <TAB> if var == "" QTCORE "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env [ "" LIBPATH_ "" + var ] <TAB> <TAB> if value : <TAB> <TAB> <TAB> core = env [ coreval ] <TAB> <TAB> <TAB> accu = [ ] <TAB> <TAB> <TAB> for lib in value : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu . append ( lib ) <TAB> <TAB> <TAB> env [ "" LIBPATH_ "" + var ] = accu",if lib not in core :,if lib in core :,False,98.72,73.59,,,
"def throttle_status ( server = None ) : <TAB> result = AmonStruct ( ) <TAB> result . allow = False <TAB> last_check = server . get ( "" last_check "" ) <TAB> server_check_period = server . get ( "" check_every "" , 60 ) <TAB> if last_check : <TAB> <TAB> period_since_last_check = unix_utc_now ( ) - last_check <TAB> <TAB> # Add 15 seconds buffer, for statsd <TAB> <TAB> period_since_last_check = period_since_last_check + 15 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.allow = True <TAB> else: <TAB> <TAB> result.allow = True # Never checked <TAB> return result",if period_since_last_check < server_check_period :,if period_since_last_check >= server_check_period :,False,98.18,73.11,,,
"def fetch_scatter_outputs ( self , task ) : <TAB> scatteroutputs = [ ] <TAB> for var in task [ "" body "" ] : <TAB> <TAB> # TODO variable support <TAB> <TAB> if var.startswith(""call""): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for output in self.tasks_dictionary[task[""body""][var][""task""]][ <TAB> <TAB> <TAB> <TAB> <TAB> ""outputs"" <TAB> <TAB> <TAB> <TAB> ]: <TAB> <TAB> <TAB> <TAB> <TAB> scatteroutputs.append( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> {""task"": task[""body""][var][""alias""], ""output"": output[0]} <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return scatteroutputs","if task [ ""body"" ] [ var ] [ ""task"" ] in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :","if ""outputs"" in self . tasks_dictionary [ task [ ""body"" ] [ var ] [ ""task"" ] ] :",False,94.21,68.71,,,
"def _add_constant_node ( self , source_node ) : <TAB> parent_ids = range ( len ( source_node . in_edges ) ) <TAB> for idx in parent_ids : <TAB> <TAB> parent_node = self . tf_graph . get_node ( source_node . in_edges [ idx ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _rename_Const ( parent_node )",if self . _has_constant ( parent_node ) :,"if parent_node . type == ""Const"" :",False,90.47,60.32,,,
"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB> <TAB> name = data[""name""] <TAB> <TAB> if name in self.ctrls: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> set = self.getSetting(data[""requires""]) <TAB> <TAB> <TAB> <TAB> for i in self.ctrls[name]: <TAB> <TAB> <TAB> <TAB> <TAB> i.Enable(set not in [""off"", ""false"", ""0""])","if data [ ""requires"" ] :","if ""requires"" in data :",False,96.61,71.16,,,
"def update_realtime ( self , stdout = "" "" , stderr = "" "" , delete = False ) : <TAB> wooey_cache = wooey_settings . WOOEY_REALTIME_CACHE <TAB> if delete == False and wooey_cache is None : <TAB> <TAB> self . stdout = stdout <TAB> <TAB> self . stderr = stderr <TAB> <TAB> self . save ( ) <TAB> elif wooey_cache is not None : <TAB> <TAB> cache = django_cache [ wooey_cache ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cache . delete ( self . get_realtime_key ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cache . set ( <TAB> <TAB> <TAB> <TAB> self . get_realtime_key ( ) , <TAB> <TAB> <TAB> <TAB> json . dumps ( { "" stdout "" : stdout , "" stderr "" : stderr } ) , <TAB> <TAB> <TAB> )",if delete :,if delete :,True,100.0,74.55,,,
"def _check_for_batch_clashes ( xs ) : <TAB> """""" Check that batch names do not overlap with sample names. """""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB> <TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB> <TAB> if batches : <TAB> <TAB> <TAB> if not isinstance ( batches , ( list , tuple ) ) : <TAB> <TAB> <TAB> <TAB> batches = [ batches ] <TAB> <TAB> <TAB> for batch in batches : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB> <TAB> <TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB> <TAB> )",if batch not in names :,if batch in names :,False,99.07,99.08,,,
"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 100 <TAB> <TAB> if self . split > 20 : <TAB> <TAB> <TAB> self . save = self . split <TAB> <TAB> <TAB> self . split = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . save <TAB> else : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 0.3 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . split = self . save <TAB> <TAB> elif self . split < 0.5 : <TAB> <TAB> <TAB> self . split = self . min <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . max <TAB> self . placeChilds ( )",if self . split > 0.5 :,if self . split <= self . min or self . split >= self . max :,False,94.12,70.5,,,
"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB> <TAB> iterator = iter ( self . file ) <TAB> <TAB> head = next ( iterator , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . repaired = [ ] <TAB> <TAB> <TAB> return True <TAB> <TAB> if isinstance ( head , str ) : <TAB> <TAB> <TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError( <TAB> <TAB> <TAB> <TAB> ""Could not open source: %r (mode: %r)"" <TAB> <TAB> <TAB> <TAB> % (self.file, self.options[""mode""]) <TAB> <TAB> <TAB> ) <TAB> return False",if head is None :,if head is None :,True,100.0,74.57,,,
"def _print_message_content ( self , peer , data ) : <TAB> inheaders = 1 <TAB> lines = data . splitlines ( ) <TAB> for line in lines : <TAB> <TAB> # headers first <TAB> <TAB> if inheaders and not line: <TAB> <TAB> <TAB> peerheader = ""X-Peer: "" + peer[0] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # decoded_data=false; make header match other binary output <TAB> <TAB> <TAB> <TAB> peerheader = repr(peerheader.encode(""utf-8"")) <TAB> <TAB> <TAB> print(peerheader) <TAB> <TAB> <TAB> inheaders = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Avoid spurious 'str on bytes instance' warning. <TAB> <TAB> <TAB> line = repr(line) <TAB> <TAB> print(line)","if not isinstance ( line , bytes ) :","if not isinstance ( data , str ) :",False,96.28,70.98,,,
"def connect ( self ) : <TAB> # Makes connection with MySQL server <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> connection = pymysql.connect(read_default_file=""/etc/mysql/conf.d/my.cnf"") <TAB> <TAB> else: <TAB> <TAB> <TAB> connection = pymysql.connect(read_default_file=""~/.my.cnf"") <TAB> <TAB> return connection <TAB> except ValueError as e: <TAB> <TAB> Log.debug(self, str(e)) <TAB> <TAB> raise MySQLConnectionError <TAB> except pymysql.err.InternalError as e: <TAB> <TAB> Log.debug(self, str(e)) <TAB> <TAB> raise MySQLConnectionError","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :","if os . path . exists ( ""/etc/mysql/conf.d/my.cnf"" ) :",True,100.0,74.16,,,
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> if not dest . parent . is_dir ( ) : <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> if dest . exists ( ) : <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }  Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutil . copy ( src , dest )",if os . path . exists ( src ) :,if src . exists ( ) :,False,97.03,72.83,,,
"def update ( self , x , who = None , metadata = None ) : <TAB> self . _retain_refs ( metadata ) <TAB> y = self . _get_key ( x ) <TAB> if self . keep == "" last "" : <TAB> <TAB> # remove key if already present so that emitted value <TAB> <TAB> # will reflect elements' actual relative ordering <TAB> <TAB> self._buffer.pop(y, None) <TAB> <TAB> self._metadata_buffer.pop(y, None) <TAB> <TAB> self._buffer[y] = x <TAB> <TAB> self._metadata_buffer[y] = metadata <TAB> else: # self.keep == ""first"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._buffer[y] = x <TAB> <TAB> <TAB> self._metadata_buffer[y] = metadata <TAB> return self.last","if self . keep == ""last"" :",if y not in self . _buffer :,False,96.11,64.3,,,
"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB> <TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB> <TAB> <TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB> <TAB> <TAB> for ak in keys : <TAB> <TAB> <TAB> <TAB> if c_date == ak [ "" CreateDate "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict ( ak ) <TAB> <TAB> <TAB> <TAB> <TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ak ) <TAB> <TAB> elif k not in res : <TAB> <TAB> <TAB> res . append ( k ) <TAB> return res","if ak [ ""c7n:match-type"" ] == ""access"" :",if ak not in res :,False,94.59,68.4,,,
"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef("""", {}, None) <TAB> for name in dir(src_flag): <TAB> <TAB> if name[:1] == ""_"": <TAB> <TAB> <TAB> continue <TAB> <TAB> dest_val = getattr(dest_flag, name, None) <TAB> <TAB> baseline_val = getattr(baseline_flag, name, None) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr(dest_flag, name, getattr(src_flag, name))",if dest_val != baseline_val :,if dest_val == baseline_val :,False,98.54,97.37,,,
"def _ws_keep_reading ( self ) : <TAB> import websockets . exceptions <TAB> while not self . _reader_stopped : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = await self . _ws . recv ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = data . encode ( "" UTF-8 "" ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> self . _error = "" EOF "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except websockets . exceptions . ConnectionClosedError : <TAB> <TAB> <TAB> # TODO: try to reconnect in case of Ctrl+D <TAB> <TAB> <TAB> self._error = ""EOF"" <TAB> <TAB> <TAB> break <TAB> <TAB> self.num_bytes_received += len(data) <TAB> <TAB> self._make_output_available(data, block=False)","if isinstance ( data , bytes ) :","if isinstance ( data , str ) :",False,98.99,73.54,,,
"def to_dict ( self ) - > Dict [ str , Any ] : <TAB> result = { } <TAB> for field_name in self . API_FIELDS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ "" stream_id "" ] = self . id <TAB> <TAB> <TAB> continue <TAB> <TAB> elif field_name == "" date_created "" : <TAB> <TAB> <TAB> result [ "" date_created "" ] = datetime_to_timestamp ( self . date_created ) <TAB> <TAB> <TAB> continue <TAB> <TAB> result [ field_name ] = getattr ( self , field_name ) <TAB> result [ "" is_announcement_only "" ] = ( <TAB> <TAB> self . stream_post_policy == Stream . STREAM_POST_POLICY_ADMINS <TAB> ) <TAB> return result","if field_name == ""stream_id"" :","if field_name == ""id"" :",False,98.34,73.38,,,
"def all_masks ( <TAB> cls , <TAB> images , <TAB> run , <TAB> run_key , <TAB> step , ) : <TAB> all_mask_groups = [ ] <TAB> for image in images : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mask_group = { } <TAB> <TAB> <TAB> for k in image . _masks : <TAB> <TAB> <TAB> <TAB> mask = image . _masks [ k ] <TAB> <TAB> <TAB> <TAB> mask_group [ k ] = mask . to_json ( run ) <TAB> <TAB> <TAB> all_mask_groups . append ( mask_group ) <TAB> <TAB> else : <TAB> <TAB> <TAB> all_mask_groups . append ( None ) <TAB> if all_mask_groups and not all ( x is None for x in all_mask_groups ) : <TAB> <TAB> return all_mask_groups <TAB> else : <TAB> <TAB> return False",if image . _masks :,if image . _masks :,True,100.0,74.54,,,
"def all_masks ( <TAB> cls , <TAB> images , <TAB> run , <TAB> run_key , <TAB> step , ) : <TAB> all_mask_groups = [ ] <TAB> for image in images : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mask_group = { } <TAB> <TAB> <TAB> for k in image . _masks : <TAB> <TAB> <TAB> <TAB> mask = image . _masks [ k ] <TAB> <TAB> <TAB> <TAB> mask_group [ k ] = mask . to_json ( run ) <TAB> <TAB> <TAB> all_mask_groups . append ( mask_group ) <TAB> <TAB> else : <TAB> <TAB> <TAB> all_mask_groups . append ( None ) <TAB> if all_mask_groups and not all ( x is None for x in all_mask_groups ) : <TAB> <TAB> return all_mask_groups <TAB> else : <TAB> <TAB> return False",if image . _masks :,"if getattr ( i , ""__self__"" , None ) != listener",False,92.74,62.05,,,
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> if timeout is None : <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode",if code == _subprocess . WAIT_OBJECT_1 :,if code == TERMINATE :,False,95.26,73.13,,,
"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB> <TAB> self . is_pulsing = False <TAB> <TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB> <TAB> self . pbar . set_text ( progress ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB> if frac < 0 : <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB> <TAB> gtk . gdk . threads_leave ( )",if frac > 1.0 :,if frac > 1 :,False,98.53,73.21,,,
"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB> <TAB> if i == "" [ "" : <TAB> <TAB> <TAB> m = - 1 <TAB> <TAB> <TAB> aas . append ( "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == - 1 : <TAB> <TAB> <TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB> <TAB> elif m == 0 : <TAB> <TAB> <TAB> aas . append ( i ) <TAB> return aas","elif i == ""]"" :","elif i == ""]"" :",True,100.0,74.41,,,
"def link ( token , base_url ) : <TAB> """""" Validation for ``link``. """""" <TAB> if get_keyword ( token ) == "" none "" : <TAB> <TAB> return "" none "" <TAB> parsed_url = get_url ( token , base_url ) <TAB> if parsed_url : <TAB> <TAB> return parsed_url <TAB> function = parse_function ( token ) <TAB> if function : <TAB> <TAB> name , args = function <TAB> <TAB> prototype = ( name , [ a . type for a in args ] ) <TAB> <TAB> args = [ getattr ( a , "" value "" , a ) for a in args ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( "" attr() "" , args [ 0 ] )","if prototype in ( ""attr"" , ""attr_type"" ) :","if prototype == ( ""attr"" , [ ""ident"" ] ) :",False,95.31,94.59,,,
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB> <TAB> <TAB> return self . current_provider . on_file ( query )",elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,elif self . current_provider . kind == directory . Provider . PROVIDER_URL :,True,100.0,74.49,,,
"def test_handle_single ( self ) : <TAB> self . skipTest ( <TAB> <TAB> "" Pops up windows and needs user input.. so disabled. "" <TAB> <TAB> "" Still worth keeping whilst we don ' t have unit tests  "" <TAB> <TAB> "" for all plugins. "" <TAB> ) <TAB> # Ignored... <TAB> for id_, plugin in self.plugins.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.h.plugin_enable(plugin, None) <TAB> <TAB> <TAB> self.h.handle(id_, self.lib, self.parent, SONGS) <TAB> <TAB> <TAB> self.h.plugin_disable(plugin)","if isinstance ( plugin , WindowsPlugin ) :",if self . h . plugin_handle ( plugin ) :,False,94.61,69.73,,,
"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . _keydata : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB> <TAB> elif hasattr ( self , k ) : <TAB> <TAB> <TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB> <TAB> attrs . append ( "" private "" ) <TAB> # PY3K: This is meant to be text, do not change to bytes (data) <TAB> return ""<%s @0x%x %s>"" % (self.__class__.__name__, id(self), "","".join(attrs))","if k == ""size"" :","if k == ""p"" :",False,98.71,73.31,,,
"def apply ( self , node , code , required ) : <TAB> yield "" try: "" <TAB> yield from self . iterIndented ( code ) <TAB> yield ""  <TAB> pass "" <TAB> yield "" except  {} : "" . format ( self . exceptionString ) <TAB> outputVariables = node . getOutputSocketVariables ( ) <TAB> for i , s in enumerate ( node . outputs ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if hasattr ( s , "" getDefaultValueCode "" ) : <TAB> <TAB> <TAB> <TAB> yield f ""  <TAB>  { outputVariables [ s . identifier ] }  =  { s . getDefaultValueCode ( ) } "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield f ""  <TAB>  { outputVariables [ s . identifier ] }  = self.outputs[ { i } ].getDefaultValue() "" <TAB> yield ""  <TAB> pass """,if i == 0 :,if s . identifier in required :,False,96.9,72.34,,,
"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB> <TAB> if "" * "" in fromlist : <TAB> <TAB> <TAB> fromlist = list ( fromlist ) <TAB> <TAB> <TAB> fromlist . remove ( "" * "" ) <TAB> <TAB> <TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB> <TAB> for x in fromlist : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB> <TAB> <TAB> <TAB> if from_name in modules : <TAB> <TAB> <TAB> <TAB> <TAB> importlib . import_module ( from_name ) <TAB> return module",if x :,"if isinstance ( getattr ( module , x , None ) , types . ModuleType ) :",False,93.64,69.68,,,
"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r = await ws . recv ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> r = r . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> msg = json . loads ( r ) <TAB> <TAB> <TAB> stream = msg . get ( "" stream "" ) <TAB> <TAB> <TAB> if stream is not None : <TAB> <TAB> <TAB> <TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB> <TAB> logging . warn ( wse ) <TAB> <TAB> await self . close ( ) <TAB> <TAB> asyncio . ensure_future ( self . _ensure_ws ( ) )","if isinstance ( r , bytes ) :","if isinstance ( r , bytes ) :",True,100.0,74.55,,,
"def add_source ( self , source , name = None ) : <TAB> """""" Adds a new data source to an existing provider. """""" <TAB> if self . randomize : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Cannot add a non-shuffleable source to an  "" <TAB> <TAB> <TAB> <TAB> "" already shuffled provider. "" <TAB> <TAB> <TAB> ) <TAB> super ( ) . add_source ( source , name = name ) <TAB> if self . randomize is True : <TAB> <TAB> self . _shuffle_len = self . entries",if self . _shuffle_len is not None :,if not source . can_shuffle ( ) :,False,94.21,65.27,,,
"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB> <TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB> <TAB> if not self . fileName : <TAB> <TAB> <TAB> buf . append ( "" line  "" ) <TAB> <TAB> buf . append ( str ( self . line ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB> <TAB> buf . append ( "" : "" ) <TAB> buf . append ( "" "" ) <TAB> return str ( "" "" ) . join ( buf )",if self . column != - 1 :,if self . column != - 1 :,True,100.0,74.51,,,
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if linenum == 0 and line [ 0 ] not in ""\t"" :",if len ( line . strip ( ) ) == 0 :,False,94.83,64.57,,,
"def scanHexEscape ( self , prefix ) : <TAB> code = 0 <TAB> leng = 4 if ( prefix == "" u "" ) else 2 <TAB> for i in xrange ( leng ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ch = self . source [ self . index ] <TAB> <TAB> <TAB> self . index + = 1 <TAB> <TAB> <TAB> code = code * 16 + HEX_CONV [ ch ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" "" <TAB> return unichr ( code )",if self . index < leng :,if self . index < self . length and isHexDigit ( self . source [ self . index ] ) :,False,88.69,66.75,,,
"def _get_table_info ( self , table_name ) : <TAB> table_addr = self . addr_space . profile . get_symbol ( table_name ) <TAB> table_size = self . _get_table_info_distorm ( ) <TAB> <IF-STMT> <TAB> <TAB> table_size = self . _get_table_info_other ( table_addr , table_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> debug . error ( "" Unable to get system call table size "" ) <TAB> return [ table_addr , table_size ]",if table_size < 0 :,if table_size == 0 :,False,95.17,70.93,,,
"def format_file_path ( filepath ) : <TAB> """""" Formats a path as absolute and with the correct platform separator. """""" <TAB> try : <TAB> <TAB> is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN . match ( filepath ) <TAB> <TAB> filepath = os . path . realpath ( os . path . abspath ( filepath ) ) <TAB> <TAB> filepath = re . sub ( BACKSLASH_REPLACE_PATTERN , "" / "" , filepath ) <TAB> <TAB> is_windows_drive = WINDOWS_DRIVE_PATTERN . match ( filepath ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filepath = filepath . capitalize ( ) <TAB> <TAB> if is_windows_network_mount : <TAB> <TAB> <TAB> # Add back a / to the front, since the previous modifications <TAB> <TAB> <TAB> # will have replaced any double slashes with single <TAB> <TAB> <TAB> filepath = ""/"" + filepath <TAB> except: <TAB> <TAB> pass <TAB> return filepath",if is_windows_drive :,if is_windows_drive :,True,100.0,99.55,,,
"def _match ( self , cre , s ) : <TAB> # Run compiled regular expression match method on 's'. <TAB> # Save result, return success. <TAB> self.mo = cre.match(s) <TAB> if __debug__: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._mesg(""\tmatched r'%r' => %r"" % (cre.pattern, self.mo.groups())) <TAB> return self.mo is not None",if self . mo is not None :,if self . mo is not None and self . debug >= 5 :,False,93.18,68.24,,,
"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB> <TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB> <TAB> <TAB> for line in f . readlines ( ) : <TAB> <TAB> <TAB> <TAB> if not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist_file , <TAB> <TAB> <TAB> )",if explicit :,if explicit :,True,100.0,74.52,,,
"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB> <TAB> if not self . flags . forc : <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> order = "" F "" <TAB> <TAB> else : <TAB> <TAB> <TAB> order = "" C "" <TAB> <TAB> result = self . _new_like_me ( order = order ) <TAB> <TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB> <TAB> func . prepared_async_call ( <TAB> <TAB> <TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return self",if self . flags . f :,if self . flags . f_contiguous :,False,98.64,73.84,,,
"def scan_spec_conf ( self , conf ) : <TAB> if "" metadata "" in conf : <TAB> <TAB> if "" annotations "" in conf [ "" metadata "" ] and conf [ "" metadata "" ] . get ( "" annotations "" ) : <TAB> <TAB> <TAB> for annotation in conf [ "" metadata "" ] [ "" annotations "" ] : <TAB> <TAB> <TAB> <TAB> for key in annotation : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" docker/default "" in annotation [ key ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> or "" runtime/default "" in annotation [ key ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if key . startswith ( ""docker/"" ) :","if ""seccomp.security.alpha.kubernetes.io/defaultProfileName"" in key :",False,94.12,72.51,,,
"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB> <TAB> with self.assertRaises(AttributeError): <TAB> <TAB> <TAB> self.tp(rawio).xyzzy <TAB> <TAB> if not IOBASE_EMITS_UNRAISABLE: <TAB> <TAB> <TAB> self.assertIsNone(cm.unraisable) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",if cm . unraisable . exc_type is not None :,elif cm . unraisable is not None :,False,95.18,70.16,,,
"def _dumpf ( frame ) : <TAB> if frame is None : <TAB> <TAB> return "" <None> "" <TAB> else : <TAB> <TAB> addn = "" (with trace!) "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> addn = ""  **No Trace Set ** "" <TAB> <TAB> return "" Frame at  %d , file  %s , line:  %d %s "" % ( <TAB> <TAB> <TAB> id ( frame ) , <TAB> <TAB> <TAB> frame . f_code . co_filename , <TAB> <TAB> <TAB> frame . f_lineno , <TAB> <TAB> <TAB> addn , <TAB> <TAB> )","if frame . f_code . co_filename == ""NoFrames"" :",if frame . f_trace is None :,False,93.59,66.27,,,
"def containsBadbytes ( self , value , bytecount = 4 ) : <TAB> for b in self . badbytes : <TAB> <TAB> tmp = value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> b = ord ( b ) <TAB> <TAB> for i in range ( bytecount ) : <TAB> <TAB> <TAB> if ( tmp & 0xFF ) == b : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> tmp >> = 8 <TAB> return False","if not isinstance ( b , int ) :",if type ( b ) == str :,False,93.99,70.03,,,
"def _set_peer_statuses ( self ) : <TAB> """""" Set peer statuses. """""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> peer . status = PEER_BAD <TAB> <TAB> elif peer . last_good > cutoff : <TAB> <TAB> <TAB> peer . status = PEER_GOOD <TAB> <TAB> elif peer . last_good : <TAB> <TAB> <TAB> peer . status = PEER_STALE <TAB> <TAB> else : <TAB> <TAB> <TAB> peer . status = PEER_NEVER",if peer . last_good < cutoff :,if peer . bad :,False,95.97,96.2,,,
"def afterTest ( self , test ) : <TAB> try : <TAB> <TAB> # If the browser window is still open, close it now. <TAB> <TAB> self.driver.quit() <TAB> except AttributeError: <TAB> <TAB> pass <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.options.headless: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> self.display.stop() <TAB> <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass",if self . display :,if self . headless_active :,False,97.39,72.64,,,
"def _written_variables_in_proxy ( self , contract ) : <TAB> variables = [ ] <TAB> if contract . is_upgradeable : <TAB> <TAB> variables_name_written_in_proxy = self . _variable_written_in_proxy ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> variables_in_contract = [ <TAB> <TAB> <TAB> <TAB> contract . get_state_variable_from_name ( v ) <TAB> <TAB> <TAB> <TAB> for v in variables_name_written_in_proxy <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> variables_in_contract = [ v for v in variables_in_contract if v ] <TAB> <TAB> <TAB> variables + = variables_in_contract <TAB> return list ( set ( variables ) )",if variables_name_written_in_proxy :,if variables_name_written_in_proxy :,True,100.0,74.32,,,
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> if name . startswith ( expr ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> if not scoperef : <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )",if name not in found_names :,if name not in found_names :,True,100.0,74.61,,,
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not name . startswith ( "" wait_until "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action ( member ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods",if is_resource_action ( member ) :,if not name [ 0 ] . isupper ( ) :,False,94.63,69.47,,,
def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self.radioButtons: <TAB> <TAB> btn = self.radioButtons[moduleID] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> btn.SetValue(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.SetValue(False) <TAB> <TAB> if self.demoModules.Exists(moduleID): <TAB> <TAB> <TAB> btn.Enable(True) <TAB> <TAB> <TAB> if moduleID == modModified: <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(True) <TAB> <TAB> else: <TAB> <TAB> <TAB> btn.Enable(False) <TAB> <TAB> <TAB> if moduleID == modModified: <TAB> <TAB> <TAB> <TAB> self.btnRestore.Enable(False),if active == btn . GetActiveID ( ) :,if moduleID == active :,False,96.27,96.01,,,
"def test_controlcharacters ( self ) : <TAB> for i in range ( 128 ) : <TAB> <TAB> c = chr ( i ) <TAB> <TAB> testString = "" string containing  %s "" % c <TAB> <TAB> if i > = 32 or c in "" \r \n \t "" : <TAB> <TAB> <TAB> # \r, \n and \t are the only legal control chars in XML <TAB> <TAB> <TAB> data = plistlib.dumps(testString, fmt=plistlib.FMT_XML) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(plistlib.loads(data), testString) <TAB> <TAB> else: <TAB> <TAB> <TAB> with self.assertRaises(ValueError): <TAB> <TAB> <TAB> <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_XML) <TAB> <TAB> plistlib.dumps(testString, fmt=plistlib.FMT_BINARY)",if data :,"if c != ""\r"" :",False,96.34,64.61,,,
"def remove_usernames ( self , username : SLT [ str ] ) - > None : <TAB> with self . __lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> f "" Can ' t set  { self . username_name }  in conjunction with (already set)  "" <TAB> <TAB> <TAB> <TAB> f "" { self . chat_id_name } s. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> parsed_username = self . _parse_username ( username ) <TAB> <TAB> self . _usernames - = parsed_username",if self . _usernames :,if self . _chat_ids :,False,97.1,72.93,,,
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> if isinstance(elem, str): <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> elif isinstance(elem, np.ndarray): <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size","elif isinstance ( elem , int ) :","elif isinstance ( elem , int ) :",True,100.0,74.35,,,
"def before_step ( self , step , feed_dict ) : <TAB> if step == 0 : <TAB> <TAB> for _type , mem in self . memories . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . gan . session . run ( tf . assign ( mem [ "" var "" ] , mem [ "" source "" ] ) )","if isinstance ( mem , dict ) :","if ""var"" in mem and ""source"" in mem :",False,87.98,62.98,,,
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> if not self . bytestream : <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1",if self . bitnum == 0 :,if self . bitnum == 8 :,False,99.0,73.85,,,
"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """""" Placeholder docstring """""" <TAB> for ( <TAB> <TAB> parameter_range_key , <TAB> <TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB> <TAB> if parameter_range_key == "" scaling_type "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for categorical_value in parameter_range_value: <TAB> <TAB> <TAB> <TAB> value_hp.validate(categorical_value) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else: <TAB> <TAB> <TAB> value_hp.validate(parameter_range_value)","if isinstance ( parameter_range_value , ( list , tuple ) ) :","if isinstance ( parameter_range_value , list ) :",False,97.15,97.01,,,
"def _trackA ( self , tracks ) : <TAB> try : <TAB> <TAB> track , start , end = self . featureA <TAB> <TAB> assert track in tracks <TAB> <TAB> return track <TAB> except TypeError : <TAB> <TAB> for track in tracks : <TAB> <TAB> <TAB> for feature_set in track . get_sets ( ) : <TAB> <TAB> <TAB> <TAB> if hasattr ( feature_set , "" features "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return track <TAB> <TAB> return None","if feature_set . features . get ( ""trackA"" ) :",if self . featureA in feature_set . features . values ( ) :,False,94.72,61.56,,,
"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB> <TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB> <TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( directory , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for file_path in walk ( full_name , path ) : <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> elif os . path . isfile ( full_name ) : <TAB> <TAB> <TAB> yield path",if os . path . isdir ( full_name ) :,if os . path . isdir ( full_name ) :,True,100.0,74.57,,,
"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> while not self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> args = self . _ipc_requests . get ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> for filename in args : <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB> <TAB> self . become_active_window ( ) <TAB> finally : <TAB> <TAB> self . after ( 50 , self . _poll_ipc_requests )",if self . _ipc_requests . empty ( ) :,if self . _ipc_requests . empty ( ) :,True,100.0,74.57,,,
"def test_read1 ( self ) : <TAB> self . test_write ( ) <TAB> blocks = [ ] <TAB> nread = 0 <TAB> with gzip . GzipFile ( self . filename , "" r "" ) as f : <TAB> <TAB> while True : <TAB> <TAB> <TAB> d = f . read1 ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> blocks . append ( d ) <TAB> <TAB> <TAB> nread + = len ( d ) <TAB> <TAB> <TAB> # Check that position was updated correctly (see issue10791). <TAB> <TAB> <TAB> self.assertEqual(f.tell(), nread) <TAB> self.assertEqual(b"""".join(blocks), data1 * 50)",if not d :,if not d :,True,100.0,74.4,,,
"def _target_generator ( self ) : <TAB> if self . _internal_target_generator is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> from . . . . model_zoo . rcnn . rpn . rpn_target import RPNTargetGenerator <TAB> <TAB> self . _internal_target_generator = RPNTargetGenerator ( <TAB> <TAB> <TAB> num_sample = self . _num_sample , <TAB> <TAB> <TAB> pos_iou_thresh = self . _pos_iou_thresh , <TAB> <TAB> <TAB> neg_iou_thresh = self . _neg_iou_thresh , <TAB> <TAB> <TAB> pos_ratio = self . _pos_ratio , <TAB> <TAB> <TAB> stds = self . _box_norm , <TAB> <TAB> <TAB> * * self . _kwargs <TAB> <TAB> ) <TAB> <TAB> return self . _internal_target_generator <TAB> else : <TAB> <TAB> return self . _internal_target_generator",if self . _box_norm is None :,if self . _net_none :,False,97.53,73.07,,,
"def time_left ( self ) : <TAB> """""" Return how many seconds are left until the timeout expires """""" <TAB> if self . is_non_blocking : <TAB> <TAB> return 0 <TAB> elif self . is_infinite : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> delta = self . target_time - self . TIME ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # clock jumped, recalculate <TAB> <TAB> <TAB> self.target_time = self.TIME() + self.duration <TAB> <TAB> <TAB> return self.duration <TAB> <TAB> else: <TAB> <TAB> <TAB> return max(0, delta)",if delta < 0 :,if delta > self . duration :,False,96.86,92.35,,,
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != "" __init__ "" : <TAB> <TAB> <TAB> if not private and name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls","if not meth . __name__ . startswith ( ""_"" ) :",if name in butnot :,False,89.86,63.65,,,
"def load_vocab ( vocab_file : str ) - > List : <TAB> """""" Loads a vocabulary file into a dictionary. """""" <TAB> vocab = collections . OrderedDict ( ) <TAB> with io . open ( vocab_file , "" r "" , encoding = "" UTF-8 "" ) as file : <TAB> <TAB> for num , line in enumerate ( file ) : <TAB> <TAB> <TAB> items = convert_to_unicode ( line . strip ( ) ) . split ( "" \t "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> token = items [ 0 ] <TAB> <TAB> <TAB> index = items [ 1 ] if len ( items ) == 2 else num <TAB> <TAB> <TAB> token = token . strip ( ) <TAB> <TAB> <TAB> vocab [ token ] = int ( index ) <TAB> <TAB> return vocab",if len ( items ) < 2 :,if len ( items ) > 2 :,False,98.88,98.75,,,
"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB> <TAB> new_slice_ = [ 0 ] <TAB> <TAB> offset = 0 <TAB> else : <TAB> <TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB> <TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_slice_ . append ( 0 ) <TAB> <TAB> elif offset < len ( slice_ ) : <TAB> <TAB> <TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB> <TAB> <TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_",if i == 0 :,if self . squeeze_dims [ i ] :,False,95.87,72.06,,,
"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB> <TAB> local_version = get_local_timestamp ( folder ) <TAB> <TAB> if remote_version > local_version : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> update_setter . set_value ( True ) <TAB> <TAB> <TAB> version_setter . set_value ( remote_version ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return False",if auto :,if auto :,True,100.0,74.37,,,
"def iter_content ( self , chunk_size_bytes ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = self . _fp . read ( chunk_size_bytes ) <TAB> <TAB> except IOError as e : <TAB> <TAB> <TAB> raise Fetcher . PermanentError ( <TAB> <TAB> <TAB> <TAB> "" Problem reading chunk from  {} :  {} "" . format ( self . _fp . name , e ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield data",if not data :,if not data :,True,100.0,74.3,,,
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """""" Convert args into gvariant. """""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> if isinstance ( arg , bool ) : <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> elif isinstance ( arg , ( int , float ) ) : <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( )","elif isinstance ( arg , str ) :","elif isinstance ( arg , str ) :",True,100.0,99.53,,,
"def _element_keywords ( cls , backend , elements = None ) : <TAB> "" Returns a dictionary of element names to allowed keywords "" <TAB> if backend not in Store . loaded_backends ( ) : <TAB> <TAB> return { } <TAB> mapping = { } <TAB> backend_options = Store . options ( backend ) <TAB> elements = elements if elements is not None else backend_options . keys ( ) <TAB> for element in elements : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> element = element if isinstance ( element , tuple ) else ( element , ) <TAB> <TAB> element_keywords = [ ] <TAB> <TAB> options = backend_options [ "" . "" . join ( element ) ] <TAB> <TAB> for group in Options . _option_groups : <TAB> <TAB> <TAB> element_keywords . extend ( options [ group ] . allowed_keywords ) <TAB> <TAB> mapping [ element [ 0 ] ] = element_keywords <TAB> return mapping",if element is None :,"if ""."" in element :",False,97.37,67.45,,,
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> if self . use_prop or self . get_prop_name ( ) : <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> elif isinstance ( value , float ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value","if isinstance ( value , int ) :","if isinstance ( value , int ) :",True,100.0,74.46,,,
"def _get_oshape ( indices_shape , depth , axis ) : <TAB> oshape = [ ] <TAB> true_axis = len ( indices_shape ) if axis == - 1 else axis <TAB> ndim = len ( indices_shape ) + 1 <TAB> indices_index = 0 <TAB> for i in range ( 0 , ndim ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> oshape . append ( depth ) <TAB> <TAB> else : <TAB> <TAB> <TAB> oshape . append ( indices_shape [ indices_index ] ) <TAB> <TAB> <TAB> indices_index + = 1 <TAB> return oshape",if indices_index == true_axis :,if i == true_axis :,False,97.12,73.03,,,
"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB> <TAB> value = value . upper ( ) <TAB> <TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value[len(prefix) :] <TAB> <TAB> <TAB> value = value.lstrip(""_"") <TAB> <TAB> if hasattr(self.group, value): <TAB> <TAB> <TAB> return getattr(self.group, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB> <TAB> return value",if value . startswith ( prefix ) :,if value . startswith ( prefix ) :,True,100.0,74.52,,,
"def shuffle_unison_inplace ( list_of_lists , random_state = None ) : <TAB> if list_of_lists : <TAB> <TAB> assert all ( len ( l ) == len ( list_of_lists [ 0 ] ) for l in list_of_lists ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> random_state . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p = np . random . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB> <TAB> return [ l [ p ] for l in list_of_lists ] <TAB> return None",if random_state :,if random_state is not None :,False,97.31,71.68,,,
"def _load_module ( self ) : <TAB> spec = self . default_module_spec <TAB> module_identifier = self . module_identifier <TAB> if module_identifier : <TAB> <TAB> impls = self . get_module_implementation_map ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ModuleNotFound ( <TAB> <TAB> <TAB> <TAB> "" Invalid module identifier  %r  in  %s "" <TAB> <TAB> <TAB> <TAB> % ( module_identifier , force_ascii ( repr ( self ) ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> spec = impls [ module_identifier ] <TAB> cls = load ( <TAB> <TAB> spec , context_explanation = "" Loading module for  %s "" % force_ascii ( repr ( self ) ) <TAB> ) <TAB> options = getattr ( self , self . module_options_field , None ) or { } <TAB> return cls ( self , options )",if module_identifier not in impls :,if module_identifier not in impls :,True,100.0,74.54,,,
"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB> <TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB> <TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( request , numbers . Integral ) : <TAB> <TAB> <TAB> <TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for j in range ( len ( data [ i ] ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data )",if i != 0 :,if shapes [ i ] is not None :,False,96.65,71.9,,,
"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB> <TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB> <TAB> <TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB> <TAB> <TAB> for ak in keys : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict ( ak ) <TAB> <TAB> <TAB> <TAB> <TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB> <TAB> <TAB> <TAB> <TAB> if ak not in res : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ak ) <TAB> <TAB> elif k not in res : <TAB> <TAB> <TAB> res . append ( k ) <TAB> return res","if c_date < ak [ ""last_rotated"" ] :","if c_date == ak [ ""CreateDate"" ] :",False,97.09,72.81,,,
"def _is_legacy_mode ( self , node ) : <TAB> """""" Checks if the ``ast.Call`` node ' s keywords signal using legacy mode. """""" <TAB> script_mode = False <TAB> py_version = "" py2 "" <TAB> for kw in node . keywords : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> script_mode = ( <TAB> <TAB> <TAB> <TAB> bool ( kw . value . value ) if isinstance ( kw . value , ast . NameConstant ) else True <TAB> <TAB> <TAB> ) <TAB> <TAB> if kw . arg == "" py_version "" : <TAB> <TAB> <TAB> py_version = kw . value . s if isinstance ( kw . value , ast . Str ) else "" py3 "" <TAB> return not ( py_version . startswith ( "" py3 "" ) or script_mode )","if kw . arg == ""script"" :","if kw . arg == ""script_mode"" :",False,98.37,85.48,,,
"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ] # type: List[V1EventTrigger] <TAB> for e in events: <TAB> <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB> <TAB> if not entity_ref: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e.kinds: <TAB> <TAB> <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <TAB> <TAB> <TAB> if status: <TAB> <TAB> <TAB> <TAB> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",if entity_ref not in statuses_by_refs :,if entity_ref not in statuses_by_refs :,True,100.0,74.41,,,
"def items ( self ) : <TAB> dict = { } <TAB> for userdir in self . XDG_DIRS . keys ( ) : <TAB> <TAB> prefix = self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = ( <TAB> <TAB> <TAB> <TAB> os . getenv ( "" HOME "" ) <TAB> <TAB> <TAB> <TAB> + "" / "" <TAB> <TAB> <TAB> <TAB> + "" / "" . join ( self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 1 : ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> path = self . get ( userdir ) . strip ( ' "" ' ) <TAB> <TAB> dict [ userdir ] = path <TAB> return dict . items ( )","if prefix == ""/"" :",if prefix :,False,97.14,70.05,,,
"def clean_objects ( string , common_attributes ) : <TAB> """""" Return object and attribute lists """""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words [ : - 1 ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB> if prefix_words_are_adj : <TAB> <TAB> <TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ string ] , [ ] <TAB> else : <TAB> <TAB> return [ string ] , [ ]",if att not in common_attributes :,if att not in common_attributes :,True,100.0,99.5,,,
"def extract_custom ( extractor , * args , * * kw ) : <TAB> for match in extractor ( * args , * * kw ) : <TAB> <TAB> msg = match [ 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unused = ( <TAB> <TAB> <TAB> <TAB> "" <unused singular (hash= %s )> "" % md5 ( msg [ 1 ] . encode ( "" utf8 "" ) ) . hexdigest ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> msg = ( unused , msg [ 1 ] , msg [ 2 ] ) <TAB> <TAB> <TAB> match = ( match [ 0 ] , match [ 1 ] , msg , match [ 3 ] ) <TAB> <TAB> yield match","if msg [ 0 ] == ""singular"" :","if isinstance ( msg , tuple ) and msg [ 0 ] == """" :",False,94.71,48.95,,,
"def test_convex_decomposition ( self ) : <TAB> mesh = g . get_mesh ( "" quadknot.obj "" ) <TAB> engines = [ ( "" vhacd "" , g . trimesh . interfaces . vhacd . exists ) ] <TAB> for engine , exists in engines : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g . log . warning ( "" skipping convex decomposition engine  %s "" , engine ) <TAB> <TAB> <TAB> continue <TAB> <TAB> g . log . info ( "" Testing convex decomposition with engine  %s "" , engine ) <TAB> <TAB> meshes = mesh . convex_decomposition ( engine = engine ) <TAB> <TAB> self . assertTrue ( len ( meshes ) > 1 ) <TAB> <TAB> for m in meshes : <TAB> <TAB> <TAB> self . assertTrue ( m . is_watertight ) <TAB> <TAB> g . log . info ( "" convex decomposition succeeded with  %s "" , engine )",if not exists :,if not exists :,True,100.0,74.59,,,
"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB> <TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB> <TAB> ) <TAB> <TAB> if hasConst : <TAB> <TAB> <TAB> idx - = 1 <TAB> <TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB> <TAB> _lt = _l . __class__ <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ostream . write ( ""  -  "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ostream . write ( ""  +  "" )","if _lt . __name__ == ""float"" :",if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) :,False,91.3,63.3,,,
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> if item < 0 : <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> if i < len ( data ) and i > - 1 : <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None",if is_tuple :,if is_tuple :,True,100.0,74.63,,,
"def process_error ( self , data ) : <TAB> if data . get ( "" error "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AuthCanceled ( self , data . get ( "" error_description "" , "" "" ) ) <TAB> <TAB> raise AuthFailed ( self , data . get ( "" error_description "" ) or data [ "" error "" ] ) <TAB> elif "" denied "" in data : <TAB> <TAB> raise AuthCanceled ( self , data [ "" denied "" ] )","if ""error_description"" in data :","if ""denied"" in data [ ""error"" ] or ""cancelled"" in data [ ""error"" ] :",False,85.16,64.78,,,
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> if char == "" > "" : <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" < "" : <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval","elif char == ""&"" :","elif char == "" "" :",False,99.17,73.71,,,
"def retry_http_digest_auth ( self , req , auth ) : <TAB> token , challenge = auth . split ( "" "" , 1 ) <TAB> chal = parse_keqv_list ( parse_http_list ( challenge ) ) <TAB> auth = self . get_authorization ( req , chal ) <TAB> if auth : <TAB> <TAB> auth_val = "" Digest  %s "" % auth <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> req . add_unredirected_header ( self . auth_header , auth_val ) <TAB> <TAB> resp = self . parent . open ( req ) <TAB> <TAB> return resp","if req . headers . get ( self . auth_header , None ) == auth_val :","if req . headers . get ( self . auth_header , None ) == auth_val :",True,100.0,74.42,,,
"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB> <TAB> sockname = None <TAB> <TAB> try : <TAB> <TAB> <TAB> sockname = self . sock . getsockname ( ) <TAB> <TAB> except ( socket . error , OSError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> self . sock . close ( ) <TAB> <TAB> if type ( sockname ) is str : <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os.remove(sockname) <TAB> self.sock = None",if os . path . exists ( sockname ) :,if os . path . exists ( sockname ) :,True,100.0,74.44,,,
"def to_nurbs ( self , curves ) : <TAB> result = [ ] <TAB> for i , c in enumerate ( curves ) : <TAB> <TAB> nurbs = SvNurbsCurve . to_nurbs ( c ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( f "" Curve # { i }  -  { c }  - can not be converted to NURBS! "" ) <TAB> <TAB> result . append ( nurbs ) <TAB> return result",if nurbs is None :,if nurbs is None :,True,100.0,74.22,,,
"def handle_1_roomid_raffle ( self , i ) : <TAB> if i [ 1 ] in [ "" handle_1_room_TV "" , "" handle_1_room_captain "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self . notify ( "" post_watching_history "" , i [ 0 ] ) <TAB> <TAB> <TAB> await self . notify ( i [ 1 ] , i [ 0 ] , i [ 2 ] ) <TAB> else : <TAB> <TAB> print ( "" hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh "" , i )","if i [ 0 ] == ""post_watching_history"" :","if await self . notify ( ""check_if_normal_room"" , i [ 0 ] , - 1 ) :",False,85.75,67.01,,,
"def init_ps_var_partition ( self ) : <TAB> ps_vars = { } <TAB> for v in self . _non_embed_vars . values ( ) : <TAB> <TAB> if v . name not in self . _var_to_ps : <TAB> <TAB> <TAB> self . _var_to_ps [ v . name ] = string_to_id ( v . name , self . _ps_num ) <TAB> <TAB> ps_id = self . _var_to_ps [ v . name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ps_vars [ ps_id ] = [ v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ps_vars [ ps_id ] . append ( v ) <TAB> self . _ps_vars = ps_vars",if ps_id not in ps_vars :,if ps_id not in ps_vars :,True,100.0,74.43,,,
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if name . endswith ( "".py"" ) :","if ""do_build"" not in name and ""do_populate_sdk"" not in name :",False,88.55,65.46,,,
"def setSelectedLabelState ( self , p ) : # selected, disabled <TAB> c = self.c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c.edit_widget(p): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g.trace(self.trace_n, c.edit_widget(p), p) <TAB> <TAB> <TAB> # g.trace(g.callers(6)) <TAB> <TAB> <TAB> self.trace_n += 1 <TAB> <TAB> self.setDisabledHeadlineColors(p)",if self . trace_n < 4 :,if 0 :,False,94.23,69.26,,,
"def setSelectedLabelState ( self , p ) : # selected, disabled <TAB> c = self.c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c.edit_widget(p): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g.trace(self.trace_n, c.edit_widget(p), p) <TAB> <TAB> <TAB> # g.trace(g.callers(6)) <TAB> <TAB> <TAB> self.trace_n += 1 <TAB> <TAB> self.setDisabledHeadlineColors(p)",if self . trace_n < 4 :,"if ( not task_types or task [ ""type"" ] . lower ( ) in task_types )",False,86.04,51.7,,,
"def GenerateVector ( self , hits , vector , level ) : <TAB> """""" Generate possible hit vectors which match the rules. """""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if item < vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> if level + 1 == len ( hits ) : <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result",if vector :,if vector :,True,100.0,99.57,,,
def _transmit_from_storage ( self ) - > None : <TAB> for blob in self . storage . gets ( ) : <TAB> <TAB> # give a few more seconds for blob lease operation <TAB> <TAB> # to reduce the chance of race (for perf consideration) <TAB> <TAB> if blob.lease(self._timeout + 5): <TAB> <TAB> <TAB> envelopes = [TelemetryItem(**x) for x in blob.get()] <TAB> <TAB> <TAB> result = self._transmit(list(envelopes)) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> blob.lease(1) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> blob.delete(),if result :,if result == ExportResult . FAILED_RETRYABLE :,False,95.54,96.35,,,
"def load_dictionary ( file ) : <TAB> oui = { } <TAB> with open ( file , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = line . split ( "" (hex) "" ) <TAB> <TAB> <TAB> <TAB> key = data [ 0 ] . replace ( "" - "" , "" : "" ) . lower ( ) . strip ( ) <TAB> <TAB> <TAB> <TAB> company = data [ 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> oui [ key ] = company <TAB> return oui","if line . startswith ( ""company"" ) :","if ""(hex)"" in line :",False,94.95,71.66,,,
"def _yield_minibatches_idx ( self , rgen , n_batches , data_ary , shuffle = True ) : <TAB> indices = np . arange ( data_ary . shape [ 0 ] ) <TAB> if shuffle : <TAB> <TAB> indices = rgen . permutation ( indices ) <TAB> if n_batches > 1 : <TAB> <TAB> remainder = data_ary . shape [ 0 ] % n_batches <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> minis = np . array_split ( indices [ : - remainder ] , n_batches ) <TAB> <TAB> <TAB> minis [ - 1 ] = np . concatenate ( ( minis [ - 1 ] , indices [ - remainder : ] ) , axis = 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> minis = np . array_split ( indices , n_batches ) <TAB> else : <TAB> <TAB> minis = ( indices , ) <TAB> for idx_batch in minis : <TAB> <TAB> yield idx_batch",if remainder > 0 :,if remainder :,False,98.52,73.79,,,
"def canonical_custom_headers ( self , headers ) : <TAB> hoi = [ ] <TAB> custom_headers = { } <TAB> for key in headers : <TAB> <TAB> lk = key . lower ( ) <TAB> <TAB> if headers [ key ] is not None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> custom_headers [ lk ] = "" , "" . join ( v . strip ( ) for v in headers . get_all ( key ) ) <TAB> sorted_header_keys = sorted ( custom_headers . keys ( ) ) <TAB> for key in sorted_header_keys : <TAB> <TAB> hoi . append ( "" %s : %s "" % ( key , custom_headers [ key ] ) ) <TAB> return "" \n "" . join ( hoi )",if lk in custom_headers :,"if lk . startswith ( ""x-amz-"" ) :",False,95.67,67.15,,,
"def validate ( self , data ) : <TAB> if not data . get ( "" reason "" ) : <TAB> <TAB> # If reason is not provided, message is required and can not be <TAB> <TAB> # null or blank. <TAB> <TAB> message = data.get(""message"") <TAB> <TAB> if not message: <TAB> <TAB> <TAB> if ""message"" not in data: <TAB> <TAB> <TAB> <TAB> msg = serializers.Field.default_error_messages[""required""] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> msg = serializers.Field.default_error_messages[""null""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> msg = serializers.CharField.default_error_messages[""blank""] <TAB> <TAB> <TAB> raise serializers.ValidationError({""message"": [msg]}) <TAB> return data","elif ""null"" in data :",elif message is None :,False,97.22,68.4,,,
def tearDown ( self ) : <TAB> try : <TAB> <TAB> os . chdir ( self . cwd ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . remove ( self . pythonexe ) <TAB> <TAB> test_support . rmtree ( self . parent_dir ) <TAB> finally : <TAB> <TAB> BaseTestCase . tearDown ( self ),if self . pythonexe :,if self . pythonexe != sys . executable :,False,92.81,66.73,,,
"def update ( self , value , label ) : <TAB> if self . _disabled : <TAB> <TAB> return <TAB> try : <TAB> <TAB> self . _progress . value = value <TAB> <TAB> self . _label . value = label <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _displayed = True <TAB> <TAB> <TAB> display_widget ( self . _widget ) <TAB> except Exception as e : <TAB> <TAB> self . _disabled = True <TAB> <TAB> logger . exception ( e ) <TAB> <TAB> wandb . termwarn ( "" Unable to render progress bar, see the user log for details "" )",if self . _displayed :,if not self . _displayed :,False,98.44,73.08,,,
"def GetBinaryOperationBinder ( self , op ) : <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _binaryOperationBinders [ op ] <TAB> <TAB> b = runtime . SymplBinaryOperationBinder ( op ) <TAB> <TAB> self . _binaryOperationBinders [ op ] = b <TAB> return b",if op in self . _binaryOperationBinders :,if self . _binaryOperationBinders . ContainsKey ( op ) :,False,90.62,67.34,,,
"def apply ( self , l , b , evaluation ) : <TAB> "" FromDigits[l_, b_] "" <TAB> if l . get_head_name ( ) == "" System`List "" : <TAB> <TAB> value = Integer ( 0 ) <TAB> <TAB> for leaf in l . leaves : <TAB> <TAB> <TAB> value = Expression ( "" Plus "" , Expression ( "" Times "" , value , b ) , leaf ) <TAB> <TAB> return value <TAB> elif isinstance ( l , String ) : <TAB> <TAB> value = FromDigits . _parse_string ( l . get_string_value ( ) , b ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> evaluation . message ( "" FromDigits "" , "" nlst "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value <TAB> else : <TAB> <TAB> evaluation . message ( "" FromDigits "" , "" nlst "" )",if value is None :,if value is None :,True,100.0,74.57,,,
"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self.send_queue.get(True, 6.0) <TAB> <TAB> <TAB> if self.socket is not None: <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self.socket.sendall(request) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.send_queue.task_done() <TAB> <TAB> except queue.Empty: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> self.stop_event.set()",if self . send_queue . empty ( ) :,if self . send_queue is not None :,False,97.62,71.63,,,
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if not rline . startswith ( eline ) :,if eline not in rline :,False,96.74,72.6,,,
"def init_weights ( self ) : <TAB> """""" Initialize model weights. """""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 , bias = 0 )","if isinstance ( m , nn . ConvTranspose2d ) :","if isinstance ( m , nn . ConvTranspose2d ) :",True,100.0,74.42,,,
"def filter_rel_attrs ( field_name , * * rel_attrs ) : <TAB> clean_dict = { } <TAB> for k , v in rel_attrs . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> splitted_key = k . split ( "" __ "" ) <TAB> <TAB> <TAB> key = "" __ "" . join ( splitted_key [ 1 : ] ) <TAB> <TAB> <TAB> clean_dict [ key ] = v <TAB> <TAB> else : <TAB> <TAB> <TAB> clean_dict [ k ] = v <TAB> return clean_dict",if field_name in k :,"if k . startswith ( field_name + ""__"" ) :",False,91.9,63.8,,,
"def cancel ( self ) : <TAB> with self . _condition : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _squash ( <TAB> <TAB> <TAB> <TAB> state_root = self . _previous_state_hash , <TAB> <TAB> <TAB> <TAB> context_ids = [ self . _previous_context_id ] , <TAB> <TAB> <TAB> <TAB> persist = False , <TAB> <TAB> <TAB> <TAB> clean_up = True , <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _cancelled = True <TAB> <TAB> self . _condition . notify_all ( )",if self . _previous_context_id :,if not self . _cancelled and not self . _final and self . _previous_context_id :,False,92.31,67.55,,,
"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB> <TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> level_ref + = len ( levels ) <TAB> <TAB> if not ( 0 < = level_ref < len ( levels ) ) : <TAB> <TAB> <TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB> <TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) )",if level_ref < 0 :,if level_ref < 0 :,True,100.0,74.44,,,
"def parse_node ( self , node , alias_map = None , conv = None ) : <TAB> sql , params , unknown = self . _parse ( node , alias_map , conv ) <TAB> if unknown and conv and params : <TAB> <TAB> params = [ conv . db_value ( i ) for i in params ] <TAB> if isinstance ( node , Node ) : <TAB> <TAB> if node . _negated : <TAB> <TAB> <TAB> sql = "" NOT  %s "" % sql <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sql = "" "" . join ( ( sql , "" AS "" , node . _alias ) ) <TAB> <TAB> if node . _ordering : <TAB> <TAB> <TAB> sql = "" "" . join ( ( sql , node . _ordering ) ) <TAB> return sql , params",if node . _alias :,if node . _alias :,True,100.0,74.56,,,
"def parse_object_id ( _ , values ) : <TAB> if values : <TAB> <TAB> for key in values : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> val = values [ key ] <TAB> <TAB> <TAB> <TAB> if len ( val ) > 10 : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values [ key ] = utils . ObjectIdSilent ( val ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values [ key ] = None",if key in values :,"if key . endswith ( ""_id"" ) :",False,94.46,62.65,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.35,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,"if i_type [ 0 : 3 ] == ""cce"" :",False,91.97,61.81,,,
"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB> <TAB> <TAB> simple_colorize ( todesc , "" description "" ) , <TAB> <TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB> <TAB> if line is None : <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",if i == 0 :,if i > 0 :,False,98.62,73.58,,,
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> if "" % "" not in pattern : <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","elif key in ( ""TIA64N"" , ""{^LN-BEG}TIA64N"" , ""{^LN-BEG}TIA64N"" ) :","elif key in ( ""TAI64N"" , ""{^LN-BEG}TAI64N"" , ""^TAI64N"" ) :",False,95.1,72.67,,,
"def ref_max_pooling_2d ( x , kernel , stride , ignore_border , pad ) : <TAB> y = [ ] <TAB> for xx in x . reshape ( ( - 1 , ) + x . shape [ - 3 : ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> xx = xx [ np . newaxis ] <TAB> <TAB> y + = [ <TAB> <TAB> <TAB> refs . pooling_2d ( xx , "" max "" , kernel , stride , pad , ignore_border ) [ np . newaxis ] <TAB> <TAB> ] <TAB> y = np . vstack ( y ) <TAB> if x . ndim == 2 : <TAB> <TAB> y = np . squeeze ( y , 1 ) <TAB> return y . reshape ( x . shape [ : - 3 ] + y . shape [ 1 : ] )",if xx . ndim == 1 :,if xx . ndim == 2 :,False,98.75,73.73,,,
"def show_topics ( ) : <TAB> """""" prints all available miscellaneous help topics. """""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB> <TAB> if not os . path . isdir ( pp ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os . listdir ( pp ) <TAB> <TAB> for pn in content : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print ( name )","if pn . endswith ( ""./"" ) :","if ""."" in pn :",False,95.1,94.53,,,
"def justify_toggle_auto ( self , event = None ) : <TAB> c = self <TAB> if c . editCommands . autojustify == 0 : <TAB> <TAB> c . editCommands . autojustify = abs ( c . config . getInt ( "" autojustify "" ) or 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g . es ( "" Autojustify on, @int autojustify ==  %s "" % c . editCommands . autojustify ) <TAB> <TAB> else : <TAB> <TAB> <TAB> g . es ( "" Set @int autojustify in @settings "" ) <TAB> else : <TAB> <TAB> c . editCommands . autojustify = 0 <TAB> <TAB> g . es ( "" Autojustify off "" )",if abs ( c . editCommands . autojustify ) > 0 :,if c . editCommands . autojustify :,False,95.34,72.23,,,
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> elif token . token_type == TOKEN_VAR : <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars",if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_TEXT :,True,100.0,74.38,,,
"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB> <TAB> if operation [ "" type "" ] == "" crop "" : <TAB> <TAB> <TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB> <TAB> <TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> width = operation [ "" width "" ] <TAB> <TAB> <TAB> height = operation [ "" height "" ] <TAB> return ( width , height )","elif operation [ ""type"" ] == ""crop"" :","if operation [ ""type"" ] == ""resize"" :",False,96.84,72.03,,,
"def get_eval_matcher ( self ) : <TAB> if isinstance ( self . data [ "" match "" ] , str ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values = [ "" explicitDeny "" , "" implicitDeny "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> values = [ "" allowed "" ] <TAB> <TAB> vf = ValueFilter ( <TAB> <TAB> <TAB> { "" type "" : "" value "" , "" key "" : "" EvalDecision "" , "" value "" : values , "" op "" : "" in "" } <TAB> <TAB> ) <TAB> else : <TAB> <TAB> vf = ValueFilter ( self . data [ "" match "" ] ) <TAB> vf . annotate = False <TAB> return vf","if self . data [ ""match"" ] == ""explicitDeny"" :","if self . data [ ""match"" ] == ""denied"" :",False,98.65,73.57,,,
"def test_training ( self ) : <TAB> if not self . model_tester . is_training : <TAB> <TAB> return <TAB> config , inputs_dict = self . model_tester . prepare_config_and_inputs_for_common ( ) <TAB> config . return_dict = True <TAB> for model_class in self . all_model_classes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> model = model_class ( config ) <TAB> <TAB> model . to ( torch_device ) <TAB> <TAB> model . train ( ) <TAB> <TAB> inputs = self . _prepare_for_class ( inputs_dict , model_class , return_labels = True ) <TAB> <TAB> loss = model ( * * inputs ) . loss <TAB> <TAB> loss . backward ( )",if not model_class . supports_train :,if model_class in MODEL_MAPPING . values ( ) :,False,94.95,70.95,,,
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> elif self . arch == "" amd64 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True )","if self . arch == ""i386"" :","if self . arch == ""i386"" :",True,100.0,74.55,,,
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize )",if size == 0 :,if size == 0 :,True,100.0,74.56,,,
"def __new__ ( cls , dependencies ) : <TAB> deps = check . list_param ( dependencies , "" dependencies "" , of_type = DependencyDefinition ) <TAB> seen = { } <TAB> for dep in deps : <TAB> <TAB> key = dep . solid + "" : "" + dep . output <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise DagsterInvalidDefinitionError ( <TAB> <TAB> <TAB> <TAB> ' Duplicate dependencies on solid  "" {dep.solid} ""  output  "" {dep.output} "" ' <TAB> <TAB> <TAB> <TAB> "" used in the same MultiDependencyDefinition. "" . format ( dep = dep ) <TAB> <TAB> <TAB> ) <TAB> <TAB> seen [ key ] = True <TAB> return super ( MultiDependencyDefinition , cls ) . __new__ ( cls , deps )",if key in seen :,if key in seen :,True,100.0,74.5,,,
"def get_explanation ( self , spec ) : <TAB> """""" Expand an explanation. """""" <TAB> if spec : <TAB> <TAB> try : <TAB> <TAB> <TAB> a = self . dns_txt ( spec ) <TAB> <TAB> <TAB> if len ( a ) == 1 : <TAB> <TAB> <TAB> <TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB> <TAB> except PermError : <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> el<IF-STMT> <TAB> <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if len ( spec ) == 0 :,if self . strict > 1 :,False,93.18,95.09,,,
"def build ( self ) : <TAB> if self . args . get ( "" sle_id "" ) : <TAB> <TAB> self . process_sle_against_current_voucher ( ) <TAB> else : <TAB> <TAB> entries_to_fix = self . get_future_entries_to_fix ( ) <TAB> <TAB> i = 0 <TAB> <TAB> while i < len ( entries_to_fix ) : <TAB> <TAB> <TAB> sle = entries_to_fix [ i ] <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> self . process_sle ( sle ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . get_dependent_entries_to_fix ( entries_to_fix , sle ) <TAB> if self . exceptions : <TAB> <TAB> self . raise_exceptions ( ) <TAB> self . update_bin ( )","if self . args . get ( ""dependent"" ) :",if sle . dependant_sle_voucher_detail_no :,False,94.7,63.32,,,
"def ValidateStopLatitude ( self , problems ) : <TAB> if self . stop_lat is not None : <TAB> <TAB> value = self . stop_lat <TAB> <TAB> try : <TAB> <TAB> <TAB> if not isinstance ( value , ( float , int ) ) : <TAB> <TAB> <TAB> <TAB> self . stop_lat = util . FloatStringToFloat ( value , problems ) <TAB> <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> <TAB> problems . InvalidValue ( "" stop_lat "" , value ) <TAB> <TAB> <TAB> del self . stop_lat <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> problems . InvalidValue ( "" stop_lat "" , value )",if value is not None :,if self . stop_lat > 90 or self . stop_lat < - 90 :,False,90.95,69.05,,,
"def set ( self , obj , * * kwargs ) : <TAB> """""" Check for missing event functions and substitute these with """""" <TAB> """""" the ignore method """""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB> <TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k1 in self . combinations [ k ] : <TAB> <TAB> <TAB> <TAB> if not hasattr ( self , k1 ) : <TAB> <TAB> <TAB> <TAB> <TAB> setattr ( self , k1 , ignore )",if k in self . combinations :,if k in self . combinations :,True,100.0,99.47,,,
"def split ( self , duration , include_remainder = True ) : <TAB> # Convert seconds to timedelta, if appropriate. <TAB> duration = _seconds_or_timedelta(duration) <TAB> if duration <= timedelta(seconds=0): <TAB> <TAB> raise ValueError(""cannot call split with a non-positive timedelta"") <TAB> start = self.start <TAB> while start < self.end: <TAB> <TAB> if start + duration <= self.end: <TAB> <TAB> <TAB> yield MayaInterval(start, start + duration) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield MayaInterval(start, self.end) <TAB> <TAB> start += duration",if include_remainder :,elif include_remainder :,False,98.45,72.49,,,
"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB> <TAB> if issubclass ( layout_object . __class__ , clz ) : <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gf = get_first_field ( layout_object , clz ) <TAB> <TAB> <TAB> if gf : <TAB> <TAB> <TAB> <TAB> return gf","if isinstance ( layout_object , fields . Field ) :","elif hasattr ( layout_object , ""get_field_names"" ) :",False,90.62,60.29,,,
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> if "" % "" not in pattern : <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""{^LN-BEG}"" ) :","if key in ( ""EPOCH"" , ""{^LN-BEG}EPOCH"" , ""^EPOCH"" ) :",False,97.71,73.79,,,
"def findOwningViewController ( self , object ) : <TAB> while object : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> description = fb . evaluateExpressionValue ( object ) . GetObjectDescription ( ) <TAB> <TAB> <TAB> print ( "" Found the owning view controller. \n {} "" . format ( description ) ) <TAB> <TAB> <TAB> cmd = ' echo  {}  | tr -d  "" \n ""  | pbcopy ' . format ( object ) <TAB> <TAB> <TAB> os . system ( cmd ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> object = self . nextResponder ( object ) <TAB> print ( "" Could not find an owning view controller "" )",if fb . evaluateExpressionValue ( object ) . IsPresent ( ) :,if self . isViewController ( object ) :,False,94.85,71.6,,,
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> if idx == num : <TAB> <TAB> <TAB> return element <TAB> <TAB> if element [ 3 ] and element [ 4 ] : <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx",if i < 0 :,"if not isinstance ( i , int ) :",False,95.31,70.33,,,
"def promtool ( * * kwargs ) : <TAB> key = "" prometheus:promtool "" <TAB> try : <TAB> <TAB> path = pathlib . Path ( util . setting ( key ) ) <TAB> except TypeError : <TAB> <TAB> yield checks . Warning ( <TAB> <TAB> <TAB> "" Missing setting for  %s  in  %s "" % ( key , settings . PROMGEN_CONFIG_FILE ) , <TAB> <TAB> <TAB> id = "" promgen.W001 "" , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield checks . Warning ( "" Unable to execute file  %s "" % path , id = "" promgen.W003 "" )",if not util . exists ( path ) :,"if not os . access ( path , os . X_OK ) :",False,93.29,70.45,,,
"def parse_config ( schema , config ) : <TAB> schemaparser = ConfigParser ( ) <TAB> schemaparser . readfp ( StringIO ( schema ) ) <TAB> cfgparser = ConfigParser ( ) <TAB> cfgparser . readfp ( StringIO ( config ) ) <TAB> result = { } <TAB> for section in cfgparser . sections ( ) : <TAB> <TAB> result_section = { } <TAB> <TAB> schema = { } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> schema = dict ( schemaparser . items ( section ) ) <TAB> <TAB> for key , value in cfgparser . items ( section ) : <TAB> <TAB> <TAB> converter = converters [ schema . get ( key , "" string "" ) ] <TAB> <TAB> <TAB> result_section [ key ] = converter ( value ) <TAB> <TAB> result [ section ] = result_section <TAB> return result",if section in schemaparser . sections ( ) :,if section in schemaparser . sections ( ) :,True,100.0,74.56,,,
"def validate_arguments ( args ) : <TAB> if args . num_pss < 1 : <TAB> <TAB> print ( "" Value error: must have ore than one parameter servers. "" ) <TAB> <TAB> exit ( 1 ) <TAB> if not GPU_IDS : <TAB> <TAB> num_cpus = multiprocessing . cpu_count ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Value error: there are  %s  available CPUs but you are requiring  %s . "" <TAB> <TAB> <TAB> <TAB> % ( num_cpus , args . cpu_trainers ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> exit ( 1 ) <TAB> if not os . path . isfile ( args . file ) : <TAB> <TAB> print ( "" Value error: model trainning file does not exist "" ) <TAB> <TAB> exit ( 1 )",if num_cpus > args . cpu_trainers :,if args . cpu_trainers > num_cpus :,False,97.67,72.93,,,
"def validate_arguments ( args ) : <TAB> if args . num_pss < 1 : <TAB> <TAB> print ( "" Value error: must have ore than one parameter servers. "" ) <TAB> <TAB> exit ( 1 ) <TAB> if not GPU_IDS : <TAB> <TAB> num_cpus = multiprocessing . cpu_count ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Value error: there are  %s  available CPUs but you are requiring  %s . "" <TAB> <TAB> <TAB> <TAB> % ( num_cpus , args . cpu_trainers ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> exit ( 1 ) <TAB> if not os . path . isfile ( args . file ) : <TAB> <TAB> print ( "" Value error: model trainning file does not exist "" ) <TAB> <TAB> exit ( 1 )",if num_cpus > args . cpu_trainers :,elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] :,False,92.8,69.98,,,
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> if item_key != "" sourceVault "" : <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] )","if obj [ ""id"" ] :","if obj [ ""id"" ] :",True,100.0,74.58,,,
"def reformatBody ( self , event = None ) : <TAB> """""" Reformat all paragraphs in the body. """""" <TAB> c , p = self , self . p <TAB> undoType = "" reformat-body "" <TAB> w = c . frame . body . wrapper <TAB> c . undoer . beforeChangeGroup ( p , undoType ) <TAB> w . setInsertPoint ( 0 ) <TAB> while 1 : <TAB> <TAB> progress = w . getInsertPoint ( ) <TAB> <TAB> c . reformatParagraph ( event , undoType = undoType ) <TAB> <TAB> ins = w . getInsertPoint ( ) <TAB> <TAB> s = w . getAllText ( ) <TAB> <TAB> w . setInsertPoint ( ins ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> c . undoer . afterChangeGroup ( p , undoType )",if s == s :,if ins <= progress or ins >= len ( s ) :,False,93.38,89.12,,,
"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB> <TAB> content . append ( project . readme . path . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB> <TAB> if ( path / fname ) . exists ( ) : <TAB> <TAB> <TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB> <TAB> for fpath in package : <TAB> <TAB> <TAB> fpath = fpath . relative_to ( project . package . path ) <TAB> <TAB> <TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content )",if project . readme . to_rst ( ) :,"if project . readme . markup != ""rst"" :",False,97.02,68.99,,,
"def __init__ ( self , response ) : <TAB> error = "" {} {} "" . format ( response . status_code , response . reason ) <TAB> extra = [ ] <TAB> try : <TAB> <TAB> response_json = response . json ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error = "" "" . join ( error [ "" message "" ] for error in response_json [ "" error_list "" ] ) <TAB> <TAB> <TAB> extra = [ <TAB> <TAB> <TAB> <TAB> error [ "" extra "" ] <TAB> <TAB> <TAB> <TAB> for error in response_json [ "" error_list "" ] <TAB> <TAB> <TAB> <TAB> if "" extra "" in error <TAB> <TAB> <TAB> ] <TAB> except JSONDecodeError : <TAB> <TAB> pass <TAB> super ( ) . __init__ ( response = response , error = error , extra = extra )","if ""error_list"" in response_json :","if ""error_list"" in response_json :",True,100.0,74.57,,,
"def handle_event ( self , fileno = None , events = None ) : <TAB> if self . _state == RUN : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _it = self . _process_result ( 0 ) # non-blocking <TAB> <TAB> try: <TAB> <TAB> <TAB> next(self._it) <TAB> <TAB> except (StopIteration, CoroStop): <TAB> <TAB> <TAB> self._it = None",if self . _it is None :,if self . _it is None :,True,100.0,74.05,,,
"def find_query ( self , needle , haystack ) : <TAB> try : <TAB> <TAB> import pinyin <TAB> <TAB> haystack_py = pinyin . get_initial ( haystack , "" "" ) <TAB> <TAB> needle_len = len ( needle ) <TAB> <TAB> start = 0 <TAB> <TAB> result = [ ] <TAB> <TAB> while True : <TAB> <TAB> <TAB> found = haystack_py . find ( needle , start ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> result . append ( ( found , needle_len ) ) <TAB> <TAB> <TAB> start = found + needle_len <TAB> <TAB> return result <TAB> except : <TAB> <TAB> return None",if found == - 1 :,if found < 0 :,False,97.17,72.68,,,
"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable ( result ) : <TAB> <TAB> <TAB> <TAB> result = result ( rv ) <TAB> <TAB> <TAB> if not isinstance ( result , basestring ) : <TAB> <TAB> <TAB> <TAB> from werkzeug . http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date ( result ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> rv . headers [ "" Last-Modified "" ] = result <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . getLogger ( __name__ ) . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv","if result != rv . headers [ ""Last-Modified"" ] :",if result :,False,96.13,67.42,,,
"def check_require ( require_modules , require_lines ) : <TAB> for require_module in require_modules : <TAB> <TAB> st = try_import ( require_module ) <TAB> <TAB> if st == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" installed  {} :  {} \n "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> require_module , require_lines [ require_module ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif st == 2 : <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" failed installed  {} :  {} \n "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> require_module , require_lines [ require_module ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if st == 1 :,elif st == 1 :,False,99.03,73.33,,,
"def bundle_directory ( self , dirpath ) : <TAB> """""" Bundle all modules/packages in the given directory. """""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> if nm . startswith ( "" . "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . bundle_module ( itempath )","elif os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :","elif nm . endswith ( "".py"" ) :",False,90.31,95.77,,,
"def _find_root ( ) : <TAB> test_dirs = [ "" Src "" , "" Build "" , "" Package "" , "" Tests "" , "" Util "" ] <TAB> root = os . getcwd ( ) <TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> while not test : <TAB> <TAB> last_root = root <TAB> <TAB> root = os . path . dirname ( root ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" Root not found "" ) <TAB> <TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> return root",if root == last_root :,if root == last_root :,True,100.0,74.55,,,
"def findMarkForUnitTestNodes ( self ) : <TAB> """""" return the position of *all* non-ignored @mark-for-unit-test nodes. """""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB> <TAB> if p . v in seen : <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> seen . append ( p . v ) <TAB> <TAB> <TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result . append ( p . copy ( ) ) <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> p . moveToThreadNext ( ) <TAB> return result","elif p . h == ""@mark-for-unit-test"" :","elif p . h . startswith ( ""@mark-for-unit-tests"" ) :",False,96.6,97.57,,,
"def startTagFrameset ( self , token ) : <TAB> self . parser . parseError ( "" unexpected-start-tag "" , { "" name "" : "" frameset "" } ) <TAB> if len ( self . tree . openElements ) == 1 or self . tree . openElements [ 1 ] . name != "" body "" : <TAB> <TAB> assert self . parser . innerHTML <TAB> elif not self . parser . framesetOK : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . tree . openElements [ 1 ] . parent . removeChild ( self . tree . openElements [ 1 ] ) <TAB> <TAB> while self . tree . openElements [ - 1 ] . name != "" html "" : <TAB> <TAB> <TAB> self . tree . openElements . pop ( ) <TAB> <TAB> self . tree . insertElement ( token ) <TAB> <TAB> self . parser . phase = self . parser . phases [ "" inFrameset "" ]","if self . tree . openElements [ 1 ] . name == ""body"" :",if self . tree . openElements [ 1 ] . parent :,False,96.71,69.72,,,
"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int ( i , 2 ) <TAB> <TAB> if val > 255 or val < 0 : <TAB> <TAB> <TAB> return None <TAB> <TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB> <TAB> ret = bytes ( ret ) <TAB> <TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB> <TAB> return ret","if i == """" :",if len ( i ) == 0 :,False,95.59,63.06,,,
"def generator ( self , data ) : <TAB> for sock in data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> offset = sock . obj_offset <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = sock . obj_vm . vtop ( sock . obj_offset ) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> Address ( offset ) , <TAB> <TAB> <TAB> <TAB> int ( sock . Pid ) , <TAB> <TAB> <TAB> <TAB> int ( sock . LocalPort ) , <TAB> <TAB> <TAB> <TAB> int ( sock . Protocol ) , <TAB> <TAB> <TAB> <TAB> str ( protos . protos . get ( sock . Protocol . v ( ) , "" - "" ) ) , <TAB> <TAB> <TAB> <TAB> str ( sock . LocalIpAddress ) , <TAB> <TAB> <TAB> <TAB> str ( sock . CreateTime ) , <TAB> <TAB> <TAB> ] , <TAB> <TAB> )",if sock . obj_vm is None :,if not self . _config . PHYSICAL_OFFSET :,False,96.34,72.25,,,
"def __init__ ( self , num_bits = 4 , always_apply = False , p = 0.5 ) : <TAB> super ( Posterize , self ) . __init__ ( always_apply , p ) <TAB> if isinstance ( num_bits , ( list , tuple ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . num_bits = [ to_tuple ( i , 0 ) for i in num_bits ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . num_bits = to_tuple ( num_bits , 0 ) <TAB> else : <TAB> <TAB> self . num_bits = to_tuple ( num_bits , num_bits )",if always_apply :,if len ( num_bits ) == 3 :,False,94.05,70.92,,,
"def tearDown ( self ) : <TAB> """""" Just in case yn00 creates some junk files, do a clean-up. """""" <TAB> del_files = [ self . out_file , "" 2YN.dN "" , "" 2YN.dS "" , "" 2YN.t "" , "" rst "" , "" rst1 "" , "" rub "" ] <TAB> for filename in del_files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> if os . path . exists ( self . working_dir ) : <TAB> <TAB> for filename in os . listdir ( self . working_dir ) : <TAB> <TAB> <TAB> filepath = os . path . join ( self . working_dir , filename ) <TAB> <TAB> <TAB> os . remove ( filepath ) <TAB> <TAB> os . rmdir ( self . working_dir )",if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,True,100.0,74.55,,,
"def tearDown ( self ) : <TAB> """""" Just in case yn00 creates some junk files, do a clean-up. """""" <TAB> del_files = [ self . out_file , "" 2YN.dN "" , "" 2YN.dS "" , "" 2YN.t "" , "" rst "" , "" rst1 "" , "" rub "" ] <TAB> for filename in del_files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> if os . path . exists ( self . working_dir ) : <TAB> <TAB> for filename in os . listdir ( self . working_dir ) : <TAB> <TAB> <TAB> filepath = os . path . join ( self . working_dir , filename ) <TAB> <TAB> <TAB> os . remove ( filepath ) <TAB> <TAB> os . rmdir ( self . working_dir )",if os . path . exists ( filename ) :,if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ),False,93.05,69.67,,,
"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB> <TAB> if not win . ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) : <TAB> <TAB> <TAB> bugs . append ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win , <TAB> <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> <TAB> <TAB> { } , <TAB> <TAB> <TAB> <TAB> <TAB> testname , <TAB> <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs","if win . __class__ . __name__ == ""ComboBox"" :","if win . Class ( ) != ""ComboBox"" or win . ref . Class ( ) != ""ComboBox"" :",False,93.73,64.05,,,
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> if result == self . source : <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not self . _is_expression ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( )",if last_end == start :,if start < last_end :,False,97.83,73.25,,,
"def unpickle_from_file ( file_path , gzip = False ) : <TAB> """""" Unpickle obj from file_path with gzipping. """""" <TAB> with tf . io . gfile . GFile ( file_path , "" rb "" ) as f : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> obj = pickle . load ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with gzip_lib . GzipFile ( fileobj = f , compresslevel = 2 ) as gzipf : <TAB> <TAB> <TAB> <TAB> obj = pickle . load ( gzipf ) <TAB> return obj",if gzip :,if not gzip :,False,98.24,82.53,,,
"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB> <TAB> user = getattr ( request , "" user "" , None ) <TAB> <TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB> <TAB> if user and user . is_authenticated ( ) : <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" email "" : user . email , <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : user . id , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ "" name "" ] = user . name <TAB> else : <TAB> <TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) )",elif user and user . is_active :,if user . name :,False,96.49,72.56,,,
"def get_item_address ( self , item ) : <TAB> """""" Get an item ' s address as a collection of names """""" <TAB> result = [ ] <TAB> while True : <TAB> <TAB> name = self . tree_ctrl . GetItemPyData ( item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> result . insert ( 0 , name ) <TAB> <TAB> <TAB> item = self . tree_ctrl . GetItemParent ( item ) <TAB> return result","if name == ""address"" :",if name is None :,False,95.23,73.41,,,
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB> if filter is None or (row, col) not in filter: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen","if filter [ row , col ] == row1 :",if self . map [ row ] [ col ] == UNSEEN :,False,95.52,70.05,,,
"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> input_array = model . example_input_array <TAB> <TAB> if input_array is not None : <TAB> <TAB> <TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB> <TAB> <TAB> self . experiment . add_graph ( model , input_array ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> "" Could not log computational graph since the "" <TAB> <TAB> <TAB> <TAB> ""  `model.example_input_array` attribute is not set "" <TAB> <TAB> <TAB> <TAB> ""  or `input_array` was not given "" , <TAB> <TAB> <TAB> <TAB> UserWarning , <TAB> <TAB> <TAB> )",if input_array is None :,if input_array is None :,True,100.0,74.51,,,
"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB> <TAB> if not len ( scene_exception ) == 2 : <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions",if scene_season == season :,if season == scene_season :,False,97.12,71.48,,,
def _clean_temp_files ( ) : <TAB> for pattern in _temp_files : <TAB> <TAB> for path in glob . glob ( pattern ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . remove ( path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( path ),if os . path . exists ( path ) :,if os . path . islink ( path ) or os . path . isfile ( path ) :,False,89.36,63.62,,,
"def wait_for_completion ( self , job_id , offset , max_results , start_time , timeout ) : <TAB> """""" Wait for job completion and return the first page. """""" <TAB> while True : <TAB> <TAB> result = self . get_query_results ( <TAB> <TAB> <TAB> job_id = job_id , page_token = None , start_index = offset , max_results = max_results <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return result <TAB> <TAB> if ( time . time ( ) - start_time ) > timeout : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Timeout: the query doesn ' t finish within  %d  seconds. "" % timeout <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 1 )",if result :,"if result [ ""jobComplete"" ] :",False,97.0,89.79,,,
"def get_data ( self , element , ranges , style ) : <TAB> <IF-STMT> <TAB> <TAB> groups = element . groupby ( element . kdims ) . items ( ) <TAB> else : <TAB> <TAB> groups = [ ( element . label , element ) ] <TAB> plots = [ ] <TAB> axis = "" x "" if self . invert_axes else "" y "" <TAB> for key , group in groups : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> label = "" , "" . join ( [ d . pprint_value ( v ) for d , v in zip ( element . kdims , key ) ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> label = key <TAB> <TAB> data = { axis : group . dimension_values ( group . vdims [ 0 ] ) , "" name "" : label } <TAB> <TAB> plots . append ( data ) <TAB> return plots",if self . invert_axes :,if element . kdims :,False,94.34,72.02,,,
"def get_files ( self , dirname ) : <TAB> if not self . _data . has_key ( dirname ) : <TAB> <TAB> self . _create ( dirname ) <TAB> else : <TAB> <TAB> new_time = self . _changed ( dirname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _update ( dirname , new_time ) <TAB> <TAB> <TAB> dcLog . debug ( "" ==>  "" + "" \t \n "" . join ( self . _data [ dirname ] [ "" flist "" ] ) ) <TAB> return self . _data [ dirname ] [ "" flist "" ]",if new_time is not None :,if new_time :,False,97.04,72.91,,,
"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . module_names . add ( name [ : - 3 ] ) <TAB> <TAB> elif "" . "" not in name : <TAB> <TAB> <TAB> self . module_names . add ( name )","if name . endswith ( "".py"" ) :","if name . endswith ( "".py"" ) :",True,100.0,74.16,,,
"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> if enable : <TAB> <TAB> <TAB> <TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation",if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,True,100.0,74.09,,,
"def sortkeypicker ( keynames ) : <TAB> negate = set ( ) <TAB> for i , k in enumerate ( keynames ) : <TAB> <TAB> if k [ : 1 ] == "" - "" : <TAB> <TAB> <TAB> keynames [ i ] = k [ 1 : ] <TAB> <TAB> <TAB> negate . add ( k [ 1 : ] ) <TAB> def getit ( adict ) : <TAB> <TAB> composite = [ adict [ k ] for k in keynames ] <TAB> <TAB> for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> composite [ i ] = - v <TAB> <TAB> return composite <TAB> return getit",if k not in negate :,if k in negate :,False,98.61,73.75,,,
"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . named_windows [ wnd_name ] = 1 <TAB> <TAB> <TAB> self . on_create_window ( wnd_name ) <TAB> <TAB> <TAB> if wnd_name in self . capture_mouse_windows : <TAB> <TAB> <TAB> <TAB> self . capture_mouse ( wnd_name ) <TAB> <TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB> <TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" )",if not self . named_windows [ wnd_name ] :,if self . named_windows [ wnd_name ] == 0 :,False,96.77,71.84,,,
"def check_action_permitted ( self ) : <TAB> if ( <TAB> <TAB> self . _action == "" sts:GetCallerIdentity "" <TAB> ) : # always allowed, even if there's an explicit Deny for it <TAB> <TAB> return True <TAB> policies = self._access_key.collect_policies() <TAB> permitted = False <TAB> for policy in policies: <TAB> <TAB> iam_policy = IAMPolicy(policy) <TAB> <TAB> permission_result = iam_policy.is_action_permitted(self._action) <TAB> <TAB> if permission_result == PermissionResult.DENIED: <TAB> <TAB> <TAB> self._raise_access_denied() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> permitted = True <TAB> if not permitted: <TAB> <TAB> self._raise_access_denied()",elif permission_result == PermissionResult . PERMIT :,elif permission_result == PermissionResult . PERMITTED :,False,98.81,72.98,,,
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> if config[key][""inverse""] is True: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if (datetime.now() + limit) < value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value",if value > limit :,if ( datetime . now ( ) - limit ) > value :,False,95.03,69.8,,,
"def replace_dataset_ids ( path , key , value ) : <TAB> """""" Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job. """""" <TAB> current_case = input_values <TAB> if key == "" id "" : <TAB> <TAB> for i , p in enumerate ( path ) : <TAB> <TAB> <TAB> if isinstance ( current_case , ( list , dict ) ) : <TAB> <TAB> <TAB> <TAB> current_case = current_case [ p ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return key , translate_values . get ( current_case [ "" id "" ] , value ) <TAB> return key , value","if i == 0 and current_case [ ""id"" ] != key :","if src == current_case . get ( ""src"" ) :",False,92.14,82.64,,,
"def load_ext ( name , funcs ) : <TAB> ExtModule = namedtuple ( "" ExtModule "" , funcs ) <TAB> ext_list = [ ] <TAB> lib_root = os . path . dirname ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) <TAB> for fun in funcs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op_ ) <TAB> return ExtModule ( * ext_list )","if fun . startswith ( ""ext_"" ) :","if fun in [ ""nms"" , ""softnms"" ] :",False,93.83,65.48,,,
"def execute_action ( self ) : <TAB> selected_actions = self . model_action . get_selected_results_with_index ( ) <TAB> if selected_actions and self . args_for_action : <TAB> <TAB> for name , _ , act_idx in selected_actions : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> action = self . actions [ act_idx ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> action . act ( [ arg for arg , _ , _ in self . args_for_action ] , self ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> debug . log ( "" execute_action "" , e )",if action . act is not None :,if action :,False,96.67,72.6,,,
"def __getattr__ ( self , attr ) : <TAB> proxy = self . __proxy <TAB> if proxy and hasattr ( proxy , attr ) : <TAB> <TAB> return getattr ( proxy , attr ) <TAB> attrmap = self . __attrmap <TAB> if attr in attrmap : <TAB> <TAB> source = attrmap [ attr ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = source ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = _import_object ( source ) <TAB> <TAB> setattr ( self , attr , value ) <TAB> <TAB> self . __log . debug ( "" loaded lazy attr  %r :  %r "" , attr , value ) <TAB> <TAB> return value <TAB> raise AttributeError ( "" ' module '  object has no attribute  ' %s ' "" % ( attr , ) )",if callable ( source ) :,if callable ( source ) :,True,100.0,74.55,,,
"def forward ( self , x ) : <TAB> # BxT -> BxCxT <TAB> x = x.unsqueeze(1) <TAB> for conv in self.conv_layers: <TAB> <TAB> residual = x <TAB> <TAB> x = conv(x) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tsz = x.size(2) <TAB> <TAB> <TAB> r_tsz = residual.size(2) <TAB> <TAB> <TAB> residual = residual[..., :: r_tsz // tsz][..., :tsz] <TAB> <TAB> <TAB> x = (x + residual) * self.residual_scale <TAB> if self.log_compression: <TAB> <TAB> x = x.abs() <TAB> <TAB> x = x + 1 <TAB> <TAB> x = x.log() <TAB> return x",if self . scale_ratio == 1 :,if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) :,False,91.97,66.91,,,
"def __Prefix_Step2a ( self , token ) : <TAB> for prefix in self . __prefix_step2a : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> token = token [ len ( prefix ) : ] <TAB> <TAB> <TAB> self . prefix_step2a_success = True <TAB> <TAB> <TAB> break <TAB> return token",if token . startswith ( prefix ) :,if token . startswith ( prefix ) and len ( token ) > 5 :,False,91.12,66.89,,,
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> if s is None : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","elif isinstance ( s , ( list , tuple ) ) and s . size != 0 :","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 :",False,92.64,68.77,,,
"def get_all_comments ( self , gallery_id , post_no , comment_cnt ) : <TAB> comment_page_cnt = ( comment_cnt - 1 ) / / self . options . comments_per_page + 1 <TAB> comments = [ ] <TAB> headers = { "" X-Requested-With "" : "" XMLHttpRequest "" } <TAB> data = { "" ci_t "" : self . _session . cookies [ "" ci_c "" ] , "" id "" : gallery_id , "" no "" : post_no } <TAB> for i in range ( comment_page_cnt ) : <TAB> <TAB> data [ "" comment_page "" ] = i + 1 <TAB> <TAB> response = self . request_comment ( headers , data ) <TAB> <TAB> batch = self . parse_comments ( response . text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> comments = batch + comments <TAB> return comments",if len ( batch ) == 0 :,if not batch :,False,96.29,72.59,,,
def run_on_module ( self ) : <TAB> try : <TAB> <TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if e . no_match_group_specs or e . error_group_specs : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e . module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e . module_depsolv_errors [ 1 ] <TAB> <TAB> <TAB> <TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger . error ( str ( e ) ),if self . opts . strict :,if self . base . conf . strict :,False,97.99,71.37,,,
"def find_field_notnull_differ ( self , meta , table_description , table_name ) : <TAB> if not self . can_detect_notnull_differ : <TAB> <TAB> return <TAB> for field in all_local_fields ( meta ) : <TAB> <TAB> attname = field . db_column or field . attname <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> null = self . get_field_db_nullable ( field , table_name ) <TAB> <TAB> if field . null != null : <TAB> <TAB> <TAB> action = field . null and "" DROP "" or "" SET "" <TAB> <TAB> <TAB> self . add_difference ( "" notnull-differ "" , table_name , attname , action )",if attname not in table_description :,"if ( table_name , attname ) in self . new_db_fields :",False,92.07,70.12,,,
"def _change_moving_module ( self , changes , dest ) : <TAB> if not self . source . is_folder ( ) : <TAB> <TAB> pymodule = self . pycore . resource_to_pyobject ( self . source ) <TAB> <TAB> source = self . import_tools . relatives_to_absolutes ( pymodule ) <TAB> <TAB> pymodule = self . tools . new_pymodule ( pymodule , source ) <TAB> <TAB> source = self . _change_occurrences_in_module ( dest , pymodule ) <TAB> <TAB> source = self . tools . new_source ( pymodule , source ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> changes . add_change ( ChangeContents ( self . source , source ) )",if self . source != source :,if source != self . source . read ( ) :,False,95.17,70.86,,,
"def get ( quality_name ) : <TAB> """""" Returns a quality object based on canonical quality name. """""" <TAB> found_components = { } <TAB> for part in quality_name . lower ( ) . split ( ) : <TAB> <TAB> component = _registry . get ( part ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" ` %s ` is not a valid quality string "" % part ) <TAB> <TAB> if component . type in found_components : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" ` %s ` cannot be defined twice in a quality "" % component . type <TAB> <TAB> <TAB> ) <TAB> <TAB> found_components [ component . type ] = component <TAB> if not found_components : <TAB> <TAB> raise ValueError ( "" No quality specified "" ) <TAB> result = Quality ( ) <TAB> for type , component in found_components . items ( ) : <TAB> <TAB> setattr ( result , type , component ) <TAB> return result",if component is None :,if not component :,False,98.33,72.16,,,
def _unselected ( self ) : <TAB> selected = self . _selected <TAB> k = 0 <TAB> z = selected [ k ] <TAB> k + = 1 <TAB> for i in range ( self . _n ) : <TAB> <TAB> if i == z : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> z = selected [ k ] <TAB> <TAB> <TAB> <TAB> k + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> z = - 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> yield i,if self . _selected [ k ] == 0 :,if k < len ( selected ) :,False,93.26,91.58,,,
"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b "" Content-Disposition: form-data;  "" , <TAB> <TAB> <TAB> format_form_param ( "" name "" , self . name ) , <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB> <TAB> <TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB> <TAB> if self . content_type is not None : <TAB> <TAB> <TAB> content_type = self . content_type . encode ( ) <TAB> <TAB> <TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB> <TAB> parts . append ( b "" \r \n \r \n "" ) <TAB> <TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers",if self . filename is not None :,if self . filename :,False,98.26,73.7,,,
"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB> <TAB> if not hasattr ( request , "" app "" ) : <TAB> <TAB> <TAB> request . app = None <TAB> <TAB> <TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> auth_prefix , auth_token = auth <TAB> <TAB> <TAB> <TAB> if auth_prefix . lower ( ) == prefix : <TAB> <TAB> <TAB> <TAB> <TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs )",if len ( auth ) == 2 :,if len ( auth ) == 2 :,True,100.0,74.56,,,
"def _shortest_hypernym_paths ( self , simulate_root ) : <TAB> if self . offset == "" 00000000 "" : <TAB> <TAB> return { self : 0 } <TAB> queue = deque ( [ ( self , 0 ) ] ) <TAB> path = { } <TAB> while queue : <TAB> <TAB> s , depth = queue . popleft ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> path [ s ] = depth <TAB> <TAB> depth + = 1 <TAB> <TAB> queue . extend ( ( hyp , depth ) for hyp in s . _hypernyms ( ) ) <TAB> if simulate_root : <TAB> <TAB> root = Synset ( self . _wordnet_corpus_reader , None , self . pos ( ) , "" 00000000 "" , "" "" ) <TAB> <TAB> path [ root ] = max ( path . values ( ) ) + 1 <TAB> return path",if s . _hypernyms_depth == 0 :,if s in path :,False,95.75,73.02,,,
"def _populate_class_variables ( ) : <TAB> lookup = { } <TAB> reverse_lookup = { } <TAB> characters_for_re = [ ] <TAB> for codepoint , name in list ( codepoint2name . items ( ) ) : <TAB> <TAB> character = chr ( codepoint ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # There's no point in turning the quotation mark into <TAB> <TAB> <TAB> # &quot;, unless it happens within an attribute value, which <TAB> <TAB> <TAB> # is handled elsewhere. <TAB> <TAB> <TAB> characters_for_re.append(character) <TAB> <TAB> <TAB> lookup[character] = name <TAB> <TAB> # But we do want to turn &quot; into the quotation mark. <TAB> <TAB> reverse_lookup[name] = character <TAB> re_definition = ""[%s]"" % """".join(characters_for_re) <TAB> return lookup, reverse_lookup, re.compile(re_definition)",if character not in lookup :,if codepoint != 34 :,False,97.71,72.47,,,
"def prepare_data_status ( self , view : sublime . View , data : Dict [ str , Any ] ) - > Any : <TAB> """""" Prepare the returned data for status """""" <TAB> if ( <TAB> <TAB> data [ "" success "" ] <TAB> <TAB> and "" No docstring "" not in data [ "" doc "" ] <TAB> <TAB> and data [ "" doc "" ] != "" list \n "" <TAB> ) : <TAB> <TAB> self . signature = data [ "" doc "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> try : <TAB> <TAB> <TAB> self . signature = self . signature . splitlines ( ) [ 2 ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return <TAB> <TAB> return self . _show_status ( view )",if self . signature is None :,if self . _signature_excluded ( self . signature ) :,False,95.41,68.68,,,
"def _setup_once_tables ( cls ) : <TAB> if cls . run_define_tables == "" once "" : <TAB> <TAB> cls . define_tables ( cls . metadata ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . metadata . create_all ( cls . bind ) <TAB> <TAB> cls . tables . update ( cls . metadata . tables )",if cls . bind :,"if cls . run_create_tables == ""once"" :",False,88.39,63.52,,,
"def _send_recursive ( self , files ) : <TAB> for base in files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # filename mixed into the bunch <TAB> <TAB> <TAB> self._send_files([base]) <TAB> <TAB> <TAB> continue <TAB> <TAB> last_dir = asbytes(base) <TAB> <TAB> for root, dirs, fls in os.walk(base): <TAB> <TAB> <TAB> self._chdir(last_dir, asbytes(root)) <TAB> <TAB> <TAB> self._send_files([os.path.join(root, f) for f in fls]) <TAB> <TAB> <TAB> last_dir = asbytes(root) <TAB> <TAB> # back out of the directory <TAB> <TAB> for i in range(len(os.path.split(last_dir))): <TAB> <TAB> <TAB> self._send_popd()","if isinstance ( base , str ) :",if not os . path . isdir ( base ) :,False,96.37,69.68,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> # Automatically register models if required. <TAB> if not is_registered(self.model): <TAB> <TAB> inline_fields = () <TAB> <TAB> for inline in self.inlines: <TAB> <TAB> <TAB> inline_model, follow_field = self._reversion_introspect_inline_admin(inline) <TAB> <TAB> <TAB> if inline_model: <TAB> <TAB> <TAB> <TAB> self._reversion_autoregister(inline_model, ()) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> inline_fields += (follow_field,) <TAB> <TAB> self._reversion_autoregister(self.model, inline_fields)",if follow_field :,if follow_field :,True,100.0,74.26,,,
"def dispatch_hook ( key , hooks , hook_data , * * kwargs ) : <TAB> """""" Dispatches a hook dictionary on a given piece of data. """""" <TAB> hooks = hooks or dict ( ) <TAB> hooks = hooks . get ( key ) <TAB> if hooks : <TAB> <TAB> if hasattr ( hooks , "" __call__ "" ) : <TAB> <TAB> <TAB> hooks = [ hooks ] <TAB> <TAB> for hook in hooks : <TAB> <TAB> <TAB> _hook_data = hook ( hook_data , * * kwargs ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> hook_data = _hook_data <TAB> return hook_data","if isinstance ( _hook_data , dict ) :",if _hook_data is not None :,False,95.53,93.51,,,
"def __call__ ( self , image , crop = True ) : <TAB> if isinstance ( image , PTensor ) : <TAB> <TAB> return self . crop_to_output ( <TAB> <TAB> <TAB> numpy_to_paddle ( self ( paddle_to_numpy ( image ) , crop = False ) ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> warp = cv . warpAffine ( <TAB> <TAB> <TAB> image , <TAB> <TAB> <TAB> self . transform_matrix , <TAB> <TAB> <TAB> image . shape [ 1 : : - 1 ] , <TAB> <TAB> <TAB> borderMode = cv . BORDER_REPLICATE , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . crop_to_output ( warp ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return warp",if crop :,if crop :,True,100.0,74.48,,,
"def __call__ ( self , image , crop = True ) : <TAB> if isinstance ( image , PTensor ) : <TAB> <TAB> return self . crop_to_output ( <TAB> <TAB> <TAB> numpy_to_paddle ( self ( paddle_to_numpy ( image ) , crop = False ) ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> warp = cv . warpAffine ( <TAB> <TAB> <TAB> image , <TAB> <TAB> <TAB> self . transform_matrix , <TAB> <TAB> <TAB> image . shape [ 1 : : - 1 ] , <TAB> <TAB> <TAB> borderMode = cv . BORDER_REPLICATE , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . crop_to_output ( warp ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return warp",if crop :,"if line . startswith ( ""ERROR:"" ) and prev_line and prev_line . startswith ( ""="" ) :",False,88.8,61.4,,,
"def end ( self , name ) : <TAB> self . soup . endData ( ) <TAB> completed_tag = self . soup . tagStack [ - 1 ] <TAB> namespace , name = self . _getNsTag ( name ) <TAB> nsprefix = None <TAB> if namespace is not None : <TAB> <TAB> for inverted_nsmap in reversed ( self . nsmaps ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> nsprefix = inverted_nsmap [ namespace ] <TAB> <TAB> <TAB> <TAB> break <TAB> self . soup . handle_endtag ( name , nsprefix ) <TAB> if len ( self . nsmaps ) > 1 : <TAB> <TAB> # This tag, or one of its parents, introduced a namespace <TAB> <TAB> # mapping, so pop it off the stack. <TAB> <TAB> self.nsmaps.pop()",if namespace in inverted_nsmap :,if inverted_nsmap is not None and namespace in inverted_nsmap :,False,95.95,71.77,,,
"def _bind_parameters ( operation , parameters ) : <TAB> # inspired by MySQL Python Connector (conversion.py) <TAB> string_parameters = {} <TAB> for (name, value) in parameters.iteritems(): <TAB> <TAB> if value is None: <TAB> <TAB> <TAB> string_parameters[name] = ""NULL"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> string_parameters[name] = ""'"" + _escape(value) + ""'"" <TAB> <TAB> else: <TAB> <TAB> <TAB> string_parameters[name] = str(value) <TAB> return operation % string_parameters","elif isinstance ( value , six . string_types ) :","elif isinstance ( value , basestring ) :",False,95.99,71.75,,,
"def plugin_on_song_ended ( self , song , skipped ) : <TAB> if song is not None : <TAB> <TAB> rating = song ( "" ~#rating "" ) <TAB> <TAB> invrating = 1.0 - rating <TAB> <TAB> delta = min ( rating , invrating ) / 2.0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rating - = delta <TAB> <TAB> else : <TAB> <TAB> <TAB> rating + = delta <TAB> <TAB> song [ "" ~#rating "" ] = rating",if skipped :,if skipped :,True,100.0,74.21,,,
"def on_activated_async ( self , view ) : <TAB> if settings [ "" modified_lines_only "" ] : <TAB> <TAB> self . freeze_last_version ( view ) <TAB> if settings [ "" enabled "" ] : <TAB> <TAB> match_trailing_spaces ( view ) <TAB> <TAB> # continuously watch view for changes to the visible region <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # track <TAB> <TAB> <TAB> active_views[view.id()] = view.visible_region() <TAB> <TAB> <TAB> self.update_on_region_change(view)",if view . id ( ) in active_views :,if not view . id ( ) in active_views :,False,98.43,72.4,,,
"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" -  "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB> <TAB> <TAB> newdiff . append ( u ( "" "" ) + line [ 2 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newdiff . append ( line ) <TAB> return newdiff","if line . startswith ( u ( ""-"" ) ) :","if line . startswith ( u ( ""Skipping"" ) ) :",False,98.98,73.94,,,
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> if os . path . isdir ( fn ) : <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .png "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )","elif fn . endswith ( "".png"" ) :","elif fn . endswith ( "".md"" ) :",False,98.8,73.6,,,
"def reward ( self ) : <TAB> """""" Returns a tuple of sum of raw and processed rewards. """""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB> if ts.raw_reward is not None: <TAB> <TAB> <TAB> raw_rewards += ts.raw_reward <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",if ts . processed_reward is not None :,if ts . processed_reward is not None :,True,100.0,99.28,,,
"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB> <TAB> s = month_name [ themonth ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s = s . decode ( encoding ) <TAB> <TAB> if withyear : <TAB> <TAB> <TAB> s = "" %s %s "" % ( s , theyear ) <TAB> <TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s",if six . PY2 :,if encoding is not None :,False,95.99,70.78,,,
"def check_digest_auth ( user , passwd ) : <TAB> """""" Check user authentication using HTTP Digest auth """""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB> <TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response ( <TAB> <TAB> <TAB> credentails , <TAB> <TAB> <TAB> passwd , <TAB> <TAB> <TAB> dict ( <TAB> <TAB> <TAB> <TAB> uri = request . script_root + request . path , <TAB> <TAB> <TAB> <TAB> body = request . data , <TAB> <TAB> <TAB> <TAB> method = request . method , <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> if credentails . get ( "" response "" ) == response_hash : <TAB> <TAB> <TAB> return True <TAB> return False","if not credentails . get ( ""user"" ) == user :",if not credentails :,False,95.51,92.41,,,
"def wrapped ( self , request ) : <TAB> try : <TAB> <TAB> return self . _finished <TAB> except AttributeError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not request . session . shouldfail and not request . session . shouldstop : <TAB> <TAB> <TAB> <TAB> log . debug ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  is still going to be used, not terminating it.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Still in use on: \n %s "" , <TAB> <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> <TAB> <TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( request ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _finished = True",if self . _finished :,if self . node_ids :,False,98.45,73.82,,,
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> if case(0): <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> elif case(1, 2): <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")","elif case ( 3 , 4 ) :","elif case ( 3 , 4 ) :",True,100.0,74.13,,,
"def task_done ( self ) : <TAB> with self . _cond : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB> <TAB> if self . _unfinished_tasks . _semlock . _is_zero ( ) : <TAB> <TAB> <TAB> self . _cond . notify_all ( )",if self . _unfinished_tasks . _semlock . _is_zero ( ) :,if not self . _unfinished_tasks . acquire ( False ) :,False,89.84,67.99,,,
"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB> <TAB> <TAB> val = None <TAB> <TAB> elif isinstance ( val , text_or_bytes ) : <TAB> <TAB> <TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val","if val == """" :",if pwd is None :,False,94.59,62.75,,,
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> if version is not None : # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB> if arch is not None: <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",if exe_data is not None :,if exe_data is not None :,True,100.0,74.51,,,
"def run ( algs ) : <TAB> for alg in algs : <TAB> <TAB> vcs = alg . get ( "" variantcaller "" ) <TAB> <TAB> if vcs : <TAB> <TAB> <TAB> if isinstance ( vcs , dict ) : <TAB> <TAB> <TAB> <TAB> vcs = reduce ( operator . add , vcs . values ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> vcs = [ vcs ] <TAB> <TAB> <TAB> return any ( vc . startswith ( prefix ) for vc in vcs if vc )","elif isinstance ( vcs , list ) :","if not isinstance ( vcs , ( list , tuple ) ) :",False,93.2,69.34,,,
"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> uri = self . request . path + "" / "" <TAB> <TAB> <TAB> if self . request . query : <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs )","if self . request . method == ""GET"" :","if self . request . method in ( ""GET"" , ""HEAD"" ) :",False,93.99,66.97,,,
"def check_response ( self , response ) : <TAB> """""" Specialized version of check_response(). """""" <TAB> for line in response : <TAB> <TAB> # Skip blank lines: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(b""OK""): <TAB> <TAB> <TAB> return <TAB> <TAB> elif line.startswith(b""Benutzer/Passwort Fehler""): <TAB> <TAB> <TAB> raise BadLogin(line) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise FailedPost(""Server returned '%s'"" % six.ensure_text(line))","if line . startswith ( b"""" ) :",if not line . strip ( ) :,False,95.56,54.0,,,
"def Walk ( self , hMenu = None ) : <TAB> if not hMenu : <TAB> <TAB> hMenu = self . handle <TAB> n = user32 . GetMenuItemCount ( hMenu ) <TAB> mi = MENUITEMINFO ( ) <TAB> for i in range ( n ) : <TAB> <TAB> mi . fMask = 2 # MIIM_ID <TAB> <TAB> user32.GetMenuItemInfoA(hMenu, i, 1, byref(mi)) <TAB> <TAB> handle = user32.GetSubMenu(hMenu, i) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield handle, self.ListItems(handle) <TAB> <TAB> <TAB> for i in self.Walk(handle): <TAB> <TAB> <TAB> <TAB> yield i",if self . IsOpened ( handle ) :,if handle :,False,95.81,71.82,,,
"def setSelection ( self , labels ) : <TAB> input = self . __validateInput ( labels ) <TAB> if len ( input ) == 0 and not self . __allowEmptySelection : <TAB> <TAB> return <TAB> if self . __allowMultipleSelection : <TAB> <TAB> self . __selectedLabels [ : ] = input <TAB> <TAB> self . __selectionChanged ( ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Parameter must be single item or a list with one element. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __selectedLabels [ : ] = input <TAB> <TAB> <TAB> self . __selectionChanged ( ) <TAB> # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB> self.__validateState()",if len ( input ) == 1 :,if len ( input ) > 1 :,False,98.47,73.7,,,
"def _parse ( self , engine ) : <TAB> """""" Parse the layer. """""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if not isinstance ( self . momentum , int ) :","if not isinstance ( self . momentum , ( int , float ) ) :",False,97.13,96.44,,,
"def get_order ( self , aBuf ) : <TAB> if not aBuf : <TAB> <TAB> return - 1 , 1 <TAB> # find out current char's byte length <TAB> first_char = wrap_ord(aBuf[0]) <TAB> if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC): <TAB> <TAB> charLen = 2 <TAB> else: <TAB> <TAB> charLen = 1 <TAB> # return its order if it is hiragana <TAB> if len(aBuf) > 1: <TAB> <TAB> second_char = wrap_ord(aBuf[1]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return second_char - 0x9F, charLen <TAB> return -1, charLen",if second_char >= 0x9F :,if ( first_char == 202 ) and ( 0x9F <= second_char <= 0xF1 ) :,False,89.86,67.73,,,
"def saveSpecial ( self , * * kwargs ) : <TAB> for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST : <TAB> <TAB> item = config . get_config ( "" misc "" , kw ) <TAB> <TAB> value = kwargs . get ( kw ) <TAB> <TAB> msg = item . set ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return badParameterResponse ( msg ) <TAB> config . save_config ( ) <TAB> raise Raiser ( self . __root )",if msg :,if msg :,True,100.0,74.22,,,
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB> <TAB> <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )",if key in valid_keys :,if key not in valid_keys :,False,98.92,72.54,,,
"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fit . calculated : <TAB> <TAB> <TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> <TAB> <TAB> fit . clearFactorReloadDependentData ( ) <TAB> <TAB> <TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs",if fit . isShown ( ) :,if fit is None :,False,96.8,72.33,,,
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range(self.height): <TAB> <TAB> for col in range(self.width): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self.map[row][col] == UNSEEN: <TAB> <TAB> <TAB> <TAB> <TAB> dist = self.distance(row1, col1, row, col) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = (row, col) <TAB> return closest_unseen","if filter is not None and filter ( row1 , col1 , row , col ) :","if filter is None or ( row , col ) not in filter :",False,95.25,69.88,,,
"def getAlphaClone ( lookfor , eager = None ) : <TAB> if isinstance ( lookfor , int ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> item = get_gamedata_session ( ) . query ( AlphaClone ) . get ( lookfor ) <TAB> <TAB> else : <TAB> <TAB> <TAB> item = ( <TAB> <TAB> <TAB> <TAB> get_gamedata_session ( ) <TAB> <TAB> <TAB> <TAB> . query ( AlphaClone ) <TAB> <TAB> <TAB> <TAB> . options ( * processEager ( eager ) ) <TAB> <TAB> <TAB> <TAB> . filter ( AlphaClone . ID == lookfor ) <TAB> <TAB> <TAB> <TAB> . first ( ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise TypeError ( "" Need integer as argument "" ) <TAB> return item",if lookfor < 100 :,if eager is None :,False,97.85,72.45,,,
"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB> <TAB> if not cur : <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new + = bytes ( [ cur ] ) <TAB> return new",if count :,if count :,True,100.0,74.27,,,
def result_iterator ( ) : <TAB> try : <TAB> <TAB> for future in fs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield future . result ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield future . result ( end_time - time . time ( ) ) <TAB> finally : <TAB> <TAB> for future in fs : <TAB> <TAB> <TAB> future . cancel ( ),if end_time is None :,if timeout is None :,False,96.34,72.49,,,
"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB> <TAB> for key , value in segment . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> if hasattr ( key , "" text "" ) : <TAB> <TAB> <TAB> <TAB> if key . text == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB> <TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB> <TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB> <TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB> <TAB> raise Exception ( "" Invalid state "" )",if key . text == index [ 0 ] :,if key == index [ 0 ] :,False,98.65,73.9,,,
"def _reset_sequences ( self , db_name ) : <TAB> conn = connections [ db_name ] <TAB> if conn . features . supports_sequence_reset : <TAB> <TAB> sql_list = conn . ops . sequence_reset_by_name_sql ( <TAB> <TAB> <TAB> no_style ( ) , conn . introspection . sequence_list ( ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cursor = conn . cursor ( ) <TAB> <TAB> <TAB> <TAB> for sql in sql_list : <TAB> <TAB> <TAB> <TAB> <TAB> cursor . execute ( sql ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> transaction . rollback_unless_managed ( using = db_name ) <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> transaction . commit_unless_managed ( using = db_name )",if sql_list :,if sql_list :,True,100.0,74.49,,,
"def _reset_sequences ( self , db_name ) : <TAB> conn = connections [ db_name ] <TAB> if conn . features . supports_sequence_reset : <TAB> <TAB> sql_list = conn . ops . sequence_reset_by_name_sql ( <TAB> <TAB> <TAB> no_style ( ) , conn . introspection . sequence_list ( ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cursor = conn . cursor ( ) <TAB> <TAB> <TAB> <TAB> for sql in sql_list : <TAB> <TAB> <TAB> <TAB> <TAB> cursor . execute ( sql ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> transaction . rollback_unless_managed ( using = db_name ) <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> transaction . commit_unless_managed ( using = db_name )",if sql_list :,"if stmt . op == "":="" and not stmt . var in self . variables :",False,92.41,60.24,,,
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <TAB> <TAB> if ext != PYTHON_SOURCE_EXTENSION: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""c"") <TAB> <TAB> if self.optimize > 0: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files",if self . optimize > 0 :,if self . compile :,False,97.96,72.61,,,
"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> if reset == ACTIVE_LOW : <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation",if reset == ACTIVE_HIGH :,if enable :,False,93.13,71.53,,,
"def _is_subnet_of ( a , b ) : <TAB> try : <TAB> <TAB> # Always false if one is v4 and the other is v6. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError(""%s and %s are not of the same version"" % (a, b)) <TAB> <TAB> return ( <TAB> <TAB> <TAB> b.network_address <= a.network_address <TAB> <TAB> <TAB> and b.broadcast_address >= a.broadcast_address <TAB> <TAB> ) <TAB> except AttributeError: <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> ""Unable to test subnet containment "" ""between %s and %s"" % (a, b) <TAB> <TAB> )",if a . version != b . version :,if a . _version != b . _version :,False,97.43,71.85,,,
"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""" .gitignore style file filtering. """""" <TAB> for item in exclude : <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> if item.endswith(""/"") and not is_dir: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item.startswith(""/"") else basename <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if match in basename :,"if fnmatch . fnmatch ( match , item . strip ( ""/"" ) ) :",False,90.93,92.81,,,
"def __recv_null ( self ) : <TAB> """""" Receive a null byte. """""" <TAB> while 1 : <TAB> <TAB> c = self . sock . recv ( 1 ) <TAB> <TAB> if c == "" "" : <TAB> <TAB> <TAB> self . close ( ) <TAB> <TAB> <TAB> raise EOFError ( "" Socket Closed "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return","if c == ""\0"" :","if c == ""\0"" :",True,100.0,99.05,,,
"def onMessage ( self , payload , isBinary ) : <TAB> if isBinary : <TAB> <TAB> self . result = "" Expected text message with payload, but got binary. "" <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . result = ( <TAB> <TAB> <TAB> <TAB> "" Expected text message with payload of length  %d , but got  %d . "" <TAB> <TAB> <TAB> <TAB> % ( self . DATALEN , len ( payload ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self.behavior = Case.OK <TAB> <TAB> <TAB> self.result = ""Received text message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if self . DATALEN != len ( payload ) :,if len ( payload ) != self . DATALEN :,False,97.63,72.51,,,
"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB> <TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB> <TAB> attr = self . getattr ( d_path ) <TAB> <TAB> if stat . S_ISDIR ( attr [ "" st_mode "" ] ) : <TAB> <TAB> <TAB> self . rename_path ( d_path , d_new_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True )","if not d . endswith ( ""/"" ) :","if d in [ ""."" , "".."" ] :",False,95.23,68.74,,,
"def dir_box_click ( self , double ) : <TAB> if double : <TAB> <TAB> name = self . list_box . get_selected_name ( ) <TAB> <TAB> path = os . path . join ( self . directory , name ) <TAB> <TAB> suffix = os . path . splitext ( name ) [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . directory = path <TAB> <TAB> else : <TAB> <TAB> <TAB> self . double_click_file ( name ) <TAB> self . update ( )",if suffix in self . directory_suffixes :,if suffix not in self . suffixes and os . path . isdir ( path ) :,False,90.62,67.01,,,
"def __getattr__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return value . mod_ns <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB> <TAB> <TAB> <TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB> <TAB> "" Module  %r  has no mapped classes  "" <TAB> <TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> )","if isinstance ( value , _ModuleMarker ) :","if isinstance ( value , _ModuleMarker ) :",True,100.0,74.52,,,
"def poll_thread ( ) : <TAB> time . sleep ( 0.5 ) <TAB> if process . wait ( ) and process_state : <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stdout , stderr = process . _communicate ( None ) <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" Web server process exited unexpectedly "" , <TAB> <TAB> <TAB> <TAB> "" app "" , <TAB> <TAB> <TAB> <TAB> stdout = stdout , <TAB> <TAB> <TAB> <TAB> stderr = stderr , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> <TAB> restart_server ( 1 )",if process . wait ( ) :,if not check_global_interrupt ( ) :,False,96.2,72.51,,,
"def apply_dateparser_timezone ( utc_datetime , offset_or_timezone_abb ) : <TAB> for name , info in _tz_offsets : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tz = StaticTzInfo ( name , info [ "" offset "" ] ) <TAB> <TAB> <TAB> return utc_datetime . astimezone ( tz )","if info [ ""offset"" ] == offset_or_timezone_abb :","if info [ ""regex"" ] . search ( "" %s"" % offset_or_timezone_abb ) :",False,85.74,58.71,,,
"def _load_wordlist ( filename ) : <TAB> if filename is None : <TAB> <TAB> return { } <TAB> path = None <TAB> for dir in ( CONFIG_DIR , ASSETS_DIR ) : <TAB> <TAB> path = os . path . realpath ( os . path . join ( dir , filename ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> words = { } <TAB> with open ( path , encoding = "" utf-8 "" ) as f : <TAB> <TAB> pairs = [ word . strip ( ) . rsplit ( "" "" , 1 ) for word in f ] <TAB> <TAB> pairs . sort ( reverse = True , key = lambda x : int ( x [ 1 ] ) ) <TAB> <TAB> words = { p [ 0 ] : int ( p [ 1 ] ) for p in pairs } <TAB> return words",if path is None :,if os . path . exists ( path ) :,False,95.5,71.78,,,
"def terminate_processes_matching_names ( match_strings , kill = False ) : <TAB> """""" Terminates processes matching particular names (case sensitive). """""" <TAB> if isinstance ( match_strings , str ) : <TAB> <TAB> match_strings = [ match_strings ] <TAB> for process in psutil . process_iter ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> process_info = process . as_dict ( attrs = [ "" name "" , "" pid "" ] ) <TAB> <TAB> <TAB> process_name = process_info [ "" name "" ] <TAB> <TAB> except ( psutil . AccessDenied , psutil . NoSuchProcess , OSError ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> terminate_process ( process_info [ "" pid "" ] , kill )",if process_name in match_strings :,if any ( x == process_name for x in match_strings ) :,False,94.08,71.76,,,
"def terminate_processes_matching_names ( match_strings , kill = False ) : <TAB> """""" Terminates processes matching particular names (case sensitive). """""" <TAB> if isinstance ( match_strings , str ) : <TAB> <TAB> match_strings = [ match_strings ] <TAB> for process in psutil . process_iter ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> process_info = process . as_dict ( attrs = [ "" name "" , "" pid "" ] ) <TAB> <TAB> <TAB> process_name = process_info [ "" name "" ] <TAB> <TAB> except ( psutil . AccessDenied , psutil . NoSuchProcess , OSError ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> terminate_process ( process_info [ "" pid "" ] , kill )",if process_name in match_strings :,"if "":"" in authority :",False,95.98,69.63,,,
"def close ( self ) : <TAB> with BrowserContext . _BROWSER_LOCK : <TAB> <TAB> BrowserContext . _BROWSER_REFCNT - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . info ( "" Destroying browser main loop "" ) <TAB> <TAB> <TAB> BrowserContext . _BROWSER_LOOP . destroy ( ) <TAB> <TAB> <TAB> BrowserContext . _BROWSER_LOOP = None",if BrowserContext . _BROWSER_REFCNT == 0 :,if BrowserContext . _BROWSER_REFCNT == 0 :,True,100.0,73.93,,,
"def _mock_get_merge_ticks ( self , order_book_id_list , trading_date , last_dt = None ) : <TAB> for tick in self . _ticks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> self . env . data_proxy . get_future_trading_date ( tick . datetime ) . date ( ) <TAB> <TAB> <TAB> != trading_date . date ( ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if last_dt and tick . datetime < = last_dt : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield tick",if not tick . is_future :,if tick . order_book_id not in order_book_id_list :,False,91.31,70.87,,,
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> if ss [ "" revision "" ] : <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> if ss [ "" patch "" ] is not None : <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""branch"" ] :","if ss [ ""branch"" ] :",True,100.0,74.62,,,
"def test_open_read_bytes ( self , sftp ) : <TAB> """""" Test reading bytes from a file """""" <TAB> f = None <TAB> try : <TAB> <TAB> self . _create_file ( "" file "" , "" xxx "" ) <TAB> <TAB> f = yield from sftp . open ( "" file "" , "" rb "" ) <TAB> <TAB> self . assertEqual ( ( yield from f . read ( ) ) , b "" xxx "" ) <TAB> finally : <TAB> <TAB> <IF-STMT> # pragma: no branch <TAB> <TAB> <TAB> yield from f.close() <TAB> <TAB> remove(""file"")",if f :,if f :,True,100.0,99.38,,,
"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB> <TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB> <TAB> if verbose == True : <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> return <TAB> while True : <TAB> <TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB> <TAB> if sock in r : <TAB> <TAB> <TAB> data = sock . recv ( 1024 ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan . send ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = chan . recv ( 1024 ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( )",elif chan in x :,if chan in r :,False,98.27,73.25,,,
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = re . search ( r "" url \ ( ' /ks-waf-error \ .png ' \ ) "" , page , re . I ) is not None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",if retval :,if retval :,True,100.0,74.18,,,
"def __init__ ( self , raw ) : <TAB> ticker_ticks = { } <TAB> for tick in raw [ "" results "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ticker_ticks [ tick [ "" T "" ] ] . append ( tick ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ticker_ticks [ tick [ "" T "" ] ] = [ tick ] <TAB> super ( ) . __init__ ( <TAB> <TAB> { ticker : Aggsv2 ( { "" results "" : ticks } ) for ticker , ticks in ticker_ticks . items ( ) } <TAB> )","if tick [ ""T"" ] in ticker_ticks :","if ticker_ticks . get ( tick [ ""T"" ] ) :",False,94.63,70.87,,,
"def _makefiles ( self , f ) : <TAB> if isinstance ( f , dict ) : <TAB> <TAB> for k , v in list ( f . items ( ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . makedir ( dirname = k , content = v ) <TAB> <TAB> <TAB> elif isinstance ( v , str ) : <TAB> <TAB> <TAB> <TAB> self . make_file ( filename = k , content = v ) <TAB> <TAB> <TAB> else : # pragma: nocover <TAB> <TAB> <TAB> <TAB> raise ValueError(""Unexpected:"", k, v) <TAB> elif isinstance(f, str): <TAB> <TAB> self._make_empty_file(f) <TAB> elif isinstance(f, list): <TAB> <TAB> self.make_list(f) <TAB> else: # pragma: nocover <TAB> <TAB> raise ValueError(""Unknown type:"", f)","if isinstance ( v , ( str , unicode ) ) :","if isinstance ( v , list ) :",False,97.34,72.8,,,
"def migrate_command_storage ( apps , schema_editor ) : <TAB> model = apps . get_model ( "" terminal "" , "" CommandStorage "" ) <TAB> init_storage_data ( model ) <TAB> setting = get_setting ( apps , schema_editor , "" TERMINAL_COMMAND_STORAGE "" ) <TAB> if not setting : <TAB> <TAB> return <TAB> values = get_storage_data ( setting ) <TAB> for name , meta in values . items ( ) : <TAB> <TAB> tp = meta . pop ( "" TYPE "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> model . objects . create ( name = name , type = tp , meta = meta )","if tp == ""NONE"" :","if not tp or name in [ ""default"" , ""null"" ] :",False,91.66,65.38,,,
"def build_vertices ( self , ulines ) : <TAB> vertex_idx = 0 <TAB> vertices = collections . OrderedDict ( ) <TAB> for line in ulines : <TAB> <TAB> for vt in line : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_vertex = ( vt . u , vt . v , 0.0 ) <TAB> <TAB> <TAB> if new_vertex in vertices : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> vt . index = vertex_idx <TAB> <TAB> <TAB> vertex_idx + = 1 <TAB> <TAB> <TAB> vertices [ new_vertex ] = 1 <TAB> return vertex_idx , list ( vertices . keys ( ) )",if vt . index != vertex_idx :,if vt . replacement is not None :,False,96.14,71.67,,,
"def get_quarantine_count ( self ) : <TAB> """""" get obj/container/account quarantine counts """""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB> <TAB> for qtype in qcounts : <TAB> <TAB> <TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB> <TAB> <TAB> if os . path . exists ( qtgt ) : <TAB> <TAB> <TAB> <TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts",if linkcount > 0 :,if linkcount > 2 :,False,98.74,98.6,,,
"def _format_arg ( self , name , trait_spec , value ) : <TAB> if name == "" mask_file "" : <TAB> <TAB> return "" "" <TAB> if name == "" op_string "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isdefined ( self . inputs . mask_file ) : <TAB> <TAB> <TAB> <TAB> return self . inputs . op_string % self . inputs . mask_file <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" -k  %s  option in op_string requires mask_file "" ) <TAB> return super ( ImageStats , self ) . _format_arg ( name , trait_spec , value )",if self . inputs . mask_file :,"if ""-k %s"" in self . inputs . op_string :",False,93.62,66.83,,,
"def _update_theme_style ( self , * args ) : <TAB> self . line_color_normal = self . theme_cls . divider_color <TAB> if not any ( [ self . error , self . _text_len_error ] ) : <TAB> <TAB> if not self . focus : <TAB> <TAB> <TAB> self . _current_hint_text_color = self . theme_cls . disabled_hint_text_color <TAB> <TAB> <TAB> self . _current_right_lbl_color = self . theme_cls . disabled_hint_text_color <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _current_error_color = self . theme_cls . disabled_hint_text_color",if self . focus_right :,"if self . helper_text_mode == ""persistent"" :",False,94.05,63.49,,,
"def createFields ( self ) : <TAB> for item in self . format : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield item [ 0 ] ( self , * item [ 1 : - 1 ] , * * item [ - 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield item [ 0 ] ( self , * item [ 1 : ] )","if item [ 0 ] in ( ""T"" , ""T"" ) :","if isinstance ( item [ - 1 ] , dict ) :",False,87.23,60.08,,,
"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement , arguments ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement ) <TAB> <TAB> except sqlite3 . OperationalError as ex : <TAB> <TAB> <TAB> if "" locked "" not in getSafeExString ( ex ) : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB> <TAB> return self . cursor . fetchall ( )",if arguments :,if arguments :,True,100.0,74.51,,,
"def set_income_account_for_fixed_assets ( self ) : <TAB> disposal_account = depreciation_cost_center = None <TAB> for d in self . get ( "" items "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not disposal_account : <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> disposal_account , <TAB> <TAB> <TAB> <TAB> <TAB> depreciation_cost_center , <TAB> <TAB> <TAB> <TAB> ) = get_disposal_account_and_cost_center ( self . company ) <TAB> <TAB> <TAB> d . income_account = disposal_account <TAB> <TAB> <TAB> if not d . cost_center : <TAB> <TAB> <TAB> <TAB> d . cost_center = depreciation_cost_center",if d . income_account :,if d . is_fixed_asset :,False,97.08,73.05,,,
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> if isinstance ( nbChars , int ) : <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> if nbChars [ 0 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )",if nbChars [ 1 ] is not None :,if nbChars [ 1 ] is not None :,True,100.0,74.44,,,
"def _get_service_full_name ( self , name , help_command_table ) : <TAB> if help_command_table and name not in self . _NON_SERVICE_COMMANDS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _HIGH_LEVEL_SERVICE_FULL_NAMES [ name ] <TAB> <TAB> service = help_command_table . get ( name ) <TAB> <TAB> if service : <TAB> <TAB> <TAB> return service . service_model . metadata [ "" serviceFullName "" ]",if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :,True,100.0,74.13,,,
"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 : # at least one complete IP address <TAB> <TAB> while 1: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp_str += ""#"" <TAB> <TAB> <TAB> tmp_str += self.get_ip_address(p) <TAB> <TAB> <TAB> p += 4 <TAB> <TAB> <TAB> if p >= self.get_len(): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4: # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",if self . get_ptr ( ) % 4 :,if p + 1 == self . get_ptr ( ) :,False,96.99,71.78,,,
"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB> <TAB> error = True <TAB> <TAB> try : <TAB> <TAB> <TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except : <TAB> <TAB> <TAB> if not self . expect_exception : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert error",if self . expect_test :,if self . expect_exception :,False,98.14,72.73,,,
"def create_composite_mounter_by_args ( args ) : <TAB> """""" Creates a CompositeMounter by the images in given args. """""" <TAB> logging . info ( "" Mount images... "" ) <TAB> mounter = composite_mounter . CompositeMounter ( ) <TAB> for partition in composite_mounter . SUPPORTED_PARTITIONS : <TAB> <TAB> image_source = vars ( args ) [ partition ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . info ( "" %s = %s "" , partition , image_source ) <TAB> <TAB> <TAB> mounter . add_by_mount_target ( partition , image_source ) <TAB> if mounter . is_empty ( ) : <TAB> <TAB> raise RuntimeError ( "" Must give at least one image source. "" ) <TAB> return mounter",if image_source :,if image_source :,True,100.0,99.44,,,
"def _get_containing_class ( self , pyname ) : <TAB> if isinstance ( pyname , pynames . DefinedName ) : <TAB> <TAB> scope = pyname . get_object ( ) . get_scope ( ) <TAB> <TAB> parent = scope . parent <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return parent . pyobject",if parent . is_parent :,"if parent is not None and parent . get_kind ( ) == ""Class"" :",False,82.14,55.04,,,
"def test_chunkcoding ( self ) : <TAB> tstring_lines = [ ] <TAB> for b in self . tstring : <TAB> <TAB> lines = b . split ( b "" \n "" ) <TAB> <TAB> last = lines . pop ( ) <TAB> <TAB> assert last == b "" "" <TAB> <TAB> lines = [ line + b "" \n "" for line in lines ] <TAB> <TAB> tstring_lines . append ( lines ) <TAB> for native , utf8 in zip ( * tstring_lines ) : <TAB> <TAB> u = self . decode ( native ) [ 0 ] <TAB> <TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] )",if self . is_chunked :,if self . roundtriptest :,False,97.7,73.66,,,
"def set_default_variants ( apps , schema_editor ) : <TAB> Product = apps . get_model ( "" product "" , "" Product "" ) <TAB> for product in Product . objects . iterator ( ) : <TAB> <TAB> first_variant = product . variants . first ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> product . default_variant = first_variant <TAB> <TAB> <TAB> product . save ( update_fields = [ "" default_variant "" , "" updated_at "" ] )","if first_variant . default_variant == """" :",if first_variant :,False,92.71,67.01,,,
"def json ( self ) : <TAB> try : <TAB> <TAB> if self . is_json ( ) : <TAB> <TAB> <TAB> raw_data = self . raw_data ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raw_data = raw_data . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> return json . loads ( raw_data ) <TAB> except ValueError : <TAB> <TAB> pass","if isinstance ( raw_data , bytes ) :","if not isinstance ( raw_data , text_type ) :",False,94.3,70.34,,,
"def clear_react ( self , message : discord . Message , emoji : MutableMapping = None ) - > None : <TAB> try : <TAB> <TAB> await message . clear_reactions ( ) <TAB> except discord . Forbidden : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> with contextlib . suppress ( discord . HTTPException ) : <TAB> <TAB> <TAB> async for key in AsyncIter ( emoji . values ( ) , delay = 0.2 ) : <TAB> <TAB> <TAB> <TAB> await message . remove_reaction ( key , self . bot . user ) <TAB> except discord . HTTPException : <TAB> <TAB> return",if self . bot . user . is_superuser :,if not emoji :,False,93.41,71.58,,,
"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB> <TAB> value = value . upper ( ) <TAB> <TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> if value.startswith(prefix): <TAB> <TAB> <TAB> <TAB> value = value[len(prefix) :] <TAB> <TAB> <TAB> value = value.lstrip(""_"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return getattr(self.group, value) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""No such constant: %s_%s"" % (self.prefix, value)) <TAB> else: <TAB> <TAB> return value","if hasattr ( self . group , value ) :","if hasattr ( self . group , value ) :",True,100.0,74.53,,,
"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB> <TAB> quote = True <TAB> else : <TAB> <TAB> for x in self : <TAB> <TAB> <TAB> if x . token_type == "" quoted-string "" : <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote : <TAB> <TAB> pre = post = "" "" <TAB> <TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB> <TAB> return super ( DisplayName , self ) . value","if self [ 0 ] . token_type == ""cfws"" or self [ 0 ] [ 0 ] . token_type == ""cfws"" :","if self [ - 1 ] . token_type == ""cfws"" or self [ - 1 ] [ - 1 ] . token_type == ""cfws"" :",False,95.78,71.41,,,
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> if root_path : <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path : <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive",if volume_guid_path :,elif volume_guid_path :,False,98.74,72.8,,,
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> if bbox is None : <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox",if parsed_drawing is not None :,if parsed_drawing :,False,98.3,73.7,,,
"def to_key ( literal_or_identifier ) : <TAB> """""" returns string representation of this object """""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k )","elif k == """" :",elif k is None :,False,97.77,54.09,,,
"def find_multiple_stats ( stats , name , _found = None , _on_found = None ) : <TAB> if _found is None : <TAB> <TAB> _found = [ ] <TAB> for child_stats in stats : <TAB> <TAB> if child_stats . name == name : <TAB> <TAB> <TAB> _found . append ( child_stats ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _on_found ( _found ) <TAB> <TAB> find_multiple_stats ( child_stats , name , _found ) <TAB> return _found",if _on_found is not None :,if callable ( _on_found ) :,False,96.02,71.1,,,
"def _run_generated_code ( <TAB> self , <TAB> code , <TAB> globs , <TAB> locs , <TAB> fails_under_py3k = True , ) : <TAB> import warnings <TAB> from zope . interface . _compat import PYTHON3 <TAB> with warnings . catch_warnings ( record = True ) as log : <TAB> <TAB> warnings . resetwarnings ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exec ( code , globs , locs ) <TAB> <TAB> <TAB> self . assertEqual ( len ( log ) , 0 ) # no longer warn <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> exec(code, globs, locs) <TAB> <TAB> <TAB> except TypeError: <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if fails_under_py3k: <TAB> <TAB> <TAB> <TAB> <TAB> self.fail(""Didn't raise TypeError"")",if PYTHON3 :,if not PYTHON3 :,False,99.06,73.53,,,
"def _get_node ( self , node_id ) : <TAB> self . non_terminated_nodes ( { } ) # Side effect: updates cache <TAB> with self.lock: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self.cached_nodes[node_id] <TAB> <TAB> instance = ( <TAB> <TAB> <TAB> self.compute.instances() <TAB> <TAB> <TAB> .get( <TAB> <TAB> <TAB> <TAB> project=self.provider_config[""project_id""], <TAB> <TAB> <TAB> <TAB> zone=self.provider_config[""availability_zone""], <TAB> <TAB> <TAB> <TAB> instance=node_id, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> .execute() <TAB> <TAB> ) <TAB> <TAB> return instance",if node_id in self . cached_nodes :,if node_id in self . cached_nodes :,True,100.0,74.22,,,
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> if ttype == SCE_PL_UNUSED : <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount < = 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break",if tval in self . opHash :,if self . opHash . has_key ( tval ) :,False,96.2,71.81,,,
"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB> <TAB> helper = self.create_helper(**kwargs) <TAB> <TAB> if is_training and self._train_helper is None: <TAB> <TAB> <TAB> self._train_helper = helper <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._infer_helper = helper <TAB> return helper",if is_training and self . _infer_helper is None :,elif not is_training and self . _infer_helper is None :,False,98.47,72.7,,,
"def get_ldset ( self , ldsets ) : <TAB> ldset = None <TAB> if self . _properties [ "" ldset_name "" ] == "" "" : <TAB> <TAB> nldset = len ( ldsets ) <TAB> <TAB> if nldset == 0 : <TAB> <TAB> <TAB> msg = _ ( "" Logical Disk Set could not be found. "" ) <TAB> <TAB> <TAB> raise exception . NotFound ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ldset = None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> _ ( "" Logical Disk Set ` %s ` could not be found. "" ) <TAB> <TAB> <TAB> <TAB> % self . _properties [ "" ldset_name "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise exception . NotFound ( msg ) <TAB> <TAB> ldset = ldsets [ self . _properties [ "" ldset_name "" ] ] <TAB> return ldset","if self . _properties [ ""ldset_name"" ] not in ldsets :","if self . _properties [ ""ldset_name"" ] not in ldsets :",True,100.0,74.62,,,
"def calc_fractal_serial ( q , maxiter ) : <TAB> # calculate z using pure python on a numpy array <TAB> # note that, unlike the other two implementations, <TAB> # the number of iterations per point is NOT constant <TAB> z = np.zeros(q.shape, complex) <TAB> output = np.resize( <TAB> <TAB> np.array( <TAB> <TAB> <TAB> 0, <TAB> <TAB> ), <TAB> <TAB> q.shape, <TAB> ) <TAB> for i in range(len(q)): <TAB> <TAB> for iter in range(maxiter): <TAB> <TAB> <TAB> z[i] = z[i] * z[i] + q[i] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> output[i] = iter <TAB> <TAB> <TAB> <TAB> break <TAB> return output",if iter % 10000 == 0 :,if abs ( z [ i ] ) > 2.0 :,False,95.4,69.89,,,
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not inst . modctxt : <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )","if isinstance ( inst , _Block ) :","if isinstance ( inst , ( _Block , _Instantiator ) ) :",False,94.06,70.99,,,
"def walks_generator ( ) : <TAB> if filelist is not None : <TAB> <TAB> bucket = [ ] <TAB> <TAB> for filename in filelist : <TAB> <TAB> <TAB> with io . open ( filename ) as inf : <TAB> <TAB> <TAB> <TAB> for line in inf : <TAB> <TAB> <TAB> <TAB> <TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB> <TAB> <TAB> <TAB> <TAB> bucket . append ( walk ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [ ] <TAB> <TAB> if len ( bucket ) : <TAB> <TAB> <TAB> yield bucket <TAB> else : <TAB> <TAB> for _ in range ( epoch ) : <TAB> <TAB> <TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB> <TAB> <TAB> <TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB> <TAB> <TAB> <TAB> yield walks",if len ( bucket ) == batch_size :,if len ( bucket ) == batch_size :,True,100.0,74.66,,,
def _traverse ( op ) : <TAB> if op in visited : <TAB> <TAB> return <TAB> visited . add ( op ) <TAB> if tag . is_injective ( op . tag ) : <TAB> <TAB> if op not in s . outputs : <TAB> <TAB> <TAB> s [ op ] . compute_inline ( ) <TAB> <TAB> for tensor in op . input_tensors : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _traverse ( tensor . op ) <TAB> callback ( op ),if tensor . is_injective ( op . tag ) :,"if isinstance ( tensor . op , tvm . te . ComputeOp ) :",False,92.19,55.1,,,
"def unwatch_run ( self , run_id , handler ) : <TAB> with self . _dict_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _handlers_dict [ run_id ] = [ <TAB> <TAB> <TAB> <TAB> ( start_cursor , callback ) <TAB> <TAB> <TAB> <TAB> for ( start_cursor , callback ) in self . _handlers_dict [ run_id ] <TAB> <TAB> <TAB> <TAB> if callback != handler <TAB> <TAB> <TAB> ] <TAB> <TAB> if not self . _handlers_dict [ run_id ] : <TAB> <TAB> <TAB> del self . _handlers_dict [ run_id ] <TAB> <TAB> <TAB> run_id_dict = self . _run_id_dict <TAB> <TAB> <TAB> del run_id_dict [ run_id ] <TAB> <TAB> <TAB> self . _run_id_dict = run_id_dict",if run_id not in run_id_dict :,if run_id in self . _run_id_dict :,False,97.9,72.3,,,
"def _PromptMySQL ( self , config ) : <TAB> """""" Prompts the MySQL configuration, retrying if the configuration is invalid. """""" <TAB> while True : <TAB> <TAB> self . _PromptMySQLOnce ( config ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB> <TAB> <TAB> if not retry : <TAB> <TAB> <TAB> <TAB> raise ConfigInitError ( )",if self . _IsConnected ( ) :,if self . _CheckMySQLConnection ( ) :,False,98.63,98.44,,,
"def get_courses_without_topic ( topic ) : <TAB> data = [ ] <TAB> for entry in frappe . db . get_all ( "" Course "" ) : <TAB> <TAB> course = frappe . get_doc ( "" Course "" , entry . name ) <TAB> <TAB> topics = [ t . topic for t in course . topics ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data . append ( course . name ) <TAB> return data",if topic in topics :,if not topics or topic not in topics :,False,94.5,69.92,,,
"def _error_handler ( action , * * keywords ) : <TAB> if keywords : <TAB> <TAB> file_type = keywords . get ( "" file_type "" , None ) <TAB> <TAB> if file_type : <TAB> <TAB> <TAB> raise exceptions . FileTypeNotSupported ( <TAB> <TAB> <TAB> <TAB> constants . FILE_TYPE_NOT_SUPPORTED_FMT % ( file_type , action ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> keywords . pop ( "" on_demand "" ) <TAB> <TAB> <TAB> msg = "" Please check if there were typos in  "" <TAB> <TAB> <TAB> msg + = "" function parameters:  %s . Otherwise  "" <TAB> <TAB> <TAB> msg + = "" unrecognized parameters were given. "" <TAB> <TAB> <TAB> raise exceptions . UnknownParameters ( msg % keywords ) <TAB> else : <TAB> <TAB> raise exceptions . UnknownParameters ( "" No parameters found! "" )","if ""on_demand"" in keywords :","if ""on_demand"" in keywords :",True,100.0,74.58,,,
"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB> <TAB> self . view . sel ( ) . add ( r ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> <IF-STMT> <TAB> <TAB> text = "" "" . join ( to_store ) <TAB> <TAB> if not text . endswith ( "" \n "" ) : <TAB> <TAB> <TAB> text = text + "" \n "" <TAB> <TAB> state = State ( self . view ) <TAB> <TAB> state . registers [ register ] = [ text ]",if self . view . sel ( ) . count ( ) > 0 :,if register :,False,86.28,69.06,,,
"def has_actor ( self , message : HasActorMessage ) - > ResultMessage : <TAB> actor_ref = message . actor_ref <TAB> # lookup allocated <TAB> for address, item in self._allocated_actors.items(): <TAB> <TAB> ref = create_actor_ref(address, actor_ref.uid) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ResultMessage(message.message_id, True, protocol=message.protocol) <TAB> return ResultMessage(message.message_id, False, protocol=message.protocol)",if item . is_actor :,if ref in item :,False,95.23,69.64,,,
"def toggleMetaButton ( self , event ) : <TAB> """""" Process clicks on toggle buttons """""" <TAB> clickedBtn = event . EventObject <TAB> if wx . GetMouseState ( ) . GetModifiers ( ) == wx . MOD_CONTROL : <TAB> <TAB> activeBtns = [ btn for btn in self . metaButtons if btn . GetValue ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> clickedBtn . setUserSelection ( clickedBtn . GetValue ( ) ) <TAB> <TAB> <TAB> self . itemView . filterItemStore ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Do 'nothing' if we're trying to turn last active button off <TAB> <TAB> <TAB> # Keep button in the same state <TAB> <TAB> <TAB> clickedBtn.setUserSelection(True) <TAB> else: <TAB> <TAB> for btn in self.metaButtons: <TAB> <TAB> <TAB> btn.setUserSelection(btn == clickedBtn) <TAB> <TAB> self.itemView.filterItemStore()",if len ( activeBtns ) == 1 :,if activeBtns :,False,96.43,96.0,,,
"def __init__ ( self , hub = None ) : # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB> <TAB> _resolver = resolver._resolver = _DualResolver() <TAB> <TAB> if config.resolver_nameservers: <TAB> <TAB> <TAB> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",if config . resolver_timeout :,if config . resolver_timeout :,True,100.0,74.14,,,
"def sub_paragraph ( self , li ) : <TAB> """""" Search for checkbox in sub-paragraph. """""" <TAB> found = False <TAB> if len ( li ) : <TAB> <TAB> first = list ( li ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> m = RE_CHECKBOX . match ( first . text ) <TAB> <TAB> <TAB> if m is not None : <TAB> <TAB> <TAB> <TAB> first . text = self . markdown . htmlStash . store ( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB> <TAB> <TAB> <TAB> ) + m . group ( "" line "" ) <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found",if first . text :,"if first . tag == ""p"" and first . text is not None :",False,93.34,92.8,,,
"def sub_paragraph ( self , li ) : <TAB> """""" Search for checkbox in sub-paragraph. """""" <TAB> found = False <TAB> if len ( li ) : <TAB> <TAB> first = list ( li ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> m = RE_CHECKBOX . match ( first . text ) <TAB> <TAB> <TAB> if m is not None : <TAB> <TAB> <TAB> <TAB> first . text = self . markdown . htmlStash . store ( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB> <TAB> <TAB> <TAB> ) + m . group ( "" line "" ) <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found",if first . text :,"if locale [ : 2 ] == ( ""en"" ) and locale [ : 5 ] != ""en_US"" :",False,87.55,89.37,,,
"def setLabel ( self , s , protect = False ) : <TAB> """""" Set the label of the minibuffer. """""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB> <TAB> w.setAllText(s) <TAB> <TAB> n = len(s) <TAB> <TAB> w.setSelectionRange(n, n, insert=n) <TAB> <TAB> if protect: <TAB> <TAB> <TAB> k.mb_prefix = s",if g . app . gui . get_minibuffer_label ( c ) :,"if hasattr ( g . app . gui , ""set_minibuffer_label"" ) :",False,94.26,95.58,,,
"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 : # have a one element wedge <TAB> <TAB> proc = (""first"", ""last"") <TAB> else: <TAB> <TAB> if su.isFirst(innerTarget) and su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""first"", ""last"") # same element can be first and last <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> proc = (""first"",) <TAB> <TAB> elif su.isLast(innerTarget): <TAB> <TAB> <TAB> proc = (""last"",) <TAB> <TAB> else: <TAB> <TAB> <TAB> proc = () <TAB> return proc",elif su . isFirst ( innerTarget ) :,elif su . isFirst ( innerTarget ) :,True,100.0,74.31,,,
"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB> <TAB> if iterations > 100 : <TAB> <TAB> <TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> status = self . master . get_status ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> iterations + = 1 <TAB> <TAB> time . sleep ( 1.0 )","if status == ""RUNNING"" :","if status . get ( ""status"" ) == ""ENDED"" :",False,91.72,63.5,,,
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> elif isinstance ( text , ShellText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )","if isinstance ( text , Completer ) :","if isinstance ( text , CodeViewText ) :",False,98.68,73.4,,,
"def validate_party_details ( self ) : <TAB> if self . party : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB> <TAB> if self . party_account and self . party_type in ( "" Customer "" , "" Supplier "" ) : <TAB> <TAB> <TAB> self . validate_account_type ( <TAB> <TAB> <TAB> <TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB> <TAB> <TAB> )",if not erpnext . is_party_valid ( self . party ) :,"if not frappe . db . exists ( self . party_type , self . party ) :",False,93.35,69.65,,,
"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB> <TAB> elif piece : <TAB> <TAB> <TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces )",if i == 0 :,if i % 2 :,False,96.4,72.41,,,
"def _convert_java_pattern_to_python ( pattern ) : <TAB> """""" Convert a replacement pattern from the Java-style `$5` to the Python-style ` \\ 5`. """""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB> <TAB> c = s [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s [ i ] = "" \\ "" <TAB> <TAB> elif c == "" \\ "" and s [ i + 1 ] == "" $ "" : <TAB> <TAB> <TAB> s [ i ] = "" "" <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s )","if c == ""\\"" and s [ i + 1 ] == ""$"" :","if c == ""$"" and s [ i + 1 ] in ""0123456789"" :",False,96.61,93.45,,,
"def download ( self , url , filename , * * kwargs ) : <TAB> try : <TAB> <TAB> r = self . get ( url , timeout = 10 , stream = True , * * kwargs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> with open ( filename , "" wb "" ) as f : <TAB> <TAB> <TAB> for chunk in r . iter_content ( chunk_size = 1024 ) : <TAB> <TAB> <TAB> <TAB> if chunk : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( chunk ) <TAB> <TAB> helpers . chmod_as_parent ( filename ) <TAB> except Exception as e : <TAB> <TAB> sickrage . app . log . debug ( <TAB> <TAB> <TAB> "" Failed to download file from  {}  - ERROR:  {} "" . format ( url , e ) <TAB> <TAB> ) <TAB> <TAB> if os . path . exists ( filename ) : <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> <TAB> return False <TAB> return True",if r . status_code != 200 :,if r . status_code >= 400 :,False,98.41,73.67,,,
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedFilesWithExtension ( "" js "" ) : <TAB> <TAB> items . append ( <TAB> <TAB> <TAB> ' <script type= "" text/javascript ""  src= "" ' <TAB> <TAB> <TAB> + item . pathAbsoluteFromProjectEncoded ( ) <TAB> <TAB> <TAB> + ' "" ></script> ' <TAB> <TAB> ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,True,100.0,74.51,,,
"def work ( self ) : <TAB> while True : <TAB> <TAB> timeout = self . timeout <TAB> <TAB> if idle . is_set ( ) : <TAB> <TAB> <TAB> timeout = self . idle_timeout <TAB> <TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB> <TAB> fetch . wait ( timeout ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( "" Stop fetch worker "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . fetch ( )",if self . is_alive ( ) :,if shutting_down . is_set ( ) :,False,95.1,72.01,,,
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" )","if ""RSA PRIVATE KEY"" in s or ""END PRIVATE KEY"" in s :","if ""BEGIN RSA PRIVATE KEY"" in s or ""BEGIN PRIVATE KEY"" in s :",False,98.15,72.96,,,
"def compare_lists ( self , l1 , l2 , key ) : <TAB> l2_lookup = { o . get ( key ) : o for o in l2 } <TAB> for obj1 in l1 : <TAB> <TAB> obj2 = l2_lookup . get ( obj1 . get ( key ) ) <TAB> <TAB> for k in obj1 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( obj1 . get ( k ) , obj2 . get ( k ) )",if k in l2 :,"if k not in ""id"" and obj1 . get ( k ) :",False,89.38,59.85,,,
"def before_get_object ( self , view_kwargs ) : <TAB> if view_kwargs . get ( "" id "" ) is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> user_favourite_event = find_user_favourite_event_by_id ( <TAB> <TAB> <TAB> <TAB> event_id = view_kwargs [ "" id "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> except NoResultFound : <TAB> <TAB> <TAB> raise ObjectNotFound ( <TAB> <TAB> <TAB> <TAB> { "" source "" : "" /data/relationships/event "" } , "" Object: not found "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> view_kwargs [ "" id "" ] = user_favourite_event . id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> view_kwargs [ "" id "" ] = None",if user_favourite_event :,if user_favourite_event is not None :,False,98.21,72.38,,,
"def close ( self ) : <TAB> super ( ) . close ( ) <TAB> if not sys . is_finalizing ( ) : <TAB> <TAB> for sig in list ( self . _signal_handlers ) : <TAB> <TAB> <TAB> self . remove_signal_handler ( sig ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> f "" Closing the loop  { self !r} "" <TAB> <TAB> <TAB> <TAB> f "" on interpreter shutdown  "" <TAB> <TAB> <TAB> <TAB> f "" stage, skipping signal handlers removal "" , <TAB> <TAB> <TAB> <TAB> ResourceWarning , <TAB> <TAB> <TAB> <TAB> source = self , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _signal_handlers . clear ( )",if self . _loop . is_alive ( ) :,if self . _signal_handlers :,False,96.3,72.73,,,
"def install_script ( self , script , install_options = None ) : <TAB> try : <TAB> <TAB> fname = utils . do_script ( <TAB> <TAB> <TAB> script , <TAB> <TAB> <TAB> python_exe = osp . join ( self . target , "" python.exe "" ) , <TAB> <TAB> <TAB> architecture = self . architecture , <TAB> <TAB> <TAB> verbose = self . verbose , <TAB> <TAB> <TAB> install_options = install_options , <TAB> <TAB> ) <TAB> except RuntimeError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" Failed! "" ) <TAB> <TAB> <TAB> raise",if self . verbose :,if not self . verbose :,False,98.53,72.89,,,
"def GetRouterForUser ( self , username ) : <TAB> """""" Returns a router corresponding to a given username. """""" <TAB> for index , router in enumerate ( self . routers ) : <TAB> <TAB> router_id = str ( index ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . debug ( <TAB> <TAB> <TAB> <TAB> "" Matched router  %s  to user  %s "" , router . __class__ . __name__ , username <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return router <TAB> logging . debug ( <TAB> <TAB> "" No router ACL rule match for user  %s . Using default  "" "" router  %s "" , <TAB> <TAB> username , <TAB> <TAB> self . default_router . __class__ . __name__ , <TAB> ) <TAB> return self . default_router",if router . username == username :,"if self . auth_manager . CheckPermissions ( username , router_id ) :",False,93.41,77.44,,,
"def charset ( self ) : <TAB> """""" The charset from the content type. """""" <TAB> header = self . environ . get ( "" CONTENT_TYPE "" ) <TAB> if header : <TAB> <TAB> ct , options = parse_options_header ( header ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if is_known_charset ( charset ) : <TAB> <TAB> <TAB> <TAB> return charset <TAB> <TAB> <TAB> return self . unknown_charset ( charset ) <TAB> return self . default_charset",if charset :,if charset :,True,100.0,99.3,,,
def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB> <TAB> self.res() <TAB> <TAB> return True <TAB> else: <TAB> <TAB> if self.count == 1: <TAB> <TAB> <TAB> self.pertGlasPos(0) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.env.reset() <TAB> <TAB> <TAB> self.pertGlasPos(1) <TAB> <TAB> self.count += 1 <TAB> <TAB> return False,if self . env :,if self . count == self . epiLen / 2 + 1 :,False,92.58,67.53,,,
"def mtimes_of_files ( dirnames : List [ str ] , suffix : str ) - > Iterator [ float ] : <TAB> for dirname in dirnames : <TAB> <TAB> for root , dirs , files in os . walk ( dirname ) : <TAB> <TAB> <TAB> for sfile in files : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield path . getmtime ( path . join ( root , sfile ) ) <TAB> <TAB> <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass",if sfile . endswith ( suffix ) :,if sfile . endswith ( suffix ) :,True,100.0,74.41,,,
"def get_all_hashes ( self ) : <TAB> event_hashes = [ ] <TAB> sample_hashes = [ ] <TAB> for a in self . event . attributes : <TAB> <TAB> h = None <TAB> <TAB> if a . type in ( "" md5 "" , "" sha1 "" , "" sha256 "" ) : <TAB> <TAB> <TAB> h = a . value <TAB> <TAB> <TAB> event_hashes . append ( h ) <TAB> <TAB> elif a . type in ( "" filename|md5 "" , "" filename|sha1 "" , "" filename|sha256 "" ) : <TAB> <TAB> <TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB> <TAB> <TAB> event_hashes . append ( h ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB> <TAB> <TAB> sample_hashes . append ( h ) <TAB> return event_hashes , sample_hashes","elif a . type == ""sample|filename"" :","elif a . type == ""malware-sample"" :",False,98.16,73.81,,,
"def _validate ( self , event ) : <TAB> if self . type is None : <TAB> <TAB> return <TAB> new = self . value <TAB> if not isinstance ( new , self . type ) and new is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . value = event . old <TAB> <TAB> types = repr ( self . type ) if isinstance ( self . type , tuple ) else self . type . __name__ <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" LiteralInput expected  %s  type but value  %s "" <TAB> <TAB> <TAB> "" is of type  %s . "" % ( types , new , type ( new ) . __name__ ) <TAB> <TAB> )",if event . old is not None :,if event :,False,96.47,72.96,,,
"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if key not in a : <TAB> <TAB> <TAB> a [ key ] = value <TAB> <TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB> <TAB> <TAB> update_dict ( a [ key ] , value ) <TAB> <TAB> elif isinstance ( a [ key ] , list ) : <TAB> <TAB> <TAB> a [ key ] . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> a [ key ] = [ a [ key ] , value ]","if isinstance ( value , dict ) :",if value is None :,False,96.02,71.99,,,
"def on_pre_save ( self , view ) : <TAB> extOrClause = "" | "" . join ( s . get ( "" format_on_save_extensions "" ) ) <TAB> extRegex = "" \\ .( "" + extOrClause + "" )$ "" <TAB> if s . get ( "" format_on_save "" ) and re . search ( extRegex , view . file_name ( ) ) : <TAB> <TAB> # only auto-format on save if there are no ""lint errors"" <TAB> <TAB> # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB> <TAB> lints_regions = [""lint-keyword-underline"", ""lint-keyword-outline""] <TAB> <TAB> for linter in lints_regions: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> view.run_command(""js_format"")","if linter . get ( ""error"" ) :",if len ( view . get_regions ( linter ) ) :,False,95.34,67.93,,,
"def readMemory ( self , va , size ) : <TAB> for mva , mmaxva , mmap , mbytes in self . _map_defs : <TAB> <TAB> if mva < = va < mmaxva : <TAB> <TAB> <TAB> mva , msize , mperms , mfname = mmap <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise envi . SegmentationViolation ( va ) <TAB> <TAB> <TAB> offset = va - mva <TAB> <TAB> <TAB> return mbytes [ offset : offset + size ] <TAB> raise envi . SegmentationViolation ( va )",if mperms != msize :,if not mperms & MM_READ :,False,94.72,71.39,,,
"def assertFilepathsEqual ( self , p1 , p2 ) : <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p1 = [ normcase ( normpath ( x ) ) for x in p1 ] <TAB> <TAB> <TAB> p2 = [ normcase ( normpath ( x ) ) for x in p2 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> assert isinstance ( p1 , ( str , unicode ) ) <TAB> <TAB> <TAB> p1 = normcase ( normpath ( p1 ) ) <TAB> <TAB> <TAB> p2 = normcase ( normpath ( p2 ) ) <TAB> self . assertEqual ( p1 , p2 )","if isinstance ( p1 , ( str , unicode ) ) :","if isinstance ( p1 , ( list , tuple ) ) :",False,97.37,72.73,,,
"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB> <TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB> <TAB> path = join ( dir_path , p ) <TAB> <TAB> if isdir ( path ) : <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files(path, paths) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths.append(path) <TAB> return paths",elif isfile ( path ) :,"elif isfile ( path ) and path . endswith ( "".csv"" ) :",False,93.57,61.91,,,
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB> <TAB> <TAB> if not inst . modctxt : <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )","if not isinstance ( inst , ( _Block , _Instantiator ) ) :","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) :",False,97.25,72.46,,,
"def __annotations_bytes ( self ) : <TAB> if self . annotations : <TAB> <TAB> a = [ ] <TAB> <TAB> for k , v in self . annotations . items ( ) : <TAB> <TAB> <TAB> if len ( k ) != 4 : <TAB> <TAB> <TAB> <TAB> raise errors . ProtocolError ( "" annotation key must be of length 4 "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> k = k . encode ( "" ASCII "" ) <TAB> <TAB> <TAB> a . append ( struct . pack ( "" !4sH "" , k , len ( v ) ) ) <TAB> <TAB> <TAB> a . append ( v ) <TAB> <TAB> return b "" "" . join ( a ) <TAB> return b "" ""","if isinstance ( k , bytes ) :","if sys . version_info >= ( 3 , 0 ) :",False,94.04,71.34,,,
"def session ( self , profile : str = "" default "" , region : str = None ) - > boto3 . Session : <TAB> region = self . _get_region ( region , profile ) <TAB> try : <TAB> <TAB> session = self . _cache_lookup ( <TAB> <TAB> <TAB> self . _session_cache , <TAB> <TAB> <TAB> [ profile , region ] , <TAB> <TAB> <TAB> self . _boto3 . Session , <TAB> <TAB> <TAB> [ ] , <TAB> <TAB> <TAB> { "" region_name "" : region , "" profile_name "" : profile } , <TAB> <TAB> ) <TAB> except ProfileNotFound : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> session = self . _boto3 . Session ( region_name = region ) <TAB> <TAB> self . _cache_set ( self . _session_cache , [ profile , region ] , session ) <TAB> return session",if region is None :,"if profile != ""default"" :",False,96.83,68.05,,,
"def spans_score ( gold_spans , system_spans ) : <TAB> correct , gi , si = 0 , 0 , 0 <TAB> while gi < len ( gold_spans ) and si < len ( system_spans ) : <TAB> <TAB> if system_spans [ si ] . start < gold_spans [ gi ] . start : <TAB> <TAB> <TAB> si + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gi + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> correct + = gold_spans [ gi ] . end == system_spans [ si ] . end <TAB> <TAB> <TAB> si + = 1 <TAB> <TAB> <TAB> gi + = 1 <TAB> return Score ( len ( gold_spans ) , len ( system_spans ) , correct )",if gold_spans [ si ] . end < system_spans [ si ] . end :,elif gold_spans [ gi ] . start < system_spans [ si ] . start :,False,95.34,70.9,,,
"def to_api ( tag , raw_value ) : <TAB> try : <TAB> <TAB> api_tag , converter = _QL_TO_SC [ tag ] if tag else ( "" q "" , None ) <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise self . error ( <TAB> <TAB> <TAB> <TAB> "" Unsupported  ' %s '  tag. Try:  %s "" % ( tag , "" ,  "" . join ( SUPPORTED ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None , None <TAB> else : <TAB> <TAB> value = str ( converter ( raw_value ) if converter else raw_value ) <TAB> <TAB> return api_tag , value",if tag in SUPPORTED :,if tag not in SUPPORTED :,False,98.58,73.21,,,
"def unpack ( self , buf ) : <TAB> dpkt . Packet . unpack ( self , buf ) <TAB> buf = buf [ self . __hdr_len__ : ] <TAB> # single-byte IE <TAB> if self.type & 0x80: <TAB> <TAB> self.len = 0 <TAB> <TAB> self.data = b"""" <TAB> # multi-byte IE <TAB> else: <TAB> <TAB> # special PER-encoded UUIE <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.len = struct.unpack("">H"", buf[:2])[0] <TAB> <TAB> <TAB> buf = buf[2:] <TAB> <TAB> # normal TLV-like IE <TAB> <TAB> else: <TAB> <TAB> <TAB> self.len = struct.unpack(""B"", buf[:1])[0] <TAB> <TAB> <TAB> buf = buf[1:] <TAB> <TAB> self.data = buf[: self.len]",if self . type == 0x02 :,if self . type == USER_TO_USER :,False,97.33,73.25,,,
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB> <TAB> <TAB> return self . current_provider . on_file ( query )",if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :,True,100.0,74.49,,,
"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB> <TAB> if not typ : <TAB> <TAB> <TAB> out + = text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out + = "" \\ fI %s \\ fR "" % text <TAB> <TAB> elif typ in [ "" strong "" , "" code "" ] : <TAB> <TAB> <TAB> out + = "" \\ fB %s \\ fR "" % text <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out","elif typ in [ ""strong"" , ""code"" ] :","elif typ == ""em"" :",False,94.79,69.73,,,
"def process ( self , buckets ) : <TAB> with self . executor_factory ( max_workers = 3 ) as w : <TAB> <TAB> futures = { } <TAB> <TAB> results = [ ] <TAB> <TAB> for b in buckets : <TAB> <TAB> <TAB> futures [ w . submit ( self . process_bucket , b ) ] = b <TAB> <TAB> for f in as_completed ( futures ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> b = futures [ f ] <TAB> <TAB> <TAB> <TAB> self . log . error ( <TAB> <TAB> <TAB> <TAB> <TAB> "" error modifying bucket: %s \n %s "" , b [ "" Name "" ] , f . exception ( ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> results + = filter ( None , [ f . result ( ) ] ) <TAB> <TAB> return results",if f . exception ( ) :,if f . exception ( ) :,True,100.0,74.58,,,
"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB> <TAB> <TAB> <TAB> "" False. "" % self . alias <TAB> <TAB> <TAB> ) <TAB> <TAB> elif self . features . supports_timezones : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB> <TAB> <TAB> <TAB> "" handles time zones conversions natively. "" % self . alias <TAB> <TAB> <TAB> )",if self . features . USE_TZ :,if not settings . USE_TZ :,False,97.75,72.59,,,
"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB> <TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB> <TAB> if each : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> key , value = each . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> key , value = each , "" "" <TAB> <TAB> <TAB> result [ key ] = value <TAB> namespace . webhook_properties = result","if ""="" in each :","if ""="" in each :",True,100.0,74.36,,,
"def _expand_query_values ( original_query_list ) : <TAB> query_list = [ ] <TAB> for key , value in original_query_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> query_list . append ( ( key , value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> key_fmt = key + "" [ %s ] "" <TAB> <TAB> <TAB> value_list = _to_kv_list ( value ) <TAB> <TAB> <TAB> query_list . extend ( ( key_fmt % k , v ) for k , v in value_list ) <TAB> return query_list","if isinstance ( value , dict ) :","if isinstance ( value , basestring ) :",False,98.45,72.94,,,
"def tags ( ) : <TAB> """""" Return a dictionary of all tags in the form  { hash: [tag_names, ...]}. """""" <TAB> tags = { } <TAB> for ( n , c ) in list_refs ( ) : <TAB> <TAB> if n . startswith ( "" refs/tags/ "" ) : <TAB> <TAB> <TAB> name = n [ 10 : ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tags [ c ] = [ ] <TAB> <TAB> <TAB> tags [ c ] . append ( name ) # more than one tag can point at 'c' <TAB> return tags",if c not in tags :,if not c in tags :,False,98.1,97.93,,,
"def test_colorspiral ( self ) : <TAB> """""" Set of 625 colours, with jitter, using get_colors(). """""" <TAB> boxedge = 20 <TAB> boxes_per_row = 25 <TAB> rows = 0 <TAB> for i , c in enumerate ( get_colors ( 625 ) ) : <TAB> <TAB> self . c . setFillColor ( c ) <TAB> <TAB> x1 = boxedge * ( i % boxes_per_row ) <TAB> <TAB> y1 = rows * boxedge <TAB> <TAB> self . c . rect ( x1 , y1 , boxedge , boxedge , fill = 1 , stroke = 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rows + = 1 <TAB> self . finish ( )",if i % boxes_per_row == 0 :,if not ( i + 1 ) % boxes_per_row :,False,95.21,73.53,,,
"def oldest_pending_update_in_days ( ) : <TAB> """""" Return the datestamp of the oldest pending update """""" <TAB> pendingupdatespath = os . path . join ( <TAB> <TAB> prefs . pref ( "" ManagedInstallDir "" ) , "" UpdateNotificationTracking.plist "" <TAB> ) <TAB> try : <TAB> <TAB> pending_updates = FoundationPlist . readPlist ( pendingupdatespath ) <TAB> except FoundationPlist . NSPropertyListSerializationException : <TAB> <TAB> return 0 <TAB> oldest_date = now = NSDate . date ( ) <TAB> for category in pending_updates : <TAB> <TAB> for name in pending_updates [ category ] : <TAB> <TAB> <TAB> this_date = pending_updates [ category ] [ name ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> oldest_date = this_date <TAB> return now . timeIntervalSinceDate_ ( oldest_date ) / ( 24 * 60 * 60 )",if this_date < oldest_date :,if this_date < oldest_date :,True,100.0,99.53,,,
"def _try_read_gpg ( path ) : <TAB> path = os . path . expanduser ( path ) <TAB> cmd = _gpg_cmd ( ) + [ path ] <TAB> log . debug ( "" gpg cmd:  %s "" , cmd ) <TAB> try : <TAB> <TAB> p = subprocess . Popen ( <TAB> <TAB> <TAB> cmd , env = os . environ , stdout = subprocess . PIPE , stderr = subprocess . PIPE <TAB> <TAB> ) <TAB> except OSError as e : <TAB> <TAB> log . error ( "" cannot decode  %s  with command  ' %s '  ( %s ) "" , path , "" "" . join ( cmd ) , e ) <TAB> else : <TAB> <TAB> out , err = p . communicate ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . error ( err . decode ( errors = "" replace "" ) . strip ( ) ) <TAB> <TAB> <TAB> return None <TAB> <TAB> return out . decode ( errors = "" replace "" )",if err :,if p . returncode != 0 :,False,96.91,72.83,,,
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( v [ i ] , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","if isinstance ( v , dict ) :","if isinstance ( v , list ) :",False,98.62,73.39,,,
"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args = [ point , index ] <TAB> <TAB> else : <TAB> <TAB> <TAB> args = [ point ] <TAB> <TAB> if pass_widget : <TAB> <TAB> <TAB> args . append ( widget ) <TAB> <TAB> try_callback ( callback , * args ) <TAB> return",if callback . __call__ ( widget ) :,if num > 1 :,False,92.3,70.91,,,
"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB> <TAB> new_parameter = copy . deepcopy ( hp ) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_parameter.name = prefix <TAB> <TAB> elif not prefix == """": <TAB> <TAB> <TAB> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB> <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB> <TAB> _add_hp(master_cs, hp)",if not new_parameter . name :,"if new_parameter . name == """" :",False,96.61,65.99,,,
"def tearDown ( self ) : <TAB> """""" Shutdown the server. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . server . stop ( ) <TAB> <TAB> if self . sl_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,True,100.0,74.13,,,
"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB> """""" Uninstall all apps """""" <TAB> our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB> output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB> pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB> pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB> pkgs = list ( pkgs ) <TAB> for pkg_name in pkgs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" uninstalling "" , pkg_name , "" "" , end = "" "" , flush = True ) <TAB> <TAB> ok = self . app_uninstall ( pkg_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" OK "" if ok else "" FAIL "" ) <TAB> return pkgs",if verbose :,if verbose :,True,100.0,99.61,,,
"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB> """""" Uninstall all apps """""" <TAB> our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB> output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB> pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB> pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB> pkgs = list ( pkgs ) <TAB> for pkg_name in pkgs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" uninstalling "" , pkg_name , "" "" , end = "" "" , flush = True ) <TAB> <TAB> ok = self . app_uninstall ( pkg_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" OK "" if ok else "" FAIL "" ) <TAB> return pkgs",if verbose :,"if k [ - 3 : ] == ""_at"" :",False,89.36,81.02,,,
"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB> """""" Uninstall all apps """""" <TAB> our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB> output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB> pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB> pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB> pkgs = list ( pkgs ) <TAB> for pkg_name in pkgs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" uninstalling "" , pkg_name , "" "" , end = "" "" , flush = True ) <TAB> <TAB> ok = self . app_uninstall ( pkg_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" OK "" if ok else "" FAIL "" ) <TAB> return pkgs",if verbose :,"if line [ 0 : 5 ] == ""GN   "" :",False,90.11,66.7,,,
"def replace_dir_vars ( path , d ) : <TAB> """""" Replace common directory paths with appropriate variable references (e.g. /etc becomes $ {sysconfdir} ) """""" <TAB> dirvars = { } <TAB> # Sort by length so we get the variables we're interested in first <TAB> for var in sorted(list(d.keys()), key=len): <TAB> <TAB> if var.endswith(""dir"") and var.lower() == var: <TAB> <TAB> <TAB> value = d.getVar(var) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dirvars[value] = var <TAB> for dirpath in sorted(list(dirvars.keys()), reverse=True): <TAB> <TAB> path = path.replace(dirpath, ""${%s}"" % dirvars[dirpath]) <TAB> return path",if value is not None :,"if value . startswith ( ""/"" ) and not ""\n"" in value and value not in dirvars :",False,90.59,91.47,,,
"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """""" Remove the first line of comment from each file if it contains a timestamp. """""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> source = os . path . join ( root , filename ) <TAB> <TAB> <TAB> with open ( source , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> lines = f . readlines ( ) <TAB> <TAB> <TAB> if len ( lines ) < 1 : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open ( source , "" w "" ) as f : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( lines [ 0 ] ) <TAB> <TAB> <TAB> <TAB> for line in lines [ 1 : ] : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( line )","if lines [ 0 ] . startswith ( ""generated"" ) :",if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) :,False,94.04,69.33,,,
"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """""" This returns the list of plugins in the callback ordered defined from the config. """""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> all_plugins += [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name, plugin in self.plugins.items() <TAB> <TAB> <TAB> <TAB> if name not in self.plugins_callback_order and plugin.is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else: <TAB> <TAB> <TAB> plugin = self.plugins[name] <TAB> <TAB> <TAB> if plugin.is_activated: <TAB> <TAB> <TAB> <TAB> all_plugins.append(plugin) <TAB> return all_plugins",if name not in self . plugins :,if name is None :,False,97.45,97.26,,,
"def test_query_level ( self ) : <TAB> "" Tests querying at a level other than max "" <TAB> # level 2 <TAB> l2 = set() <TAB> for p in self.tile_paths: <TAB> <TAB> l2.add(p[0:2]) <TAB> for path in iterate_base4(2): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.assertTrue(self.tree.query_path(path)) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.assertFalse(self.tree.query_path(path)) <TAB> # level 1: <TAB> self.assertTrue(self.tree.query_path((0,))) <TAB> self.assertTrue(self.tree.query_path((1,))) <TAB> self.assertTrue(self.tree.query_path((2,))) <TAB> self.assertFalse(self.tree.query_path((3,)))",if path in l2 :,if path in l2 :,True,100.0,74.09,,,
"def program_exists ( name ) : <TAB> paths = ( os . getenv ( "" PATH "" ) or os . defpath ) . split ( os . pathsep ) <TAB> for p in paths : <TAB> <TAB> fn = "" %s / %s "" % ( p , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return not os . path . isdir ( fn ) and os . access ( fn , os . X_OK )",if os . path . isfile ( fn ) :,if os . path . exists ( fn ) :,False,97.7,72.85,,,
"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB> <TAB> for patching in patched . patchings : <TAB> <TAB> <TAB> arg = exit_stack . enter_context ( patching ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> keywargs . update ( arg ) <TAB> <TAB> <TAB> elif patching . new is DEFAULT : <TAB> <TAB> <TAB> <TAB> extra_args . append ( arg ) <TAB> <TAB> args + = tuple ( extra_args ) <TAB> <TAB> yield ( args , keywargs )",if patching . old is KEY :,if patching . attribute_name is not None :,False,95.71,71.63,,,
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . CONNECT_MODE : <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . POLY_MODE :,if k == neighbors . ENABLED :,False,97.43,73.11,,,
"def calcUniqueStates ( self ) : <TAB> # Here we show which colors can be relied on to map to an <TAB> # internal state. The current position will be at the first <TAB> # character in the buffer styled that color, so this might not <TAB> # work in all cases. <TAB> self.uniqueStates = {} <TAB> for k in self.holdUniqueStates.keys(): <TAB> <TAB> v = self.holdUniqueStates[k] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.uniqueStates[k] = v.keys()[0] <TAB> <TAB> <TAB> log.debug(""Map style [%s] to state [%s]"", k, v.keys()[0]) <TAB> <TAB> log.debug(""Style [%s] maps to states [%s]"", k, "", "".join(v.keys())) <TAB> self.holdUniqueStates = None",if k not in self . uniqueStates :,if len ( v . keys ( ) ) == 1 :,False,94.62,69.48,,,
"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB> <TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB> <TAB> elif "" filename "" in handler . keys ( ) : <TAB> <TAB> <TAB> filename = handler [ "" filename "" ] <TAB> <TAB> <TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB> <TAB> <TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config )",if handler_id in used_handlers :,if handler_id not in used_handlers :,False,99.03,73.85,,,
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . locations and machine . location in self . locations : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines",if self . _is_machines_selected ( machine ) :,if self . _args . host and self . _args . host == machine . name :,False,89.96,67.45,,,
"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB> <TAB> key = "" pocsuite_target "" <TAB> <TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB> <TAB> logger . info ( info_msg ) <TAB> <TAB> targets = r . get ( key ) <TAB> <TAB> count = 0 <TAB> <TAB> if targets : <TAB> <TAB> <TAB> for target in targets : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB> <TAB> logger . info ( info_msg )",if target . is_valid ( ) :,if self . add_target ( target ) :,False,96.3,72.06,,,
"def tearDown ( self ) : <TAB> suffix = str ( os . getgid ( ) ) <TAB> cli = monitoring_v3 . MetricServiceClient ( ) <TAB> for md in cli . list_metric_descriptors ( "" projects/ {} "" . format ( PROJECT ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cli . delete_metric_descriptor ( md . name ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass",if md . name . endswith ( suffix ) :,"if ""OpenCensus"" in md . name and suffix in md . name :",False,90.84,60.89,,,
"def InitializeColours ( self ) : <TAB> """""" Initializes the 16 custom colours in :class:`CustomPanel`. """""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB> <TAB> c = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> if c . IsOk ( ) : <TAB> <TAB> <TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _customColours [ i ] = wx . WHITE <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _colourSelection = i",if c == curr :,if c == curr :,True,100.0,99.43,,,
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> if index < 0 or index > = len ( self . features ) : <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]",if feature :,if feature :,True,100.0,74.66,,,
"def _get_data_from_buffer ( obj ) : <TAB> try : <TAB> <TAB> view = memoryview ( obj ) <TAB> except TypeError : <TAB> <TAB> # try to use legacy buffer protocol if 2.7, otherwise re-raise <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> view = memoryview(buffer(obj)) <TAB> <TAB> <TAB> warnings.warn( <TAB> <TAB> <TAB> <TAB> ""using old buffer interface to unpack %s; "" <TAB> <TAB> <TAB> <TAB> ""this leads to unpacking errors if slicing is used and "" <TAB> <TAB> <TAB> <TAB> ""will be removed in a future version"" % type(obj), <TAB> <TAB> <TAB> <TAB> RuntimeWarning, <TAB> <TAB> <TAB> <TAB> stacklevel=3, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> if view.itemsize != 1: <TAB> <TAB> raise ValueError(""cannot unpack from multi-byte object"") <TAB> return view","if sys . version_info < ( 2 , 7 ) :",if PY2 :,False,95.32,72.08,,,
"def import_modules ( modules , safe = True ) : <TAB> """""" Safely import a list of *modules* """""" <TAB> all = [ ] <TAB> for mname in modules : <TAB> <TAB> if mname . endswith ( "" .* "" ) : <TAB> <TAB> <TAB> to_load = expand_star ( mname ) <TAB> <TAB> else : <TAB> <TAB> <TAB> to_load = [ mname ] <TAB> <TAB> for module in to_load : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> all . append ( import_module ( module ) ) <TAB> <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> return all",if safe :,if not safe :,False,98.74,96.14,,,
"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB> <TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB> <TAB> if type == "" V "" : <TAB> <TAB> <TAB> write_vuint ( port , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> write_vint ( port , value ) <TAB> <TAB> elif type == "" s "" : <TAB> <TAB> <TAB> write_bvec ( port , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( )","elif type == ""i"" :","elif type == ""v"" :",False,98.77,73.68,,,
"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB> <TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . mkdir ( folder ) <TAB> <TAB> <TAB> init_path = join ( folder , "" __init__.py "" ) <TAB> <TAB> <TAB> if not exists ( init_path ) : <TAB> <TAB> <TAB> <TAB> create_file ( init_path )",if not exists ( folder ) :,if not exists ( folder ) :,True,100.0,74.32,,,
"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB> <TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB> <TAB> node_specific_config = self . available_node_types [ node_type ] <TAB> <TAB> if fields_key in node_specific_config : <TAB> <TAB> <TAB> fields = node_specific_config [ fields_key ] <TAB> return fields",if node_type not in self . available_node_types :,if node_type not in self . available_node_types :,True,100.0,74.42,,,
"def _maybe_fix_sequence_in_union ( <TAB> aliases : List [ Alias ] , typecst : cst . SubscriptElement ) - > cst . SubscriptElement : <TAB> slc = typecst . slice <TAB> if isinstance ( slc , cst . Index ) : <TAB> <TAB> val = slc . value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return cst . ensure_type ( <TAB> <TAB> <TAB> <TAB> typecst . deep_replace ( val , _get_clean_type_from_subscript ( aliases , val ) ) , <TAB> <TAB> <TAB> <TAB> cst . SubscriptElement , <TAB> <TAB> <TAB> ) <TAB> return typecst","if isinstance ( val , cst . SubscriptElement ) :","if isinstance ( val , cst . Subscript ) :",False,98.47,73.1,,,
"def cancel_download ( self , downloads ) : <TAB> # Make sure we're always dealing with a list <TAB> if isinstance(downloads, Download): <TAB> <TAB> downloads = [downloads] <TAB> for download in downloads: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.cancel_current_download() <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__paused = True <TAB> <TAB> <TAB> new_queue = queue.Queue() <TAB> <TAB> <TAB> while not self.__queue.empty(): <TAB> <TAB> <TAB> <TAB> queued_download = self.__queue.get() <TAB> <TAB> <TAB> <TAB> if download == queued_download: <TAB> <TAB> <TAB> <TAB> <TAB> download.cancel() <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> new_queue.put(queued_download) <TAB> <TAB> <TAB> self.__queue = new_queue <TAB> <TAB> <TAB> self.__paused = False",if self . __paused :,if download == self . __current_download :,False,96.86,71.84,,,
"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB> <TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB> <TAB> if account . discriminator == "" easaccount "" : <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB> <TAB> else : <TAB> <TAB> <TAB> create_categories_for_folders ( account , db_session ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> set_labels_for_imapuids ( account , db_session ) <TAB> <TAB> db_session . commit ( )","if account . discriminator == ""imapuids"" :","if account . discriminator == ""gmailaccount"" :",False,98.71,73.24,,,
"def __init__ ( self , fmt = None , * args ) : <TAB> if not isinstance ( fmt , BaseException ) : <TAB> <TAB> Error . __init__ ( self , fmt , * args ) <TAB> else : <TAB> <TAB> e = fmt <TAB> <TAB> cls = e . __class__ <TAB> <TAB> fmt = "" %s . %s :  %s "" % ( cls . __module__ , cls . __name__ , e ) <TAB> <TAB> tb = sys . exc_info ( ) [ 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fmt + = "" \n "" <TAB> <TAB> <TAB> fmt + = "" "" . join ( traceback . format_tb ( tb ) ) <TAB> <TAB> Error . __init__ ( self , fmt )",if tb :,if tb :,True,100.0,74.49,,,
"def setLabel ( self , label ) : <TAB> if label is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . label . scene ( ) . removeItem ( self . label ) <TAB> <TAB> <TAB> self . label = None <TAB> else : <TAB> <TAB> if self . label is None : <TAB> <TAB> <TAB> self . label = TextItem ( ) <TAB> <TAB> <TAB> self . label . setParentItem ( self ) <TAB> <TAB> self . label . setText ( label ) <TAB> <TAB> self . _updateLabel ( )",if self . label is not None :,if self . label is not None :,True,100.0,74.39,,,
"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB> <TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . handle_request ( ) <TAB> <TAB> if self . event is not None and self . event . is_set ( ) : <TAB> <TAB> <TAB> break",if rd :,if rd :,True,100.0,74.24,,,
"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB> <TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . handle_request ( ) <TAB> <TAB> if self . event is not None and self . event . is_set ( ) : <TAB> <TAB> <TAB> break",if rd :,"if formatstring == ""w:xz"" :",False,91.94,63.24,,,
"def _datastore_get_handler ( signal , sender , keys , * * kwargs ) : <TAB> txn = current_transaction ( ) <TAB> if txn : <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise PreventedReadError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Attempted to read key ( %s : %s ) inside a transaction  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" where it was marked protected "" % ( key . kind ( ) , key . id_or_name ( ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> txn . _fetched_keys . update ( set ( keys ) )",if key . is_protected ( ) :,if key in txn . _protected_keys :,False,95.88,71.9,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.35,,,
"def write_vuint ( port , x ) : <TAB> if x < 0 : <TAB> <TAB> raise Exception ( "" vuints must not be negative "" ) <TAB> elif x == 0 : <TAB> <TAB> port . write ( "" \0 "" ) <TAB> else : <TAB> <TAB> while x : <TAB> <TAB> <TAB> seven_bits = x & 0x7F <TAB> <TAB> <TAB> x >> = 7 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> port . write ( chr ( 0x80 | seven_bits ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> port . write ( chr ( seven_bits ) )",if x & 0x80 :,if x :,False,97.99,73.22,,,
"def _expand_srcs ( self ) : <TAB> """""" Expand src to [(src, full_path)] """""" <TAB> result = [ ] <TAB> for src in self . srcs : <TAB> <TAB> full_path = self . _source_file_path ( src ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Assume generated <TAB> <TAB> <TAB> full_path = self._target_file_path(src) <TAB> <TAB> result.append((src, full_path)) <TAB> return result",if not self . is_file_safe ( full_path ) :,if not os . path . exists ( full_path ) :,False,94.35,89.14,,,
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/ops "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",True,100.0,74.3,,,
"def set_shape ( self , shape ) : <TAB> """""" Sets a shape. """""" <TAB> if self . _shape is not None : <TAB> <TAB> logger . warning ( ' Modifying the shape of Placeholder  "" %s "" . ' , self . name ) <TAB> if not isinstance ( shape , ( list , tuple ) ) : <TAB> <TAB> shape = ( shape , ) <TAB> shape = tuple ( x if x != "" None "" else None for x in shape ) <TAB> for x in shape : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ParsingError ( <TAB> <TAB> <TAB> <TAB> ' All entries in  "" shape ""  must be integers, or in special  ' <TAB> <TAB> <TAB> <TAB> "" cases None. Shape is:  {} "" . format ( shape ) <TAB> <TAB> <TAB> ) <TAB> self . _shape = shape","if not isinstance ( x , ( int , float ) ) :","if not isinstance ( x , ( int , type ( None ) ) ) :",False,97.56,82.75,,,
"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB> <TAB> for field_name in field_names : <TAB> <TAB> <TAB> field_name = field_name . lower ( ) <TAB> <TAB> <TAB> if "" : "" in line : <TAB> <TAB> <TAB> <TAB> left , right = line . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> <TAB> left = left . strip ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> right = right . strip ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not right . isdigit ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None",if left . startswith ( field_name ) :,if left == field_name and len ( right ) > 0 :,False,96.08,71.42,,,
"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB> <TAB> value = getattr ( self , attribute . code , None ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> attribute . validate_value ( value ) <TAB> <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB> <TAB> <TAB> <TAB> )",if not attribute . is_blank :,if attribute . required :,False,97.43,73.17,,,
"def append ( self , s ) : <TAB> buf = self . buf <TAB> if buf is None : <TAB> <TAB> strbuf = self . strbuf <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . strbuf = strbuf + s <TAB> <TAB> <TAB> return <TAB> <TAB> buf = self . _create_buffer ( ) <TAB> buf . append ( s ) <TAB> # use buf.__len__ rather than len(buf) FBO of not getting <TAB> # OverflowError on Python 2 <TAB> sz = buf.__len__() <TAB> if not self.overflowed: <TAB> <TAB> if sz >= self.overflow: <TAB> <TAB> <TAB> self._set_large_buffer()",if strbuf :,if len ( strbuf ) + len ( s ) < STRBUF_LIMIT :,False,92.4,68.76,,,
"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB> <TAB> RequiredArgumentMissingError , <TAB> <TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB> <TAB> if namespace . name is None : <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> <IF-STMT> <TAB> <TAB> if namespace . name is None : <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" )",if namespace . by_subscription is not None :,if namespace . by_subscription is not None :,True,100.0,74.55,,,
"def Handle ( self , args , context = None ) : <TAB> for client_id in args . client_ids : <TAB> <TAB> cid = str ( client_id ) <TAB> <TAB> data_store . REL_DB . RemoveClientLabels ( cid , context . username , args . labels ) <TAB> <TAB> labels_to_remove = set ( args . labels ) <TAB> <TAB> existing_labels = data_store . REL_DB . ReadClientLabels ( cid ) <TAB> <TAB> for label in existing_labels : <TAB> <TAB> <TAB> labels_to_remove . discard ( label . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> idx = client_index . ClientIndex ( ) <TAB> <TAB> <TAB> idx . RemoveClientLabels ( cid , labels_to_remove )",if len ( labels_to_remove ) > 0 :,if labels_to_remove :,False,95.89,72.37,,,
"def delete_snapshot ( self , snapshot ) : <TAB> snap_name = self . _get_snap_name ( snapshot [ "" id "" ] ) <TAB> LOG . debug ( "" Deleting snapshot ( %s ) "" , snapshot [ "" id "" ] ) <TAB> self . client_login ( ) <TAB> try : <TAB> <TAB> self . client . delete_snapshot ( snap_name , self . backend_type ) <TAB> except exception . DotHillRequestError as ex : <TAB> <TAB> # if the volume wasn't found, ignore the error <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> LOG.exception(""Deleting snapshot %s failed"", snapshot[""id""]) <TAB> <TAB> raise exception.Invalid(ex) <TAB> finally: <TAB> <TAB> self.client_logout()",if ex . status == 404 :,"if ""The volume was not found on this system."" in ex . args :",False,92.38,64.99,,,
"def jobs ( self ) : <TAB> # How many jobs have we done? <TAB> total_processed = 0 <TAB> for jobEntity in self.jobItems.query_entities(): <TAB> <TAB> # Process the items in the page <TAB> <TAB> yield AzureJob.fromEntity(jobEntity) <TAB> <TAB> total_processed += 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Produce some feedback for the user, because this can take <TAB> <TAB> <TAB> # a long time on, for example, Azure <TAB> <TAB> <TAB> logger.debug(""Processed %d total jobs"" % total_processed) <TAB> logger.debug(""Processed %d total jobs"" % total_processed)",if total_processed % 100 == 0 :,if total_processed % 1000 == 0 :,False,98.59,72.94,,,
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . stop ( ),if self . counter >= self . max :,if self . counter == self . count :,False,97.81,97.96,,,
"def get_instance ( cls , pool_size = None ) : <TAB> if cls . _instance is not None : <TAB> <TAB> return cls . _instance <TAB> # Lazy init <TAB> with cls._SINGLETON_LOCK: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls._instance = cls( <TAB> <TAB> <TAB> <TAB> ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB> <TAB> <TAB> ) <TAB> return cls._instance",if cls . _instance is None :,if cls . _instance is None :,True,100.0,74.13,,,
"def set_state ( self , state ) : <TAB> if self . _inhibit_play : <TAB> <TAB> # PLAYING, PAUSED change the state for after buffering is finished, <TAB> <TAB> # everything else aborts buffering <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # abort <TAB> <TAB> <TAB> self.__set_inhibit_play(False) <TAB> <TAB> <TAB> self.bin.set_state(state) <TAB> <TAB> <TAB> return <TAB> <TAB> self._wanted_state = state <TAB> else: <TAB> <TAB> self.bin.set_state(state)",if state == self . _wanted_state :,"if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) :",False,90.36,63.92,,,
"def seen_add ( options ) : <TAB> seen_name = options . add_value <TAB> if is_imdb_url ( seen_name ) : <TAB> <TAB> console ( "" IMDB url detected, try to parse ID "" ) <TAB> <TAB> imdb_id = extract_id ( seen_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seen_name = imdb_id <TAB> <TAB> else : <TAB> <TAB> <TAB> console ( "" Could not parse IMDB ID "" ) <TAB> db . add ( seen_name , "" cli_add "" , { "" cli_add "" : seen_name } ) <TAB> console ( "" Added  %s  as seen. This will affect all tasks. "" % seen_name )",if imdb_id :,if imdb_id :,True,100.0,74.39,,,
"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog(gen_log, "".*Response with code 204 should not have body""): <TAB> <TAB> response = self.fetch(""/?error=1"") <TAB> <TAB> if not self.http1: <TAB> <TAB> <TAB> self.skipTest(""requires HTTP/1.x"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""curl client accepts invalid headers"") <TAB> <TAB> self.assertEqual(response.code, 599)",if not self . http1 . headers :,if self . http_client . configured_class != SimpleAsyncHTTPClient :,False,92.11,68.34,,,
"def set_related_perm ( _mapper : Mapper , _connection : Connection , target : Slice ) - > None : <TAB> src_class = target . cls_model <TAB> id_ = target . datasource_id <TAB> if id_ : <TAB> <TAB> ds = db . session . query ( src_class ) . filter_by ( id = int ( id_ ) ) . first ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> target . perm = ds . perm <TAB> <TAB> <TAB> target . schema_perm = ds . schema_perm",if ds :,if ds :,True,100.0,74.24,,,
"def on_modified_async ( self , view ) : <TAB> if self . is_command_line ( view ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> view . run_command ( "" text_pastry_selection_preview "" )",if self . editor . is_active ( ) :,"if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == ""search"" :",False,63.53,42.95,,,
"def _improve_answer_span ( <TAB> doc_tokens , input_start , input_end , tokenizer , orig_answer_text ) : <TAB> """""" Returns tokenized answer spans that better match the annotated answer. """""" <TAB> tok_answer_text = "" "" . join ( tokenizer . tokenize ( orig_answer_text ) ) <TAB> for new_start in range ( input_start , input_end + 1 ) : <TAB> <TAB> for new_end in range ( input_end , new_start - 1 , - 1 ) : <TAB> <TAB> <TAB> text_span = "" "" . join ( doc_tokens [ new_start : ( new_end + 1 ) ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return new_start , new_end <TAB> return input_start , input_end",if text_span in tok_answer_text :,if text_span == tok_answer_text :,False,98.34,98.36,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18 : <TAB> <TAB> <TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26 : <TAB> <TAB> <TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34 : <TAB> <TAB> <TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.57,,,
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if obj [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> if item_key != "" sourceVault "" : <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] )","if ""resource-group"" in obj :","if ""resourcegroup"" not in [ x . lower ( ) for x in obj . keys ( ) ] :",False,91.9,67.91,,,
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , DECODE ) <TAB> version = DECODE_VERSION <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,True,100.0,74.44,,,
"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tw.line("""") <TAB> <TAB> entry.toterminal(tw) <TAB> <TAB> if i < len(self.reprentries) - 1: <TAB> <TAB> <TAB> next_entry = self.reprentries[i + 1] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry.style == ""long"" <TAB> <TAB> <TAB> <TAB> or entry.style == ""short"" <TAB> <TAB> <TAB> <TAB> and next_entry.style == ""long"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB> <TAB> tw.line(self.extraline)",if last_style and last_style != entry . style :,"if entry . style == ""long"" :",False,95.37,91.75,,,
"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB> <TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> found + = 1 <TAB> <TAB> <TAB> if found == 2 : <TAB> <TAB> <TAB> <TAB> if division in "" \n "" . join ( lines ) : <TAB> <TAB> <TAB> <TAB> <TAB> break # already in the right place <TAB> <TAB> <TAB> <TAB> lines.insert(i + 1, """") <TAB> <TAB> <TAB> <TAB> lines.insert(i + 2, division) <TAB> <TAB> <TAB> <TAB> break <TAB> return ""\n"".join(lines)",if line . strip ( ) == division :,"if line . startswith ( '""""""' ) :",False,95.97,65.46,,,
def run_on_module ( self ) : <TAB> try : <TAB> <TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB> <TAB> if self . base . conf . strict : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e . module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e . module_depsolv_errors [ 1 ] <TAB> <TAB> <TAB> <TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger . error ( str ( e ) ),if e . module_base . conf . strict :,if e . no_match_group_specs or e . error_group_specs :,False,92.83,70.17,,,
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize )",elif size <= 7 :,elif size <= 9 :,False,98.87,73.7,,,
"def is_valid ( self ) : <TAB> """""" Determines whether file is valid for this reader """""" <TAB> blocklist = self . open ( ) <TAB> valid = True <TAB> for line in blocklist : <TAB> <TAB> line = decode_bytes ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ( start , end ) = self . parse ( line ) <TAB> <TAB> <TAB> <TAB> if not re . match ( r "" ^( \ d { 1,3} \ .) {4} $ "" , start + "" . "" ) or not re . match ( <TAB> <TAB> <TAB> <TAB> <TAB> r "" ^( \ d { 1,3} \ .) {4} $ "" , end + "" . "" <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> break <TAB> blocklist . close ( ) <TAB> return valid",if line :,if not self . is_ignored ( line ) :,False,96.33,72.21,,,
"def next ( self ) : <TAB> while self . index < len ( self . data ) : <TAB> <TAB> uid = self . _read_next_word ( ) <TAB> <TAB> dont_care = self . _read_next_word ( ) <TAB> <TAB> entry = self . _read_next_string ( ) <TAB> <TAB> total_size = int ( 4 + 4 + len ( entry ) ) <TAB> <TAB> count = int ( total_size / self . SIZE ) <TAB> <TAB> if count == 0 : <TAB> <TAB> <TAB> mod = self . SIZE - total_size <TAB> <TAB> else : <TAB> <TAB> <TAB> mod = self . SIZE - int ( total_size - ( count * self . SIZE ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> remainder = self . _read_next_block ( mod ) <TAB> <TAB> yield ( uid , entry )",if mod > 0 :,if mod > 0 :,True,100.0,74.54,,,
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> if param . name : <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> if param . type : <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out",if param . desc :,"if param . desc and """" . join ( param . desc ) . strip ( ) :",False,93.25,50.58,,,
"def assert_backend ( self , expected_translated , language = "" cs "" ) : <TAB> """""" Check that backend has correct data. """""" <TAB> translation = self . get_translation ( language ) <TAB> translation . commit_pending ( "" test "" , None ) <TAB> store = translation . component . file_format_cls ( translation . get_filename ( ) , None ) <TAB> messages = set ( ) <TAB> translated = 0 <TAB> for unit in store . content_units : <TAB> <TAB> id_hash = unit . id_hash <TAB> <TAB> self . assertFalse ( id_hash in messages , "" Duplicate string in in backend file! "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> translated + = 1 <TAB> self . assertEqual ( <TAB> <TAB> translated , <TAB> <TAB> expected_translated , <TAB> <TAB> "" Did not found expected number of translations ( {}  !=  {} ). "" . format ( <TAB> <TAB> <TAB> translated , expected_translated <TAB> <TAB> ) , <TAB> )",if unit . is_backend :,if unit . is_translated ( ) :,False,98.26,97.42,,,
"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . script_running [ 1 : ] <TAB> <TAB> elif self . script_last and self . script_last [ 1 ] == name : <TAB> <TAB> <TAB> return self . script_last [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( error )",if self . script_running and self . script_running [ 1 ] == name :,if self . script_running and self . script_running [ 1 ] == name :,True,100.0,74.32,,,
"def dict_no_value_from_proto_list ( obj_list ) : <TAB> d = dict ( ) <TAB> for item in obj_list : <TAB> <TAB> possible_dict = json . loads ( item . value_json ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB> <TAB> <TAB> # Should investigate why the config payload even has 'wandb_version'. <TAB> <TAB> <TAB> logger.warning(""key '{}' has no 'value' attribute"".format(item.key)) <TAB> <TAB> <TAB> continue <TAB> <TAB> d[item.key] = possible_dict[""value""] <TAB> return d","if possible_dict [ ""type"" ] == ""tss"" :","if not isinstance ( possible_dict , dict ) or ""value"" not in possible_dict :",False,91.01,60.89,,,
"def visit ( self , node ) : <TAB> """""" dispatcher on node ' s class/bases name. """""" <TAB> cls = node . __class__ <TAB> try : <TAB> <TAB> visitmethod = self . cache [ cls ] <TAB> except KeyError : <TAB> <TAB> for subclass in cls . __mro__ : <TAB> <TAB> <TAB> visitmethod = getattr ( self , subclass . __name__ , None ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> visitmethod = self . __object <TAB> <TAB> self . cache [ cls ] = visitmethod <TAB> visitmethod ( node )",if visitmethod is None :,if visitmethod is not None :,False,98.59,98.09,,,
"def _get_adapter ( <TAB> mcls , <TAB> reversed_mro : Tuple [ type , . . . ] , <TAB> collection : Dict [ Any , Dict [ type , Adapter ] ] , <TAB> kwargs : Dict [ str , Any ] , ) - > Optional [ Adapter ] : <TAB> registry_key = mcls . get_registry_key ( kwargs ) <TAB> adapters = collection . get ( registry_key ) <TAB> if adapters is None : <TAB> <TAB> return None <TAB> result = None <TAB> seen : Set [ Adapter ] = set ( ) <TAB> for base in reversed_mro : <TAB> <TAB> for adaptee , adapter in adapters . items ( ) : <TAB> <TAB> <TAB> found = mcls . _match_adapter ( base , adaptee , adapter ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result = found <TAB> <TAB> <TAB> <TAB> seen . add ( found ) <TAB> return result",if found not in seen :,if found and found not in seen :,False,98.82,73.66,,,
"def test_pt_BR_rg ( self ) : <TAB> for _ in range ( 100 ) : <TAB> <TAB> to_test = self . fake . rg ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert re . search ( r "" ^ \ d {8} X "" , to_test ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert re . search ( r "" ^ \ d {9} $ "" , to_test )",if self . fake . is_python :,"if ""X"" in to_test :",False,93.08,64.61,,,
"def get_user_extra_data_by_client_id ( self , client_id , username ) : <TAB> extra_data = { } <TAB> current_client = self . clients . get ( client_id , None ) <TAB> if current_client : <TAB> <TAB> for readable_field in current_client . get_readable_fields ( ) : <TAB> <TAB> <TAB> attribute = list ( <TAB> <TAB> <TAB> <TAB> filter ( <TAB> <TAB> <TAB> <TAB> <TAB> lambda f : f [ "" Name "" ] == readable_field , <TAB> <TAB> <TAB> <TAB> <TAB> self . users . get ( username ) . attributes , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> extra_data . update ( { attribute [ 0 ] [ "" Name "" ] : attribute [ 0 ] [ "" Value "" ] } ) <TAB> return extra_data",if attribute :,if len ( attribute ) > 0 :,False,97.11,72.02,,,
"def augment ( self , resources ) : <TAB> super ( ) . augment ( resources ) <TAB> for r in resources : <TAB> <TAB> md = r . get ( "" SAMLMetadataDocument "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> root = sso_metadata ( md ) <TAB> <TAB> r [ "" IDPSSODescriptor "" ] = root [ "" IDPSSODescriptor "" ] <TAB> return resources",if not md :,if not md :,True,100.0,74.13,,,
"def __init__ ( self , mode = 0 , decode = None ) : <TAB> self . regex = self . REGEX [ mode ] <TAB> self . decode = decode <TAB> if decode : <TAB> <TAB> self . header = _ ( <TAB> <TAB> <TAB> "" ### This log has been decoded with automatic search pattern \n "" <TAB> <TAB> <TAB> "" ### If some paths are not decoded you can manually decode them with: \n "" <TAB> <TAB> ) <TAB> <TAB> self . header + = "" ###  ' backintime --quiet  "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . header + = ' --profile  "" %s "" ' % decode . config . profileName ( ) <TAB> <TAB> self . header + = "" --decode <path> ' \n \n "" <TAB> else : <TAB> <TAB> self . header = "" """,if mode == 1 :,if int ( decode . config . currentProfile ( ) ) > 1 :,False,94.36,70.64,,,
"def _get_dynamic_attr ( self , attname , obj , default = None ) : <TAB> try : <TAB> <TAB> attr = getattr ( self , attname ) <TAB> except AttributeError : <TAB> <TAB> return default <TAB> if callable ( attr ) : <TAB> <TAB> # Check co_argcount rather than try/excepting the function and <TAB> <TAB> # catching the TypeError, because something inside the function <TAB> <TAB> # may raise the TypeError. This technique is more accurate. <TAB> <TAB> try: <TAB> <TAB> <TAB> code = six.get_function_code(attr) <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> code = six.get_function_code(attr.__call__) <TAB> <TAB> <IF-STMT> # one argument is 'self' <TAB> <TAB> <TAB> return attr(obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> return attr() <TAB> return attr",if code == co_argcount :,if code . co_argcount == 2 :,False,97.37,72.53,,,
"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB> <TAB> tokentype , token = tokens [ i ] <TAB> <TAB> i + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len ( tokens ) <TAB> <TAB> <TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB> <TAB> <TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB> <TAB> <TAB> i + = 2 <TAB> <TAB> if token == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token [ 0 ] in "" .0123456789 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token","if tokentype != ""ident"" :","if tokentype != ""id"" :",False,99.13,73.96,,,
"def _add_disk_config ( self , context , images ) : <TAB> for image in images : <TAB> <TAB> metadata = image [ "" metadata "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raw_value = metadata [ INTERNAL_DISK_CONFIG ] <TAB> <TAB> <TAB> value = utils . bool_from_str ( raw_value ) <TAB> <TAB> <TAB> image [ API_DISK_CONFIG ] = disk_config_to_api ( value )",if INTERNAL_DISK_CONFIG in metadata :,if INTERNAL_DISK_CONFIG in metadata :,True,100.0,74.03,,,
"def test_edgeql_expr_valid_setop_07 ( self ) : <TAB> expected_error_msg = "" cannot be applied to operands "" <TAB> # IF ELSE with every scalar as the condition <TAB> for val in get_test_values(): <TAB> <TAB> query = f""""""SELECT 1 IF {val} ELSE 2;"""""" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self.assert_query_result(query, [1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> # every other combination must produce an error <TAB> <TAB> <TAB> with self.assertRaisesRegex( <TAB> <TAB> <TAB> <TAB> edgedb.QueryError, expected_error_msg, msg=query <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> async with self.con.transaction(): <TAB> <TAB> <TAB> <TAB> <TAB> await self.con.execute(query)",if val == expected_error_msg :,"if val == ""<bool>True"" :",False,96.91,93.47,,,
"def get_all_url_infos ( ) - > Dict [ str , UrlInfo ] : <TAB> """""" Returns dict associating URL to UrlInfo. """""" <TAB> url_infos = { } <TAB> for path in _checksum_paths ( ) . values ( ) : <TAB> <TAB> dataset_url_infos = load_url_infos ( path ) <TAB> <TAB> for url , url_info in dataset_url_infos . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" URL  {}  is registered with 2+ distinct size/checksum tuples.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" {}  vs  {} "" . format ( url , url_info , url_infos [ url ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> url_infos . update ( dataset_url_infos ) <TAB> return url_infos",if url_info . size != 2 :,"if url_infos . get ( url , url_info ) != url_info :",False,94.11,93.16,,,
"def global_fixes ( ) : <TAB> """""" Yield multiple (code, function) tuples. """""" <TAB> for function in list ( globals ( ) . values ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> arguments = _get_parameters ( function ) <TAB> <TAB> <TAB> if arguments [ : 1 ] != [ "" source "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> code = extract_code_from_function ( function ) <TAB> <TAB> <TAB> if code : <TAB> <TAB> <TAB> <TAB> yield ( code , function )","if isinstance ( function , ast . FunctionType ) :",if inspect . isfunction ( function ) :,False,95.34,94.38,,,
"def createSocket ( self ) : <TAB> skt = Port . createSocket ( self ) <TAB> if self . listenMultiple : <TAB> <TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEPORT , 1 ) <TAB> return skt",if self . listenMultiple :,"if hasattr ( socket , ""SO_REUSEPORT"" ) :",False,88.04,60.17,,,
"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB> <TAB> if out and sep : <TAB> <TAB> <TAB> out . append ( sep ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out + = item . _asStringList ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out . append ( str ( item ) ) <TAB> return out","elif isinstance ( item , _StringList ) :","if isinstance ( item , ParseResults ) :",False,94.9,70.87,,,
"def parse_c_comments ( lexer , tok , ntok ) : <TAB> if tok != "" / "" or ntok != "" * "" : <TAB> <TAB> return False <TAB> quotes = lexer . quotes <TAB> lexer . quotes = "" "" <TAB> while True : <TAB> <TAB> tok = lexer . get_token ( ) <TAB> <TAB> ntok = lexer . get_token ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lexer . quotes = quotes <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> lexer . push_token ( ntok ) <TAB> return True","if tok == ""/"" and ntok == ""*"" :","if tok == ""*"" and ntok == ""/"" :",False,99.09,72.39,,,
"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB> <TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB> <TAB> if c1 : <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> if sibling.getFirstChild(): <TAB> <TAB> <TAB> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB> <TAB> sibling = sibling.getNextSibling()",if c2 :,if c2 :,True,100.0,74.43,,,
"def __view_beside ( self , onsideof , * * kwargs ) : <TAB> bounds = self . info [ "" bounds "" ] <TAB> min_dist , found = - 1 , None <TAB> for ui in UiObject ( self . session , Selector ( * * kwargs ) ) : <TAB> <TAB> dist = onsideof ( bounds , ui . info [ "" bounds "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> min_dist , found = dist , ui <TAB> return found",if dist < min_dist :,if dist >= 0 and ( min_dist < 0 or dist < min_dist ) :,False,87.91,67.69,,,
"def __eq__ ( self , other ) : <TAB> if isinstance ( other , numeric_range ) : <TAB> <TAB> empty_self = not bool ( self ) <TAB> <TAB> empty_other = not bool ( other ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return empty_self and empty_other # True if both empty <TAB> <TAB> else: <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> self._start == other._start <TAB> <TAB> <TAB> <TAB> and self._step == other._step <TAB> <TAB> <TAB> <TAB> and self._get_by_index(-1) == other._get_by_index(-1) <TAB> <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return False",if empty_self and empty_other :,if empty_self or empty_other :,False,98.83,72.9,,,
"def _buffered_generator ( self , size ) : <TAB> buf = [ ] <TAB> c_size = 0 <TAB> push = buf . append <TAB> while 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> while c_size < size : <TAB> <TAB> <TAB> <TAB> c = next ( self . _gen ) <TAB> <TAB> <TAB> <TAB> push ( c ) <TAB> <TAB> <TAB> <TAB> if c : <TAB> <TAB> <TAB> <TAB> <TAB> c_size + = 1 <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield concat ( buf ) <TAB> <TAB> del buf [ : ] <TAB> <TAB> c_size = 0",if c_size == size :,if not c_size :,False,97.46,72.6,,,
"def connect ( self ) : <TAB> with self . _conn_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Error, database not properly initialized  "" "" before opening connection "" <TAB> <TAB> <TAB> ) <TAB> <TAB> with self . exception_wrapper ( ) : <TAB> <TAB> <TAB> self . __local . conn = self . _connect ( self . database , * * self . connect_kwargs ) <TAB> <TAB> <TAB> self . __local . closed = False <TAB> <TAB> <TAB> self . initialize_connection ( self . __local . conn )",if self . __local . conn is None :,if self . deferred :,False,94.98,72.18,,,
"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB> <TAB> for name , var in new_subst . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> subst [ name ] = var <TAB> <TAB> <TAB> elif subst [ name ] is not var : <TAB> <TAB> <TAB> <TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst",if name not in subst :,if name not in subst :,True,100.0,74.29,,,
"def remove ( self , tag ) : <TAB> """""" Removes a tag recursively from all containers. """""" <TAB> new_contents = [ ] <TAB> self . content_size = 0 <TAB> for element in self . contents : <TAB> <TAB> if element . name != tag : <TAB> <TAB> <TAB> new_contents . append ( element ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> element . remove ( tag ) <TAB> <TAB> <TAB> self . content_size + = element . size ( ) <TAB> self . contents = new_contents",if element . tag == tag :,"if isinstance ( element , Container ) :",False,95.14,91.82,,,
"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB> <TAB> if isinstance ( prop_value , dict ) and prop_value : <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list(prop_value.keys())[0] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> func = getattr(self, func_name) <TAB> <TAB> <TAB> <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB> <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB> <TAB> return props",if func_name in self . fake_func_mapping :,"if func_name . startswith ( ""_"" ) :",False,96.42,63.07,,,
"def visit_try_stmt ( self , o : "" mypy.nodes.TryStmt "" ) - > str : <TAB> a = [ o . body ] # type: List[Any] <TAB> for i in range(len(o.vars)): <TAB> <TAB> a.append(o.types[i]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> a.append(o.vars[i]) <TAB> <TAB> a.append(o.handlers[i]) <TAB> if o.else_body: <TAB> <TAB> a.append((""Else"", o.else_body.body)) <TAB> if o.finally_body: <TAB> <TAB> a.append((""Finally"", o.finally_body.body)) <TAB> return self.dump(a, o)",if o . vars [ i ] :,if o . vars [ i ] :,True,100.0,74.1,,,
"def everythingIsUnicode ( d ) : <TAB> """""" Takes a dictionary, recursively verifies that every value is unicode """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True","elif isinstance ( i , dict ) and not everythingIsUnicode ( i ) :","elif isinstance ( i , _bytes ) :",False,96.37,71.97,,,
"def msg_ser ( inst , sformat , lev = 0 ) : <TAB> if sformat in [ "" urlencoded "" , "" json "" ] : <TAB> <TAB> if isinstance ( inst , Message ) : <TAB> <TAB> <TAB> res = inst . serialize ( sformat , lev ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res = inst <TAB> elif sformat == "" dict "" : <TAB> <TAB> if isinstance ( inst , Message ) : <TAB> <TAB> <TAB> res = inst . serialize ( sformat , lev ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res = inst <TAB> <TAB> elif isinstance ( inst , str ) : # Iff ID Token <TAB> <TAB> <TAB> res = inst <TAB> <TAB> else: <TAB> <TAB> <TAB> raise MessageException(""Wrong type: %s"" % type(inst)) <TAB> else: <TAB> <TAB> raise PyoidcError(""Unknown sformat"", inst) <TAB> return res","elif sformat == ""json"" :","elif isinstance ( inst , dict ) :",False,96.88,67.7,,,
"def start_container_if_stopped ( self , container , attach_logs = False , quiet = False ) : <TAB> if not container . is_running : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( "" Starting  %s "" % container . name ) <TAB> <TAB> if attach_logs : <TAB> <TAB> <TAB> container . attach_log_stream ( ) <TAB> <TAB> return self . start_container ( container )",if not quiet :,if not quiet :,True,100.0,74.1,,,
"def layer_op ( self , input_image , mask = None ) : <TAB> if not isinstance ( input_image , dict ) : <TAB> <TAB> self . _set_full_border ( input_image ) <TAB> <TAB> input_image = np . pad ( input_image , self . full_border , mode = self . mode ) <TAB> <TAB> return input_image , mask <TAB> for name , image in input_image . items ( ) : <TAB> <TAB> self . _set_full_border ( image ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tf . logging . warning ( <TAB> <TAB> <TAB> <TAB> "" could not pad, dict name  %s  not in  %s "" , name , self . image_name <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> input_image [ name ] = np . pad ( image , self . full_border , mode = self . mode ) <TAB> return input_image , mask",if name not in self . image_name :,if name not in self . image_name :,True,100.0,74.59,,,
"def __Suffix_Noun_Step2b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step2b : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> token = token [ : - 2 ] <TAB> <TAB> <TAB> self . suffix_noun_step2b_success = True <TAB> <TAB> <TAB> break <TAB> return token",if token . endswith ( suffix ) :,if token . endswith ( suffix ) and len ( token ) >= 5 :,False,90.52,66.62,,,
"def replace_header_items ( ps , replacments ) : <TAB> match = read_while ( ps , header_item_or_end_re . match , lambda match : match is None ) <TAB> while not ps . current_line . startswith ( "" */ "" ) : <TAB> <TAB> match = header_item_re . match ( ps . current_line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = match . groupdict ( ) [ "" key "" ] <TAB> <TAB> <TAB> if key in replacments : <TAB> <TAB> <TAB> <TAB> ps . current_line = match . expand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" \ g<key> \ g<space> %s \n "" % replacments [ key ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> ps . read_line ( )",if match :,if match is not None :,False,97.88,72.3,,,
"def __projectBookmark ( widget , location ) : <TAB> script = None <TAB> while widget is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> script = widget . scriptNode ( ) <TAB> <TAB> <TAB> if isinstance ( script , Gaffer . ScriptNode ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> widget = widget . parent ( ) <TAB> if script is not None : <TAB> <TAB> p = script . context ( ) . substitute ( location ) <TAB> <TAB> if not os . path . exists ( p ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . makedirs ( p ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return p <TAB> else : <TAB> <TAB> return os . getcwd ( )","if isinstance ( widget , Gaffer . WidgetNode ) :","if hasattr ( widget , ""scriptNode"" ) :",False,96.86,64.15,,,
"def events_to_str ( event_field , all_events ) : <TAB> result = [ ] <TAB> for ( flag , string ) in all_events : <TAB> <TAB> c_flag = flag <TAB> <TAB> if event_field & c_flag : <TAB> <TAB> <TAB> result . append ( string ) <TAB> <TAB> <TAB> event_field = event_field & ( ~ c_flag ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> if event_field : <TAB> <TAB> result . append ( hex ( event_field ) ) <TAB> return "" | "" . join ( result )",if event_field == 0 :,if not event_field :,False,96.24,72.04,,,
"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """""" return (bucket_name, prefix) for all s3 logging targets """""" <TAB> for b in buckets : <TAB> <TAB> if b . get ( "" Logging "" ) : <TAB> <TAB> <TAB> if self_log : <TAB> <TAB> <TAB> <TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( b [ "" Name "" ] , "" "" )","elif b . get ( ""Bucket"" ) :","if not self_log and b [ ""Name"" ] . startswith ( ""cf-templates-"" ) :",False,91.59,66.34,,,
"def extract_file ( tgz , tarinfo , dst_path , buffer_size = 10 << 20 , log_function = None ) : <TAB> """""" Extracts  ' tarinfo '  from  ' tgz '  and writes to  ' dst_path ' . """""" <TAB> src = tgz . extractfile ( tarinfo ) <TAB> if src is None : <TAB> <TAB> return <TAB> dst = tf . compat . v1 . gfile . GFile ( dst_path , "" wb "" ) <TAB> while 1 : <TAB> <TAB> buf = src . read ( buffer_size ) <TAB> <TAB> if not buf : <TAB> <TAB> <TAB> break <TAB> <TAB> dst . write ( buf ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log_function ( len ( buf ) ) <TAB> dst . close ( ) <TAB> src . close ( )",if log_function :,if log_function is not None :,False,97.79,80.12,,,
"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB> <TAB> if k in ( "" lccn "" , "" oclc "" , "" isbn "" ) : <TAB> <TAB> <TAB> fields [ k ] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields","if isinstance ( v , ( list , tuple ) ) :","if k == ""full_title"" :",False,90.9,65.22,,,
"def disconnect_application ( self ) : <TAB> if not self . is_app_running ( self . APP_BACKDROP ) : <TAB> <TAB> self . socket . send ( commands . CloseCommand ( destination_id = False ) ) <TAB> <TAB> start_time = time . time ( ) <TAB> <TAB> while not self . is_app_running ( None ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . socket . send_and_wait ( commands . StatusCommand ( ) ) <TAB> <TAB> <TAB> except cast_socket . ConnectionTerminatedException : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_time = time . time ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TimeoutException ( ) <TAB> <TAB> <TAB> time . sleep ( self . WAIT_INTERVAL ) <TAB> else : <TAB> <TAB> logger . debug ( "" Closing not necessary. Backdrop is running ... "" )",if current_time - start_time > self . MAX_TIME :,if current_time - start_time > self . timeout :,False,98.24,73.75,,,
"def matches ( self , cursor_offset , line , * * kwargs ) : <TAB> cs = lineparts . current_string ( cursor_offset , line ) <TAB> if cs is None : <TAB> <TAB> return None <TAB> matches = set ( ) <TAB> username = cs . word . split ( os . path . sep , 1 ) [ 0 ] <TAB> user_dir = os . path . expanduser ( username ) <TAB> for filename in self . safe_glob ( os . path . expanduser ( cs . word ) ) : <TAB> <TAB> if os . path . isdir ( filename ) : <TAB> <TAB> <TAB> filename + = os . path . sep <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = username + filename [ len ( user_dir ) : ] <TAB> <TAB> matches . add ( filename ) <TAB> return matches",if filename . startswith ( user_dir ) :,"if cs . word . startswith ( ""~"" ) :",False,95.65,63.99,,,
"def eventFilter ( self , obj , event ) : <TAB> if event . type ( ) == QEvent . MouseButtonPress : <TAB> <TAB> button = event . button ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _app . browser . back ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> elif button == Qt . ForwardButton : <TAB> <TAB> <TAB> self . _app . browser . forward ( ) <TAB> <TAB> <TAB> return True <TAB> return False",if button == Qt . BackButton :,if button == Qt . BackButton :,True,100.0,74.28,,,
"def reset_parameters ( self ) : <TAB> for m in self . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Embedding ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nn . init . constant_ ( m . weight , 0.1 ) <TAB> <TAB> <TAB> nn . init . constant_ ( m . bias , 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for p in m . parameters ( ) : <TAB> <TAB> <TAB> <TAB> nn . init . normal_ ( p , 0 , 0.1 )","if isinstance ( m , nn . Linear ) :","elif isinstance ( m , nn . LayerNorm ) :",False,96.76,71.88,,,
"def get_scalding_core ( self ) : <TAB> lib_dir = os . path . join ( self . scalding_home , "" lib "" ) <TAB> for j in os . listdir ( lib_dir ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p = os . path . join ( lib_dir , j ) <TAB> <TAB> <TAB> logger . debug ( "" Found scalding-core:  %s "" , p ) <TAB> <TAB> <TAB> return p <TAB> raise luigi . contrib . hadoop . HadoopJobError ( "" Could not find scalding-core. "" )","if j . endswith ( "".scalding-core"" ) :","if j . startswith ( ""scalding-core-"" ) :",False,95.89,72.13,,,
"def save ( self ) : <TAB> """""" Saves a new set of golden output frames to disk. """""" <TAB> for pixels , ( relative_to_assets , filename ) in zip ( <TAB> <TAB> self . iter_render ( ) , self . _iter_paths ( ) <TAB> ) : <TAB> <TAB> full_directory_path = os . path . join ( self . _ASSETS_DIR , relative_to_assets ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( full_directory_path ) <TAB> <TAB> path = os . path . join ( full_directory_path , filename ) <TAB> <TAB> _save_pixels ( pixels , path )",if not os . path . isdir ( full_directory_path ) :,if not os . path . exists ( full_directory_path ) :,False,98.59,98.22,,,
"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> iter = op . inputs <TAB> <TAB> else : <TAB> <TAB> <TAB> iter = op . outputs <TAB> <TAB> for i in iter : <TAB> <TAB> <TAB> for name in names : <TAB> <TAB> <TAB> <TAB> if i . raw_name == name and name not in map : <TAB> <TAB> <TAB> <TAB> <TAB> map [ i . raw_name ] = i . full_name <TAB> <TAB> if len ( map ) == len ( names ) : <TAB> <TAB> <TAB> break <TAB> for name in names : <TAB> <TAB> new_names . append ( map [ name ] ) <TAB> return new_names","if mod == ""input"" :","if mod == ""input"" :",True,100.0,74.57,,,
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",elif item [ 1 ] :,elif item [ 1 ] :,True,100.0,74.42,,,
"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions: <TAB> <TAB> if ex < 500: <TAB> <TAB> <TAB> app.register_error_handler(ex, error_http) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB> <TAB> def handle_exception(e): <TAB> <TAB> <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB> <TAB> <TAB> return error_http(FailedDependency())",if ex . status_code == 403 :,elif ex == 500 :,False,95.22,70.54,,,
"def decode ( self , ids ) : <TAB> ids = pad_decr ( ids ) <TAB> tokens = [ ] <TAB> for int_id in ids : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tokens . append ( self . _vocab_list [ int_id ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens . append ( self . _oov_token ) <TAB> return self . _decode_token_separator . join ( tokens )",if int_id in self . _vocab_list :,if int_id < len ( self . _vocab_list ) :,False,94.39,69.65,,,
"def remove_contest ( contest_id ) : <TAB> with SessionGen ( ) as session : <TAB> <TAB> contest = session . query ( Contest ) . filter ( Contest . id == contest_id ) . first ( ) <TAB> <TAB> if not contest : <TAB> <TAB> <TAB> print ( "" No contest with id  %s  found. "" % contest_id ) <TAB> <TAB> <TAB> return False <TAB> <TAB> contest_name = contest . name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" Not removing contest ` %s ' . "" % contest_name ) <TAB> <TAB> <TAB> return False <TAB> <TAB> session . delete ( contest ) <TAB> <TAB> session . commit ( ) <TAB> <TAB> print ( "" Contest ` %s '  removed. "" % contest_name ) <TAB> return True",if not session . exists ( contest_name ) :,if not ask ( contest ) :,False,96.34,72.61,,,
def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB> <TAB> if self . expr2 is None : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno,if self . expr3 is None :,if self . expr3 is None :,True,100.0,99.44,,,
"def _send_internal ( self , bytes_ ) : <TAB> # buffering <TAB> if self.pendings: <TAB> <TAB> self.pendings += bytes_ <TAB> <TAB> bytes_ = self.pendings <TAB> try: <TAB> <TAB> # reconnect if possible <TAB> <TAB> self._reconnect() <TAB> <TAB> # send message <TAB> <TAB> self.socket.sendall(bytes_) <TAB> <TAB> # send finished <TAB> <TAB> self.pendings = None <TAB> except Exception: # pylint: disable=broad-except <TAB> <TAB> # close socket <TAB> <TAB> self._close() <TAB> <TAB> # clear buffer if it exceeds max bufer size <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # TODO: add callback handler here <TAB> <TAB> <TAB> self.pendings = None <TAB> <TAB> else: <TAB> <TAB> <TAB> self.pendings = bytes_",if len ( bytes_ ) > self . max_bufer_size :,if self . pendings and ( len ( self . pendings ) > self . bufmax ) :,False,94.16,68.53,,,
"def _unpack ( self , fmt , byt ) : <TAB> d = unpack ( self . _header [ "" byteorder "" ] + fmt , byt ) [ 0 ] <TAB> if fmt [ - 1 ] in self . MISSING_VALUES : <TAB> <TAB> nmin , nmax = self . MISSING_VALUES [ fmt [ - 1 ] ] <TAB> <TAB> if d < nmin or d > nmax : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return StataMissingValue ( nmax , d ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return None <TAB> return d",if nmin == nmax :,if self . _missing_values :,False,95.08,72.26,,,
"def tuple_iter ( self ) : <TAB> for x in range ( <TAB> <TAB> self . center . x - self . max_radius , self . center . x + self . max_radius + 1 <TAB> ) : <TAB> <TAB> for y in range ( <TAB> <TAB> <TAB> self . center . y - self . max_radius , self . center . y + self . max_radius + 1 <TAB> <TAB> ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield ( x , y )",if self . center [ x ] [ y ] < self . center [ y ] [ x ] :,"if self . min_radius <= self . center . distance ( ( x , y ) ) <= self . max_radius :",False,85.24,66.39,,,
"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB> <TAB> <TAB> <TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB> <TAB> <TAB> <TAB> genename_element . attrib [ "" type "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if genename_element . attrib [ "" type "" ] == "" primary "" : <TAB> <TAB> <TAB> <TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> append_to_annotations ( ann_key , genename_element . text )","if genename_element . tag . startswith ( ""gene"" ) :","if ""type"" in genename_element . attrib :",False,95.06,71.24,,,
"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB> <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> if isinstance(c.getSymbol().getSymbolType(), SymbolType.PieSliceSymbolType): <TAB> <TAB> <TAB> c.invalidate() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices",if c . isSystemCurveIndex ( ) :,elif i == iFirstCurve :,False,95.52,70.02,,,
"def gen_app_versions ( self ) : <TAB> for app_config in apps . get_app_configs ( ) : <TAB> <TAB> name = app_config . verbose_name <TAB> <TAB> app = app_config . module <TAB> <TAB> version = self . get_app_version ( app ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield app . __name__ , name , version",if version is not None :,if version :,False,95.72,71.29,,,
"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB> <TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB> <TAB> if part in ( "" . "" , "" .. "" ) : <TAB> <TAB> <TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB> <TAB> checkpath = os . path . join ( checkpath , part ) <TAB> <TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB> <TAB> if os . path . islink ( checkpath ) : <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" )",if not os . path . exists ( checkpath ) :,if not os . path . exists ( checkpath ) :,True,100.0,74.64,,,
"def create_or_update_tag_at_scope ( cmd , resource_id = None , tags = None , tag_name = None ) : <TAB> rcf = _resource_client_factory ( cmd . cli_ctx ) <TAB> if resource_id is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IncorrectUsageError ( "" Tags could not be empty. "" ) <TAB> <TAB> Tags = cmd . get_models ( "" Tags "" ) <TAB> <TAB> tag_obj = Tags ( tags = tags ) <TAB> <TAB> return rcf . tags . create_or_update_at_scope ( scope = resource_id , properties = tag_obj ) <TAB> return rcf . tags . create_or_update ( tag_name = tag_name )",if tags is None :,if not tags :,False,97.64,72.5,,,
"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> if self . settings . get ( IGNORE_CASE_SETTING ) : <TAB> <TAB> <TAB> compare_entry = compare_entry . lower ( ) <TAB> <TAB> <TAB> compare_base = compare_base . lower ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if entry not in sugg : <TAB> <TAB> <TAB> <TAB> sugg . append ( entry ) <TAB> return sugg",if compare_entry . startswith ( compare_base ) :,"if self . compare_entries ( compare_entry , compare_base ) :",False,94.78,70.9,,,
"def createFields ( self ) : <TAB> yield String ( self , "" dict_start "" , 2 ) <TAB> while not self . eof : <TAB> <TAB> addr = self . absolute_address + self . current_size <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for field in parsePDFType ( self ) : <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> yield String ( self , "" dict_end "" , 2 )",if addr < self . absolute_address :,"if self . stream . readBytes ( addr , 2 ) != "">>"" :",False,87.83,61.63,,,
"def Visit_and_test ( self , node ) : # pylint: disable=invalid-name <TAB> # and_test ::= not_test ('and' not_test)* <TAB> for child in node.children: <TAB> <TAB> self.Visit(child) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _AppendTokenSubtype(child, format_token.Subtype.BINARY_OPERATOR)","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :","if isinstance ( child , pytree . Leaf ) and child . value == ""and"" :",True,100.0,73.74,,,
"def getfiledata ( directories ) : <TAB> columns = None <TAB> data = [ ] <TAB> counter = 1 <TAB> for directory in directories : <TAB> <TAB> for f in os . listdir ( directory ) : <TAB> <TAB> <TAB> if not os . path . isfile ( os . path . join ( directory , f ) ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> counter + = 1 <TAB> <TAB> <TAB> st = os . stat ( os . path . join ( directory , f ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> columns = [ "" rowid "" , "" name "" , "" directory "" ] + [ <TAB> <TAB> <TAB> <TAB> <TAB> x for x in dir ( st ) if x . startswith ( "" st_ "" ) <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> data . append ( [ counter , f , directory ] + [ getattr ( st , x ) for x in columns [ 3 : ] ] ) <TAB> return columns , data",if columns is None :,if columns is None :,True,100.0,74.67,,,
"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB> <TAB> value = getattr ( obj , attr , None ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = formatter ( attr , value ) <TAB> <TAB> info_add ( name , value )",if formatter :,if formatter is not None :,False,96.28,70.9,,,
"def main ( args ) : <TAB> ap = argparse . ArgumentParser ( ) <TAB> ap . add_argument ( "" job_ids "" , nargs = "" + "" , type = int , help = "" ID of a running job "" ) <TAB> ns = ap . parse_args ( args ) <TAB> _stash = globals ( ) [ "" _stash "" ] <TAB> """""" :type : StaSh """""" <TAB> for job_id in ns . job_ids : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" killing job  {}  ... "" . format ( job_id ) ) <TAB> <TAB> <TAB> worker = _stash . runtime . worker_registry . get_worker ( job_id ) <TAB> <TAB> <TAB> worker . kill ( ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" error: no such job with id:  {} "" . format ( job_id ) ) <TAB> <TAB> <TAB> break",if _stash . is_running ( job_id ) :,if job_id in _stash . runtime . worker_registry :,False,96.02,83.17,,,
"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB> <TAB> if self . choices is None : <TAB> <TAB> <TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise OptionError ( <TAB> <TAB> <TAB> <TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB> <TAB> <TAB> <TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> ) <TAB> elif self . choices is not None : <TAB> <TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self )","elif not isinstance ( self . choices , list ) :","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) :",False,93.37,69.97,,,
"def add_file ( pipe , srcpath , tgtpath ) : <TAB> with open ( srcpath , "" rb "" ) as handle : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> write ( pipe , enc ( "" M 100755 inline  %s \n "" % tgtpath ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> write ( pipe , enc ( "" M 100644 inline  %s \n "" % tgtpath ) ) <TAB> <TAB> data = handle . read ( ) <TAB> <TAB> write ( pipe , enc ( "" data  %d \n "" % len ( data ) ) ) <TAB> <TAB> write ( pipe , enc ( data ) ) <TAB> <TAB> write ( pipe , enc ( "" \n "" ) )",if os . path . exists ( srcpath ) :,"if os . access ( srcpath , os . X_OK ) :",False,94.74,71.72,,,
"def cdf ( self , x ) : <TAB> if x == numpy . inf : <TAB> <TAB> return 1.0 <TAB> else : # Inefficient sum. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError(""Invalid value."") <TAB> <TAB> c = 0.0 <TAB> <TAB> for i in xrange(x + 1): <TAB> <TAB> <TAB> c += self.probability(i) <TAB> <TAB> return c",if x < 0 :,if x != int ( x ) :,False,93.64,69.2,,,
"def convert_to_strings ( self , out , seq_len ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( out ) : <TAB> <TAB> utterances = [ ] <TAB> <TAB> for p , utt in enumerate ( batch ) : <TAB> <TAB> <TAB> size = seq_len [ b ] [ p ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> transcript = "" "" . join ( <TAB> <TAB> <TAB> <TAB> <TAB> map ( lambda x : self . int_to_char [ x . item ( ) ] , utt [ 0 : size ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> transcript = "" "" <TAB> <TAB> <TAB> utterances . append ( transcript ) <TAB> <TAB> results . append ( utterances ) <TAB> return results",if size :,if size > 0 :,False,98.46,73.32,,,
"def get_date_range ( self ) : <TAB> if not hasattr ( self , "" start "" ) or not hasattr ( self , "" end "" ) : <TAB> <TAB> args = ( self . today . year , self . today . month ) <TAB> <TAB> form = self . get_form ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args = ( int ( form . cleaned_data [ "" year "" ] ) , int ( form . cleaned_data [ "" month "" ] ) ) <TAB> <TAB> self . start = self . get_start ( * args ) <TAB> <TAB> self . end = self . get_end ( * args ) <TAB> return self . start , self . end",if form . cleaned_data :,if form . is_valid ( ) :,False,96.37,72.76,,,
"def save_stats ( self ) : <TAB> LOGGER . info ( "" Saving task-level statistics. "" ) <TAB> has_headers = os . path . isfile ( paths . TABLE_COUNT_PATH ) <TAB> with open ( paths . TABLE_COUNT_PATH , "" a "" ) as csvfile : <TAB> <TAB> headers = [ "" start_time "" , "" database_name "" , "" number_tables "" ] <TAB> <TAB> writer = csv . DictWriter ( <TAB> <TAB> <TAB> csvfile , delimiter = "" , "" , lineterminator = "" \n "" , fieldnames = headers <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> writer . writeheader ( ) <TAB> <TAB> writer . writerow ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" start_time "" : self . start_time , <TAB> <TAB> <TAB> <TAB> "" database_name "" : self . database_name , <TAB> <TAB> <TAB> <TAB> "" number_tables "" : self . count , <TAB> <TAB> <TAB> } <TAB> <TAB> )",if has_headers :,if not has_headers :,False,99.07,73.67,,,
"def _CheckCanaryCommand ( self ) : <TAB> <IF-STMT> # fast path <TAB> <TAB> return <TAB> with self._lock: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> logging.info(""Testing OpenStack CLI command is installed and working"") <TAB> <TAB> cmd = os_utils.OpenStackCLICommand(self, ""image"", ""list"") <TAB> <TAB> stdout, stderr, _ = cmd.Issue() <TAB> <TAB> if stderr: <TAB> <TAB> <TAB> raise errors.Config.InvalidValue( <TAB> <TAB> <TAB> <TAB> ""OpenStack CLI test command failed. Please make sure the OpenStack "" <TAB> <TAB> <TAB> <TAB> ""CLI client is installed and properly configured"" <TAB> <TAB> <TAB> ) <TAB> <TAB> OpenStackVirtualMachine.command_works = True",if OpenStackVirtualMachine . command_works :,if OpenStackVirtualMachine . command_works :,True,100.0,74.39,,,
"def test_windows_hidden ( self ) : <TAB> if not sys . platform == "" win32 "" : <TAB> <TAB> self . skipTest ( "" sys.platform is not windows "" ) <TAB> <TAB> return <TAB> # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB> hidden_mask = 2 <TAB> with tempfile.NamedTemporaryFile() as f: <TAB> <TAB> # Hide the file using <TAB> <TAB> success = ctypes.windll.kernel32.SetFileAttributesW(f.name, hidden_mask) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.skipTest(""unable to set file attributes"") <TAB> <TAB> self.assertTrue(hidden.is_hidden(f.name))",if not success :,if not success :,True,100.0,74.26,,,
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> if r is None : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return b "" "" . join ( y )",if e :,elif r :,False,98.41,73.37,,,
"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB> <TAB> has_xml = accepts . find ( b "" xml "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> semicolon = accepts . find ( b "" ; "" ) <TAB> <TAB> <TAB> if semicolon < 0 or has_xml < semicolon : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if has_xml > 0 :,if has_xml > 0 :,True,100.0,74.16,,,
"def times ( self , value : int ) : <TAB> if value is None : <TAB> <TAB> self . _times = None <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> candidate = int ( value ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> # pylint: disable:raise-missing-from <TAB> <TAB> <TAB> raise BarException(f""cannot set repeat times to: {value!r}"") <TAB> <TAB> if candidate < 0: <TAB> <TAB> <TAB> raise BarException( <TAB> <TAB> <TAB> <TAB> f""cannot set repeat times to a value less than zero: {value}"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise BarException(""cannot set repeat times on a start Repeat"") <TAB> <TAB> self._times = candidate",if self . start_repeat :,"if self . direction == ""start"" :",False,96.71,67.57,,,
"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB> <TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB> <TAB> if "" self "" in stack [ 0 ] . f_locals : <TAB> <TAB> <TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB> <TAB> <TAB> <TAB> print ( layer_names [ layer ] ) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> # <TAB> out=[out] <TAB> return out",if layer in layer_names :,if layer in layer_names :,True,100.0,74.55,,,
"def do_begin ( self , byte ) : <TAB> if byte . isspace ( ) : <TAB> <TAB> return <TAB> if byte != "" < "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _leadingBodyData = byte <TAB> <TAB> <TAB> return "" bodydata "" <TAB> <TAB> self . _parseError ( "" First char of document [ {!r} ] wasn ' t < "" . format ( byte ) ) <TAB> return "" tagstart """,if self . _leadingBodyData is None :,if self . beExtremelyLenient :,False,95.34,72.03,,,
"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB> <TAB> r = repr ( n ) <TAB> <TAB> <IF-STMT> # then it can be inside a comment! <TAB> <TAB> <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB> <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB> <TAB> return n <TAB> if isinstance(n, constants.Constant): <TAB> <TAB> if comment: <TAB> <TAB> <TAB> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB> <TAB> return str(n) <TAB> else: <TAB> <TAB> return hex(n)","if r . startswith ( ""//"" ) :",if not comment :,False,96.0,67.13,,,
"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB> <TAB> DEFAULT_DOMAIN_PATH , <TAB> <TAB> DEFAULT_STORIES_FILE , <TAB> <TAB> tmpdir . strpath , <TAB> <TAB> interpreter = RegexInterpreter ( ) , <TAB> <TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB> <TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB> <TAB> if hasattr ( policy . featurizer , "" max_history "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 2 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 5",if policy . featurizer . max_history == 1 :,if type ( policy ) == FormPolicy :,False,95.57,71.47,,,
"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> log ( str ( index ) + ""  --->>  "" + _distro_dir ) <TAB> <TAB> user_input = read_input_uninstall ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> <TAB> if index == user_input : <TAB> <TAB> <TAB> <TAB> <TAB> config . uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro ( ) <TAB> else : <TAB> <TAB> log ( "" No distro installed on  "" + config . usb_disk )",if user_input :,if user_input is not False :,False,98.04,72.22,,,
"def set_random_avatar ( user ) : <TAB> galleries = get_available_galleries ( include_default = True ) <TAB> if not galleries : <TAB> <TAB> raise RuntimeError ( "" no avatar galleries are set "" ) <TAB> avatars_list = [ ] <TAB> for gallery in galleries : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> avatars_list = gallery [ "" images "" ] <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> avatars_list + = gallery [ "" images "" ] <TAB> random_avatar = random . choice ( avatars_list ) <TAB> store . store_new_avatar ( user , Image . open ( random_avatar . image ) )",if not avatars_list :,"if gallery [ ""name"" ] == DEFAULT_GALLERY :",False,93.2,66.1,,,
"def make_query ( self , key , filters ) : <TAB> meta = self . get_meta ( key ) <TAB> q = { meta . facet_key : self . normalize_key ( meta . path ) } <TAB> if filters : <TAB> <TAB> if filters . get ( "" has_fulltext "" ) == "" true "" : <TAB> <TAB> <TAB> q [ "" has_fulltext "" ] = "" true "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> q [ "" publish_year "" ] = filters [ "" publish_year "" ] <TAB> return q","if filters . get ( ""publish_year"" ) :","if filters . get ( ""publish_year"" ) :",True,100.0,74.34,,,
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","elif name == ""likelihood.covar.raw_length"" :","elif name == ""mean_module.constant"" :",False,96.43,73.54,,,
"def _test_pooling ( input_shape , * * kwargs ) : <TAB> _test_pooling_iteration ( input_shape , * * kwargs ) <TAB> if is_gpu_available ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> input_shape = [ input_shape [ ii ] for ii in ( 0 , 3 , 1 , 2 ) ] <TAB> <TAB> <TAB> kwargs [ "" data_format "" ] = "" NCHW "" <TAB> <TAB> <TAB> _test_pooling_iteration ( input_shape , * * kwargs )","if isinstance ( input_shape , ( list , tuple ) ) :",if len ( input_shape ) == 4 :,False,92.37,69.18,,,
"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB> <TAB> key = "" pocsuite_target "" <TAB> <TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB> <TAB> logger . info ( info_msg ) <TAB> <TAB> targets = r . get ( key ) <TAB> <TAB> count = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for target in targets : <TAB> <TAB> <TAB> <TAB> if self . add_target ( target ) : <TAB> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB> <TAB> logger . info ( info_msg )",if targets :,if targets :,True,100.0,74.47,,,
"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> setattr ( json_api_settings , setting , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> delattr ( json_api_settings , setting )",elif setting in DEFAULTS . keys ( ) :,"elif hasattr ( json_api_settings , setting ) :",False,93.01,70.69,,,
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass","elif attrname . startswith ( ""salt_"" ) :","elif hasattr ( self . metadata , attrname ) :",False,96.43,67.71,,,
"def test_02_looking_at_listdir_path_ ( name ) : <TAB> for dline in listdir . json ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert dline [ "" type "" ] in ( "" DIRECTORY "" , "" FILE "" ) , listdir . text <TAB> <TAB> <TAB> assert dline [ "" uid "" ] == 0 , listdir . text <TAB> <TAB> <TAB> assert dline [ "" gid "" ] == 0 , listdir . text <TAB> <TAB> <TAB> assert dline [ "" name "" ] == name , listdir . text <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( f "" / { path } / { name }  not found "" )","if dline [ ""path"" ] == path :","if dline [ ""path"" ] == f""{path}/{name}"" :",False,94.01,70.5,,,
"def DeletePlugin ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB> <TAB> result = Mongo . coll [ "" Plugin "" ] . find_one_and_delete ( <TAB> <TAB> <TAB> { "" _id "" : ObjectId ( oid ) } , remove = True <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ "" filename "" ] = result [ "" filename "" ] + "" .py "" <TAB> <TAB> if os . path . exists ( file_path + result [ "" filename "" ] ) : <TAB> <TAB> <TAB> os . remove ( file_path + result [ "" filename "" ] ) <TAB> <TAB> <TAB> return "" success "" <TAB> return "" fail ""","if result [ ""filename"" ] :","if not result [ ""filename"" ] . find ( ""."" ) > - 1 :",False,93.04,68.0,,,
"def iterparent ( self , node ) : <TAB> """""" Iterator wrapper to get allowed parent and child all at once. """""" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield node, child <TAB> <TAB> <TAB> yield from self.iterparent(child)","if isinstance ( child , TOC ) :","if not self . header_rgx . match ( child . tag ) and child . tag not in [ ""pre"" , ""code"" ] :",False,78.66,62.25,,,
"def _get_matched_layout ( command ) : <TAB> # don't use command.split_script here because a layout mismatch will likely <TAB> # result in a non-splitable script as per shlex <TAB> cmd = command.script.split("" "") <TAB> for source_layout in source_layouts: <TAB> <TAB> is_all_match = True <TAB> <TAB> for cmd_part in cmd: <TAB> <TAB> <TAB> if not all([ch in source_layout or ch in ""-_"" for ch in cmd_part]): <TAB> <TAB> <TAB> <TAB> is_all_match = False <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return source_layout",if is_all_match :,if is_all_match :,True,100.0,74.34,,,
"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB> <TAB> if n . op in failed_ops : <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled ( n ) <TAB> <TAB> if has_unknown_shape ( tiled_n ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self.get_tileable_nsplits(n, chunk_result=chunk_result) <TAB> <TAB> <TAB> for node in (n, tiled_n): <TAB> <TAB> <TAB> <TAB> node._update_shape(tuple(sum(nsplit) for nsplit in new_nsplits)) <TAB> <TAB> <TAB> tiled_n._nsplits = new_nsplits",if tiled_n . shape is None :,if any ( c . key not in chunk_result for c in tiled_n . chunks ) :,False,93.0,67.2,,,
"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB> <TAB> if len ( all_items ) < target : <TAB> <TAB> <TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> on . append ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> off . append ( o ) <TAB> return on , off",if o . disabled :,if o . selected :,False,98.79,73.7,,,
def parse_flow_sequence_entry_mapping_value ( self ) : <TAB> if self . check_token ( ValueToken ) : <TAB> <TAB> token = self . get_token ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . states . append ( self . parse_flow_sequence_entry_mapping_end ) <TAB> <TAB> <TAB> return self . parse_flow_node ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB> <TAB> <TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> else : <TAB> <TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB> <TAB> token = self . peek_token ( ) <TAB> <TAB> return self . process_empty_scalar ( token . start_mark ),if token . value == ValueToken . FlowSequenceEntryMappingEnd :,"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) :",False,94.81,56.76,,,
"def serialize_config ( self , session , key , tid , language ) : <TAB> cache_key = gen_cache_key ( key , tid , language ) <TAB> cache_obj = None <TAB> if cache_key not in self . cache : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cache_obj = db_admin_serialize_node ( session , tid , language ) <TAB> <TAB> elif key == "" notification "" : <TAB> <TAB> <TAB> cache_obj = db_get_notification ( session , tid , language ) <TAB> <TAB> self . cache [ cache_key ] = cache_obj <TAB> return self . cache [ cache_key ]","if key == ""node"" :","if key == ""node"" :",True,100.0,74.36,,,
"def get_lldp_neighbors ( self ) : <TAB> commands = [ "" show lldp neighbors "" ] <TAB> output = self . device . run_commands ( commands ) [ 0 ] [ "" lldpNeighbors "" ] <TAB> lldp = { } <TAB> for n in output : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lldp [ n [ "" port "" ] ] = [ ] <TAB> <TAB> lldp [ n [ "" port "" ] ] . append ( <TAB> <TAB> <TAB> { "" hostname "" : n [ "" neighborDevice "" ] , "" port "" : n [ "" neighborPort "" ] } <TAB> <TAB> ) <TAB> return lldp","if n [ ""port"" ] not in lldp :","if n [ ""port"" ] not in lldp . keys ( ) :",False,96.6,72.25,,,
"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB> <TAB> name = venv . path . name <TAB> <TAB> if self . option ( "" full-path "" ) : <TAB> <TAB> <TAB> name = str ( venv . path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> self . line ( name )",if current_env == venv :,if venv == current_env :,False,96.94,72.72,,,
"def resolve_env_secrets ( config , environ ) : <TAB> """""" Create copy that recursively replaces  { "" $env "" :  "" NAME "" } with values from environ """""" <TAB> if isinstance ( config , dict ) : <TAB> <TAB> if list ( config . keys ( ) ) == [ "" $env "" ] : <TAB> <TAB> <TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key : resolve_env_secrets ( value , environ ) <TAB> <TAB> <TAB> <TAB> for key , value in config . items ( ) <TAB> <TAB> <TAB> } <TAB> elif isinstance ( config , list ) : <TAB> <TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB> <TAB> return config","elif config . keys ( ) == [ ""$env"" ] :","elif list ( config . keys ( ) ) == [ ""$file"" ] :",False,97.16,71.39,,,
"def _is_valid_16bit_as_path ( cls , buf ) : <TAB> two_byte_as_size = struct . calcsize ( "" !H "" ) <TAB> while buf : <TAB> <TAB> ( type_ , num_as ) = struct . unpack_from ( <TAB> <TAB> <TAB> cls . _SEG_HDR_PACK_STR , six . binary_type ( buf ) <TAB> <TAB> ) <TAB> <TAB> if type_ is not cls . _AS_SET and type_ is not cls . _AS_SEQUENCE : <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf [ struct . calcsize ( cls . _SEG_HDR_PACK_STR ) : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf [ num_as * two_byte_as_size : ] <TAB> return True",if num_as * two_byte_as_size != 2 :,if len ( buf ) < num_as * two_byte_as_size :,False,96.48,71.21,,,
"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB> <TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newParent . _element . text = "" "" <TAB> <TAB> if self . _element . text is not None : <TAB> <TAB> <TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent )",if self . _element . text is None :,if not newParent . _element . text :,False,95.82,71.62,,,
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",if operation_name == definition . name :,elif definition . name and definition . name . value == operation_name :,False,95.2,70.71,,,
"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return str ( item ) <TAB> <TAB> elif vw . isValidPointer ( item ) : <TAB> <TAB> <TAB> return vw . reprPointer ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB> <TAB> return reprComplex ( vw , item ) # recurse <TAB> elif ptype is dict: <TAB> <TAB> return ""{%s}"" % "","".join( <TAB> <TAB> <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return repr(item)",if vw . isValidString ( item ) :,if - 1024 < item < 1024 :,False,96.78,71.72,,,
"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cmds = cmd . split ( "" & "" ) <TAB> <TAB> <TAB> for c in cmds : <TAB> <TAB> <TAB> <TAB> if len ( c ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB> <TAB> else : <TAB> <TAB> <TAB> b64cmd = base64 . b64encode ( cmd ) <TAB> <TAB> <TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB> <TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd","if ""&"" in cmd :",if reverseConn not in cmd :,False,97.96,69.21,,,
"def render_tasks ( self ) - > List : <TAB> results = [ ] <TAB> for task in self . tasks . values ( ) : <TAB> <TAB> job_entry = self . jobs . get ( task . job_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not self . should_render_job ( job_entry ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> files = self . get_file_counts ( [ task ] ) <TAB> <TAB> entry = ( <TAB> <TAB> <TAB> task . job_id , <TAB> <TAB> <TAB> task . task_id , <TAB> <TAB> <TAB> task . state , <TAB> <TAB> <TAB> task . type . name , <TAB> <TAB> <TAB> task . target , <TAB> <TAB> <TAB> files , <TAB> <TAB> <TAB> task . pool , <TAB> <TAB> <TAB> task . end_time , <TAB> <TAB> ) <TAB> <TAB> results . append ( entry ) <TAB> return results",if job_entry :,if job_entry :,True,100.0,74.57,,,
"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB> <TAB> if key not in environ : <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote ( environ [ key ] ) <TAB> <TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> break <TAB> return self . app ( environ , start_response )",if request_uri . startswith ( script_name ) :,if request_uri . startswith ( script_name ) :,True,100.0,74.48,,,
"def _add_role_information ( self , function_dict , role_id ) : <TAB> # Make it easier to build rules based on policies attached to execution roles <TAB> function_dict[""role_arn""] = role_id <TAB> role_name = role_id.split(""/"")[-1] <TAB> function_dict[ <TAB> <TAB> ""execution_role"" <TAB> ] = await self.facade.awslambda.get_role_with_managed_policies(role_name) <TAB> if function_dict.get(""execution_role""): <TAB> <TAB> statements = [] <TAB> <TAB> for policy in function_dict[""execution_role""].get(""policies""): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> statements += policy[""Document""][""Statement""] <TAB> <TAB> function_dict[""execution_role""][""policy_statements""] = statements","if policy [ ""RoleArn"" ] == role_name :","if ""Document"" in policy and ""Statement"" in policy [ ""Document"" ] :",False,93.82,65.21,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 8 : <TAB> <TAB> <TAB> self . set_ts ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.14,,,
"def format_counts ( results , json_output = False , human_readable = False ) : <TAB> if json_output : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> yield json . dumps ( result ) <TAB> else : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> space_consumed = result . get ( "" spaceConsumed "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> space_consumed = _sizeof_fmt ( int ( result . get ( "" spaceConsumed "" ) ) ) <TAB> <TAB> <TAB> yield "" %12s %12s %18s %s "" % ( <TAB> <TAB> <TAB> <TAB> result . get ( "" directoryCount "" ) , <TAB> <TAB> <TAB> <TAB> result . get ( "" fileCount "" ) , <TAB> <TAB> <TAB> <TAB> space_consumed , <TAB> <TAB> <TAB> <TAB> result . get ( "" path "" ) , <TAB> <TAB> <TAB> )",if space_consumed is None :,if human_readable :,False,97.5,73.38,,,
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> if parsed_drawing : <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox",elif d . GetLayer ( ) == pcbnew . BoundingBox_Cuts :,if bbox is None :,False,94.64,71.76,,,
"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB> <TAB> if k . step is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Must specify start index "" ) <TAB> <TAB> elif k . stop is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB> <TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB> <TAB> addr = k <TAB> return self . _deeper ( addr = addr )",elif k . start is None :,elif k . start is None :,True,100.0,74.62,,,
"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB> <TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context . __copy__ ( ) ) <TAB> <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context ) <TAB> <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> except ConstructError as ex : <TAB> <TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj",if self . subcon . conflags & self . FLAG_SKIP_CONTEXT :,"if self . predicate ( subobj , context ) :",False,91.17,69.88,,,
"def before_run ( self , run_context ) : <TAB> if "" featurizer "" in self . model_portion and ( <TAB> <TAB> self . need_to_refresh or self . refresh_base_model <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . refresh_base_model = True <TAB> <TAB> self . init_fn ( <TAB> <TAB> <TAB> None , run_context . session , self . model_portion , self . refresh_base_model <TAB> <TAB> ) <TAB> <TAB> self . need_to_refresh = False <TAB> <TAB> self . refresh_base_model = False",if self . refresh_base_model :,"if self . model_portion == ""whole_featurizer"" :",False,93.58,64.93,,,
"def run ( self ) : <TAB> while True : <TAB> <TAB> task = self . requestQueue . get ( ) <TAB> <TAB> if task is None : <TAB> <TAB> <TAB> # The ""None"" value is used as a sentinel by <TAB> <TAB> <TAB> # ThreadPool.cleanup(). This indicates that there <TAB> <TAB> <TAB> # are no more tasks, so we should quit. <TAB> <TAB> <TAB> break <TAB> <TAB> try: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise SCons.Errors.BuildError(task.targets[0], errstr=interrupt_msg) <TAB> <TAB> <TAB> task.execute() <TAB> <TAB> except: <TAB> <TAB> <TAB> task.exception_set() <TAB> <TAB> <TAB> ok = False <TAB> <TAB> else: <TAB> <TAB> <TAB> ok = True <TAB> <TAB> self.resultsQueue.put((task, ok))",if task . targets :,if self . interrupted ( ) :,False,97.51,71.83,,,
"def get_overdue_evergreen_documents ( * , db_session ) - > List [ Optional [ Document ] ] : <TAB> """""" Returns all documents that have need had a recent evergreen notification. """""" <TAB> documents = ( <TAB> <TAB> db_session . query ( Document ) . filter ( Document . evergreen == True ) <TAB> ) . all ( ) # noqa <TAB> overdue_documents = [] <TAB> now = datetime.utcnow() <TAB> for d in documents: <TAB> <TAB> next_reminder = d.evergreen_last_reminder_at + timedelta( <TAB> <TAB> <TAB> days=d.evergreen_reminder_interval <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> overdue_documents.append(d) <TAB> return overdue_documents",if next_reminder > now :,if now > next_reminder :,False,97.68,97.48,,,
"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB> <TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB> <TAB> if not exists ( folder ) : <TAB> <TAB> <TAB> os . mkdir ( folder ) <TAB> <TAB> <TAB> init_path = join ( folder , "" __init__.py "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> create_file ( init_path )","if not exists ( os . path . join ( init_path , ""app.py"" ) ) :",if not exists ( init_path ) :,False,91.44,64.16,,,
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> if leaf == SymbolTrue : <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse : <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector","if isinstance ( leaf , Integer ) :","if isinstance ( leaf , Integer ) :",True,100.0,74.5,,,
"def replace ( self , old , new ) : <TAB> v_m = self . var_map <TAB> size = v_m [ self . size ] <TAB> if not ( size . is_const ( ) or size . is_ident ( ) ) : <TAB> <TAB> size . replace ( old , new ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v_m [ new . value ( ) ] = new <TAB> <TAB> <TAB> self . size = new . value ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v_m [ old ] = new",if new . is_ident ( ) :,if new . is_ident ( ) :,True,100.0,74.38,,,
"def method_for_doctype ( doctype ) : <TAB> method = "" xhtml "" <TAB> if doctype : <TAB> <TAB> if doctype . startswith ( "" html "" ) : <TAB> <TAB> <TAB> method = "" html "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> method = "" xhtml "" <TAB> <TAB> elif doctype . startswith ( "" svg "" ) : <TAB> <TAB> <TAB> method = "" xml "" <TAB> <TAB> else : <TAB> <TAB> <TAB> method = "" xhtml "" <TAB> return method","elif doctype . startswith ( ""xhtml"" ) :","elif doctype . startswith ( ""xhtml"" ) :",True,100.0,74.29,,,
"def delete ( self , trans , * * kwd ) : <TAB> idnum = kwd [ self . tagged_item_id ] <TAB> item = self . _get_item_from_id ( trans , idnum , check_writable = True ) <TAB> if item is not None : <TAB> <TAB> ex_obj = self . get_item_extended_metadata_obj ( trans , item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . unset_item_extended_metadata_obj ( trans , item ) <TAB> <TAB> <TAB> self . delete_extended_metadata ( trans , ex_obj )",if ex_obj is None :,if ex_obj is not None :,False,98.31,72.62,,,
"def check_testv ( self , testv ) : <TAB> test_good = True <TAB> f = open ( self . home , "" rb+ "" ) <TAB> for ( offset , length , operator , specimen ) in testv : <TAB> <TAB> data = self . _read_share_data ( f , offset , length ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> test_good = False <TAB> <TAB> <TAB> break <TAB> f . close ( ) <TAB> return test_good",if not data :,"if not testv_compare ( data , operator , specimen ) :",False,91.14,68.91,,,
"def get_history_user ( self , instance ) : <TAB> """""" Get the modifying user from instance or middleware. """""" <TAB> try : <TAB> <TAB> return instance . _history_user <TAB> except AttributeError : <TAB> <TAB> request = None <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> request = self . thread . request <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> pass <TAB> return self . get_user ( instance = instance , request = request )",if self . thread :,if self . thread . request . user . is_authenticated :,False,93.46,80.25,,,
"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB> <TAB> for width in VALUES : <TAB> <TAB> <TAB> strlen = abs ( width * height ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> strlen * = size <TAB> <TAB> <TAB> if strlen < MAX_LEN : <TAB> <TAB> <TAB> <TAB> data = "" A "" * strlen <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> arguments = ( data , size , width , height ) + extra <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arguments = ( data , width , height ) + extra <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> func ( * arguments ) <TAB> <TAB> <TAB> except ( ValueError , imageop . error ) : <TAB> <TAB> <TAB> <TAB> pass",if size :,if size :,True,100.0,74.62,,,
"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB> <TAB> if value and value != "" "" : <TAB> <TAB> <TAB> if value [ 0 ] != "" / "" : <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == "" load_time "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Page load time must be specified in integer milliseconds. "" <TAB> <TAB> <TAB> ) <TAB> object . __setattr__ ( self , name , value )",if value and value . integer_seconds > 0 :,"if value and not isinstance ( value , int ) :",False,96.09,71.31,,,
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> if self . is_computed ( ) : <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self . value ( ) is self : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False",if self . is_scalar ( ) :,if self . error ( ) is None :,False,98.11,72.83,,,
"def _exclude_node ( self , name ) : <TAB> if "" exclude_nodes "" in self . node_filters : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . loggit . info ( ' Excluding node  "" {0} ""  due to node_filters ' . format ( name ) ) <TAB> <TAB> <TAB> return True <TAB> return False","if self . node_filters [ ""exclude_nodes"" ] ( name ) :","if name in self . node_filters [ ""exclude_nodes"" ] :",False,94.15,69.58,,,
"def enumerate_projects ( ) : <TAB> """""" List projects in _DEFAULT_APP_DIR. """""" <TAB> src_path = os . path . join ( _DEFAULT_APP_DIR , "" src "" ) <TAB> projects = { } <TAB> for project in os . listdir ( src_path ) : <TAB> <TAB> projects [ project ] = [ ] <TAB> <TAB> project_path = os . path . join ( src_path , project ) <TAB> <TAB> for file in os . listdir ( project_path ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> projects [ project ] . append ( file [ : - 8 ] ) <TAB> return projects","if file . endswith ( "".py"" ) :","if file . endswith ( "".gwt.xml"" ) :",False,97.45,96.93,,,
"def zip_readline_read_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"") as zipfp, zipfp.open(TESTFN) as zipopen: <TAB> <TAB> data = b"""" <TAB> <TAB> while True: <TAB> <TAB> <TAB> read = zipopen.readline() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data += read <TAB> <TAB> <TAB> read = zipopen.read(100) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data += read <TAB> self.assertEqual(data, self.data)",if not read :,if not read :,True,100.0,99.35,,,
"def f ( view , s ) : <TAB> if mode == modes . NORMAL : <TAB> <TAB> return sublime . Region ( 0 ) <TAB> elif mode == modes . VISUAL : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return sublime . Region ( s . a + 1 , 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return sublime . Region ( s . a , 0 ) <TAB> elif mode == modes . INTERNAL_NORMAL : <TAB> <TAB> return sublime . Region ( view . full_line ( s . b ) . b , 0 ) <TAB> elif mode == modes . VISUAL_LINE : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return sublime . Region ( 0 , s . b ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return sublime . Region ( 0 , s . a ) <TAB> return s",if s . a < s . b :,if s . a < s . b :,True,100.0,74.61,,,
def response ( self ) : <TAB> try : <TAB> <TAB> response = requests . get ( str ( self ) ) <TAB> <TAB> rjson = response . json ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( response . text ) <TAB> <TAB> return rjson <TAB> except Exception as e : <TAB> <TAB> raise ResponseFanartError ( str ( e ) ),"if response . status_code != 200 and rjson [ ""status_code"" ] != 200 :","if not isinstance ( rjson , dict ) :",False,81.25,58.56,,,
"def __get_type ( self , cexpr ) : <TAB> """""" Returns one of the following types:  ' R '  - read value,  ' W '  - write value,  ' A '  - function argument """""" <TAB> child = cexpr <TAB> for p in reversed ( self . parents ) : <TAB> <TAB> assert p , "" Failed to get type at  "" + helper . to_hex ( self . __function_address ) <TAB> <TAB> if p . cexpr . op == idaapi . cot_call : <TAB> <TAB> <TAB> return "" Arg "" <TAB> <TAB> if not p . is_expr ( ) : <TAB> <TAB> <TAB> return "" R "" <TAB> <TAB> if p . cexpr . op == idaapi . cot_asg : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return "" W "" <TAB> <TAB> <TAB> return "" R "" <TAB> <TAB> child = p . cexpr",if not p . is_expr ( ) :,if p . cexpr . x == child :,False,96.31,92.21,,,
"def _extract_lemma ( self , parse : Parse ) - > str : <TAB> special_feats = [ x for x in self . SPECIAL_FEATURES if x in parse . tag ] <TAB> if len ( special_feats ) == 0 : <TAB> <TAB> return parse . normal_form <TAB> # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB> for other in parse.lexeme: <TAB> <TAB> tag = other.tag <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> tag.case == ""nomn"" <TAB> <TAB> <TAB> and tag.gender == parse.tag.gender <TAB> <TAB> <TAB> and tag.number == ""sing"" <TAB> <TAB> ): <TAB> <TAB> <TAB> return other.word <TAB> return parse.normal_form","if tag . case == ""patrony"" and tag . number in special_feats :",if any ( x not in tag for x in special_feats ) :,False,93.5,62.8,,,
"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self . words : <TAB> <TAB> <TAB> <TAB> matched = bool ( re . search ( _regex , w ) ) <TAB> <TAB> <TAB> <TAB> if matched : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] )","elif wildcard_count == 2 and argument [ 0 ] . endswith ( ""*"" ) :","if wildcard_count == 1 and argument [ 0 ] . endswith ( ""*"" ) :",False,98.27,73.39,,,
def getAllEntries ( self ) : <TAB> entries = [ ] <TAB> for bucket in self . buckets : <TAB> <TAB> last = None <TAB> <TAB> for entry in bucket . entries : <TAB> <TAB> <TAB> if last is not None : <TAB> <TAB> <TAB> <TAB> last . size = entry . virtualOffset - last . virtualOffset <TAB> <TAB> <TAB> last = entry <TAB> <TAB> <TAB> entries . append ( entry ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> entries [ - 1 ] . size = bucket . endOffset - entries [ - 1 ] . virtualOffset <TAB> return entries,if entries [ - 1 ] . size > bucket . endOffset :,if len ( entries ) != 0 :,False,92.36,77.17,,,
def clean ( self ) : <TAB> if self . _ctx : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) <TAB> <TAB> else : <TAB> <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_reset ( self . _ctx ) <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_free ( self . _ctx ),if libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) :,"if hasattr ( libcrypto , ""EVP_CIPHER_CTX_cleanup"" ) :",False,91.57,49.63,,,
"def _addTab ( self , name , label , idx = None ) : <TAB> label = getLanguageString ( label ) <TAB> tab = Tab ( self , name , label ) <TAB> tab . idx = self . _makeTab ( tab , idx ) <TAB> if idx != None : <TAB> <TAB> # Update index list when inserting tabs at arbitrary positions <TAB> <TAB> newIdxList = {} <TAB> <TAB> for tIdx, t in list(self._tabs_by_idx.items()): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> t.idx += 1 <TAB> <TAB> <TAB> newIdxList[t.idx] = t <TAB> <TAB> self._tabs_by_idx = newIdxList <TAB> self._tabs_by_idx[tab.idx] = tab <TAB> self._tabs_by_name[tab.name] = tab <TAB> return tab",if t . idx < idx :,if int ( tIdx ) >= idx :,False,96.64,71.67,,,
"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB> <TAB> user = self . users . get ( current_user . id , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if _new_login : <TAB> <TAB> <TAB> <TAB> user [ "" session_count "" ] + = 1 <TAB> <TAB> <TAB> user [ "" key "" ] = _key",if user is None :,if user is None :,True,100.0,74.36,,,
"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB> <TAB> self.rpcserver.stop() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.backend_rpcserver.stop() <TAB> <TAB> if self.cluster_rpcserver: <TAB> <TAB> <TAB> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.coordination: <TAB> <TAB> try: <TAB> <TAB> <TAB> coordination.COORDINATOR.stop() <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass <TAB> super(Service, self).stop(graceful=True)",if self . backend_rpcserver :,if self . backend_rpcserver :,True,100.0,74.29,,,
"def __genmenuOnlyAllocated ( menu ) : <TAB> for submenu in menu . Submenus : <TAB> <TAB> __genmenuOnlyAllocated ( submenu ) <TAB> if menu . OnlyUnallocated == True : <TAB> <TAB> tmp [ "" cache "" ] . addMenuEntries ( menu . AppDirs ) <TAB> <TAB> menuentries = [ ] <TAB> <TAB> for rule in menu . Rules : <TAB> <TAB> <TAB> menuentries = rule . do ( <TAB> <TAB> <TAB> <TAB> tmp [ "" cache "" ] . getMenuEntries ( menu . AppDirs ) , rule . Type , 2 <TAB> <TAB> <TAB> ) <TAB> <TAB> for menuentry in menuentries : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> menuentry . Parents . append ( menu ) <TAB> <TAB> <TAB> <TAB> #  menuentry.Add = False <TAB> <TAB> <TAB> <TAB> #  menuentry.Allocated = True <TAB> <TAB> <TAB> <TAB> menu.MenuEntries.append(menuentry)",if menuentry . Add == True :,if menuentry . Add == True :,True,100.0,74.57,,,
"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB> <TAB> from pygments . lexers . _lua_builtins import MODULES <TAB> <TAB> for mod , func in iteritems ( MODULES ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options )","if isinstance ( func , ( Module , Module ) ) :",if mod not in self . disabled_modules :,False,93.69,69.99,,,
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> elif r : <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y )",if e :,if r is None :,False,97.95,72.93,,,
"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB> <TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB> <TAB> <TAB> if child . h . startswith ( tag ) : <TAB> <TAB> <TAB> <TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList",if child . b is None :,"if tag == ""@menu"" :",False,96.72,69.06,,,
"def import_suffix_generator ( a_block , datatype = False ) : <TAB> if datatype is False : <TAB> <TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield name , suffix <TAB> else : <TAB> <TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB> <TAB> <TAB> if ( suffix . import_enabled ( ) is True ) and ( <TAB> <TAB> <TAB> <TAB> suffix . get_datatype ( ) is datatype <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> yield name , suffix",if suffix . import_enabled ( ) is True :,if suffix . import_enabled ( ) is True :,True,100.0,74.48,,,
"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB> <TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB> <TAB> if part in ( "" . "" , "" .. "" ) : <TAB> <TAB> <TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB> <TAB> checkpath = os . path . join ( checkpath , part ) <TAB> <TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB> <TAB> if not os . path . exists ( checkpath ) : <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" )",if not os . path . islink ( checkpath ) :,if os . path . islink ( checkpath ) :,False,98.91,74.06,,,
"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB> <TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if fstyle . startswith ( "" % ( "" ) and fstyle . endswith ( "" )s "" ) : <TAB> <TAB> <TAB> <TAB> key = fstyle [ 2 : - 2 ] <TAB> <TAB> <TAB> <TAB> fstyle = context [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats","if isinstance ( fstyle , str ) :","if isinstance ( fstyle , basestring ) :",False,99.07,74.02,,,
"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB> <TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB> <TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB> <TAB> <TAB> if len ( ci_names ) == 0 or ci . lower ( ) in ci_names : <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result","if key == ""ci"" :","if key == ""CI_KEEP_ALIVE"" :",False,96.83,73.68,,,
"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB> <TAB> fn = mo . groups ( ) [ 0 ] <TAB> <TAB> fn = fn . replace ( "" "" , "" _ "" ) <TAB> <TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB> <TAB> if not fn : <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn = unicode ( fn ) <TAB> <TAB> if note_markdown ( note ) : <TAB> <TAB> <TAB> fn + = "" .mkdn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> fn + = "" .txt "" <TAB> <TAB> return fn <TAB> else : <TAB> <TAB> return "" ""","if isinstance ( fn , bytes ) :","if isinstance ( fn , str ) :",False,99.0,73.84,,,
"def post ( self , orgname , teamname ) : <TAB> if _syncing_setup_allowed ( orgname ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> team = model . team . get_organization_team ( orgname , teamname ) <TAB> <TAB> except model . InvalidTeamException : <TAB> <TAB> <TAB> raise NotFound ( ) <TAB> <TAB> config = request . get_json ( ) <TAB> <TAB> # Ensure that the specified config points to a valid group. <TAB> <TAB> status, err = authentication.check_group_lookup_args(config) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidRequest(""Could not sync to group: %s"" % err) <TAB> <TAB> # Set the team's syncing config. <TAB> <TAB> model.team.set_team_syncing(team, authentication.federated_service, config) <TAB> <TAB> return team_view(orgname, team) <TAB> raise Unauthorized()",if status != 200 :,if not status :,False,97.74,72.72,,,
"def _marshalData ( self ) : <TAB> if self . _cache == None : <TAB> <TAB> d = self . _data <TAB> <TAB> s = "" "" <TAB> <TAB> s = time . strftime ( "" % H: % M: % S "" , ( 0 , 0 , 0 ) + d + ( 0 , 0 , - 1 ) ) <TAB> <TAB> f = d [ 2 ] - int ( d [ 2 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s + = ( "" %g "" % f ) [ 1 : ] <TAB> <TAB> s + = "" Z "" <TAB> <TAB> self . _cache = s <TAB> return self . _cache",if f > 0 :,if f != 0 :,False,97.93,73.45,,,
"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB> <TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB> <TAB> if level_ref < 0 : <TAB> <TAB> <TAB> level_ref + = len ( levels ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB> <TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) )",if level_ref >= len ( levels ) :,if not ( 0 <= level_ref < len ( levels ) ) :,False,93.72,70.19,,,
"def iterfieldselect ( source , field , where , complement , missing ) : <TAB> it = iter ( source ) <TAB> hdr = next ( it ) <TAB> yield tuple ( hdr ) <TAB> indices = asindices ( hdr , field ) <TAB> getv = operator . itemgetter ( * indices ) <TAB> for row in it : <TAB> <TAB> try : <TAB> <TAB> <TAB> v = getv ( row ) <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> v = missing <TAB> <TAB> <IF-STMT> # XOR <TAB> <TAB> <TAB> yield tuple(row)",if ( v == where ) or ( v == complement ) :,if bool ( where ( v ) ) != complement :,False,91.96,69.79,,,
"def _test_wait_read_invalid_switch ( self , sleep ) : <TAB> sock1 , sock2 = socket . socketpair ( ) <TAB> try : <TAB> <TAB> p = gevent . spawn ( <TAB> <TAB> <TAB> util . wrap_errors ( <TAB> <TAB> <TAB> <TAB> AssertionError , socket . wait_read <TAB> <TAB> <TAB> ) , # pylint:disable=no-member <TAB> <TAB> <TAB> sock1.fileno(), <TAB> <TAB> ) <TAB> <TAB> gevent.get_hub().loop.run_callback(switch_None, p) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gevent.sleep(sleep) <TAB> <TAB> result = p.get() <TAB> <TAB> assert isinstance(result, AssertionError), result <TAB> <TAB> assert ""Invalid switch"" in str(result), repr(str(result)) <TAB> finally: <TAB> <TAB> sock1.close() <TAB> <TAB> sock2.close()",if sleep :,if sleep is not None :,False,98.19,71.66,,,
"def train ( config , args ) : <TAB> gan = setup_gan ( config , inputs , args ) <TAB> test_batches = [ ] <TAB> for i in range ( args . steps ) : <TAB> <TAB> gan . step ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> correct_prediction = 0 <TAB> <TAB> <TAB> total = 0 <TAB> <TAB> <TAB> for ( x , y ) in gan . inputs . testdata ( ) : <TAB> <TAB> <TAB> <TAB> prediction = gan . generator ( x ) <TAB> <TAB> <TAB> <TAB> correct_prediction + = ( <TAB> <TAB> <TAB> <TAB> <TAB> torch . argmax ( prediction , 1 ) == torch . argmax ( y , 1 ) <TAB> <TAB> <TAB> <TAB> ) . sum ( ) <TAB> <TAB> <TAB> <TAB> total + = y . shape [ 0 ] <TAB> <TAB> <TAB> accuracy = ( float ( correct_prediction ) / total ) * 100 <TAB> <TAB> <TAB> print ( "" accuracy:  "" , accuracy ) <TAB> return sum_metrics",if args . verbose :,if i % args . sample_every == 0 and i > 0 :,False,94.74,71.28,,,
"def process_response ( self , request , response , spider ) : <TAB> if not response . body : <TAB> <TAB> return response <TAB> for fmt , func in six . iteritems ( self . _formats ) : <TAB> <TAB> new_response = func ( response ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> "" Decompressed response with format:  %(responsefmt)s "" , <TAB> <TAB> <TAB> <TAB> { "" responsefmt "" : fmt } , <TAB> <TAB> <TAB> <TAB> extra = { "" spider "" : spider } , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return new_response <TAB> return response",if new_response . responsefmt == fmt :,if new_response :,False,96.49,72.85,,,
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> if option != other_option : <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option","if isinstance ( option , six . string_types ) :","if scan_argv ( self . argv , option ) is not None :",False,93.71,69.12,,,
"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB> <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB> if cls.needs_target_sync: <TAB> <TAB> <TAB> unit.target = unit.source <TAB> <TAB> <TAB> unit.rich_target = unit.rich_source <TAB> return store","if unit . source == """" :",if unit . isheader ( ) :,False,96.45,67.31,,,
"def _pre_get_table ( self , _ctx , table_name ) : <TAB> vsctl_table = self . _get_table ( table_name ) <TAB> schema_helper = self . schema_helper <TAB> schema_helper . register_table ( vsctl_table . table_name ) <TAB> for row_id in vsctl_table . row_ids : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> schema_helper . register_table ( row_id . table ) <TAB> <TAB> if row_id . name_column : <TAB> <TAB> <TAB> schema_helper . register_columns ( row_id . table , [ row_id . name_column ] ) <TAB> <TAB> if row_id . uuid_column : <TAB> <TAB> <TAB> schema_helper . register_columns ( row_id . table , [ row_id . uuid_column ] ) <TAB> return vsctl_table",if row_id . table_name :,if row_id . table :,False,98.42,73.3,,,
"def __init__ ( self , pin = None , pull_up = False ) : <TAB> super ( InputDevice , self ) . __init__ ( pin ) <TAB> try : <TAB> <TAB> self . pin . function = "" input "" <TAB> <TAB> pull = "" up "" if pull_up else "" down "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . pin . pull = pull <TAB> except : <TAB> <TAB> self . close ( ) <TAB> <TAB> raise <TAB> self . _active_state = False if pull_up else True <TAB> self . _inactive_state = True if pull_up else False","if self . pin . pin_type == ""pin"" :",if self . pin . pull != pull :,False,94.5,66.62,,,
"def _increment_operations_count ( self , operation , executed ) : <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _executed_operations + = 1 <TAB> <TAB> <TAB> self . _executed [ operation . job_type ] + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _skipped [ operation . job_type ] + = 1",if executed :,if executed :,True,100.0,73.97,,,
"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <TAB> <TAB> elif type in self.__event_types_at_proxy: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",if type in self . __event_types_at_proxy :,if type in self . __proxy_properties__ :,False,96.46,72.64,,,
"def validate_pull_secret ( namespace ) : <TAB> if namespace . pull_secret is None : <TAB> <TAB> # TODO: add aka.ms link here <TAB> <TAB> warning = ( <TAB> <TAB> <TAB> ""No --pull-secret provided: cluster will not include samples or operators from "" <TAB> <TAB> <TAB> + ""Red Hat or from certified partners."" <TAB> <TAB> ) <TAB> <TAB> logger.warning(warning) <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception() <TAB> <TAB> except: <TAB> <TAB> <TAB> raise InvalidArgumentValueError(""Invalid --pull-secret."")","if namespace . pull_secret not in [ ""samples"" , ""operators"" ] :","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) :",False,92.78,61.77,,,
"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB> <TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB> <TAB> if type == "" V "" : <TAB> <TAB> <TAB> write_vuint ( port , value ) <TAB> <TAB> elif type == "" v "" : <TAB> <TAB> <TAB> write_vint ( port , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> write_bvec ( port , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( )","elif type == ""b"" :","elif type == ""s"" :",False,98.77,73.68,,,
"def data ( self ) : <TAB> if self . _data is not None : <TAB> <TAB> return self . _data <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with open ( self . path , "" rb "" ) as jsonfile : <TAB> <TAB> <TAB> <TAB> data = jsonfile . read ( ) . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> <TAB> data = json . loads ( data ) <TAB> <TAB> <TAB> <TAB> self . _data = data <TAB> <TAB> <TAB> <TAB> return self . _data <TAB> <TAB> else : <TAB> <TAB> <TAB> return dict ( )",if self . path :,if os . path . exists ( self . path ) :,False,94.24,70.1,,,
"def interact ( self ) : <TAB> self . output . write ( "" \n "" ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> request = self . getline ( "" help>  "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except ( KeyboardInterrupt , EOFError ) : <TAB> <TAB> <TAB> break <TAB> <TAB> request = strip ( request ) <TAB> <TAB> # Make sure significant trailing quotation marks of literals don't <TAB> <TAB> # get deleted while cleaning input <TAB> <TAB> if ( <TAB> <TAB> <TAB> len(request) > 2 <TAB> <TAB> <TAB> and request[0] == request[-1] in (""'"", '""') <TAB> <TAB> <TAB> and request[0] not in request[1:-1] <TAB> <TAB> ): <TAB> <TAB> <TAB> request = request[1:-1] <TAB> <TAB> if lower(request) in (""q"", ""quit""): <TAB> <TAB> <TAB> break <TAB> <TAB> self.help(request)",if not request :,if not request :,True,100.0,74.58,,,
"def api_attachment_metadata ( self ) : <TAB> resp = [ ] <TAB> for part in self . parts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> k = { <TAB> <TAB> <TAB> "" content_type "" : part . block . content_type , <TAB> <TAB> <TAB> "" size "" : part . block . size , <TAB> <TAB> <TAB> "" filename "" : part . block . filename , <TAB> <TAB> <TAB> "" id "" : part . block . public_id , <TAB> <TAB> } <TAB> <TAB> content_id = part . content_id <TAB> <TAB> if content_id : <TAB> <TAB> <TAB> if content_id [ 0 ] == "" < "" and content_id [ - 1 ] == "" > "" : <TAB> <TAB> <TAB> <TAB> content_id = content_id [ 1 : - 1 ] <TAB> <TAB> <TAB> k [ "" content_id "" ] = content_id <TAB> <TAB> resp . append ( k ) <TAB> return resp",if part . block . public_id is None :,if not part . is_attachment :,False,96.62,72.57,,,
"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB> <TAB> if line . startswith ( u ( "" Skipping "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB> <TAB> <TAB> newdiff . append ( u ( "" "" ) + line [ 2 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newdiff . append ( line ) <TAB> return newdiff","if line . startswith ( u ( ""Not in"" ) ) :","if line . startswith ( u ( ""- "" ) ) :",False,98.58,73.68,,,
"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB> <TAB> API_CACHE_LOCK . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> API_CACHE = { } <TAB> <TAB> <TAB> if API_CACHE . get ( url ) is None : <TAB> <TAB> <TAB> <TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api",if API_CACHE is None :,if API_CACHE is None :,True,100.0,74.45,,,
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_index_name_ : <TAB> <TAB> res + = prefix + ( "" index_name:  %s \n "" % self . DebugFormatString ( self . index_name_ ) ) <TAB> cnt = 0 <TAB> for e in self . prefix_value_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" prefix_value %s :  %s \n "" % ( elm , self . DebugFormatString ( e ) ) ) <TAB> <TAB> cnt + = 1 <TAB> if self . has_value_prefix_ : <TAB> <TAB> res + = prefix + ( <TAB> <TAB> <TAB> "" value_prefix:  %s \n "" % self . DebugFormatBool ( self . value_prefix_ ) <TAB> <TAB> ) <TAB> return res",if printElemNumber :,if printElemNumber :,True,100.0,74.58,,,
"def add_group ( x , nl , in_group , mw ) : <TAB> if len ( x ) == 0 : <TAB> <TAB> return x <TAB> if len ( x ) > 1 and not in_group : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ "" [[ "" ] + x + [ "" ]] "" ] <TAB> <TAB> mw . warn ( <TAB> <TAB> <TAB> "" Equation will multiplex and may produce inaccurate results (see manual) "" <TAB> <TAB> ) <TAB> return [ "" [ "" ] + x + [ "" ] "" ]",if nl :,"if supports_group ( x , nl ) :",False,93.7,70.93,,,
"def unfulfilled_items ( self ) : <TAB> unfulfilled_items = 0 <TAB> for order_item in self . items . all ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> aggr = order_item . deliver_item . aggregate ( delivered = Sum ( "" quantity "" ) ) <TAB> <TAB> <TAB> unfulfilled_items + = order_item . quantity - ( aggr [ "" delivered "" ] or 0 ) <TAB> return unfulfilled_items",if order_item . quantity :,if not order_item . canceled :,False,95.48,70.65,,,
"def _get_pattern ( self , pattern_id ) : <TAB> """""" Get pattern item by id. """""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = self . tagged_blocks . get_data ( key ) <TAB> <TAB> <TAB> for pattern in data : <TAB> <TAB> <TAB> <TAB> if pattern . pattern_id == pattern_id : <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None",if self . tagged_blocks . has_data ( key ) :,if key in self . tagged_blocks :,False,93.45,93.19,,,
"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB> <TAB> rs = domain . connection . query_with_attributes ( <TAB> <TAB> <TAB> domain , query , attr_names , next_token = next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs : <TAB> <TAB> <TAB> if max_items : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results + = 1 <TAB> <TAB> next_token = rs . next_token <TAB> <TAB> more_results = next_token != None",if num_results == max_items :,if num_results == max_items :,True,100.0,74.46,,,
"def find_deprecated_settings ( source ) : # pragma: no cover <TAB> from celery.utils import deprecated <TAB> for name, opt in flatten(NAMESPACES): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> deprecated.warn( <TAB> <TAB> <TAB> <TAB> description=""The {0!r} setting"".format(name), <TAB> <TAB> <TAB> <TAB> deprecation=opt.deprecate_by, <TAB> <TAB> <TAB> <TAB> removal=opt.remove_by, <TAB> <TAB> <TAB> <TAB> alternative=""Use the {0.alt} instead"".format(opt), <TAB> <TAB> <TAB> ) <TAB> return source",if name in source :,"if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) :",False,87.63,61.61,,,
"def tearDown ( self ) : <TAB> """""" Shutdown the server. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> if self . sl_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,True,100.0,74.14,,,
"def broadcast_events ( self , events ) : <TAB> LOGGER . debug ( "" Broadcasting events:  %s "" , events ) <TAB> with self . _subscribers_cv : <TAB> <TAB> # Copy the subscribers <TAB> <TAB> subscribers = {conn: sub.copy() for conn, sub in self._subscribers.items()} <TAB> if subscribers: <TAB> <TAB> for connection_id, subscriber in subscribers.items(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> subscriber_events = [ <TAB> <TAB> <TAB> <TAB> <TAB> event for event in events if subscriber.is_subscribed(event) <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <TAB> event_list = EventList(events=subscriber_events) <TAB> <TAB> <TAB> <TAB> self._send(connection_id, event_list.SerializeToString())","if isinstance ( subscriber , Subscriber ) :",if subscriber . is_listening ( ) :,False,96.97,71.69,,,
"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB> <TAB> stdout = None <TAB> <TAB> try : <TAB> <TAB> <TAB> stdout , stderr = Popen ( <TAB> <TAB> <TAB> <TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB> <TAB> <TAB> <TAB> stdout = PIPE , <TAB> <TAB> <TAB> <TAB> stderr = PIPE , <TAB> <TAB> <TAB> ) . communicate ( ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> if stdout : <TAB> <TAB> <TAB> <TAB> for line in stdout . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info",if line :,if len ( line ) == 2 :,False,97.29,72.69,,,
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if len ( a ) != b . len : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a . ptr == b . ptr : <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if a . len != b . len :,if a is None :,False,96.49,72.59,,,
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> if type ( item ) is ActionHandle : <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else: # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",if type ( ah ) is ActionHandle :,if type ( ah ) is not ActionHandle :,False,98.98,73.49,,,
"def startElement ( self , name , attrs , connection ) : <TAB> if name == "" Parameter "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self [ self . _current_param . name ] = self . _current_param <TAB> <TAB> self . _current_param = Parameter ( self ) <TAB> <TAB> return self . _current_param",if self . _current_param . name :,if self . _current_param :,False,96.27,71.77,,,
"def _find_class_in_descendants ( self , search_key ) : <TAB> for cls in self . primitive_classes : <TAB> <TAB> cls_key = ( cls . __name__ , cls . __module__ ) <TAB> <TAB> self . class_cache [ cls_key ] = cls <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return cls",if cls_key in search_key :,if cls_key == search_key :,False,96.47,71.31,,,
"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB> <TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB> <TAB> if c1 : <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB> <TAB> <TAB> if c2 : <TAB> <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sibling.getFirstChild().doWorkForFindAll(v, target, partialMatch) <TAB> <TAB> sibling = sibling.getNextSibling()",if sibling . getChildCount ( ) > 0 :,if sibling . getFirstChild ( ) :,False,96.99,72.37,,,
"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB> <TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB> <TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB> <TAB> outputs . append ( block_out ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB> <TAB> <TAB> route = self . upsample ( route ) <TAB> return outputs",if i > 0 :,if i < 2 :,False,98.21,73.27,,,
"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""" .gitignore style file filtering. """""" <TAB> for item in exclude : <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item.startswith(""/"") else basename <TAB> <TAB> if fnmatch.fnmatch(match, item.strip(""/"")): <TAB> <TAB> <TAB> return True <TAB> return False","if is_dir and item . endswith ( ""/"" ) :","if item . endswith ( ""/"" ) and not is_dir :",False,96.54,96.45,,,
"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB> <TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if line . startswith ( ' "" "" "" ' ) : <TAB> <TAB> <TAB> found + = 1 <TAB> <TAB> <TAB> if found == 2 : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break # already in the right place <TAB> <TAB> <TAB> <TAB> lines.insert(i + 1, """") <TAB> <TAB> <TAB> <TAB> lines.insert(i + 2, division) <TAB> <TAB> <TAB> <TAB> break <TAB> return ""\n"".join(lines)",if i + 1 == len ( lines ) :,"if division in ""\n"" . join ( lines ) :",False,95.75,93.24,,,
"def buildImage ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" COCO-IMG-2015 "" ) <TAB> version = "" 1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building image data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES[:1]: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,True,100.0,74.47,,,
"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB> <TAB> col = text [ 1 : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return col <TAB> <TAB> elif len ( col ) == 3 : <TAB> <TAB> <TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB> <TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text",if len ( col ) == 2 :,if len ( col ) == 6 :,False,98.18,73.15,,,
"def tree_print ( tree ) : <TAB> for key in tree : <TAB> <TAB> print ( key , end = "" "" ) # end=' ' prevents a newline character <TAB> <TAB> tree_element = tree[key] # multiple lookups is expensive, even amortized O(1)! <TAB> <TAB> for subElem in tree_element: <TAB> <TAB> <TAB> print("" -> "", subElem, end="" "") <TAB> <TAB> <TAB> <IF-STMT> # OP wants indenting after digits <TAB> <TAB> <TAB> <TAB> print(""\n "") # newline and a space to match indenting <TAB> <TAB> print() # forces a newline","if subElem == "" "" :",if type ( subElem ) != str :,False,95.16,65.63,,,
"def is_dse_cluster ( path ) : <TAB> try : <TAB> <TAB> with open ( os . path . join ( path , "" CURRENT "" ) , "" r "" ) as f : <TAB> <TAB> <TAB> name = f . readline ( ) . strip ( ) <TAB> <TAB> <TAB> cluster_path = os . path . join ( path , name ) <TAB> <TAB> <TAB> filename = os . path . join ( cluster_path , "" cluster.conf "" ) <TAB> <TAB> <TAB> with open ( filename , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> data = yaml . load ( f ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> except IOError : <TAB> <TAB> return False","if data [ ""name"" ] == ""dse"" :","if ""dse_dir"" in data :",False,94.46,67.79,,,
"def delete_old_target_output_files ( classpath_prefix ) : <TAB> """""" Delete existing output files or symlinks for target. """""" <TAB> directory , basename = os . path . split ( classpath_prefix ) <TAB> pattern = re . compile ( <TAB> <TAB> r "" ^ {basename} (([0-9]+)( \ .jar)?|classpath \ .txt)$ "" . format ( <TAB> <TAB> <TAB> basename = re . escape ( basename ) <TAB> <TAB> ) <TAB> ) <TAB> files = [ filename for filename in os . listdir ( directory ) if pattern . match ( filename ) ] <TAB> for rel_path in files : <TAB> <TAB> path = os . path . join ( directory , rel_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> safe_delete ( path )",if os . path . exists ( path ) :,if os . path . islink ( path ) or os . path . isfile ( path ) :,False,94.68,70.29,,,
"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB> <TAB> test_dir = os.path.join(dist_dir, d) <TAB> <TAB> for n in os.listdir(test_dir): <TAB> <TAB> <TAB> if n.endswith("".py"") and not n.startswith(""bad""): <TAB> <TAB> <TAB> <TAB> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""Testing %s"" % filename) <TAB> <TAB> source = read_pyfile(filename) <TAB> <TAB> self.check_roundtrip(source)",if os . path . isfile ( filename ) :,if test_support . verbose :,False,96.13,70.34,,,
"def __str__ ( self ) : <TAB> if self . HasError ( ) : <TAB> <TAB> return self . ErrorAsStr ( ) <TAB> else : <TAB> <TAB> # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB> <TAB> string = self._action <TAB> <TAB> if self._target is not None: <TAB> <TAB> <TAB> string += ' ""{target}""'.format(target=self._target) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = self._filename <TAB> <TAB> <TAB> if self._lineno is not None: <TAB> <TAB> <TAB> <TAB> path += "":{lineno}"".format(lineno=self._lineno) <TAB> <TAB> <TAB> string += "" ({path})"".format(path=path) <TAB> <TAB> return string",if self . _filename is not None :,if self . _filename is not None :,True,100.0,74.37,,,
"def extra_action_out ( self , input_dict , state_batches , model , action_dist ) : <TAB> with self . _no_grad_context ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stats_dict = extra_action_out_fn ( <TAB> <TAB> <TAB> <TAB> self , input_dict , state_batches , model , action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stats_dict = parent_cls . extra_action_out ( <TAB> <TAB> <TAB> <TAB> self , input_dict , state_batches , model , action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _convert_to_non_torch_type ( stats_dict )",if extra_action_out_fn :,if extra_action_out_fn :,True,100.0,74.28,,,
"def _retract_bindings ( fstruct , inv_bindings , fs_class , visited ) : <TAB> # Visit each node only once: <TAB> if id(fstruct) in visited: <TAB> <TAB> return <TAB> visited.add(id(fstruct)) <TAB> if _is_mapping(fstruct): <TAB> <TAB> items = fstruct.items() <TAB> elif _is_sequence(fstruct): <TAB> <TAB> items = enumerate(fstruct) <TAB> else: <TAB> <TAB> raise ValueError(""Expected mapping or sequence"") <TAB> for (fname, fval) in items: <TAB> <TAB> if isinstance(fval, fs_class): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> fstruct[fname] = inv_bindings[id(fval)] <TAB> <TAB> <TAB> _retract_bindings(fval, inv_bindings, fs_class, visited)",if id ( fval ) in inv_bindings :,if id ( fval ) in inv_bindings :,True,100.0,74.34,,,
"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( dep . repo , WarehouseBaseRepo ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep . repo . repos : <TAB> <TAB> <TAB> if repo . from_config : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) )",if dep . repo is None :,if dep . repo is None :,True,100.0,74.47,,,
"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB> <TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB> <TAB> if not isinstance ( key , str ) : <TAB> <TAB> <TAB> key = str ( key ) <TAB> <TAB> detyper = self . get_detyper ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper(val) <TAB> <TAB> if deval is None: <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",if detyper is None :,if detyper is None :,True,100.0,74.51,,,
"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field.delete() <TAB> <TAB> <TAB> return <TAB> <TAB> if isinstance(self.data, FileStorage) and not is_empty(self.data.stream): <TAB> <TAB> <TAB> if not field.grid_id: <TAB> <TAB> <TAB> <TAB> func = field.put <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> func = field.replace <TAB> <TAB> <TAB> func( <TAB> <TAB> <TAB> <TAB> self.data.stream, <TAB> <TAB> <TAB> <TAB> filename=self.data.filename, <TAB> <TAB> <TAB> <TAB> content_type=self.data.content_type, <TAB> <TAB> <TAB> )",if field . deleted :,if self . _should_delete :,False,97.2,72.51,,,
"def _load ( container ) : <TAB> if isinstance ( container , str ) : <TAB> <TAB> # If container is a filename. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with open(container, ""rb"") as f: <TAB> <TAB> <TAB> <TAB> return pickle.load(f) <TAB> <TAB> # If container is a pickle string. <TAB> <TAB> else: <TAB> <TAB> <TAB> return pickle.loads(container) <TAB> # If container is an open file <TAB> elif isinstance(container, IOBase): <TAB> <TAB> return pickle.load(container) <TAB> # What else could it be? <TAB> else: <TAB> <TAB> l.error(""Cannot unpickle container of type %s"", type(container)) <TAB> <TAB> return None",if os . path . isfile ( container ) :,if all ( c in string . printable for c in container ) and os . path . exists ( container ) :,False,92.07,66.84,,,
"def append_row ( self , row ) : <TAB> self . allocate_future_payments ( row ) <TAB> self . set_invoice_details ( row ) <TAB> self . set_party_details ( row ) <TAB> self . set_ageing ( row ) <TAB> if self . filters . get ( "" group_by_party "" ) : <TAB> <TAB> self . update_sub_total_row ( row , row . party ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . append_subtotal_row ( self . previous_party ) <TAB> <TAB> self . previous_party = row . party <TAB> self . data . append ( row )",if self . previous_party :,if self . previous_party and ( self . previous_party != row . party ) :,False,91.47,68.8,,,
"def gg1 ( ) : <TAB> while 1 : <TAB> <TAB> tt = 3 <TAB> <TAB> while tt > 0 : <TAB> <TAB> <TAB> trace . append ( tt ) <TAB> <TAB> <TAB> val = yield <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tt = 10 # <= uncomment this line <TAB> <TAB> <TAB> <TAB> trace.append(""breaking early..."") <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> tt -= 1 <TAB> <TAB> trace.append(""try!"")","if val == ""0"" :",if val is not None :,False,95.92,63.84,,,
"def migrate_common_facts ( facts ) : <TAB> """""" Migrate facts from various roles into common """""" <TAB> params = { "" node "" : ( "" portal_net "" ) , "" master "" : ( "" portal_net "" ) } <TAB> if "" common "" not in facts : <TAB> <TAB> facts [ "" common "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB> if role in facts: <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> facts[""common""][param] = facts[role].pop(param) <TAB> return facts",if param not in facts [ role ] :,if param in facts [ role ] :,False,98.68,98.47,,,
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> if self . do_manders : <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> if self . do_costes : <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ]",if self . do_correlations :,if self . do_corr_and_slope :,False,97.64,73.87,,,
"def access_modes ( self ) : <TAB> """""" access_modes property """""" <TAB> if self . _access_modes is None : <TAB> <TAB> self . _access_modes = self . get_access_modes ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _access_modes = list ( self . _access_modes ) <TAB> return self . _access_modes","if isinstance ( self . _access_modes , list ) :","if not isinstance ( self . _access_modes , list ) :",False,97.71,92.82,,,
"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = len ( data ) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . context [ "" total "" ] = 0 <TAB> <TAB> <TAB> data = { "" items "" : [ ] } <TAB> <TAB> return data [ "" items "" ] <TAB> return data",if self . context :,"if data [ ""items"" ] :",False,96.16,68.84,,,
"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = len ( data ) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . context [ "" total "" ] = 0 <TAB> <TAB> <TAB> data = { "" items "" : [ ] } <TAB> <TAB> return data [ "" items "" ] <TAB> return data",if self . context :,"if isinstance ( result , tuple )",False,96.14,71.69,,,
"def on_torrent_created ( self , result ) : <TAB> if not result : <TAB> <TAB> return <TAB> self . dialog_widget . btn_create . setEnabled ( True ) <TAB> self . dialog_widget . edit_channel_create_torrent_progress_label . setText ( <TAB> <TAB> "" Created torrent "" <TAB> ) <TAB> if "" torrent "" in result : <TAB> <TAB> self . create_torrent_notification . emit ( { "" msg "" : "" Torrent successfully created "" } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_torrent_to_channel ( result [ "" torrent "" ] ) <TAB> <TAB> self . close_dialog ( )","if result [ ""torrent"" ] :",if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) :,False,89.61,65.13,,,
"def save ( self ) : <TAB> for var_name in self . default_config : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if var_name in self . file_config : <TAB> <TAB> <TAB> <TAB> del self . file_config [ var_name ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . file_config [ var_name ] = getattr ( self , var_name ) <TAB> with open ( self . config_path , "" w "" ) as f : <TAB> <TAB> f . write ( json . dumps ( self . file_config , indent = 2 ) )","if hasattr ( self , var_name ) :","if getattr ( self , var_name , None ) == self . default_config [ var_name ] :",False,88.79,67.97,,,
"def get_class_parameters ( kwarg ) : <TAB> ret = { "" attrs "" : [ ] } <TAB> for key in ( "" rsc "" , "" fsc "" , "" usc "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret [ "" attrs "" ] . append ( <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> "" TCA_HFSC_ %s "" % key . upper ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" m1 "" : get_rate ( kwarg [ key ] . get ( "" m1 "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" d "" : get_time ( kwarg [ key ] . get ( "" d "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" m2 "" : get_rate ( kwarg [ key ] . get ( "" m2 "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> return ret",if key in kwarg :,if key in kwarg :,True,100.0,74.64,,,
"def forward ( self , x ) : <TAB> f_x = x <TAB> if self . exp : <TAB> <TAB> f_x = self . exp_swish ( self . exp_bn ( self . exp ( f_x ) ) ) <TAB> f_x = self . dwise_swish ( self . dwise_bn ( self . dwise ( f_x ) ) ) <TAB> f_x = self . se ( f_x ) <TAB> f_x = self . lin_proj_bn ( self . lin_proj ( f_x ) ) <TAB> if self . has_skip : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f_x = drop_connect ( f_x , effnet_cfg . EN . DC_RATIO ) <TAB> <TAB> f_x = x + f_x <TAB> return f_x",if self . drop_connect :,if self . training and effnet_cfg . EN . DC_RATIO > 0.0 :,False,93.15,70.18,,,
"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> log ( str ( index ) + ""  --->>  "" + _distro_dir ) <TAB> <TAB> user_input = read_input_uninstall ( ) <TAB> <TAB> if user_input is not False : <TAB> <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> config . uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro ( ) <TAB> else : <TAB> <TAB> log ( "" No distro installed on  "" + config . usb_disk )","if _distro_dir . endswith ( "".usb"" ) :",if index == user_input :,False,94.39,65.23,,,
"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> if alias . name == "" * "" : <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation )",if self . futuresAllowed :,if not self . futuresAllowed :,False,98.96,73.77,,,
"def _split_and_load ( batch , ctx_list ) : <TAB> """""" Split data to 1 batch each device. """""" <TAB> new_batch = [ ] <TAB> for _ , data in enumerate ( batch ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_data = [ x . as_in_context ( ctx ) for x , ctx in zip ( data , ctx_list ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_data = [ data . as_in_context ( ctx_list [ 0 ] ) ] <TAB> <TAB> new_batch . append ( new_data ) <TAB> return new_batch","if isinstance ( data , ( list , tuple ) ) :","if isinstance ( data , ( list , tuple ) ) :",True,100.0,99.39,,,
"def wait_success ( self , timeout = 60 * 10 ) : <TAB> for i in range ( timeout / / 10 ) : <TAB> <TAB> time . sleep ( 10 ) <TAB> <TAB> status = self . query_job ( ) <TAB> <TAB> print ( "" job  {}  status is  {} "" . format ( self . job_id , status ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if status and status in [ <TAB> <TAB> <TAB> StatusSet . CANCELED , <TAB> <TAB> <TAB> StatusSet . TIMEOUT , <TAB> <TAB> <TAB> StatusSet . FAILED , <TAB> <TAB> ] : <TAB> <TAB> <TAB> return False <TAB> return False","if status and status in [ StatusSet . SUCCESS , StatusSet . FAILED ] :",if status and status == StatusSet . SUCCESS :,False,94.71,71.65,,,
"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rel_root = "" "" <TAB> <TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB> <TAB> if not os . path . exists ( dst_root ) : <TAB> <TAB> <TAB> os . makedirs ( dst_root ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) )",if os . path . isdir ( src_root ) :,if src_root != src_dir :,False,96.02,72.43,,,
"def _make_padded_shapes ( self , dataset , decoders ) : <TAB> padded_shapes = dataset . output_shapes <TAB> for i , hparams_i in enumerate ( self . _hparams . datasets ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not hparams_i [ "" pad_to_max_seq_length "" ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> text_and_id_shapes = MonoTextData . _make_padded_text_and_id_shapes ( <TAB> <TAB> <TAB> dataset , hparams_i , decoders [ i ] , self . text_name ( i ) , self . text_id_name ( i ) <TAB> <TAB> ) <TAB> <TAB> padded_shapes . update ( text_and_id_shapes ) <TAB> return padded_shapes","if hparams_i [ ""num_layers"" ] != self . _num_layers :","if not _is_text_data ( hparams_i [ ""data_type"" ] ) :",False,92.91,70.4,,,
"def format_errors ( messages ) : <TAB> errors = { } <TAB> for k , v in messages . items ( ) : <TAB> <TAB> key = camelize ( k , uppercase_first_letter = False ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errors [ key ] = format_errors ( v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> errors [ key ] = v [ 0 ] <TAB> return errors","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.24,,,
"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for item in value : <TAB> <TAB> <TAB> <TAB> if isinstance ( item , AST ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . visit ( item , parents ) <TAB> <TAB> elif isinstance ( value , AST ) : <TAB> <TAB> <TAB> self . visit ( value , parents )","if isinstance ( value , list ) :","if isinstance ( value , list ) :",True,100.0,74.38,,,
"def get_override_css ( self ) : <TAB> """""" handls allow_css_overrides setting. """""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB> <TAB> filename = self . view . file_name ( ) <TAB> <TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB> <TAB> if filename and filetypes : <TAB> <TAB> <TAB> for filetype in filetypes : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( css_filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" ""","if filetype . startswith ( "".css"" ) :",if filename . endswith ( filetype ) :,False,96.28,72.38,,,
"def clean ( self ) : <TAB> super ( ) . clean ( ) <TAB> # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB> if self.cluster.site is not None: <TAB> <TAB> for device in self.cleaned_data.get(""devices"", []): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ""devices"": ""{} belongs to a different site ({}) than the cluster ({})"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> device, device.site, self.cluster.site <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> )",if device . site != self . cluster . site :,if device . site != self . cluster . site :,True,100.0,74.46,,,
"def _setProcessPriority ( process , nice_val , disable_gc ) : <TAB> org_nice_val = Computer . _process_original_nice_value <TAB> try : <TAB> <TAB> process . nice ( nice_val ) <TAB> <TAB> Computer . in_high_priority_mode = nice_val != org_nice_val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gc . disable ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gc . enable ( ) <TAB> <TAB> return True <TAB> except psutil . AccessDenied : <TAB> <TAB> print2err ( <TAB> <TAB> <TAB> "" WARNING: Could not set process  {}  priority  "" <TAB> <TAB> <TAB> "" to  {} "" . format ( process . pid , nice_val ) <TAB> <TAB> ) <TAB> <TAB> return False",if disable_gc :,if disable_gc :,True,100.0,74.43,,,
"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB> <TAB> <TAB> <TAB> "" may only return a single token for an And alternative,  "" <TAB> <TAB> <TAB> <TAB> "" in future will return the full list of tokens "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> stacklevel = 3 , <TAB> <TAB> <TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches )",if name in self . named_alternation_tokens :,"if any ( isinstance ( e , And ) for e in self . exprs ) :",False,94.54,69.54,,,
"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB> <TAB> content . append ( project . readme . path . name ) <TAB> <TAB> if project . readme . markup != "" rst "" : <TAB> <TAB> <TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB> <TAB> for fpath in package : <TAB> <TAB> <TAB> fpath = fpath . relative_to ( project . package . path ) <TAB> <TAB> <TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content )",if os . path . isfile ( fname ) :,if ( path / fname ) . exists ( ) :,False,96.6,72.38,,,
"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB> <TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB> <TAB> for j , s in enumerate ( c ) : <TAB> <TAB> <TAB> if j < segmentCount : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices [ index ] = 1 <TAB> <TAB> <TAB> index + = s [ 1 ] <TAB> return controlPointIndices",if s [ 0 ] == va [ j ] :,"if glyph . contours [ i ] . segments [ j ] . type == ""line"" :",False,90.07,60.39,,,
"def MergeFrom ( self , other ) : <TAB> if self . message_class is not None : <TAB> <TAB> if other . Parse ( self . message_class ) : <TAB> <TAB> <TAB> self . message . MergeFrom ( other . message ) <TAB> elif other . message_class is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . message = other . message_class ( ) <TAB> <TAB> <TAB> self . message_class = other . message_class <TAB> <TAB> self . message . MergeFrom ( other . message ) <TAB> else : <TAB> <TAB> self . message + = other . message",if not self . message :,if not self . Parse ( other . message_class ) :,False,94.43,71.16,,,
"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . unlink ( file ) <TAB> <TAB> <TAB> elif os . path . isdir ( file ) : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( file ) <TAB> <TAB> except Exception as error : <TAB> <TAB> <TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB> <TAB> <TAB> sys . exit ( 1 )",if os . path . isfile ( file ) :,if os . path . isfile ( file ) :,True,100.0,74.5,,,
"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB> <TAB> val = self . nodeValue <TAB> <TAB> if not isinstance ( val , str ) : <TAB> <TAB> <TAB> val = str ( self . nodeValue ) <TAB> else : <TAB> <TAB> v = self . nodeValue <TAB> <TAB> if not isinstance ( v , str ) : <TAB> <TAB> <TAB> v = str ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = "" "" . join ( v . split ( ) ) <TAB> <TAB> val = escape ( v ) <TAB> w ( val )","if isinstance ( v , list ) :",if strip :,False,96.63,72.98,,,
"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB> <TAB> value = getattr ( self , attribute . code , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if attribute . required : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> attribute . validate_value ( value ) <TAB> <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB> <TAB> <TAB> <TAB> )",if value is None :,if value is None :,True,100.0,74.59,,,
"def PyJsHoisted_BinaryExpression_ ( node , parent , this , arguments , var = var ) : <TAB> var = Scope ( <TAB> <TAB> { u "" node "" : node , u "" this "" : this , u "" arguments "" : arguments , u "" parent "" : parent } , var <TAB> ) <TAB> var . registers ( [ u "" node "" , u "" parent "" ] ) <TAB> if PyJsStrictEq ( var . get ( u "" node "" ) . get ( u "" operator "" ) , Js ( u "" in "" ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return var . get ( u "" true "" ) <TAB> <TAB> if var . get ( u "" t "" ) . callprop ( u "" isFor "" , var . get ( u "" parent "" ) ) : <TAB> <TAB> <TAB> return var . get ( u "" true "" ) <TAB> return Js ( False )","if var . get ( u""t"" ) . callprop ( u""isFor"" , var . get ( u""parent"" ) ) :","if var . get ( u""t"" ) . callprop ( u""isVariableDeclarator"" , var . get ( u""parent"" ) ) :",False,98.93,74.0,,,
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> if n . _child . isidentical ( expr ) : <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> elif n not in fields : <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )","elif isinstance ( n , str ) :","if not isinstance ( n , _strtypes ) :",False,97.31,72.8,,,
"def encode ( self , msg ) : <TAB> """""" Encodes the message to the stream encoding. """""" <TAB> stream = self . stream <TAB> rv = msg + "" \n "" <TAB> if ( PY2 and is_unicode ( rv ) ) or not ( <TAB> <TAB> PY2 or is_unicode ( rv ) or _is_text_stream ( stream ) <TAB> ) : <TAB> <TAB> enc = self . encoding <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> enc = getattr ( stream , "" encoding "" , None ) or "" utf-8 "" <TAB> <TAB> rv = rv . encode ( enc , "" replace "" ) <TAB> return rv",if not enc :,if enc is None :,False,97.31,73.84,,,
"def color_convert ( self , to_color_space , preserve_alpha = True ) : <TAB> if to_color_space == self . color_space and preserve_alpha : <TAB> <TAB> return self <TAB> else : <TAB> <TAB> pixels = pixels_as_float ( self . pixels ) <TAB> <TAB> converted = convert_color ( <TAB> <TAB> <TAB> pixels , self . color_space , to_color_space , preserve_alpha <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return Image ( converted , to_color_space )",if converted is None :,if converted is None :,True,100.0,74.26,,,
"def seek ( self , pos ) : <TAB> if self . closed : <TAB> <TAB> raise IOError ( "" Cannot seek on a closed file "" ) <TAB> for n , idx in enumerate ( self . _indexes [ : : - 1 ] ) : <TAB> <TAB> if idx . offset < = pos : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _idxiter = iter ( self . _indexes [ - ( n + 1 ) : ] ) <TAB> <TAB> <TAB> <TAB> self . _nextidx ( ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise Exception ( "" Cannot seek to pos "" ) <TAB> self . _curfile . seek ( pos - self . _curidx . offset )",if n + 1 < len ( self . _indexes ) :,if idx != self . _curidx :,False,94.24,71.52,,,
"def load_from_json ( self , node_data : dict , import_version : float ) : <TAB> if import_version < = 0.08 : <TAB> <TAB> self . image_pointer = unpack_pointer_property_name ( <TAB> <TAB> <TAB> bpy . data . images , node_data , "" image_name "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> proposed_name = node_data . get ( "" image_name "" ) <TAB> <TAB> <TAB> self . info ( f "" image data not found in current  { proposed_name } "" )",if self . image_pointer is None :,if not self . image_pointer :,False,96.65,71.45,,,
"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB> <TAB> if operator == "" Average "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB> <TAB> elif operator == "" Max "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB> <TAB> elif operator == "" Min "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB> <TAB> elif operator == "" Sum "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _SumAggregator ( ) )","elif operator == ""Count"" :","elif operator == ""Count"" :",True,100.0,74.59,,,
"def attrgetter ( item ) : <TAB> items = [ None ] * len ( attribute ) <TAB> for i , attribute_part in enumerate ( attribute ) : <TAB> <TAB> item_i = item <TAB> <TAB> for part in attribute_part : <TAB> <TAB> <TAB> item_i = environment . getitem ( item_i , part ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> item_i = postprocess ( item_i ) <TAB> <TAB> items [ i ] = item_i <TAB> return items",if postprocess :,if postprocess is not None :,False,96.51,70.93,,,
"def work ( self ) : <TAB> while True : <TAB> <TAB> timeout = self . timeout <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> timeout = self . idle_timeout <TAB> <TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB> <TAB> fetch . wait ( timeout ) <TAB> <TAB> if shutting_down . is_set ( ) : <TAB> <TAB> <TAB> log . info ( "" Stop fetch worker "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . fetch ( )",if self . idle_timeout is not None :,if idle . is_set ( ) :,False,94.09,70.7,,,
"def testCoreInterfaceIntInputData ( ) : <TAB> result_testing = False <TAB> for _ in range ( 10 ) : <TAB> <TAB> hsyncnet_instance = hsyncnet ( <TAB> <TAB> <TAB> [ [ 1 ] , [ 2 ] , [ 3 ] , [ 20 ] , [ 21 ] , [ 22 ] ] , 2 , initial_type . EQUIPARTITION , ccore = True <TAB> <TAB> ) <TAB> <TAB> analyser = hsyncnet_instance . process ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result_testing = True <TAB> <TAB> <TAB> break <TAB> assert result_testing",if analyser . interface_int_data [ 0 ] == 0 :,if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 :,False,91.12,68.83,,,
"def _gen ( ) : <TAB> buf = [ ] <TAB> iterable = dataset ( ) <TAB> try : <TAB> <TAB> while len ( buf ) < buffer_size : <TAB> <TAB> <TAB> buf . append ( next ( iterable ) ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> i = random . randint ( 0 , buffer_size - 1 ) <TAB> <TAB> <TAB> n = next ( iterable ) <TAB> <TAB> <TAB> yield buf [ i ] <TAB> <TAB> <TAB> buf [ i ] = n <TAB> except StopIteration : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> random . shuffle ( buf ) <TAB> <TAB> <TAB> for i in buf : <TAB> <TAB> <TAB> <TAB> yield i",if shuffle :,if len ( buf ) :,False,97.18,72.27,,,
"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB> <TAB> if isinstance ( elt , ( int , long ) ) : <TAB> <TAB> <TAB> l . append ( _names . get ( elt , elt ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> l . append ( elt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l . append ( debug_tree ( elt ) ) <TAB> return l","elif isinstance ( elt , dict ) :","elif isinstance ( elt , str ) :",False,97.98,72.79,,,
"def reverse_code ( apps : StateApps , schema_editor : DatabaseSchemaEditor ) - > None : <TAB> PreregistrationUser = apps . get_model ( "" zerver "" , "" PreregistrationUser "" ) <TAB> for user in PreregistrationUser . objects . all ( ) : <TAB> <TAB> <IF-STMT> # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB> <TAB> <TAB> user.invited_as_admin = True <TAB> <TAB> else: # PreregistrationUser.INVITE_AS['MEMBER'] <TAB> <TAB> <TAB> user.invited_as_admin = False <TAB> <TAB> user.save(update_fields=[""invited_as_admin""])",if user . is_realm_admin :,if user . invited_as == 2 :,False,95.3,71.11,,,
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out",if not line :,"if line . startswith ( "">>END"" ) :",False,95.49,66.95,,,
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints","elif text [ 0 ] in ""\n\x85\u2028\u2029"" :","if text [ - 1 ] not in ""\n\x85\u2028\u2029"" :",False,95.25,70.33,,,
"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB> <TAB> if not which ( "" initdb "" ) : <TAB> <TAB> <TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB> <TAB> if not psycopg2 : <TAB> <TAB> <TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pytest . skip ( <TAB> <TAB> <TAB> <TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB> <TAB> <TAB> ) <TAB> return request . getfixturevalue ( request . param )",if not GALAXY_TEST_AMQP_INTERNAL_CONNECTION :,"if not os . environ . get ( ""GALAXY_TEST_AMQP_INTERNAL_CONNECTION"" ) :",False,94.08,67.36,,,
"def do_rollout ( agent , env , num_steps , render = False ) : <TAB> total_rew = 0 <TAB> ob = env . reset ( ) <TAB> for t in range ( num_steps ) : <TAB> <TAB> a = agent . act ( ob ) <TAB> <TAB> ( ob , reward , done , _info ) = env . step ( a ) <TAB> <TAB> total_rew + = reward <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> env . render ( ) <TAB> <TAB> if done : <TAB> <TAB> <TAB> break <TAB> return total_rew , t + 1",if render :,if render and t % 3 == 0 :,False,94.5,70.67,,,
"def _handle_subrepos ( self , ctx , dirty_trees ) : <TAB> substate = util . parse_hgsubstate ( ctx [ "" .hgsubstate "" ] . data ( ) . splitlines ( ) ) <TAB> sub = util . OrderedDict ( ) <TAB> if "" .hgsub "" in ctx : <TAB> <TAB> sub = util . parse_hgsub ( ctx [ "" .hgsub "" ] . data ( ) . splitlines ( ) ) <TAB> for path , sha in substate . iteritems ( ) : <TAB> <TAB> # Ignore non-Git repositories keeping state in .hgsubstate. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os.path.dirname(path) <TAB> <TAB> dirty_trees.add(d) <TAB> <TAB> tree = self._dirs.setdefault(d, dulobjs.Tree()) <TAB> <TAB> tree.add(os.path.basename(path), dulobjs.S_IFGITLINK, sha)",if path in dirty_trees :,"if path in sub and not sub [ path ] . startswith ( ""[git]"" ) :",False,92.51,64.28,,,
"def get_property_file_image_choices ( self , pipeline ) : <TAB> columns = pipeline . get_measurement_columns ( ) <TAB> image_names = [ ] <TAB> for column in columns : <TAB> <TAB> object_name , feature , coltype = column [ : 3 ] <TAB> <TAB> choice = feature [ ( len ( C_FILE_NAME ) + 1 ) : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> image_names . append ( choice ) <TAB> return image_names",if choice not in image_names :,"if object_name == ""Image"" and ( feature . startswith ( C_FILE_NAME ) ) :",False,83.83,57.74,,,
"def check_all_decorator_order ( ) : <TAB> """""" Check that in all test files, the slow decorator is always last. """""" <TAB> errors = [ ] <TAB> for fname in os . listdir ( PATH_TO_TESTS ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = os . path . join ( PATH_TO_TESTS , fname ) <TAB> <TAB> <TAB> new_errors = check_decorator_order ( filename ) <TAB> <TAB> <TAB> errors + = [ f "" -  { filename } , line  { i } "" for i in new_errors ] <TAB> if len ( errors ) > 0 : <TAB> <TAB> msg = "" \n "" . join ( errors ) <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> f "" The parameterized decorator (and its variants) should always be first, but this is not the case in the following files: \n { msg } "" <TAB> <TAB> )","if fname . endswith ( "".py"" ) :","if fname . endswith ( "".py"" ) :",True,100.0,99.59,,,
"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB> <TAB> if col and col . get_title ( ) == _ ( "" Active "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id )","if self . store . get_value ( tree_id , 0 ) == _ ( ""Active"" ) :","if self . watchdirs [ watchdir_id ] [ ""enabled"" ] :",False,91.31,70.52,,,
"def get_conv_output_size ( input_size , kernel_size , stride , padding , dilation ) : <TAB> ndim = len ( input_size ) <TAB> output_size = [ ] <TAB> for i in range ( ndim ) : <TAB> <TAB> size = ( <TAB> <TAB> <TAB> input_size [ i ] + 2 * padding [ i ] - dilation [ i ] * ( kernel_size [ i ] - 1 ) - 1 <TAB> <TAB> ) / / stride [ i ] + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> output_size . append ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> output_size . append ( size ) <TAB> return output_size",if size == 0 :,if kernel_size [ i ] == - 1 :,False,94.27,70.96,,,
"def from_location ( cls , location , basename , metadata = None , * * kw ) : <TAB> project_name , version , py_version , platform = [ None ] * 4 <TAB> basename , ext = os . path . splitext ( basename ) <TAB> if ext . lower ( ) in ( "" .egg "" , "" .egg-info "" ) : <TAB> <TAB> match = EGG_NAME ( basename ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> project_name , version , py_version , platform = match . group ( <TAB> <TAB> <TAB> <TAB> "" name "" , "" ver "" , "" pyver "" , "" plat "" <TAB> <TAB> <TAB> ) <TAB> return cls ( <TAB> <TAB> location , <TAB> <TAB> metadata , <TAB> <TAB> project_name = project_name , <TAB> <TAB> version = version , <TAB> <TAB> py_version = py_version , <TAB> <TAB> platform = platform , <TAB> <TAB> * * kw <TAB> )",if match :,if match :,True,100.0,74.59,,,
"def __new__ ( metacls , typename , bases , namespace ) : <TAB> annotations = namespace . get ( "" __annotations__ "" , { } ) <TAB> for t in annotations . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for ut in t . __args__ : <TAB> <TAB> <TAB> <TAB> _assert_tensorizer_type ( ut ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _assert_tensorizer_type ( t ) <TAB> return super ( ) . __new__ ( metacls , typename , bases , namespace )","if hasattr ( t , ""__args__"" ) :","if getattr ( t , ""__origin__"" , """" ) is Union :",False,92.46,49.57,,,
"def decode_content ( self ) : <TAB> """""" Return the best possible representation of the response body. """""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB> <TAB> ct , options = parse_options_header ( ct ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . json ( charset ) <TAB> <TAB> elif ct . startswith ( "" text/ "" ) : <TAB> <TAB> <TAB> return self . text ( charset ) <TAB> <TAB> elif ct == FORM_URL_ENCODED : <TAB> <TAB> <TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content","if ct . startswith ( ""application/json"" ) :",if ct in JSON_CONTENT_TYPES :,False,94.78,68.09,,,
"def get_full_path ( path ) : <TAB> if "" :// "" not in path : <TAB> <TAB> path = os . path . join ( self . AUTO_COLL_TEMPL , path , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = os . path . join ( abs_path , path ) <TAB> return path","if os . path . isdir ( os . path . join ( path , ""coll"" ) ) :",if abs_path :,False,80.4,59.74,,,
"def __getitem__ ( self , name_or_path ) : <TAB> if isinstance ( name_or_path , integer_types ) : <TAB> <TAB> return list . __getitem__ ( self , name_or_path ) <TAB> elif isinstance ( name_or_path , tuple ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> val = self <TAB> <TAB> <TAB> for fid in name_or_path : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise KeyError # path contains base value <TAB> <TAB> <TAB> <TAB> val = val[fid] <TAB> <TAB> <TAB> return val <TAB> <TAB> except (KeyError, IndexError): <TAB> <TAB> <TAB> raise KeyError(name_or_path) <TAB> else: <TAB> <TAB> raise TypeError(self._INDEX_ERROR % name_or_path)",if fid not in val :,"if not isinstance ( val , FeatStruct ) :",False,96.62,70.88,,,
"def scan ( scope ) : <TAB> for s in scope . children : <TAB> <TAB> if s . start_pos < = position < = s . end_pos : <TAB> <TAB> <TAB> if isinstance ( s , ( tree . Scope , tree . Flow ) ) : <TAB> <TAB> <TAB> <TAB> return scan ( s ) or s <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return scan ( s ) <TAB> return None","elif isinstance ( s , ( tree . Scope , tree . Flow ) ) :","elif s . type in ( ""suite"" , ""decorated"" ) :",False,89.45,61.08,,,
"def _get_key ( self ) : <TAB> if not self . key : <TAB> <TAB> self . _channel . send ( u "" pake "" , self . msg1 ) <TAB> <TAB> pake_msg = self . _channel . get ( u "" pake "" ) <TAB> <TAB> self . key = self . sp . finish ( pake_msg ) <TAB> <TAB> self . verifier = self . derive_key ( u "" wormhole:verifier "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> confkey = self . derive_key ( u "" wormhole:confirmation "" ) <TAB> <TAB> nonce = os . urandom ( CONFMSG_NONCE_LENGTH ) <TAB> <TAB> confmsg = make_confmsg ( confkey , nonce ) <TAB> <TAB> self . _channel . send ( u "" _confirm "" , confmsg )",if not self . verifier :,if not self . _send_confirm :,False,97.31,73.58,,,
"def executeScript ( self , script ) : <TAB> if len ( script ) > 0 : <TAB> <TAB> commands = [ ] <TAB> <TAB> for l in script : <TAB> <TAB> <TAB> extracted = self . extract_command ( l ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> commands . append ( extracted ) <TAB> <TAB> for command in commands : <TAB> <TAB> <TAB> cmd , argv = command <TAB> <TAB> <TAB> self . dispatch_command ( cmd , argv )",if extracted is not None :,if extracted :,False,96.64,72.48,,,
"def create_path ( n , fullname , meta ) : <TAB> if meta : <TAB> <TAB> meta . create_path ( fullname ) <TAB> else : <TAB> <TAB> # These fallbacks are important -- meta could be null if, for <TAB> <TAB> # example, save created a ""fake"" item, i.e. a new strip/graft <TAB> <TAB> # path element, etc. You can find cases like that by <TAB> <TAB> # searching for ""Metadata()"". <TAB> <TAB> unlink(fullname) <TAB> <TAB> if stat.S_ISDIR(n.mode): <TAB> <TAB> <TAB> mkdirp(fullname) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os.symlink(n.readlink(), fullname)",if n . readlink ( ) :,elif stat . S_ISLNK ( n . mode ) :,False,94.57,69.9,,,
def get_cycle ( self ) : <TAB> if self . has_cycle ( ) : <TAB> <TAB> cross_node = self . path [ - 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . path [ self . path . index ( cross_node ) : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . path <TAB> return [ ],if cross_node in self . path :,if self . path . count ( cross_node ) > 1 :,False,90.19,64.56,,,
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """""" Select first block delimited by start_tag and end_tag """""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif str_in [ pos ] == end_tag : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",if str_in [ pos ] == start_tag :,if str_in [ pos ] == start_tag :,True,100.0,99.5,,,
"def device ( self ) : <TAB> """""" Device on which the data array of this variable reside. """""" <TAB> # lazy initialization for performance <TAB> if self._device is None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._device = backend.CpuDevice() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._device = backend.get_device_from_array(self._data[0]) <TAB> return self._device",if self . _data [ 0 ] is None :,if self . _data [ 0 ] is None :,True,100.0,73.99,,,
"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB> <TAB> <TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB> <TAB> if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) : <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB> <TAB> raise",if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD :,if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT :,False,96.85,73.36,,,
"def run ( self ) : <TAB> """""" Continual loop evaluating when_statements """""" <TAB> while len ( self . library ) > 0 : <TAB> <TAB> for name , expression in self . library . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del self . library [ name ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> expression . evaluate ( ) <TAB> <TAB> sleep ( 0.01 ) <TAB> return",if name in self . when_statements :,if expression . remove_me == True :,False,93.14,67.53,,,
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" < "" : <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" "" : <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval","if char == "">"" :","if char == "">"" :",True,100.0,74.65,,,
"def _source_target_path ( source , source_path , source_location ) : <TAB> target_path_attr = source . target_path or source . resdef . target_path <TAB> if source . preserve_path : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" target-path  ' %s '  specified with preserve-path - ignoring "" , <TAB> <TAB> <TAB> <TAB> target_path_attr , <TAB> <TAB> <TAB> ) <TAB> <TAB> return os . path . relpath ( os . path . dirname ( source_path ) , source_location ) <TAB> else : <TAB> <TAB> return target_path_attr or source . resdef . target_path or "" """,if target_path_attr :,if target_path_attr :,True,100.0,74.39,,,
"def _load_user_from_header ( self , header ) : <TAB> if self . _header_callback : <TAB> <TAB> user = self . _header_callback ( header ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> app = current_app . _get_current_object ( ) <TAB> <TAB> <TAB> user_loaded_from_header . send ( app , user = user ) <TAB> <TAB> <TAB> return user <TAB> return None",if user :,if user is not None :,False,96.16,69.72,,,
"def setup ( cls ) : <TAB> "" Check dependencies and warn about firewalling "" <TAB> pathCheck ( "" brctl "" , moduleName = "" bridge-utils "" ) <TAB> # Disable Linux bridge firewalling so that traffic can flow! <TAB> for table in ""arp"", ""ip"", ""ip6"": <TAB> <TAB> cmd = ""sysctl net.bridge.bridge-nf-call-%stables"" % table <TAB> <TAB> out = quietRun(cmd).strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warn(""Warning: Linux bridge may not work with"", out, ""\n"")",if out :,"if out . endswith ( ""1"" ) :",False,94.0,67.48,,,
"def _browse_your_music ( web_client , variant ) : <TAB> if not web_client . logged_in : <TAB> <TAB> return [ ] <TAB> if variant in ( "" tracks "" , "" albums "" ) : <TAB> <TAB> items = flatten ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> page . get ( "" items "" , [ ] ) <TAB> <TAB> <TAB> <TAB> for page in web_client . get_all ( <TAB> <TAB> <TAB> <TAB> <TAB> f "" me/ { variant } "" , <TAB> <TAB> <TAB> <TAB> <TAB> params = { "" market "" : "" from_token "" , "" limit "" : 50 } , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if page <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return list ( translator . web_to_track_refs ( items ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return list ( translator . web_to_album_refs ( items ) ) <TAB> else : <TAB> <TAB> return [ ]","if variant == ""tracks"" :","if variant == ""tracks"" :",True,100.0,74.63,,,
"def reset_styling ( self ) : <TAB> for edge in self . fsm_graph . edges_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" edge "" , { } ) . get ( "" default "" ) <TAB> <TAB> edge . attr . update ( style_attr ) <TAB> for node in self . fsm_graph . nodes_iter ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" node "" , { } ) . get ( "" inactive "" ) <TAB> <TAB> <TAB> node . attr . update ( style_attr ) <TAB> for sub_graph in self . fsm_graph . subgraphs_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" graph "" , { } ) . get ( "" default "" ) <TAB> <TAB> sub_graph . graph_attr . update ( style_attr )","if node . state == ""state"" :","if ""point"" not in node . attr [ ""shape"" ] :",False,94.67,68.19,,,
"def reset_styling ( self ) : <TAB> for edge in self . fsm_graph . edges_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" edge "" , { } ) . get ( "" default "" ) <TAB> <TAB> edge . attr . update ( style_attr ) <TAB> for node in self . fsm_graph . nodes_iter ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" node "" , { } ) . get ( "" inactive "" ) <TAB> <TAB> <TAB> node . attr . update ( style_attr ) <TAB> for sub_graph in self . fsm_graph . subgraphs_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" graph "" , { } ) . get ( "" default "" ) <TAB> <TAB> sub_graph . graph_attr . update ( style_attr )","if node . state == ""state"" :",if msg . message_type == message_type,False,95.72,68.63,,,
"def POP ( cpu , * regs ) : <TAB> for reg in regs : <TAB> <TAB> val = cpu . stack_pop ( cpu . address_bit_size / / 8 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cpu . _set_mode_by_val ( val ) <TAB> <TAB> <TAB> val = val & ~ 0x1 <TAB> <TAB> reg . write ( val )",if reg . is_valid ( ) :,"if reg . reg in ( ""PC"" , ""R15"" ) :",False,89.72,61.78,,,
"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB> <TAB> if "" track "" in field : <TAB> <TAB> <TAB> self . processTrack ( field [ "" track "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] )","if ""movie_hdr"" in field :","if ""movie_hdr"" in field :",True,100.0,73.95,,,
"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB> <TAB> local_version = get_local_timestamp ( folder ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if auto : <TAB> <TAB> <TAB> <TAB> update_setter . set_value ( True ) <TAB> <TAB> <TAB> version_setter . set_value ( remote_version ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return False",if local_version > remote_version :,if remote_version > local_version :,False,98.04,72.38,,,
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> if idx > = len ( selections ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> if len(values) + 1 < idx: <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",if i > 0 :,if i >= 0 and i < len ( selections ) :,False,95.72,71.32,,,
"def find_int_identifiers ( directory ) : <TAB> results = find_rules ( directory , has_int_identifier ) <TAB> print ( "" Number of rules with integer identifiers:  %d "" % len ( results ) ) <TAB> for result in results : <TAB> <TAB> rule_path = result [ 0 ] <TAB> <TAB> product_yaml_path = result [ 1 ] <TAB> <TAB> product_yaml = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> product_yaml = yaml . open_raw ( product_yaml_path ) <TAB> <TAB> fix_file ( rule_path , product_yaml , fix_int_identifier )",if product_yaml_path :,if product_yaml_path is not None :,False,97.21,71.21,,,
"def condition ( self ) : <TAB> if self . __condition is None : <TAB> <TAB> if len ( self . flat_conditions ) == 1 : <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self.__condition = self.flat_conditions[0] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self.__condition = lambda _: True <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__condition = lambda x: all(cond(x) for cond in self.flat_conditions) <TAB> return self.__condition","elif isinstance ( self . flat_conditions [ 0 ] , ( list , tuple ) ) :",elif len ( self . flat_conditions ) == 0 :,False,93.07,69.52,,,
"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB> <TAB> if season == scene_season : <TAB> <TAB> <TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions","if scene_exception . startswith ( ""#"" ) :",if not len ( scene_exception ) == 2 :,False,92.78,60.23,,,
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i > = 0 and i < len ( selections ) : <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> if len(values) + 1 < idx: <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",if idx == 0 :,if idx >= len ( selections ) :,False,96.99,72.6,,,
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i > = 0 and i < len ( selections ) : <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> if len(values) + 1 < idx: <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",if idx == 0 :,"if "":"" not in path_or_uri_like :",False,94.49,64.34,,,
def mainWindow ( ) : <TAB> global MW <TAB> if not MW : <TAB> <TAB> for i in qApp . topLevelWidgets ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> MW = i <TAB> <TAB> <TAB> <TAB> return MW <TAB> <TAB> return None <TAB> else : <TAB> <TAB> return MW,if i . isVisible ( ) :,"if i . objectName ( ) == ""MainWindow"" :",False,91.29,51.03,,,
"def async_get_service ( hass , config , discovery_info = None ) : <TAB> # pylint: disable=unused-argument <TAB> """"""Get the demo notification service."""""" <TAB> for account, account_dict in hass.data[DATA_ALEXAMEDIA][""accounts""].items(): <TAB> <TAB> for key, _ in account_dict[""devices""][""media_player""].items(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _LOGGER.debug( <TAB> <TAB> <TAB> <TAB> <TAB> ""%s: Media player %s not loaded yet; delaying load"", <TAB> <TAB> <TAB> <TAB> <TAB> hide_email(account), <TAB> <TAB> <TAB> <TAB> <TAB> hide_serial(key), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return False <TAB> return AlexaNotificationService(hass)",if key not in config [ DATA_ALEXAMEDIA ] :,"if key not in account_dict [ ""entities"" ] [ ""media_player"" ] :",False,94.08,68.83,,,
"def _migrate_bool ( self , name : str , true_value : str , false_value : str ) - > None : <TAB> if name not in self . _settings : <TAB> <TAB> return <TAB> values = self . _settings [ name ] <TAB> if not isinstance ( values , dict ) : <TAB> <TAB> return <TAB> for scope , val in values . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_value = true_value if val else false_value <TAB> <TAB> <TAB> self . _settings [ name ] [ scope ] = new_value <TAB> <TAB> <TAB> self . changed . emit ( )","if isinstance ( val , bool ) :","if isinstance ( val , bool ) :",True,100.0,74.45,,,
"def send ( self , data , flags = 0 ) : <TAB> self . _checkClosed ( ) <TAB> if self . _sslobj : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" non-zero flags not allowed in calls to send() on  %s "" % self . __class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _sslobj . write ( data ) <TAB> else : <TAB> <TAB> return socket . send ( self , data , flags )",if flags != 0 :,if flags != 0 :,True,100.0,74.3,,,
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> if not dep_cnts : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt[""_deps""]: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",if dep_cnt :,if dep_cnt :,True,100.0,74.43,,,
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> if item . endswith ( "" / "" ) : <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result",elif is_regex . match ( item ) :,elif is_dict . match ( item ) :,False,99.09,74.01,,,
"def PrintColGroup ( col_names , schema ) : <TAB> """""" Print HTML colgroup element, used for JavaScript sorting. """""" <TAB> print ( ""  <colgroup> "" ) <TAB> for i , col in enumerate ( col_names ) : <TAB> <TAB> if col . endswith ( "" _HREF "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> # CSS class is used for sorting <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> css_class = ""number"" <TAB> <TAB> else: <TAB> <TAB> <TAB> css_class = ""case-insensitive"" <TAB> <TAB> # NOTE: id is a comment only; not used <TAB> <TAB> print(' <TAB> <col id=""{}"" type=""{}"" />'.format(col, css_class)) <TAB> print("" </colgroup>"")",if i == 0 :,if schema . IsNumeric ( col ) :,False,96.52,96.12,,,
"def check_region ( self , region ) : <TAB> for other in self . regions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( other . start < region . start < other . end ) or ( <TAB> <TAB> <TAB> other . start < region . end < other . end <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise Exception ( "" %r  overlaps with  %r "" % ( region , other ) )",if region == other :,if other is region :,False,95.72,71.6,,,
"def _write_value ( self , rng , value , scalar ) : <TAB> if rng . api and value : <TAB> <TAB> # it is assumed by this stage that value is a list of lists <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value[0][0] <TAB> <TAB> else: <TAB> <TAB> <TAB> rng = rng.resize(len(value), len(value[0])) <TAB> <TAB> rng.raw_value = value","if isinstance ( value [ 0 ] , list ) :",if scalar :,False,91.75,69.27,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24 : <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.56,,,
"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face.outer or del_flag in face.flags: <TAB> <TAB> <TAB> continue <TAB> <TAB> if only_select and not face.select: <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",if face . outer and del_flag in face . flags :,if face . inners and face . outer :,False,96.38,71.93,,,
"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB> <TAB> try: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return int(anime.get(y, 0)) <TAB> <TAB> except ValueError as e: <TAB> <TAB> <TAB> continue <TAB> return 0","if anime . get ( x , 0 ) == x_value :","if anime . get ( x , False ) == x_value :",False,98.43,72.28,,,
"def dir_copy ( src_dir , dest_dir , merge_if_exists = True ) : <TAB> try : <TAB> <TAB> if not os . path . exists ( dest_dir ) : <TAB> <TAB> <TAB> shutil . copytree ( src_dir , dest_dir ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> merge_dir ( src_dir , dest_dir ) <TAB> except OSError as e : <TAB> <TAB> # If source is not a directory, copy with shutil.copy <TAB> <TAB> if e.errno == errno.ENOTDIR: <TAB> <TAB> <TAB> shutil.copy(src_dir, dest_dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> logging.error(""Could not copy %s to %s"", src_dir, dest_dir)",elif merge_if_exists :,elif merge_if_exists :,True,100.0,74.37,,,
"def mapping ( self ) : <TAB> m = { } <TAB> if getGdriveCredentialsFile ( ) is not None : <TAB> <TAB> m [ "" gdrive "" ] = "" "" <TAB> unknown = 0 <TAB> for f in self . scan : <TAB> <TAB> bits = f . split ( "" # "" , 2 ) <TAB> <TAB> if len ( bits ) == 1 : <TAB> <TAB> <TAB> label = os . path . basename ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> label = bits [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> label = "" L "" + str ( unknown ) <TAB> <TAB> <TAB> unknown + = 1 <TAB> <TAB> m [ label ] = bits [ 0 ] <TAB> return m",if unknown :,"if not label or len ( label ) == 0 or label == """" :",False,91.22,52.58,,,
"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB> <TAB> return [ ] <TAB> if not http . headers : <TAB> <TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance(headers, dict): <TAB> <TAB> headers = headers.items() <TAB> output = [] <TAB> for key, value in headers: <TAB> <TAB> if key != ""User-Agent"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse(value) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self.get_tag_from_ua(ua) <TAB> <TAB> if result: <TAB> <TAB> <TAB> output.append(result) <TAB> return output",if not ua :,if not ua :,True,100.0,74.49,,,
"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB> <TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB> <TAB> for i , g in enumerate ( groups ) : <TAB> <TAB> <TAB> if g : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [ ] <TAB> <TAB> <TAB> <TAB> <TAB> for _ , vs in g : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1 . extend ( vs ) <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g1 <TAB> <TAB> yield k , tuple ( t )",if direct_upstreams :,if i in direct_upstreams :,False,98.73,73.44,,,
"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "" > "" : <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip : <TAB> <TAB> <TAB> continue <TAB> <TAB> if letter . isalnum ( ) or letter == "" "" : <TAB> <TAB> <TAB> if letter == "" "" : <TAB> <TAB> <TAB> <TAB> letter = "" _ "" <TAB> <TAB> <TAB> question + = letter . lower ( ) <TAB> return question","if letter == ""<"" :","if letter == ""<"" :",True,100.0,74.42,,,
"def _module_repr_from_spec ( spec ) : <TAB> """""" Return the repr to use for the module. """""" <TAB> # We mostly replicate _module_repr() using the spec attributes. <TAB> name = ""?"" if spec.name is None else spec.name <TAB> if spec.origin is None: <TAB> <TAB> if spec.loader is None: <TAB> <TAB> <TAB> return ""<module {!r}>"".format(name) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""<module {!r} ({!r})>"".format(name, spec.loader) <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""<module {!r} from {!r}>"".format(name, spec.origin) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""<module {!r} ({})>"".format(spec.name, spec.origin)",if spec . loader is None :,if spec . has_location :,False,98.18,72.55,,,
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> if self . any_match : <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return not self . inverse # True <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self.inverse # False <TAB> if self.any_match: <TAB> <TAB> return self.inverse # False <TAB> else: <TAB> <TAB> return not self.inverse # True",if self . inverse and self . any_match not in self . patterns :,if not result :,False,92.95,71.15,,,
"def frequent_thread_switches ( ) : <TAB> """""" Make concurrency bugs more likely to manifest. """""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval )","if hasattr ( sys , ""setswitchinterval"" ) :","if hasattr ( sys , ""getswitchinterval"" ) :",False,98.93,98.73,,,
"def record_expected_exportable_production ( self , ticks ) : <TAB> """""" Record the amount of production that should be transferred to other islands. """""" <TAB> for ( quota_holder , resource_id ) , amount in self . _low_priority_requests . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _settlement_manager_id [ quota_holder ] = WorldObject . get_object_by_id ( <TAB> <TAB> <TAB> <TAB> int ( quota_holder [ 1 : ] . split ( "" , "" ) [ 0 ] ) <TAB> <TAB> <TAB> ) . settlement_manager . worldid <TAB> <TAB> self . trade_storage [ self . _settlement_manager_id [ quota_holder ] ] [ resource_id ] + = ( <TAB> <TAB> <TAB> ticks * amount <TAB> <TAB> )",if quota_holder not in self . _settlement_manager_id :,if quota_holder not in self . _settlement_manager_id :,True,100.0,99.47,,,
"def _method_events_callback ( self , values ) : <TAB> try : <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" echo foo2 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB> <TAB> <TAB> return "" echo foo3 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo3 "" ) : <TAB> <TAB> <TAB> return "" exit \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB> <TAB> return "" echo foo1 \n ""","if previous_echoed . endswith ( ""foo1"" ) :","if previous_echoed . endswith ( ""foo1"" ) :",True,100.0,74.56,,,
"def describe_cluster_snapshots ( self , cluster_identifier = None , snapshot_identifier = None ) : <TAB> if cluster_identifier : <TAB> <TAB> cluster_snapshots = [ ] <TAB> <TAB> for snapshot in self . snapshots . values ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cluster_snapshots . append ( snapshot ) <TAB> <TAB> if cluster_snapshots : <TAB> <TAB> <TAB> return cluster_snapshots <TAB> if snapshot_identifier : <TAB> <TAB> if snapshot_identifier in self . snapshots : <TAB> <TAB> <TAB> return [ self . snapshots [ snapshot_identifier ] ] <TAB> <TAB> raise ClusterSnapshotNotFoundError ( snapshot_identifier ) <TAB> return self . snapshots . values ( )",if snapshot . identifier == cluster_identifier :,if snapshot . cluster . cluster_identifier == cluster_identifier :,False,97.12,72.46,,,
def get_snippet_edit_handler ( model ) : <TAB> if model not in SNIPPET_EDIT_HANDLERS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # use the edit handler specified on the page class <TAB> <TAB> <TAB> edit_handler = model.edit_handler <TAB> <TAB> else: <TAB> <TAB> <TAB> panels = extract_panel_definitions_from_model_class(model) <TAB> <TAB> <TAB> edit_handler = ObjectList(panels) <TAB> <TAB> SNIPPET_EDIT_HANDLERS[model] = edit_handler.bind_to(model=model) <TAB> return SNIPPET_EDIT_HANDLERS[model],"if isinstance ( model , Page ) :","if hasattr ( model , ""edit_handler"" ) :",False,94.6,61.84,,,
"def start ( ) : <TAB> if os . environ . get ( "" RUN_MAIN "" ) != "" true "" : <TAB> <TAB> try : <TAB> <TAB> <TAB> exit_code = restart_with_reloader ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . kill ( os . getpid ( ) , - exit_code ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . exit ( exit_code ) <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> pass",if exit_code != 0 :,if exit_code < 0 :,False,97.62,72.73,,,
"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB> <TAB> if len ( l ) < 5 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( l [ 2 ] ) <TAB> <TAB> <TAB> int ( l [ 3 ] ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> # <TAB> <TAB>  ret.append(improve(l[0])) <TAB> <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB> <TAB> ret.append(item) <TAB> return ret","if l [ 0 ] . startswith ( ""DISCOVER"" ) :","if l [ 0 ] == ""Filename"" :",False,96.19,72.14,,,
"def ipfs_publish ( self , lib ) : <TAB> with tempfile . NamedTemporaryFile ( ) as tmp : <TAB> <TAB> self . ipfs_added_albums ( lib , tmp . name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cmd = "" ipfs add --nocopy -q  "" . split ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> cmd = "" ipfs add -q  "" . split ( ) <TAB> <TAB> <TAB> cmd . append ( tmp . name ) <TAB> <TAB> <TAB> output = util . command_output ( cmd ) <TAB> <TAB> except ( OSError , subprocess . CalledProcessError ) as err : <TAB> <TAB> <TAB> msg = "" Failed to publish library. Error:  {0} "" . format ( err ) <TAB> <TAB> <TAB> self . _log . error ( msg ) <TAB> <TAB> <TAB> return False <TAB> <TAB> self . _log . info ( "" hash of library:  {0} "" , output )","if lib == ""s3"" :","if self . config [ ""nocopy"" ] :",False,96.54,72.41,,,
"def spends ( self ) : <TAB> # Return spends indexed by hashX <TAB> spends = defaultdict(list) <TAB> utxos = self.mempool_utxos() <TAB> for tx_hash, tx in self.txs.items(): <TAB> <TAB> for n, input in enumerate(tx.inputs): <TAB> <TAB> <TAB> if input.is_generation(): <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> prevout = (input.prev_hash, input.prev_idx) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> hashX, value = utxos.pop(prevout) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> hashX, value = self.db_utxos[prevout] <TAB> <TAB> <TAB> spends[hashX].append(prevout) <TAB> return spends",if prevout in utxos :,if prevout in utxos :,True,100.0,74.29,,,
"def terminate ( self ) : <TAB> if self . returncode is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> os . kill ( self . pid , TERM_SIGNAL ) <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> if getattr ( exc , "" errno "" , None ) != errno . ESRCH : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise",if exc . errno != errno . EPERM :,if self . wait ( timeout = 0.1 ) is None :,False,90.85,66.95,,,
"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB> <TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB> <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB> <TAB> thisDynamic = self._value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> thisDynamic = thisDynamic[1:] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic[-1] == ""z"": <TAB> <TAB> <TAB> thisDynamic = thisDynamic[:-1] <TAB> <TAB> if thisDynamic in dynamicStrToScalar: <TAB> <TAB> <TAB> return dynamicStrToScalar[thisDynamic] <TAB> <TAB> else: <TAB> <TAB> <TAB> return dynamicStrToScalar[None]","if thisDynamic [ 0 ] == ""s"" :","if ""s"" in thisDynamic :",False,95.93,71.67,,,
"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB> <TAB> if "" . "" in valname : <TAB> <TAB> <TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB> <TAB> <TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ valname ] = value <TAB> for name in config : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config",if name in self . __dict__ :,if name in self . values :,False,96.27,73.39,,,
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> if not isinstance ( op_list , list ) : <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list",if dictionary . path in paths :,if dictionary . path in paths :,True,100.0,74.48,,,
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> if k . lower ( ) == ikey : <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)","if isinstance ( key , ( list , tuple ) ) :","if isinstance ( key , ( int , long ) ) :",False,98.09,73.15,,,
"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB> <TAB> if o . selected : <TAB> <TAB> <TAB> on . append ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> off . append ( o ) <TAB> return on , off",if self . _is_item_missing ( name ) :,if len ( all_items ) < target :,False,94.41,72.15,,,
"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """""" Return standard location of genome directories. """""" <TAB> if galaxy_dir : <TAB> <TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB> <TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB> <TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB> <TAB> if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) : <TAB> <TAB> <TAB> return gdirs [ 0 ]",if seq_file :,if seq_file and os . path . exists ( seq_file ) :,False,94.32,69.3,,,
"def _PrintFuncs ( self , names ) : <TAB> # type: (List[str]) -> int <TAB> status = 0 <TAB> for name in names: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(name) <TAB> <TAB> <TAB> # TODO: Could print LST for -f, or render LST. Bash does this. 'trap' <TAB> <TAB> <TAB> # could use that too. <TAB> <TAB> else: <TAB> <TAB> <TAB> status = 1 <TAB> return status","if name . endswith ( ""-f"" ) :",if name in self . funcs :,False,93.76,61.72,,,
"def package_files ( self ) : <TAB> seen_package_directories = ( ) <TAB> directories = self . distribution . package_dir or { } <TAB> empty_directory_exists = "" "" in directories <TAB> packages = self . distribution . packages or [ ] <TAB> for package in packages : <TAB> <TAB> if package in directories : <TAB> <TAB> <TAB> package_directory = directories [ package ] <TAB> <TAB> elif empty_directory_exists : <TAB> <TAB> <TAB> package_directory = os . path . join ( directories [ "" "" ] , package ) <TAB> <TAB> else : <TAB> <TAB> <TAB> package_directory = package <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seen_package_directories + = ( package_directory + "" . "" , ) <TAB> <TAB> <TAB> yield package_directory",if package_directory not in seen_package_directories :,if not package_directory . startswith ( seen_package_directories ) :,False,95.7,71.47,,,
"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB> <TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with open ( conf_file ) as conf_handle : <TAB> <TAB> <TAB> <TAB> value = fn ( conf_handle ) <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> return value <TAB> return None",if os . path . exists ( conf_file ) :,if conf_file :,False,92.64,69.99,,,
"def on_text ( self , text ) : <TAB> if text != self . chosen_text : <TAB> <TAB> self . fail_test ( ' Expected  "" {} "" , received  "" {} "" ' . format ( self . chosen_text , text ) ) <TAB> else : <TAB> <TAB> self . checks_passed + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . pass_test ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _select_next_text ( )",if self . checks_passed == self . checks_passed :,if self . checks_passed >= self . number_of_checks :,False,94.0,71.44,,,
"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB> <TAB> if self . _is_ast_node ( name , item ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item() <TAB> <TAB> <TAB> if isinstance(x, ast.AST): <TAB> <TAB> <TAB> <TAB> self.assertEqual(type(x._fields), tuple)","if name == ""index"" :","if name == ""Index"" :",False,98.61,72.72,,,
"def apply ( self , response ) : <TAB> updated_headers = self . update_headers ( response ) <TAB> if updated_headers : <TAB> <TAB> response . headers . update ( updated_headers ) <TAB> <TAB> warning_header_value = self . warning ( response ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response . headers . update ( { "" Warning "" : warning_header_value } ) <TAB> return response",if warning_header_value :,if warning_header_value is not None :,False,95.95,70.1,,,
"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB> <TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB> <TAB> if self . use_parallel_executor and not self . use_double_buffer : <TAB> <TAB> <TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) )",if self . use_parallel_executor :,if not self . use_parallel_executor :,False,98.97,73.58,,,
def finalize ( self ) : <TAB> if self . _started : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _queue . put ( None ) <TAB> <TAB> <TAB> self . _queue . join ( ) <TAB> <TAB> <TAB> self . _consumer . join ( ) <TAB> <TAB> self . _started = False <TAB> self . _finalized = True,if self . _consumer is not None :,if not self . _finalized :,False,93.28,91.51,,,
"def _get_ilo_version ( self ) : <TAB> try : <TAB> <TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if e . code == 405 : <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e . code == 501 : <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2",if e . code != 404 :,"if hasattr ( e , ""code"" ) :",False,94.01,64.23,,,
"def _check_data ( self , source , expected_bytes , expected_duration ) : <TAB> received_bytes = 0 <TAB> received_seconds = 0.0 <TAB> bytes_to_read = 1024 <TAB> while True : <TAB> <TAB> data = source . get_audio_data ( bytes_to_read ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> received_bytes + = data . length <TAB> <TAB> received_seconds + = data . duration <TAB> <TAB> self . assertEqual ( data . length , len ( data . data ) ) <TAB> self . assertAlmostEqual ( expected_duration , received_seconds , places = 1 ) <TAB> self . assertAlmostEqual ( expected_bytes , received_bytes , delta = 5 )",if not data :,if data is None :,False,97.63,72.08,,,
"def __randomize_interval_task ( self ) : <TAB> for job in self . aps_scheduler . get_jobs ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . aps_scheduler . modify_job ( <TAB> <TAB> <TAB> <TAB> job . id , <TAB> <TAB> <TAB> <TAB> next_run_time = datetime . now ( ) <TAB> <TAB> <TAB> <TAB> + timedelta ( <TAB> <TAB> <TAB> <TAB> <TAB> seconds = randrange ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job . trigger . interval . total_seconds ( ) * 0.75 , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job . trigger . interval . total_seconds ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> )",if job . trigger . interval :,"if isinstance ( job . trigger , IntervalTrigger ) :",False,96.64,71.25,,,
"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB> <TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB> <TAB> p , q = i . as_numer_denom ( ) <TAB> <TAB> tol = c / q * * 2 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return i <TAB> <TAB> if tol < machine_epsilon : <TAB> <TAB> <TAB> break <TAB> return x",if p < tol :,if abs ( i - x ) <= tol :,False,93.63,69.61,,,
"def fix_newlines ( lines ) : <TAB> """""" Convert newlines to unix. """""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if line . endswith ( "" \r \n "" ) : <TAB> <TAB> <TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lines [ i ] = line [ : - 1 ] + "" \n ""","elif line . endswith ( ""\r"" ) :","elif line . endswith ( ""\r"" ) :",True,100.0,74.23,,,
"def payment_control_render ( self , request : HttpRequest , payment : OrderPayment ) : <TAB> template = get_template ( "" pretixplugins/paypal/control.html "" ) <TAB> sale_id = None <TAB> for trans in payment . info_data . get ( "" transactions "" , [ ] ) : <TAB> <TAB> for res in trans . get ( "" related_resources "" , [ ] ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sale_id = res [ "" sale "" ] [ "" id "" ] <TAB> ctx = { <TAB> <TAB> "" request "" : request , <TAB> <TAB> "" event "" : self . event , <TAB> <TAB> "" settings "" : self . settings , <TAB> <TAB> "" payment_info "" : payment . info_data , <TAB> <TAB> "" order "" : payment . order , <TAB> <TAB> "" sale_id "" : sale_id , <TAB> } <TAB> return template . render ( ctx )","if res [ ""sale"" ] :","if ""sale"" in res and ""id"" in res [ ""sale"" ] :",False,95.35,69.85,,,
"def for_name ( self , name ) : <TAB> try : <TAB> <TAB> name_resources = self . _resources [ name ] <TAB> except KeyError : <TAB> <TAB> raise LookupError ( name ) <TAB> else : <TAB> <TAB> for res in name_resources : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> inst = res . inst ( ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> log . exception ( "" error initializing  %s "" , res ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> log . error ( "" error initializing  %s :  %s "" , res , e ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield inst",if log_enabled ( ) :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,False,95.81,71.03,,,
"def describe ( self , done = False ) : <TAB> description = ShellCommand . describe ( self , done ) <TAB> if done : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> description = [ "" compile "" ] <TAB> <TAB> description . append ( "" %d  projects "" % self . getStatistic ( "" projects "" , 0 ) ) <TAB> <TAB> description . append ( "" %d  files "" % self . getStatistic ( "" files "" , 0 ) ) <TAB> <TAB> warnings = self . getStatistic ( "" warnings "" , 0 ) <TAB> <TAB> if warnings > 0 : <TAB> <TAB> <TAB> description . append ( "" %d  warnings "" % warnings ) <TAB> <TAB> errors = self . getStatistic ( "" errors "" , 0 ) <TAB> <TAB> if errors > 0 : <TAB> <TAB> <TAB> description . append ( "" %d  errors "" % errors ) <TAB> return description","if description == """" :",if not description :,False,97.09,70.28,,,
"def parse_list ( tl ) : <TAB> ls = [ ] <TAB> nm = [ ] <TAB> while True : <TAB> <TAB> term , nmt , tl = parse_term ( tl ) <TAB> <TAB> ls . append ( term ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nm . append ( nmt ) <TAB> <TAB> if tl [ 0 ] != "" , "" : <TAB> <TAB> <TAB> break <TAB> <TAB> tl = tl [ 1 : ] <TAB> return ls , nm , tl",if nmt :,if nmt is not None :,False,96.59,71.24,,,
"def infer_dataset_impl ( path ) : <TAB> if IndexedRawTextDataset . exists ( path ) : <TAB> <TAB> return "" raw "" <TAB> elif IndexedDataset . exists ( path ) : <TAB> <TAB> with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB> <TAB> <TAB> magic = f . read ( 8 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return "" cached "" <TAB> <TAB> <TAB> elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] : <TAB> <TAB> <TAB> <TAB> return "" mmap "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return None <TAB> elif FastaDataset . exists ( path ) : <TAB> <TAB> return "" fasta "" <TAB> else : <TAB> <TAB> return None",if magic == IndexedDataset . Index . _HDR_MAGIC :,if magic == IndexedDataset . _HDR_MAGIC :,False,98.76,73.89,,,
"def _get ( self ) : <TAB> fut = item = None <TAB> with self . _mutex : <TAB> <TAB> # Critical section never blocks. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fut = Future() <TAB> <TAB> <TAB> fut.add_done_callback( <TAB> <TAB> <TAB> <TAB> lambda f: self._get_complete() if not f.cancelled() else None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self._getters.append(fut) <TAB> <TAB> else: <TAB> <TAB> <TAB> item = self._get_item() <TAB> <TAB> <TAB> self._get_complete() <TAB> return item, fut",if self . _is_critical ( ) :,if not self . _queue or self . _getters :,False,94.97,68.82,,,
"def validate ( self ) : <TAB> dates = [ ] <TAB> for d in self . get ( "" leave_block_list_dates "" ) : <TAB> <TAB> # date is not repeated <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe.msgprint( <TAB> <TAB> <TAB> <TAB> _(""Date is repeated"") + "":"" + d.block_date, raise_exception=1 <TAB> <TAB> <TAB> ) <TAB> <TAB> dates.append(d.block_date)",if d . block_date not in dates :,if d . block_date in dates :,False,98.13,72.44,,,
"def on_choose_watch_dir_clicked ( self ) : <TAB> if self . window ( ) . watchfolder_enabled_checkbox . isChecked ( ) : <TAB> <TAB> previous_watch_dir = self . window ( ) . watchfolder_location_input . text ( ) or "" "" <TAB> <TAB> watch_dir = QFileDialog . getExistingDirectory ( <TAB> <TAB> <TAB> self . window ( ) , <TAB> <TAB> <TAB> "" Please select the watch folder "" , <TAB> <TAB> <TAB> previous_watch_dir , <TAB> <TAB> <TAB> QFileDialog . ShowDirsOnly , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self . window ( ) . watchfolder_location_input . setText ( watch_dir )",if not watch_dir :,if not watch_dir :,True,100.0,74.39,,,
"def log_generator ( self , limit = 6000 , * * kwargs ) : <TAB> # Generator for show_log_panel <TAB> skip = 0 <TAB> while True: <TAB> <TAB> logs = self.log(limit=limit, skip=skip, **kwargs) <TAB> <TAB> if not logs: <TAB> <TAB> <TAB> break <TAB> <TAB> for entry in logs: <TAB> <TAB> <TAB> yield entry <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> skip = skip + limit",if skip >= limit :,if len ( logs ) < limit :,False,95.3,69.92,,,
"def _setUpClass ( cls ) : <TAB> global solver <TAB> import pyomo . environ <TAB> from pyomo . solvers . tests . io . writer_test_cases import testCases <TAB> for test_case in testCases : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> solver [ ( test_case . name , test_case . io ) ] = True",if test_case . name in PYOMO_ENV_TEST_CASES :,"if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) :",False,78.58,61.11,,,
"def _get_file_data ( self , normpath , normrev ) : <TAB> data = self . client . cat ( normpath , normrev ) <TAB> if has_expanded_svn_keywords ( data ) : <TAB> <TAB> # Find out if this file has any keyword expansion set. <TAB> <TAB> # If it does, collapse these keywords. This is because SVN <TAB> <TAB> # will return the file expanded to us, which would break patching. <TAB> <TAB> keywords = self.client.propget(""svn:keywords"", normpath, normrev, recurse=True) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = collapse_svn_keywords(data, force_bytes(keywords[normpath])) <TAB> return data",if keywords and keywords [ normpath ] :,if normpath in keywords :,False,96.02,71.32,,,
"def add_controller_list ( path ) : <TAB> if not os . path . exists ( os . path . join ( path , "" __init__.py "" ) ) : <TAB> <TAB> bb . fatal ( "" Controllers directory  %s  exists but is missing __init__.py "" % path ) <TAB> files = sorted ( <TAB> <TAB> [ f for f in os . listdir ( path ) if f . endswith ( "" .py "" ) and not f . startswith ( "" _ "" ) ] <TAB> ) <TAB> for f in files : <TAB> <TAB> module = "" oeqa.controllers. "" + f [ : - 3 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> controllerslist . append ( module ) <TAB> <TAB> else : <TAB> <TAB> <TAB> bb . warn ( <TAB> <TAB> <TAB> <TAB> "" Duplicate controller module found for  %s , only one added. Layers should create unique controller module names "" <TAB> <TAB> <TAB> <TAB> % module <TAB> <TAB> <TAB> )","if os . path . exists ( os . path . join ( path , module , ""controllers"" ) ) :",if module not in controllerslist :,False,91.74,66.97,,,
"def on_session2 ( event ) : <TAB> new_xmpp . get_roster ( ) <TAB> new_xmpp . send_presence ( ) <TAB> logging . info ( roster [ 0 ] ) <TAB> data = roster [ 0 ] [ "" roster "" ] [ "" items "" ] <TAB> logging . info ( data ) <TAB> for jid , item in data . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_xmpp . send_presence ( ptype = "" subscribe "" , pto = jid ) <TAB> <TAB> new_xmpp . update_roster ( jid , name = item [ "" name "" ] , groups = item [ "" groups "" ] ) <TAB> new_xmpp . disconnect ( )","if item [ ""type"" ] == ""subscribe"" :","if item [ ""subscription"" ] != ""none"" :",False,95.97,72.33,,,
"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> <TAB> elif isinstance ( sym , ast . ClassDef ) : <TAB> <TAB> <TAB> result = _parse_class_simplified ( sym ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB> <TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results","if isinstance ( sym , ast . FunctionDef ) :","if isinstance ( sym , ast . FunctionDef ) :",True,100.0,74.6,,,
"def check_args ( args ) : <TAB> """""" Checks that the args are coherent. """""" <TAB> check_args_has_attributes ( args ) <TAB> if args . v : <TAB> <TAB> non_version_attrs = [ v for k , v in args . __dict__ . items ( ) if k != "" v "" ] <TAB> <TAB> print ( "" non_version_attrs "" , non_version_attrs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fail ( "" Cannot show the version number with another command. "" ) <TAB> <TAB> return <TAB> if args . i is None : <TAB> <TAB> fail ( "" Cannot draw ER diagram of no database. "" ) <TAB> if args . o is None : <TAB> <TAB> fail ( "" Cannot draw ER diagram with no output file. "" )",if args . v != non_version_attrs :,if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 :,False,91.33,64.34,,,
"def handle ( self , * args , * * options ) : <TAB> if not settings . ST_BASE_DIR . endswith ( "" spirit "" ) : <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> "" settings.ST_BASE_DIR is not the spirit root folder, are you overriding it? "" <TAB> <TAB> ) <TAB> for root , dirs , files in os . walk ( settings . ST_BASE_DIR ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> with utils . pushd ( root ) : <TAB> <TAB> <TAB> call_command ( <TAB> <TAB> <TAB> <TAB> "" makemessages "" , stdout = self . stdout , stderr = self . stderr , * * options <TAB> <TAB> <TAB> ) <TAB> self . stdout . write ( "" ok "" )","if ""settings"" not in dirs :","if ""locale"" not in dirs :",False,98.78,73.6,,,
"def scan ( scope ) : <TAB> for s in scope . children : <TAB> <TAB> if s . start_pos < = position < = s . end_pos : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return scan ( s ) or s <TAB> <TAB> <TAB> elif s . type in ( "" suite "" , "" decorated "" ) : <TAB> <TAB> <TAB> <TAB> return scan ( s ) <TAB> return None","if s . type in ( ""suite"" , ""decorated"" ) :","if isinstance ( s , ( tree . Scope , tree . Flow ) ) :",False,89.37,60.03,,,
def run_sync ( self ) : <TAB> count = 0 <TAB> while count < self . args . num_messages : <TAB> <TAB> batch = self . receiver . fetch_next ( max_batch_size = self . args . num_messages - count ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for msg in batch : <TAB> <TAB> <TAB> <TAB> msg . complete ( ) <TAB> <TAB> count + = len ( batch ),if len ( batch ) > 0 :,if self . args . peeklock :,False,93.55,66.55,,,
"def __getitem__ ( self , item ) : <TAB> if self . _datas is not None : <TAB> <TAB> ret = [ ] <TAB> <TAB> for data in self . _datas : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . append ( data [ self . _offset ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . append ( data . iloc [ self . _offset ] ) <TAB> <TAB> self . _offset + = 1 <TAB> <TAB> return ret <TAB> else : <TAB> <TAB> return self . _get_data ( item )",if item == self . _offset :,"if isinstance ( data , np . ndarray ) :",False,94.5,70.16,,,
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> if code == ""550"": <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> if not self.isempty(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise # pragma: no cover",if not self . isdir ( path ) :,if self . isfile ( path ) :,False,98.14,72.28,,,
"def replaces_in_file ( file , replacement_list ) : <TAB> rs = [ ( re . compile ( regexp ) , repl ) for ( regexp , repl ) in replacement_list ] <TAB> file_tmp = file + "" . "" + str ( os . getpid ( ) ) + "" .tmp "" <TAB> with open ( file , "" r "" ) as f : <TAB> <TAB> with open ( file_tmp , "" w "" ) as f_tmp : <TAB> <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <TAB> for r , replace in rs : <TAB> <TAB> <TAB> <TAB> <TAB> match = r . search ( line ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = replace + "" \n "" <TAB> <TAB> <TAB> <TAB> f_tmp . write ( line ) <TAB> shutil . move ( file_tmp , file )",if match :,if match :,True,100.0,74.58,,,
"def _get_path_check_mem ( self , i , size ) : <TAB> if size > 0 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p = self . _get_path ( i , - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p = self . _get_path ( i , size ) <TAB> <TAB> <TAB> if p . startswith ( "" /dev/shm "" ) : <TAB> <TAB> <TAB> <TAB> env . meminfo . add ( size ) <TAB> else : <TAB> <TAB> p = self . _get_path ( i , size ) <TAB> return p",if size == 0 :,if env . meminfo . rss + size > env . meminfo . mem_limit_soft :,False,89.2,67.79,,,
"def find_widget_by_id ( self , id , parent = None ) : <TAB> """""" Recursively searches for widget with specified ID """""" <TAB> if parent == None : <TAB> <TAB> if id in self : <TAB> <TAB> <TAB> return self [ id ] # Do things fast if possible <TAB> <TAB> parent = self[""editor""] <TAB> for c in parent.get_children(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if c.get_id() == id: <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance(c, Gtk.Container): <TAB> <TAB> <TAB> r = self.find_widget_by_id(id, c) <TAB> <TAB> <TAB> if not r is None: <TAB> <TAB> <TAB> <TAB> return r <TAB> return None","if isinstance ( c , Gtk . Widget ) :","if hasattr ( c , ""get_id"" ) :",False,96.05,71.82,,,
"def _deserialize ( cls , io ) : <TAB> flags = VideoFlags ( ) <TAB> flags . byte = U8 . read ( io ) <TAB> if flags . bit . type == VIDEO_FRAME_TYPE_COMMAND_FRAME : <TAB> <TAB> data = VideoCommandFrame . deserialize ( io ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = AVCVideoData . deserialize ( io ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = io . read ( ) <TAB> return cls ( flags . bit . type , flags . bit . codec , data )",if flags . bit . type == AVC_VideoData_TYPE_AVC :,if flags . bit . codec == VIDEO_CODEC_ID_AVC :,False,94.52,72.29,,,
"def asciiLogData ( data , maxlen = 64 , replace = False ) : <TAB> ellipses = ""  ... "" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dd = data [ : maxlen ] + ellipses <TAB> <TAB> else : <TAB> <TAB> <TAB> dd = data <TAB> <TAB> return dd . decode ( "" utf8 "" , errors = "" replace "" if replace else "" strict "" ) <TAB> except : <TAB> <TAB> return "" 0x "" + binLogData ( data , maxlen )",if len ( data ) > maxlen :,if len ( data ) > maxlen - len ( ellipses ) :,False,95.09,71.16,,,
"def _check_units ( self , new_unit_system ) : <TAB> # If no unit system has been specified for me yet, adopt the incoming <TAB> # system <TAB> if self.unit_system is None: <TAB> <TAB> self.unit_system = new_unit_system <TAB> else: <TAB> <TAB> # Otherwise, make sure they match <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Unit system mismatch %d v. %d"" % (self.unit_system, new_unit_system) <TAB> <TAB> <TAB> )",if self . unit_system != new_unit_system :,if self . unit_system != new_unit_system :,True,100.0,74.18,,,
"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB> <TAB> visitor = process_file ( filename ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB> <TAB> <TAB> if fix : <TAB> <TAB> <TAB> <TAB> print ( "" Fixing:  %s "" % filename ) <TAB> <TAB> <TAB> <TAB> fix_file ( filename )",if visitor :,if visitor . needs_fix ( ) :,False,94.45,71.09,,,
"def assign_attributes_to_variants ( variant_attributes ) : <TAB> for value in variant_attributes : <TAB> <TAB> pk = value [ "" pk "" ] <TAB> <TAB> defaults = value [ "" fields "" ] <TAB> <TAB> defaults [ "" variant_id "" ] = defaults . pop ( "" variant "" ) <TAB> <TAB> defaults [ "" assignment_id "" ] = defaults . pop ( "" assignment "" ) <TAB> <TAB> assigned_values = defaults . pop ( "" values "" ) <TAB> <TAB> assoc , created = AssignedVariantAttribute . objects . update_or_create ( <TAB> <TAB> <TAB> pk = pk , defaults = defaults <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assoc . values . set ( AttributeValue . objects . filter ( pk__in = assigned_values ) )",if created :,if created :,True,100.0,74.48,,,
"def _info ( self , userlist ) : <TAB> for strng in userlist : <TAB> <TAB> group_matched = False <TAB> <TAB> for env in self . base . comps . environments_by_pattern ( strng ) : <TAB> <TAB> <TAB> self . output . display_groups_in_environment ( env ) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB> for group in self . base . comps . groups_by_pattern ( strng ) : <TAB> <TAB> <TAB> self . output . display_pkgs_in_groups ( group ) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . error ( _ ( "" Warning: Group  %s  does not exist. "" ) , strng ) <TAB> return 0 , [ ]",if group_matched :,if not group_matched :,False,98.74,73.29,,,
"def parse_implements_interfaces ( parser ) : <TAB> types = [ ] <TAB> if parser . token . value == "" implements "" : <TAB> <TAB> advance ( parser ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> types . append ( parse_named_type ( parser ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> return types","if parser . token . value in ( ""implements"" , ""implements"" ) :","if not peek ( parser , TokenKind . NAME ) :",False,87.39,58.67,,,
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> if isinstance ( leaf , Integer ) : <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> if leaf == SymbolTrue : <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector",elif leaf == SymbolFalse :,elif leaf == SymbolFalse :,True,100.0,74.5,,,
"def update_gstin ( context ) : <TAB> dirty = False <TAB> for key , value in iteritems ( frappe . form_dict ) : <TAB> <TAB> if key != "" party "" : <TAB> <TAB> <TAB> address_name = frappe . get_value ( "" Address "" , key ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> address = frappe . get_doc ( "" Address "" , address_name ) <TAB> <TAB> <TAB> <TAB> address . gstin = value . upper ( ) <TAB> <TAB> <TAB> <TAB> address . save ( ignore_permissions = True ) <TAB> <TAB> <TAB> <TAB> dirty = True <TAB> if dirty : <TAB> <TAB> frappe . db . commit ( ) <TAB> <TAB> context . updated = True",if address_name :,if address_name :,True,100.0,74.48,,,
"def everythingIsUnicode ( d ) : <TAB> """""" Takes a dictionary, recursively verifies that every value is unicode """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True","if isinstance ( k , dict ) :","if isinstance ( v , dict ) and k != ""headers"" :",False,95.28,68.95,,,
"def check_graph ( graph ) : # pragma: no cover <TAB> for c in graph: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError(""cannot have fuse"") <TAB> <TAB> for inp in c.inputs: <TAB> <TAB> <TAB> if isinstance(inp.op, Fuse): <TAB> <TAB> <TAB> <TAB> raise RuntimeError(""cannot have fuse"")","if isinstance ( c . op , Ground ) :","if isinstance ( c . op , Fuse ) :",False,97.64,71.58,,,
"def __getattr__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( value , _ModuleMarker ) : <TAB> <TAB> <TAB> <TAB> return value . mod_ns <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB> <TAB> <TAB> <TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB> <TAB> "" Module  %r  has no mapped classes  "" <TAB> <TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> )","if isinstance ( value , _ClassMarker ) :",if value is not None :,False,96.13,71.74,,,
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> if port . port_no == in_port : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret",if allow_nw_id is not None and nw_id_ == allow_nw_id :,if nw_id_ == nw_id :,False,93.37,71.48,,,
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> if not len ( line . strip ( ) ) : <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" option "" , [ head . split ( None ) , tail ] ) ) <TAB> return entries","if head == ""#"" :",if not len ( head ) :,False,96.04,67.07,,,
"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB> <TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if getattr(command, ""positional_arg"", False): <TAB> <TAB> <TAB> continue <TAB> <TAB> names.append(key) <TAB> return names","if startswith and getattr ( command , ""command_name"" , None ) == startswith :",if startswith is not None and not key . startswith ( startswith ) :,False,90.09,61.07,,,
"def _convert_example ( example , use_bfloat16 ) : <TAB> """""" Cast int64 into int32 and float32 to bfloat16 if use_bfloat16. """""" <TAB> for key in list ( example . keys ( ) ) : <TAB> <TAB> val = example [ key ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = tf . sparse . to_dense ( val ) <TAB> <TAB> if val . dtype == tf . int64 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . int32 ) <TAB> <TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB> <TAB> example [ key ] = val","if isinstance ( val , ( list , tuple ) ) :",if tf . keras . backend . is_sparse ( val ) :,False,93.86,76.04,,,
"def _get_lang_zone ( self , lang ) : <TAB> if lang not in self . _lang_zone_from_lang : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _lang_zone_from_lang [ lang ] = MultiLangZone ( self . mgr , lang ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _lang_zone_from_lang [ lang ] = LangZone ( self . mgr , lang ) <TAB> return self . _lang_zone_from_lang [ lang ]",if lang in self . _multi_lang_zones :,if self . mgr . is_multilang ( lang ) :,False,92.34,68.71,,,
"def dispatch ( self , request , * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB> except Http404 as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> request . original_path_info = request . path_info <TAB> <TAB> <TAB> <TAB> request . path_info = settings . FEINCMS_CMS_404_PAGE <TAB> <TAB> <TAB> <TAB> response = super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB> <TAB> <TAB> <TAB> response . status_code = 404 <TAB> <TAB> <TAB> <TAB> return response <TAB> <TAB> <TAB> except Http404 : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> else : <TAB> <TAB> <TAB> raise",if settings . FEINCMS_CMS_404_PAGE :,if settings . FEINCMS_CMS_404_PAGE :,True,100.0,74.54,,,
"def _maybe_update_dropout ( self , step ) : <TAB> for i in range ( len ( self . dropout_steps ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . model . update_dropout ( self . dropout [ i ] ) <TAB> <TAB> <TAB> logger . info ( "" Updated dropout to  %f  from step  %d "" % ( self . dropout [ i ] , step ) )",if self . dropout_steps [ i ] [ 0 ] > step :,if step > 1 and step == self . dropout_steps [ i ] + 1 :,False,89.88,67.79,,,
"def bulk_move ( * args , * * kwargs ) : <TAB> for arg in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PopupException ( _ ( "" Source path and destination path cannot be same "" ) ) <TAB> <TAB> request . fs . rename ( <TAB> <TAB> <TAB> urllib . unquote ( arg [ "" src_path "" ] ) , urllib . unquote ( arg [ "" dest_path "" ] ) <TAB> <TAB> )","if arg [ ""src_path"" ] != arg [ ""dest_path"" ] :","if arg [ ""src_path"" ] == arg [ ""dest_path"" ] :",False,98.01,72.83,,,
"def asisWrite ( self , root ) : <TAB> at , c = self , self . c <TAB> try : <TAB> <TAB> c . endEditing ( ) <TAB> <TAB> c . init_error_dialogs ( ) <TAB> <TAB> fileName = at . initWriteIvars ( root , root . atAsisFileNodeName ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> at . addToOrphanList ( root ) <TAB> <TAB> <TAB> return <TAB> <TAB> at . openOutputStream ( ) <TAB> <TAB> for p in root . self_and_subtree ( copy = False ) : <TAB> <TAB> <TAB> at . writeAsisNode ( p ) <TAB> <TAB> contents = at . closeOutputStream ( ) <TAB> <TAB> at . replaceFile ( contents , at . encoding , fileName , root ) <TAB> except Exception : <TAB> <TAB> at . writeException ( fileName , root )",if not fileName :,"if not at . precheck ( fileName , root ) :",False,95.61,71.43,,,
"def asisWrite ( self , root ) : <TAB> at , c = self , self . c <TAB> try : <TAB> <TAB> c . endEditing ( ) <TAB> <TAB> c . init_error_dialogs ( ) <TAB> <TAB> fileName = at . initWriteIvars ( root , root . atAsisFileNodeName ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> at . addToOrphanList ( root ) <TAB> <TAB> <TAB> return <TAB> <TAB> at . openOutputStream ( ) <TAB> <TAB> for p in root . self_and_subtree ( copy = False ) : <TAB> <TAB> <TAB> at . writeAsisNode ( p ) <TAB> <TAB> contents = at . closeOutputStream ( ) <TAB> <TAB> at . replaceFile ( contents , at . encoding , fileName , root ) <TAB> except Exception : <TAB> <TAB> at . writeException ( fileName , root )",if not fileName :,"if line . startswith ( ""data:"" ) :",False,95.02,63.63,,,
"def process_formdata ( self , valuelist ) : <TAB> if valuelist : <TAB> <TAB> if valuelist [ 0 ] == "" __None "" : <TAB> <TAB> <TAB> self . data = None <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . data = None <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> obj = self . queryset . get ( pk = valuelist [ 0 ] ) <TAB> <TAB> <TAB> <TAB> self . data = obj <TAB> <TAB> <TAB> except DoesNotExist : <TAB> <TAB> <TAB> <TAB> self . data = None","if valuelist [ 0 ] == ""__None"" :",if self . queryset is None :,False,93.6,62.62,,,
"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB> <TAB> <TAB> <TAB> "" will return a list of all parsed tokens in an And alternative,  "" <TAB> <TAB> <TAB> <TAB> "" in prior versions only the first token was returned "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> stacklevel = 3 , <TAB> <TAB> <TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches )",if name in self . named_alternation :,"if any ( isinstance ( e , And ) for e in self . exprs ) :",False,94.56,69.6,,,
"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB> <TAB> form = BookMarkForm ( request . POST ) <TAB> <TAB> if form . is_valid ( ) : <TAB> <TAB> <TAB> form_type = form . save ( ) <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> url = reverse ( "" servers "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url = reverse ( "" metrics "" ) <TAB> <TAB> return redirect ( url ) <TAB> else : <TAB> <TAB> return redirect ( reverse ( "" servers "" ) )","if form_type == ""metrics"" :","if form_type == ""server"" :",False,98.88,73.7,,,
"def __init__ ( self , post_id , artist , page , tzInfo = None , dateFormat = None ) : <TAB> self . imageUrls = list ( ) <TAB> self . imageResizedUrls = list ( ) <TAB> self . imageId = int ( post_id ) <TAB> self . _tzInfo = tzInfo <TAB> self . dateFormat = dateFormat <TAB> if page is not None : <TAB> <TAB> post_json = demjson . decode ( page ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> artist_id = post_json [ "" data "" ] [ "" item "" ] [ "" user "" ] [ "" id "" ] <TAB> <TAB> <TAB> self . artist = SketchArtist ( artist_id , page , tzInfo , dateFormat ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . artist = artist <TAB> <TAB> self . parse_post ( post_json [ "" data "" ] [ "" item "" ] )",if artist is None :,if artist is None :,True,100.0,74.59,,,
"def _create_batch_iterator ( <TAB> self , <TAB> mark_as_delete : Callable [ [ Any ] , None ] , <TAB> to_key : Callable [ [ Any ] , Any ] , <TAB> to_value : Callable [ [ Any ] , Any ] , <TAB> batch : Iterable [ EventT ] , ) - > Iterable [ Tuple [ Any , Any ] ] : <TAB> for event in batch : <TAB> <TAB> key = to_key ( event . key ) <TAB> <TAB> # to delete keys in the table we set the raw value to None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mark_as_delete(key) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield key, to_value(event.value)",if mark_as_delete :,if event . message . value is None :,False,95.46,70.67,,,
"def test_lc_numeric_nl_langinfo ( self ) : <TAB> # Test nl_langinfo against known values <TAB> tested = False <TAB> for loc in candidate_locales: <TAB> <TAB> try: <TAB> <TAB> <TAB> setlocale(LC_NUMERIC, loc) <TAB> <TAB> <TAB> setlocale(LC_CTYPE, loc) <TAB> <TAB> except Error: <TAB> <TAB> <TAB> continue <TAB> <TAB> for li, lc in ((RADIXCHAR, ""decimal_point""), (THOUSEP, ""thousands_sep"")): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tested = True <TAB> if not tested: <TAB> <TAB> self.skipTest(""no suitable locales"")",if lc in candidate_locales :,"if self . numeric_tester ( ""nl_langinfo"" , nl_langinfo ( li ) , lc , loc ) :",False,88.0,60.33,,,
"def _level_up_logging ( self ) : <TAB> for handler in self . log . handlers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if handler . level != logging . DEBUG : <TAB> <TAB> <TAB> <TAB> handler . setLevel ( logging . DEBUG ) <TAB> <TAB> <TAB> <TAB> self . log . debug ( "" Leveled up log file verbosity "" )","if isinstance ( handler , logging . FileHandler ) :","if issubclass ( handler . __class__ , logging . FileHandler ) :",False,90.9,70.13,,,
def _show_axes_changed ( self ) : <TAB> marker = self . marker <TAB> if ( self . _vtk_control is not None ) and ( marker is not None ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> marker . interactor = None <TAB> <TAB> <TAB> marker . enabled = False <TAB> <TAB> else : <TAB> <TAB> <TAB> marker . interactor = self . interactor <TAB> <TAB> <TAB> marker . enabled = True <TAB> <TAB> self . render ( ),if self . interactor is None :,if not self . show_axes :,False,94.85,69.46,,,
"def handle_keypress ( self , rawKey , modifiers , key , * args ) : <TAB> if self . recordKeyboard and self . __delayPassed ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . insideKeys = True <TAB> <TAB> <TAB> self . targetParent . start_key_sequence ( ) <TAB> <TAB> modifierCount = len ( modifiers ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> modifierCount > 1 <TAB> <TAB> <TAB> or ( modifierCount == 1 and Key . SHIFT not in modifiers ) <TAB> <TAB> <TAB> or ( Key . SHIFT in modifiers and len ( rawKey ) > 1 ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . targetParent . append_hotkey ( rawKey , modifiers ) <TAB> <TAB> elif key not in MODIFIERS : <TAB> <TAB> <TAB> self . targetParent . append_key ( key )","if key == ""Hardware"" :",if not self . insideKeys :,False,96.56,64.22,,,
"def transform ( self , data ) : <TAB> with timer ( "" transform  %s "" % self . name , logging . DEBUG ) : <TAB> <TAB> if self . operator in { "" lat "" , "" latitude "" } : <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_latitude ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_longitude ) <TAB> <TAB> elif self . operator in { "" acc "" , "" accuracy "" } : <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_accuracy ) <TAB> <TAB> raise NameError ( "" Unknown GeoIP operator [lat, lon, acc]:  %s "" % self . operator )","elif self . operator in { ""lon"" , ""longitude"" } :","elif self . operator in { ""lon"" , ""longitude"" } :",True,100.0,74.56,,,
"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB> <TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB> <TAB> <TAB> if self . environment_id : <TAB> <TAB> <TAB> <TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected",if self . service_id :,if self . service_id :,True,100.0,74.16,,,
"def _run_response_middleware ( self , request , response , request_name = None ) : <TAB> named_middleware = self . named_response_middleware . get ( request_name , deque ( ) ) <TAB> applicable_middleware = self . response_middleware + named_middleware <TAB> if applicable_middleware : <TAB> <TAB> for middleware in applicable_middleware : <TAB> <TAB> <TAB> _response = middleware ( request , response ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _response = await _response <TAB> <TAB> <TAB> if _response : <TAB> <TAB> <TAB> <TAB> response = _response <TAB> <TAB> <TAB> <TAB> break <TAB> return response","if isinstance ( _response , asyncio . Callable ) :",if isawaitable ( _response ) :,False,95.65,71.48,,,
"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> if self._should_delete: <TAB> <TAB> <TAB> field.delete() <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not field.grid_id: <TAB> <TAB> <TAB> <TAB> func = field.put <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> func = field.replace <TAB> <TAB> <TAB> func( <TAB> <TAB> <TAB> <TAB> self.data.stream, <TAB> <TAB> <TAB> <TAB> filename=self.data.filename, <TAB> <TAB> <TAB> <TAB> content_type=self.data.content_type, <TAB> <TAB> <TAB> )",if self . data . stream :,"if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) :",False,92.92,67.6,,,
"def _import_hash ( self , operator ) : <TAB> # Import required modules into local namespace so that pipelines <TAB> # may be evaluated directly <TAB> for key in sorted(operator.import_hash.keys()): <TAB> <TAB> module_list = "", "".join(sorted(operator.import_hash[key])) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exec(""from {} import {}"".format(key[4:], module_list)) <TAB> <TAB> else: <TAB> <TAB> <TAB> exec(""from {} import {}"".format(key, module_list)) <TAB> <TAB> for var in operator.import_hash[key]: <TAB> <TAB> <TAB> self.operators_context[var] = eval(var)","if key . startswith ( ""import"" ) :","if key . startswith ( ""tpot."" ) :",False,98.29,72.57,,,
"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB> <TAB> f_path = os . path . join ( folder , f ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB> <TAB> <TAB> if extension in file_extensions : <TAB> <TAB> <TAB> <TAB> os . remove ( f_path )",if os . path . isfile ( f_path ) :,if os . path . isfile ( f_path ) :,True,100.0,74.2,,,
"def clearBuffer ( self ) : <TAB> if self . shouldLose == - 1 : <TAB> <TAB> return <TAB> if self . producer : <TAB> <TAB> self . producer . resumeProducing ( ) <TAB> if self . buffer : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . logFile . write ( "" loopback receiving  %s \n "" % repr ( self . buffer ) ) <TAB> <TAB> buffer = self . buffer <TAB> <TAB> self . buffer = b "" "" <TAB> <TAB> self . target . dataReceived ( buffer ) <TAB> if self . shouldLose == 1 : <TAB> <TAB> self . shouldLose = - 1 <TAB> <TAB> self . target . connectionLost ( failure . Failure ( main . CONNECTION_DONE ) )",if self . logFile :,if self . logFile :,True,100.0,74.5,,,
"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB> <TAB> if self . _write_line : <TAB> <TAB> <TAB> sys . stderr . write ( fn + "" :  "" ) <TAB> <TAB> if bytes : <TAB> <TAB> <TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sys . stderr . write ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _write_line = True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data )",if self . line_length :,"if ( data [ - 1 ] ) == ""\n"" :",False,92.37,62.44,,,
def stop ( self ) : <TAB> self . queue_com . state_lock . acquire ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . queue_com . state = STOPPED <TAB> <TAB> <TAB> self . remove ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> finally : <TAB> <TAB> self . queue_com . state_lock . release ( ),if self . queue_com . state == ACTIVE :,if self . queue_com . state == RUNNING and self . stop_task ( ) :,False,91.56,83.09,,,
"def _handle_special_args ( self , pyobjects ) : <TAB> if len ( pyobjects ) == len ( self . arguments . args ) : <TAB> <TAB> if self . arguments . vararg : <TAB> <TAB> <TAB> pyobjects . append ( rope . base . builtins . get_list ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pyobjects . append ( rope . base . builtins . get_dict ( ) )",if self . arguments . vararg :,if self . arguments . kwarg :,False,97.64,72.49,,,
"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB> <TAB> filename , position = self . last_edit_cursor_pos <TAB> <TAB> if not osp . isfile ( filename ) : <TAB> <TAB> <TAB> self . last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> self . load ( filename ) <TAB> <TAB> <TAB> editor = self . get_current_editor ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> editor . set_cursor_position ( position )",if editor :,if position < editor . document ( ) . characterCount ( ) :,False,93.1,68.07,,,
"def _create_sentence_objects ( self ) : <TAB> """""" Returns a list of Sentence objects from the raw text. """""" <TAB> sentence_objects = [ ] <TAB> sent_tokenizer = SentenceTokenizer ( locale = self . language . code ) <TAB> seq = Sequence ( self . raw ) <TAB> seq = sent_tokenizer . transform ( seq ) <TAB> for start_index , end_index in zip ( seq . idx [ : - 1 ] , seq . idx [ 1 : ] ) : <TAB> <TAB> # Sentences share the same models as their parent blob <TAB> <TAB> sent = seq.text[start_index:end_index].strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> s = Sentence(sent, start_index=start_index, end_index=end_index) <TAB> <TAB> s.detected_languages = self.detected_languages <TAB> <TAB> sentence_objects.append(s) <TAB> return sentence_objects",if not sent :,if not sent :,True,100.0,99.5,,,
"def to_json_schema ( self , parent = None ) : <TAB> schema = { } <TAB> if not parent : <TAB> <TAB> schema [ "" title "" ] = self . title <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> schema [ "" description "" ] = self . description <TAB> <TAB> if self . has_default : <TAB> <TAB> <TAB> schema [ "" default "" ] = self . default <TAB> <TAB> schema [ "" _required_ "" ] = self . required <TAB> if self . null : <TAB> <TAB> schema [ "" type "" ] = [ "" string "" , "" null "" ] <TAB> else : <TAB> <TAB> schema [ "" type "" ] = "" string "" <TAB> if self . enum is not None : <TAB> <TAB> schema [ "" enum "" ] = self . enum <TAB> return schema",if self . description is not None :,if self . description :,False,97.84,73.57,,,
def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB> <TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB> <TAB> return # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os.sep + f <TAB> <TAB> if os.path.isdir(path): <TAB> <TAB> <TAB> rmdir(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.unlink(path) <TAB> os.rmdir(dirname),"if not f . endswith ( "".py"" ) :","if f in ( ""."" , "".."" ) :",False,94.83,63.94,,,
"def convert_whole_dir ( path = Path ( "" marian_ckpt/ "" ) ) : <TAB> for subdir in tqdm ( list ( path . ls ( ) ) ) : <TAB> <TAB> dest_dir = f "" marian_converted/ { subdir . name } "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> convert ( source_dir , dest_dir )",if not os . path . exists ( dest_dir ) :,"if ( dest_dir / ""pytorch_model.bin"" ) . exists ( ) :",False,87.51,62.66,,,
"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB> <TAB> col = text [ 1 : ] <TAB> <TAB> if len ( col ) == 6 : <TAB> <TAB> <TAB> return col <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB> <TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text",elif len ( col ) == 3 :,elif len ( col ) == 3 :,True,100.0,74.39,,,
"def _init_rel_seek ( self ) : <TAB> "" Sets the file object ' s position to the relative location set above. "" <TAB> rs , fo = self . _rel_seek , self . _file_obj <TAB> if rs == 0.0 : <TAB> <TAB> fo . seek ( 0 , os . SEEK_SET ) <TAB> else : <TAB> <TAB> fo . seek ( 0 , os . SEEK_END ) <TAB> <TAB> size = fo . tell ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _cur_pos = size <TAB> <TAB> else : <TAB> <TAB> <TAB> target = int ( size * rs ) <TAB> <TAB> <TAB> fo . seek ( target , os . SEEK_SET ) <TAB> <TAB> <TAB> self . _align_to_newline ( ) <TAB> <TAB> <TAB> self . _cur_pos = fo . tell ( )",if size < self . _max_size :,if rs == 1.0 :,False,95.87,72.57,,,
"def parse_command_line ( self , argv = None ) : <TAB> """""" Parse the command line """""" <TAB> if self . config : <TAB> <TAB> parser = argparse . ArgumentParser ( add_help = False ) <TAB> <TAB> self . settings [ "" config "" ] . add_argument ( parser ) <TAB> <TAB> opts , _ = parser . parse_known_args ( argv ) <TAB> <TAB> if opts . config is not None : <TAB> <TAB> <TAB> self . set ( "" config "" , opts . config ) <TAB> <TAB> self . params . update ( self . import_from_module ( ) ) <TAB> parser = self . parser ( ) <TAB> opts = parser . parse_args ( argv ) <TAB> for k , v in opts . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . set ( k . lower ( ) , v )",if k . lower ( ) in self . params :,if v is None :,False,95.58,82.69,,,
"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( <TAB> <TAB> "" shield "" , region_name = "" us-east-1 "" <TAB> ) <TAB> protections = get_type_protections ( client , self . manager . get_model ( ) ) <TAB> protected_resources = { p [ "" ResourceArn "" ] for p in protections } <TAB> state = self . data . get ( "" state "" , False ) <TAB> results = [ ] <TAB> for arn , r in zip ( self . manager . get_arns ( resources ) , resources ) : <TAB> <TAB> r [ "" c7n:ShieldProtected "" ] = shielded = arn in protected_resources <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results . append ( r ) <TAB> <TAB> elif not shielded and not state : <TAB> <TAB> <TAB> results . append ( r ) <TAB> return results",if state :,if shielded and state :,False,98.43,73.42,,,
"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self . skip_ws ( aList , i ) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> if i > = len ( aList ) or aList [ i ] == "" \n "" : <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList[j:i] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else: <TAB> <TAB> <TAB> i += 1","if aList [ i ] == ""\r"" :",if self . is_ws ( aList [ i ] ) :,False,94.9,64.1,,,
"def predict ( request : Request ) : <TAB> form = await request . form ( ) <TAB> files , entry = convert_input ( form ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return JSONResponse ( ALL_FEATURES_PRESENT_ERROR , status_code = 400 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = model . predict ( data_dict = [ entry ] ) . to_dict ( "" records "" ) [ 0 ] <TAB> <TAB> <TAB> return JSONResponse ( resp ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> logger . error ( "" Error:  {} "" . format ( str ( e ) ) ) <TAB> <TAB> <TAB> return JSONResponse ( COULD_NOT_RUN_INFERENCE_ERROR , status_code = 500 ) <TAB> finally : <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> os . remove ( f . name )","if entry in [ ""features"" , ""features"" ] :",if ( entry . keys ( ) & input_features ) != input_features :,False,93.08,63.86,,,
"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __conn . close ( ) <TAB> <TAB> <TAB> self . __conn = None <TAB> <TAB> for _ , l in self . _library_cache . items ( ) : <TAB> <TAB> <TAB> if hasattr ( l , "" _reset "" ) and callable ( l . _reset ) : <TAB> <TAB> <TAB> <TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB> <TAB> <TAB> <TAB> l . _reset ( ) # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",if self . __conn :,if self . __conn is not None :,False,97.64,72.23,,,
"def read ( self ) : <TAB> if op . isfile ( self . fileName ) : <TAB> <TAB> with textfile_open ( self . fileName , "" rt "" ) as fid : <TAB> <TAB> <TAB> items = json . load ( fid ) <TAB> <TAB> <TAB> # TODO: catch JSON exception... <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> items = dict() <TAB> else: <TAB> <TAB> items = dict() <TAB> self._items.clear() <TAB> self._items.update(items) <TAB> self._haveReadData = True",if items is None :,if items is None :,True,100.0,74.24,,,
"def get_django_comment ( text : str , i : int ) - > str : <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end < = len ( text ) : <TAB> <TAB> if text [ end - 2 : end ] == "" #} "" : <TAB> <TAB> <TAB> return text [ i : end ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unclosed_end = end <TAB> <TAB> end + = 1 <TAB> raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] )","if text [ end ] == "" "" :","if not unclosed_end and text [ end ] == ""<"" :",False,93.92,70.61,,,
"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self._eval_late_binding(value) <TAB> <TAB> <TAB> schema = self.late_bind_schemas.get(key) <TAB> <TAB> <TAB> if schema is not None: <TAB> <TAB> <TAB> <TAB> value_ = schema.validate(value_) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self._late_binding_returnvalues[key] = value_ <TAB> <TAB> return value_ <TAB> else: <TAB> <TAB> return value",if value_ is not None :,if value_ is KeyError :,False,98.52,73.02,,,
"def connect ( * args , * * ckwargs ) : <TAB> if "" give_content_type "" in kwargs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs [ "" give_content_type "" ] ( args [ 6 ] [ "" content-type "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> kwargs [ "" give_content_type "" ] ( "" "" ) <TAB> if "" give_connect "" in kwargs : <TAB> <TAB> kwargs [ "" give_connect "" ] ( * args , * * ckwargs ) <TAB> status = code_iter . next ( ) <TAB> etag = etag_iter . next ( ) <TAB> timestamp = timestamps_iter . next ( ) <TAB> if status == - 1 : <TAB> <TAB> raise HTTPException ( ) <TAB> return FakeConn ( status , etag , body = kwargs . get ( "" body "" , "" "" ) , timestamp = timestamp )","if args [ 6 ] [ ""content-type"" ] :","if len ( args ) >= 7 and ""content_type"" in args [ 6 ] :",False,93.04,70.91,,,
"def _reset ( self ) : <TAB> self . _handle_connect ( ) <TAB> if self . rewarder_session : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> env_id = random . choice ( self . _sample_env_ids ) <TAB> <TAB> <TAB> logger . info ( "" Randomly sampled env_id= {} "" . format ( env_id ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> env_id = None <TAB> <TAB> self . rewarder_session . reset ( env_id = env_id ) <TAB> else : <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" No rewarder session exists, so cannot send a reset via the rewarder channel "" <TAB> <TAB> ) <TAB> self . _reset_mask ( ) <TAB> return [ None ] * self . n",if random . random ( ) < self . _sample_env_ids :,if self . _sample_env_ids :,False,96.56,72.74,,,
"def _create_architecture_list ( architectures , current_arch ) : <TAB> if not architectures : <TAB> <TAB> return [ _Architecture ( build_on = [ current_arch ] ) ] <TAB> build_architectures : List [ str ] = [ ] <TAB> architecture_list : List [ _Architecture ] = [ ] <TAB> for item in architectures : <TAB> <TAB> if isinstance ( item , str ) : <TAB> <TAB> <TAB> build_architectures . append ( item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> architecture_list . append ( <TAB> <TAB> <TAB> <TAB> _Architecture ( build_on = item . get ( "" build-on "" ) , run_on = item . get ( "" run-on "" ) ) <TAB> <TAB> <TAB> ) <TAB> if build_architectures : <TAB> <TAB> architecture_list . append ( _Architecture ( build_on = build_architectures ) ) <TAB> return architecture_list","elif isinstance ( item , dict ) :","if isinstance ( item , dict ) :",False,98.91,73.52,,,
"def inspect ( self , pokemon ) : <TAB> # Make sure it was not caught! <TAB> for caught_pokemon in self.cache: <TAB> <TAB> same_latitude = ""{0:.4f}"".format(pokemon[""latitude""]) == ""{0:.4f}"".format( <TAB> <TAB> <TAB> caught_pokemon[""latitude""] <TAB> <TAB> ) <TAB> <TAB> same_longitude = ""{0:.4f}"".format(pokemon[""longitude""]) == ""{0:.4f}"".format( <TAB> <TAB> <TAB> caught_pokemon[""longitude""] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> if len(self.cache) >= 200: <TAB> <TAB> self.cache.pop(0) <TAB> self.cache.append(pokemon)","if not same_latitude and not caught_pokemon [ ""is_caught"" ] :",if same_latitude and same_longitude :,False,93.64,66.6,,,
"def parley ( self ) : <TAB> for x in [ 0 , 1 ] : <TAB> <TAB> a = self . agents [ x ] . act ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" [DONE] "" in a [ "" text "" ] : <TAB> <TAB> <TAB> <TAB> self . agents [ x - 1 ] . observe ( <TAB> <TAB> <TAB> <TAB> <TAB> { "" id "" : "" World "" , "" text "" : "" The other agent has ended the chat. "" } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self . episodeDone = True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . agents [ x - 1 ] . observe ( a )","if a [ ""id"" ] == ""World"" :",if a is not None :,False,94.37,68.11,,,
"def _prepare_subset ( <TAB> full_data : torch . Tensor , <TAB> full_targets : torch . Tensor , <TAB> num_samples : int , <TAB> digits : Sequence , ) : <TAB> classes = { d : 0 for d in digits } <TAB> indexes = [ ] <TAB> for idx , target in enumerate ( full_targets ) : <TAB> <TAB> label = target . item ( ) <TAB> <TAB> if classes . get ( label , float ( "" inf "" ) ) > = num_samples : <TAB> <TAB> <TAB> continue <TAB> <TAB> indexes . append ( idx ) <TAB> <TAB> classes [ label ] + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> data = full_data [ indexes ] <TAB> targets = full_targets [ indexes ] <TAB> return data , targets",if classes [ label ] == 0 :,if all ( classes [ k ] >= num_samples for k in classes ) :,False,92.46,69.8,,,
"def get_work_root ( self , flags ) : <TAB> _flags = flags . copy ( ) <TAB> _flags [ "" is_toplevel "" ] = True <TAB> target = self . _get_target ( _flags ) <TAB> if target : <TAB> <TAB> _flags [ "" target "" ] = target . name <TAB> <TAB> tool = self . get_tool ( _flags ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return target . name + "" - "" + tool <TAB> <TAB> else : <TAB> <TAB> <TAB> raise SyntaxError ( <TAB> <TAB> <TAB> <TAB> "" Failed to determine work root. Could not resolve tool for target  "" <TAB> <TAB> <TAB> <TAB> + target . name <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise SyntaxError ( "" Failed to determine work root. Could not resolve target "" )",if tool :,if tool :,True,100.0,74.54,,,
"def run_command ( self , data ) : <TAB> """""" Run editor commands. """""" <TAB> parts = data . split ( "" "" ) <TAB> cmd = parts [ 0 ] . lower ( ) <TAB> if cmd in self . operations . keys ( ) : <TAB> <TAB> return self . run_operation ( cmd ) <TAB> args = "" "" . join ( parts [ 1 : ] ) <TAB> self . logger . debug ( "" Looking for command  ' {0} ' "" . format ( cmd ) ) <TAB> if cmd in self . modules . modules . keys ( ) : <TAB> <TAB> self . logger . debug ( "" Trying to run command  ' {0} ' "" . format ( cmd ) ) <TAB> <TAB> self . get_editor ( ) . store_action_state ( cmd ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> self . set_status ( "" Command  ' {0} '  not found. "" . format ( cmd ) ) <TAB> <TAB> return False <TAB> return True","if self . run_module ( cmd , args ) :","if not self . run_module ( cmd , args ) :",False,99.04,97.36,,,
"def get_main_chain_layers ( self ) : <TAB> """""" Return a list of layer IDs in the main chain. """""" <TAB> main_chain = self . get_main_chain ( ) <TAB> ret = [ ] <TAB> for u in main_chain : <TAB> <TAB> for v , layer_id in self . adj_list [ u ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . append ( layer_id ) <TAB> return ret",if v == u and layer_id not in ret :,if v in main_chain and u in main_chain :,False,92.04,94.37,,,
"def hash ( self , context ) : <TAB> with context : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return IECore . MurmurHash ( ) <TAB> <TAB> h = GafferDispatch . TaskNode . hash ( self , context ) <TAB> <TAB> h . append ( self [ "" fileName "" ] . hash ( ) ) <TAB> <TAB> h . append ( self [ "" in "" ] . hash ( ) ) <TAB> <TAB> h . append ( self . __parameterHandler . hash ( ) ) <TAB> <TAB> return h",if self . __parameterHandler is None :,"if not self [ ""fileName"" ] . getValue ( ) or self [ ""in"" ] . source ( ) == self [ ""in"" ] :",False,78.84,59.14,,,
"def hash ( self , context ) : <TAB> with context : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return IECore . MurmurHash ( ) <TAB> <TAB> h = GafferDispatch . TaskNode . hash ( self , context ) <TAB> <TAB> h . append ( self [ "" fileName "" ] . hash ( ) ) <TAB> <TAB> h . append ( self [ "" in "" ] . hash ( ) ) <TAB> <TAB> h . append ( self . __parameterHandler . hash ( ) ) <TAB> <TAB> return h",if self . __parameterHandler is None :,"if src [ : , : , 3 ] . any ( ) :",False,90.18,68.01,,,
"def check_permissions ( self , obj ) : <TAB> request = self . context . get ( "" request "" ) <TAB> for Perm in permissions : <TAB> <TAB> perm = Perm ( ) <TAB> <TAB> if not perm . has_permission ( request , self ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True",if not perm . is_superuser and not perm . is_superuser :,"if not perm . has_object_permission ( request , self , obj ) :",False,88.31,68.08,,,
"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB> <TAB> if op . attr_key == "" storage_scope "" : <TAB> <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> <TAB> return op . body <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> <TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" )","if isinstance ( op , tvm . tir . For ) :","if op . attr_key == ""virtual_thread"" :",False,94.4,66.16,,,
"def task_done ( self ) : <TAB> with self . _cond : <TAB> <TAB> if not self . _unfinished_tasks . acquire ( False ) : <TAB> <TAB> <TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _cond . notify_all ( )",if self . _finished_tasks . acquire ( False ) :,if self . _unfinished_tasks . _semlock . _is_zero ( ) :,False,88.43,68.4,,,
"def get_json ( self ) : <TAB> if not hasattr ( self , "" _json "" ) : <TAB> <TAB> self . _json = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _json = json . loads ( self . request . body ) <TAB> return self . _json","if self . request and self . request . method == ""POST"" :","if self . request . headers . get ( ""Content-Type"" , """" ) . startswith ( ""application/json"" ) :",False,78.33,54.03,,,
"def userfullname ( ) : <TAB> """""" Get the user ' s full name. """""" <TAB> global _userfullname <TAB> <IF-STMT> <TAB> <TAB> uid = os . getuid ( ) <TAB> <TAB> entry = pwd_from_uid ( uid ) <TAB> <TAB> if entry : <TAB> <TAB> <TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname","if _userfullname == """" :",if not _userfullname :,False,90.66,52.46,,,
"def test_scatter ( self ) : <TAB> for rank in range ( self . world_size ) : <TAB> <TAB> tensor = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tensor = [ torch . tensor ( i ) for i in range ( self . world_size ) ] <TAB> <TAB> result = comm . get ( ) . scatter ( tensor , rank , size = ( ) ) <TAB> <TAB> self . assertTrue ( torch . is_tensor ( result ) ) <TAB> <TAB> self . assertEqual ( result . item ( ) , self . rank )",if rank % 2 == 0 :,if self . rank == rank :,False,95.31,71.5,,,
"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB> <TAB> if pos in decompiler . targets : <TAB> <TAB> <TAB> decompiler . process_target ( pos ) <TAB> <TAB> method = getattr ( decompiler , opname , None ) <TAB> <TAB> if method is None : <TAB> <TAB> <TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB> <TAB> decompiler . pos = pos <TAB> <TAB> decompiler . next_pos = next_pos <TAB> <TAB> x = method ( * arg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> decompiler . stack . append ( x )",if x is not None :,if x is not None :,True,100.0,74.47,,,
"def print_scenario_ran ( self , scenario ) : <TAB> if scenario . passed : <TAB> <TAB> self . wrt ( "" OK "" ) <TAB> elif scenario . failed : <TAB> <TAB> reason = self . scenarios_and_its_fails [ scenario ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . wrt ( "" FAILED "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . wrt ( "" ERROR "" ) <TAB> self . wrt ( "" \n "" )","if reason . reason == ""failed"" :","if isinstance ( reason . exception , AssertionError ) :",False,93.27,64.27,,,
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> if scan_argv ( self . argv , option ) is not None : <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> if option != other_option : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option",if other_option != option :,"if scan_argv ( self . argv , other_option ) is not None :",False,92.7,68.74,,,
"def print_po_snippet ( en_loc_old_lists , context ) : <TAB> for m , localized , old in zip ( * en_loc_old_lists ) : <TAB> <TAB> if m == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> localized = old <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" #:  {file} : {line} \n "" <TAB> <TAB> <TAB> ' msgid  "" {context} {en_month} "" \n ' <TAB> <TAB> <TAB> ' msgstr  "" {localized_month} "" \n ' . format ( <TAB> <TAB> <TAB> <TAB> context = context , <TAB> <TAB> <TAB> <TAB> file = filename , <TAB> <TAB> <TAB> <TAB> line = print_po_snippet . line , <TAB> <TAB> <TAB> <TAB> en_month = m , <TAB> <TAB> <TAB> <TAB> localized_month = localized , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> print_po_snippet . line + = 1",if m == localized :,if m == localized :,True,100.0,74.54,,,
"def set_status ( self , dict_new ) : <TAB> for i , value in dict_new . items ( ) : <TAB> <TAB> self . dict_bili [ i ] = value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . dict_bili [ "" pcheaders "" ] [ "" cookie "" ] = value <TAB> <TAB> <TAB> self . dict_bili [ "" appheaders "" ] [ "" cookie "" ] = value","if i == ""pcheaders"" :","if i == ""cookie"" :",False,97.68,72.39,,,
"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB> <TAB> child = pathobj . child ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pathdict [ key ] = child <TAB> <TAB> <TAB> child . setContent ( value ) <TAB> <TAB> elif isinstance ( value , dict ) : <TAB> <TAB> <TAB> child . createDirectory ( ) <TAB> <TAB> <TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict","if isinstance ( value , str ) :","if isinstance ( value , bytes ) :",False,98.53,73.44,,,
"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB> <TAB> example = list ( example ) <TAB> <TAB> if len_map is not None : <TAB> <TAB> <TAB> for key , max_len in len_map . items ( ) : <TAB> <TAB> <TAB> <TAB> example_len = example [ key ] . shape <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB> <TAB> yield tuple ( example )",if len ( example_len ) > max_len :,if example_len > max_len :,False,96.31,72.42,,,
"def check ( self , * * kw ) : <TAB> if not kw : <TAB> <TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB> <TAB> if "" dir "" in kw : <TAB> <TAB> <TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw )","if ""file"" in kw :","if ""file"" in kw :",True,100.0,74.4,,,
"def next_instruction_is_function_or_class ( lines ) : <TAB> """""" Is the first non-empty, non-commented line of the cell either a function or a class? """""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if parser . is_quoted ( ) : <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) : # empty line <TAB> <TAB> <TAB> if i > 0 and not lines[i - 1].strip(): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False","if line . startswith ( ""function"" ) :","if line . startswith ( ( ""#"" , ""@"" , "" "" , "")"" ) ) :",False,93.92,95.94,,,
"def askCheckReadFile ( self , localFile , remoteFile ) : <TAB> if not kb . bruteMode : <TAB> <TAB> message = "" do you want confirmation that the remote file  ' %s ' "" % remoteFile <TAB> <TAB> message + = "" has been successfully downloaded from the back-end  "" <TAB> <TAB> message + = "" DBMS file system? [Y/n]  "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _checkFileLength ( localFile , remoteFile , True ) <TAB> return None",if self . _confirm ( message ) :,"if readInput ( message , default = ""Y"" , boolean = True ) :",False,89.11,63.0,,,
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> if version is not None : # if failed to get version bail <TAB> <TAB> <TAB> major, minor, _ = version <TAB> <TAB> <TAB> arch = load_arch_data(hive_name, company, tag, tag_key, default_arch) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> exe_data = load_exe(hive_name, company, company_key, tag) <TAB> <TAB> <TAB> <TAB> if exe_data is not None: <TAB> <TAB> <TAB> <TAB> <TAB> exe, args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company, major, minor, arch, exe, args",if arch is not None :,if arch is not None :,True,100.0,74.51,,,
"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB> <TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB> <TAB> c = s [ pos ] <TAB> <TAB> if c == "" { "" : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> <TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB> <TAB> return pos <TAB> return None","elif c == ""}"" :","elif c == ""}"" :",True,100.0,74.5,,,
"def pred ( field , value , item ) : <TAB> for suffix , p in _BUILTIN_PREDS . iteritems ( ) : <TAB> <TAB> if field . endswith ( suffix ) : <TAB> <TAB> <TAB> f = field [ : field . index ( suffix ) ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return p ( getattr ( item , f ) , value ) <TAB> if not hasattr ( item , field ) or getattr ( item , field ) is None : <TAB> <TAB> return False <TAB> if isinstance ( value , type ( lambda x : x ) ) : <TAB> <TAB> return value ( getattr ( item , field ) ) <TAB> return getattr ( item , field ) == value",if f not in field :,"if not hasattr ( item , f ) or getattr ( item , f ) is None :",False,91.25,68.74,,,
"def init_weights ( self ) : <TAB> """""" Initialize model weights. """""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB> <TAB> if isinstance ( m , nn . ConvTranspose2d ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 , bias = 0 )","if isinstance ( m , nn . BatchNorm2d ) :","if isinstance ( m , nn . Conv2d ) :",False,98.49,73.27,,,
"def test_byteswap ( self ) : <TAB> if self . typecode == "" u "" : <TAB> <TAB> example = "" \U00100100 "" <TAB> else : <TAB> <TAB> example = self . example <TAB> a = array . array ( self . typecode , example ) <TAB> self . assertRaises ( TypeError , a . byteswap , 42 ) <TAB> if a . itemsize in ( 1 , 2 , 4 , 8 ) : <TAB> <TAB> b = array . array ( self . typecode , example ) <TAB> <TAB> b . byteswap ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( a , b ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertNotEqual ( a , b ) <TAB> <TAB> b . byteswap ( ) <TAB> <TAB> self . assertEqual ( a , b )",if a . itemsize == 1 :,if a . itemsize == 1 :,True,100.0,74.56,,,
"def _remove_blocks_from_variables ( variables ) : <TAB> new_variables = [ ] <TAB> for name , variable in variables : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_variables . extend ( variable . locals ) <TAB> <TAB> <TAB> new_variables . append ( ( name , variable . result ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_variables . append ( ( name , variable ) ) <TAB> return new_variables","if isinstance ( variable , Variable ) :",if variable . is_block ( ) :,False,94.31,70.45,,,
def scope ( self ) : <TAB> <IF-STMT> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . scope_ = Scope ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . scope_,if self . scope_ is None :,if self . scope_ is None :,True,100.0,99.11,,,
"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( ) # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB> <TAB> if v is not None: <TAB> <TAB> <TAB> if k == ""attrlist"": <TAB> <TAB> <TAB> <TAB> v = subs_attrs(v) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes(v, attrs) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)","elif k == ""attributes"" :",if v :,False,95.86,63.37,,,
"def parse ( self , response ) : <TAB> try : <TAB> <TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB> <TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB> <TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB> <TAB> return <TAB> for item in content [ "" data "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB> <TAB> elif "" hoverURL "" in item : <TAB> <TAB> <TAB> img_url = item [ "" hoverURL "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict ( file_url = img_url )","if ""objURL"" in item :","if ""objURL"" in item :",True,100.0,74.56,,,
"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <TAB> <TAB> if instr.mnemonic.startswith(""lsr""): <TAB> <TAB> <TAB> return ""LSR"" <TAB> <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB> <TAB> <TAB> return ""LSL"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)","elif instr . mnemonic . startswith ( ""asr"" ) :","elif instr . mnemonic . startswith ( ""asr"" ) :",True,100.0,74.21,,,
"def _clean_regions ( items , region ) : <TAB> """""" Intersect region with target file if it exists """""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB> <TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( target , six . string_types ) and os . path . isfile ( target ) : <TAB> <TAB> <TAB> <TAB> target = _load_regions ( target ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> target = [ target ] <TAB> <TAB> <TAB> return target",if target :,if target :,True,100.0,99.45,,,
def reader_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB> <TAB> self . active_readers - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . active_writers + = 1 <TAB> <TAB> <TAB> self . waiting_writers - = 1 <TAB> <TAB> <TAB> self . can_write . release ( ) <TAB> finally : <TAB> <TAB> self . mutex . release ( ),if self . active_writers >= 0 :,if self . active_readers == 0 and self . waiting_writers != 0 :,False,90.63,65.06,,,
def reader_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB> <TAB> self . active_readers - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . active_writers + = 1 <TAB> <TAB> <TAB> self . waiting_writers - = 1 <TAB> <TAB> <TAB> self . can_write . release ( ) <TAB> finally : <TAB> <TAB> self . mutex . release ( ),if self . active_writers >= 0 :,if len ( subwords ) >= delimiter_len and subwords [ - delimiter_len : ] == delimiter :,False,83.64,59.86,,,
"def _make_var_names ( exog ) : <TAB> if hasattr ( exog , "" name "" ) : <TAB> <TAB> var_names = exog . name <TAB> elif hasattr ( exog , "" columns "" ) : <TAB> <TAB> var_names = exog . columns <TAB> else : <TAB> <TAB> raise ValueError ( "" exog is not a Series or DataFrame or is unnamed. "" ) <TAB> try : <TAB> <TAB> var_names = "" "" . join ( var_names ) <TAB> except TypeError : # cannot have names that are numbers, pandas default <TAB> <TAB> from statsmodels.base.data import _make_exog_names <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> var_names = ""x1"" <TAB> <TAB> else: <TAB> <TAB> <TAB> var_names = "" "".join(_make_exog_names(exog)) <TAB> return var_names","if isinstance ( exog , np . ndarray ) :",if exog . ndim == 1 :,False,95.97,71.57,,,
"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for extension in self . extensions : <TAB> <TAB> <TAB> <TAB> self [ extension ] = self . type <TAB> <TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB> <TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB> <TAB> pattern = attrs [ "" pattern "" ] <TAB> <TAB> if pattern . startswith ( "" *. "" ) : <TAB> <TAB> <TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) )",if self . extensions :,if self . type :,False,98.54,73.42,,,
"def nodes ( self , id = None , name = None ) : <TAB> for node_dict in self . node_ls ( id = id , name = name ) : <TAB> <TAB> node_id = node_dict [ "" ID "" ] <TAB> <TAB> node = DockerNode ( self , node_id , inspect = node_dict ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield node",if node . is_live :,if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) :,False,81.74,64.33,,,
"def fix_repeating_arguments ( self ) : <TAB> """""" Fix elements that should accumulate/increment values. """""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self",elif type ( e . value ) is None :,if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 :,False,92.08,76.93,,,
"def vi_search ( self , rng ) : <TAB> for i in rng : <TAB> <TAB> line_history = self . _history . history [ i ] <TAB> <TAB> pos = line_history . get_line_text ( ) . find ( self . _vi_search_text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _history . history_cursor = i <TAB> <TAB> <TAB> self . l_buffer . line_buffer = list ( line_history . line_buffer ) <TAB> <TAB> <TAB> self . l_buffer . point = pos <TAB> <TAB> <TAB> self . vi_undo_restart ( ) <TAB> <TAB> <TAB> return True <TAB> self . _bell ( ) <TAB> return False",if pos != - 1 :,if pos >= 0 :,False,97.21,72.53,,,
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if type ( test . value ) in self . _const_types : <TAB> <TAB> <TAB> <TAB> if not test . value : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope )","if isinstance ( test , ast . If ) :","if isinstance ( test , ast . Const ) :",False,98.31,73.15,,,
"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB> <TAB> squid_host = self . squid_hosts [ nickname ] <TAB> <TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fulldata = fulldata . splitlines ( ) <TAB> <TAB> <TAB> for data in fulldata : <TAB> <TAB> <TAB> <TAB> matches = self . stat_pattern . match ( data ) <TAB> <TAB> <TAB> <TAB> if matches : <TAB> <TAB> <TAB> <TAB> <TAB> self . publish_counter ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> )",if len ( fulldata ) > 0 :,if fulldata is not None :,False,96.92,72.01,,,
"def convert ( x , base , exponents ) : <TAB> out = [ ] <TAB> for e in exponents : <TAB> <TAB> d = int ( x / ( base * * e ) ) <TAB> <TAB> x - = d * ( base * * e ) <TAB> <TAB> out . append ( digits [ d ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return out",if x == 0 :,if x == 0 and e < 0 :,False,95.47,70.98,,,
"def print_doc ( manager , options ) : <TAB> plugin_name = options . doc <TAB> plugin = plugins . get ( plugin_name , None ) <TAB> if plugin : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> console ( "" Plugin  %s  does not have documentation "" % plugin_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> console ( "" "" ) <TAB> <TAB> <TAB> console ( trim ( plugin . instance . __doc__ ) ) <TAB> <TAB> <TAB> console ( "" "" ) <TAB> else : <TAB> <TAB> console ( "" Could not find plugin  %s "" % plugin_name )",if not plugin . instance . __doc__ :,if not plugin . instance . __doc__ :,True,100.0,74.41,,,
"def _set_attrs ( self , attrs ) : <TAB> for attr in self . ATTRS : <TAB> <TAB> if attr in attrs : <TAB> <TAB> <TAB> setattr ( self , attr , attrs [ attr ] ) <TAB> <TAB> <TAB> del attrs [ attr ] <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> setattr ( self , attr , NO_DEFAULT ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> setattr ( self , attr , None ) <TAB> if attrs : <TAB> <TAB> attrs = sorted ( attrs . keys ( ) ) <TAB> <TAB> raise OptionError ( "" invalid keyword arguments:  %s "" % "" ,  "" . join ( attrs ) , self )",if not attrs :,"if attr == ""default"" :",False,96.11,66.97,,,
"def _get_set_scope ( <TAB> ir_set : irast . Set , scope_tree : irast . ScopeTreeNode ) - > irast . ScopeTreeNode : <TAB> if ir_set . path_scope_id : <TAB> <TAB> new_scope = scope_tree . root . find_by_unique_id ( ir_set . path_scope_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise errors . InternalServerError ( <TAB> <TAB> <TAB> <TAB> f "" dangling scope pointer to node with uid "" <TAB> <TAB> <TAB> <TAB> f "" : { ir_set . path_scope_id }  in  { ir_set !r} "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> new_scope = scope_tree <TAB> return new_scope",if new_scope is None :,if new_scope is None :,True,100.0,74.4,,,
"def test_leave_one_out ( self ) : <TAB> correct = 0 <TAB> k = 3 <TAB> model = kNN . train ( xs , ys , k ) <TAB> predictions = [ 1 , 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 ] <TAB> for i in range ( len ( predictions ) ) : <TAB> <TAB> model = kNN . train ( xs [ : i ] + xs [ i + 1 : ] , ys [ : i ] + ys [ i + 1 : ] , k ) <TAB> <TAB> prediction = kNN . classify ( model , xs [ i ] ) <TAB> <TAB> self . assertEqual ( prediction , predictions [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> correct + = 1 <TAB> self . assertEqual ( correct , 13 )",if i % 2 == 0 :,if prediction == ys [ i ] :,False,96.39,72.54,,,
"def import_files ( self , files ) : <TAB> """""" Import a list of MORE (.csv) files. """""" <TAB> c = self . c <TAB> if files : <TAB> <TAB> changed = False <TAB> <TAB> self . tab_width = c . getTabWidth ( c . p ) <TAB> <TAB> for fileName in files : <TAB> <TAB> <TAB> g . setGlobalOpenDir ( fileName ) <TAB> <TAB> <TAB> p = self . import_file ( fileName ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> p . contract ( ) <TAB> <TAB> <TAB> <TAB> p . setDirty ( ) <TAB> <TAB> <TAB> <TAB> c . setChanged ( True ) <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> if changed : <TAB> <TAB> <TAB> c . redraw ( p )",if p :,if p :,True,100.0,99.51,,,
"def getPageTemplate ( payload , place ) : <TAB> retVal = ( kb . originalPage , kb . errorIsNone ) <TAB> if payload and place : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> page , _ , _ = Request . queryPage ( payload , place , content = True , raise404 = False ) <TAB> <TAB> <TAB> kb . pageTemplates [ ( payload , place ) ] = ( page , kb . lastParserStatus is None ) <TAB> <TAB> retVal = kb . pageTemplates [ ( payload , place ) ] <TAB> return retVal","if ( payload , place ) not in kb . pageTemplates :","if ( payload , place ) not in kb . pageTemplates :",True,100.0,74.41,,,
"def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB> <TAB> if isinstance ( constraint_data , LinearCanonicalRepn ) : <TAB> <TAB> <TAB> if constraint_data . variables is None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if isinstance ( constraint_data , LinearCanonicalRepn ) :",if constraint_data . body . polynomial_degree ( ) == 0 :,False,88.58,66.48,,,
"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB> <TAB> if self . _return_feature ( f ) and hasattr ( f , name ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB> <TAB> <TAB> feat = f <TAB> if feat is None : <TAB> <TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name )",if not f . unique :,if feat is not None :,False,96.19,71.42,,,
"def hideEvent ( self , event ) : <TAB> """""" Reimplement Qt method """""" <TAB> if not self . light : <TAB> <TAB> for plugin in self . widgetlist : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> plugin . visibility_changed ( True ) <TAB> QMainWindow . hideEvent ( self , event )",if plugin . visibility_changed ( ) :,if plugin . isAncestorOf ( self . last_focused_widget ) :,False,89.32,65.46,,,
"def move_stdout_to_stderr ( self ) : <TAB> to_remove = [ ] <TAB> to_add = [ ] <TAB> for consumer_level , consumer in self . consumers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> to_remove . append ( ( consumer_level , consumer ) ) <TAB> <TAB> <TAB> to_add . append ( ( consumer_level , sys . stderr ) ) <TAB> for item in to_remove : <TAB> <TAB> self . consumers . remove ( item ) <TAB> self . consumers . extend ( to_add )",if consumer is not None :,if consumer == sys . stdout :,False,95.4,71.19,,,
"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB> <TAB> self . context . log . info ( <TAB> <TAB> <TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB> <TAB> ) <TAB> <TAB> subject = self . derived_by_original . get ( <TAB> <TAB> <TAB> exported_python_target , exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB> <TAB> created [ exported_python_target ] = setup_dir <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for dep in dependencies : <TAB> <TAB> <TAB> <TAB> if is_exported_python_target ( dep ) : <TAB> <TAB> <TAB> <TAB> <TAB> create ( dep )",if dependencies :,if self . _recursive :,False,97.59,72.55,,,
"def __add__ ( self , other ) : <TAB> other = ArithmeticExpression . try_unpack_const ( other ) <TAB> if not self . symbolic and type ( other ) is int : <TAB> <TAB> return SpOffset ( self . _bits , self . _to_signed ( self . offset + other ) ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return SpOffset ( self . _bits , self . offset + other ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return SpOffset ( <TAB> <TAB> <TAB> <TAB> self . _bits , <TAB> <TAB> <TAB> <TAB> ArithmeticExpression ( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression . Add , <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . offset , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other , <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> )",if self . symbolic :,if self . symbolic :,True,100.0,74.58,,,
"def __add__ ( self , other ) : <TAB> other = ArithmeticExpression . try_unpack_const ( other ) <TAB> if not self . symbolic and type ( other ) is int : <TAB> <TAB> return SpOffset ( self . _bits , self . _to_signed ( self . offset + other ) ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return SpOffset ( self . _bits , self . offset + other ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return SpOffset ( <TAB> <TAB> <TAB> <TAB> self . _bits , <TAB> <TAB> <TAB> <TAB> ArithmeticExpression ( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression . Add , <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . offset , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other , <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> )",if self . symbolic :,"if e . args [ 0 ] == ""no such module: VirtualSpatialIndex"" :",False,94.32,62.47,,,
"def _get_github_client ( self ) - > "" Github "" : <TAB> from github import Github <TAB> if self . access_token_secret is not None : <TAB> <TAB> # If access token secret specified, load it <TAB> <TAB> access_token = Secret(self.access_token_secret).get() <TAB> else: <TAB> <TAB> # Otherwise, fallback to loading from local secret or environment variable <TAB> <TAB> access_token = prefect.context.get(""secrets"", {}).get(""GITHUB_ACCESS_TOKEN"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> access_token = os.getenv(""GITHUB_ACCESS_TOKEN"") <TAB> return Github(access_token)",if access_token is None :,if access_token is None :,True,100.0,74.23,,,
"def make_tab ( lists ) : <TAB> if hasattr ( lists , "" tolist "" ) : <TAB> <TAB> lists = lists . tolist ( ) <TAB> ut = [ ] <TAB> for rad in lists : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ut . append ( "" \t "" . join ( [ "" %s "" % x for x in rad ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ut . append ( "" %s "" % rad ) <TAB> return "" \n "" . join ( ut )","if isinstance ( rad , ( list , tuple ) ) :","if type ( rad ) in [ list , tuple ] :",False,93.54,69.91,,,
"def _ensure_ffi_initialized ( cls ) : <TAB> with cls . _init_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . lib = build_conditional_library ( lib , CONDITIONAL_NAMES ) <TAB> <TAB> <TAB> cls . _lib_loaded = True <TAB> <TAB> <TAB> # initialize the SSL library <TAB> <TAB> <TAB> cls.lib.SSL_library_init() <TAB> <TAB> <TAB> # adds all ciphers/digests for EVP <TAB> <TAB> <TAB> cls.lib.OpenSSL_add_all_algorithms() <TAB> <TAB> <TAB> # loads error strings for libcrypto and libssl functions <TAB> <TAB> <TAB> cls.lib.SSL_load_error_strings() <TAB> <TAB> <TAB> cls._register_osrandom_engine()",if cls . lib is None :,if not cls . _lib_loaded :,False,96.41,71.04,,,
def writer_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB> <TAB> self . active_writers - = 1 <TAB> <TAB> if self . waiting_writers != 0 : <TAB> <TAB> <TAB> self . active_writers + = 1 <TAB> <TAB> <TAB> self . waiting_writers - = 1 <TAB> <TAB> <TAB> self . can_write . release ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> t = self . waiting_readers <TAB> <TAB> <TAB> self . waiting_readers = 0 <TAB> <TAB> <TAB> self . active_readers + = t <TAB> <TAB> <TAB> while t > 0 : <TAB> <TAB> <TAB> <TAB> self . can_read . release ( ) <TAB> <TAB> <TAB> <TAB> t - = 1 <TAB> finally : <TAB> <TAB> self . mutex . release ( ),if self . waiting_readers != 0 :,elif self . waiting_readers != 0 :,False,98.94,73.43,,,
"def _spans ( self , operands ) : <TAB> spans = { } <TAB> k = 0 <TAB> j = 0 <TAB> for mode in ( self . FLOAT , self . MPMATH ) : <TAB> <TAB> for i , operand in enumerate ( operands [ k : ] ) : <TAB> <TAB> <TAB> if operand [ 0 ] > mode : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> j = i + k + 1 <TAB> <TAB> <IF-STMT> # only init state? then ignore. <TAB> <TAB> <TAB> j = 0 <TAB> <TAB> spans[mode] = slice(k, j) <TAB> <TAB> k = j <TAB> spans[self.SYMBOLIC] = slice(k, len(operands)) <TAB> return spans",if j >= len ( operands ) :,if k == 0 and j == 1 :,False,94.88,70.91,,,
"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> status = location.Status(response.status_code, response.text) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = location.Status(response.status_code) <TAB> else: <TAB> <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <TAB> <TAB> if completion_routine: <TAB> <TAB> <TAB> return completion_routine(status) <TAB> <TAB> raise IOError(response.text) <TAB> else: <TAB> <TAB> if completion_routine: <TAB> <TAB> <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",if response . ok :,if not response . ok :,False,98.89,72.99,,,
"def readinto ( self , buf ) : <TAB> if self . current_frame : <TAB> <TAB> n = self . current_frame . readinto ( buf ) <TAB> <TAB> if n == 0 and len ( buf ) != 0 : <TAB> <TAB> <TAB> self . current_frame = None <TAB> <TAB> <TAB> n = len ( buf ) <TAB> <TAB> <TAB> buf [ : ] = self . file_read ( n ) <TAB> <TAB> <TAB> return n <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB> <TAB> return n <TAB> else : <TAB> <TAB> n = len ( buf ) <TAB> <TAB> buf [ : ] = self . file_read ( n ) <TAB> <TAB> return n",if n == 0 and len ( buf ) == 0 :,if n < len ( buf ) :,False,95.26,72.31,,,
"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB> <TAB> value = mydict [ name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id ( mydict ) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited . add ( myid ) <TAB> <TAB> mydict = mydict . Parent <TAB> <TAB> if mydict is None : <TAB> <TAB> <TAB> return",if value is not None :,if value is not None :,True,100.0,74.38,,,
"def _handle_Mul ( self , expr ) : <TAB> arg0 , arg1 = expr . args <TAB> expr_0 = self . _expr ( arg0 ) <TAB> if expr_0 is None : <TAB> <TAB> return None <TAB> expr_1 = self . _expr ( arg1 ) <TAB> if expr_1 is None : <TAB> <TAB> return None <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # self.tyenv is not used <TAB> <TAB> <TAB> mask = (1 << expr.result_size(self.tyenv)) - 1 <TAB> <TAB> <TAB> return (expr_0 * expr_1) & mask <TAB> <TAB> else: <TAB> <TAB> <TAB> return expr_0 * expr_1 <TAB> except TypeError as e: <TAB> <TAB> self.l.warning(e) <TAB> <TAB> return None",if self . tyenv is not None :,"if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :",False,91.99,68.73,,,
"def end_request ( self , request_id ) : <TAB> """""" Removes the information associated with given request_id. """""" <TAB> with self . _lock : <TAB> <TAB> del self . _request_wsgi_environ [ request_id ] <TAB> <TAB> del self . _request_id_to_server_configuration [ request_id ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _request_id_to_instance [ request_id ]",if request_id in self . _request_id_to_instance :,if request_id in self . _request_id_to_instance :,True,100.0,99.01,,,
def generate ( ) : <TAB> <IF-STMT> <TAB> <TAB> decoder = zlib . decompressobj ( 16 + zlib . MAX_WBITS ) <TAB> while True : <TAB> <TAB> chunk = self . raw . read ( chunk_size ) <TAB> <TAB> if not chunk : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> chunk = decoder . decompress ( chunk ) <TAB> <TAB> yield chunk,if self . decompress :,if self . _gzipped :,False,93.8,75.27,,,
"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB> <TAB> name = venv . path . name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = str ( venv . path ) <TAB> <TAB> if venv == current_env : <TAB> <TAB> <TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> self . line ( name )","if name == ""name"" :","if self . option ( ""full-path"" ) :",False,94.55,71.04,,,
"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB> <TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB> <TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB> <TAB> for aggr in aggrs : <TAB> <TAB> <TAB> for c in cols : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators = [ ] <TAB> <TAB> <TAB> <TAB> if aggr and aggr not in c . aggregators : <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators + = [ aggr ]",if c not in sheet :,"if not hasattr ( c , ""aggregators"" ) :",False,94.64,64.53,,,
"def on_pre_output_coercion ( <TAB> directive_args : Dict [ str , Any ] , <TAB> next_directive : Callable , <TAB> value : Any , <TAB> ctx : Optional [ Any ] , <TAB> info : "" ResolveInfo "" , ) : <TAB> value = await next_directive ( value , ctx , info ) <TAB> if value is None : <TAB> <TAB> return value <TAB> try : <TAB> <TAB> py_enum = _ENUM_MAP [ directive_args [ "" name "" ] ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ None if item is None else py_enum ( item ) . name for item in value ] <TAB> <TAB> return py_enum ( value ) . name <TAB> except Exception : <TAB> <TAB> pass <TAB> return value","if isinstance ( value , ( list , tuple ) ) :","if isinstance ( value , list ) :",False,96.88,72.92,,,
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words : <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> <TAB> yield x,"if isinstance ( word , ( list , tuple ) ) :",if re_han . match ( blk ) :,False,95.68,46.44,,,
"def refresh_archive_action ( self ) : <TAB> archive_name = self . selected_archive_name ( ) <TAB> if archive_name is not None : <TAB> <TAB> params = BorgInfoArchiveThread . prepare ( self . profile ( ) , archive_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> thread = BorgInfoArchiveThread ( params [ "" cmd "" ] , params , parent = self . app ) <TAB> <TAB> <TAB> thread . updated . connect ( self . _set_status ) <TAB> <TAB> <TAB> thread . result . connect ( self . refresh_archive_result ) <TAB> <TAB> <TAB> self . _toggle_all_buttons ( False ) <TAB> <TAB> <TAB> thread . start ( )","if params [ ""cmd"" ] :","if params [ ""ok"" ] :",False,98.59,73.28,,,
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> if not name [ 0 ] . isupper ( ) : <TAB> <TAB> <TAB> <TAB> if not name . startswith ( "" wait_until "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods",if inspect . isclass ( member ) :,if is_resource_action ( member ) :,False,96.23,72.57,,,
"def _get_compressor ( compress_type , compresslevel = None ) : <TAB> if compress_type == ZIP_DEFLATED : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return zlib . compressobj ( compresslevel , zlib . DEFLATED , - 15 ) <TAB> <TAB> return zlib . compressobj ( zlib . Z_DEFAULT_COMPRESSION , zlib . DEFLATED , - 15 ) <TAB> elif compress_type == ZIP_BZIP2 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return bz2 . BZ2Compressor ( compresslevel ) <TAB> <TAB> return bz2 . BZ2Compressor ( ) <TAB> # compresslevel is ignored for ZIP_LZMA <TAB> elif compress_type == ZIP_LZMA: <TAB> <TAB> return LZMACompressor() <TAB> else: <TAB> <TAB> return None",if compresslevel is not None :,if compresslevel is not None :,True,100.0,74.48,,,
"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB> <TAB> line = plyfile.readline() <TAB> <TAB> if b""element"" in line: <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> num_points = int(line[2]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties","if b""type"" in line :","elif b""property"" in line :",False,97.55,96.35,,,
"def download_release_artifacts ( self , version ) : <TAB> try : <TAB> <TAB> os . mkdir ( self . artifacts_dir ) <TAB> except FileExistsError : <TAB> <TAB> pass <TAB> for job_name in self . build_ids : <TAB> <TAB> build_number = self . build_ids . get ( job_name ) <TAB> <TAB> build_status = self . _get_build_status ( job_name , build_number ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _download_job_artifact ( job_name , build_number , version ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Build for  {}  is not fininished "" . format ( job_name ) ) <TAB> <TAB> <TAB> print ( "" \t Run  ' build '  action to check status of  {} "" . format ( job_name ) )","if build_status == ""finished"" :","if build_status == ""built"" :",False,98.87,73.53,,,
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass","if not attrname . startswith ( ""_"" ) :","if attrname . startswith ( ""__"" ) :",False,98.66,73.12,,,
"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB> <TAB> name = heur [ "" name "" ] <TAB> <TAB> if name in excluded : <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur [ "" sql "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB> <TAB> <TAB> print ( sql ) <TAB> <TAB> <TAB> assert sql . find ( name ) != - 1 <TAB> <TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs )",if not sql :,if sql . lower ( ) . find ( name . lower ( ) ) == - 1 :,False,90.97,68.71,,,
def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield child . nodeValue <TAB> <TAB> if child . nodeType == child . ELEMENT_NODE : <TAB> <TAB> <TAB> for item in gettext ( child ) : <TAB> <TAB> <TAB> <TAB> yield item,if child . nodeType == child . TEXT_NODE :,if child . nodeType == child . TEXT_NODE :,True,100.0,74.0,,,
"def update ( self ) : <TAB> """""" Update properties over dbus. """""" <TAB> self . _check_dbus ( ) <TAB> _LOGGER . info ( "" Updating service information "" ) <TAB> self . _services . clear ( ) <TAB> try : <TAB> <TAB> systemd_units = await self . sys_dbus . systemd . list_units ( ) <TAB> <TAB> for service_data in systemd_units [ 0 ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _services . add ( ServiceInfo . read_from ( service_data ) ) <TAB> except ( HassioError , IndexError ) : <TAB> <TAB> _LOGGER . warning ( "" Can ' t update host service information! "" )","if service_data . startswith ( ""host"" ) :","if not service_data [ 0 ] . endswith ( "".service"" ) or service_data [ 2 ] != ""loaded"" :",False,87.77,62.3,,,
"def filtercomments ( source ) : <TAB> """""" NOT USED: strips trailing comments and put them at the top. """""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB> <TAB> elif re . search ( r "" ^ \ s* \ / \ / "" , source ) : <TAB> <TAB> <TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment : <TAB> <TAB> <TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB> <TAB> <TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source","if ""*"" in source :","if re . search ( r""^\s*\/\*"" , source ) :",False,92.83,72.06,,,
"def _getSourceStamp_sync ( self , ssid ) : <TAB> if ssid in self . sourcestamps : <TAB> <TAB> ssdict = self . sourcestamps [ ssid ] . copy ( ) <TAB> <TAB> ssdict [ "" ssid "" ] = ssid <TAB> <TAB> patchid = ssdict [ "" patchid "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ssdict . update ( self . patches [ patchid ] ) <TAB> <TAB> <TAB> ssdict [ "" patchid "" ] = patchid <TAB> <TAB> else : <TAB> <TAB> <TAB> ssdict [ "" patch_body "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_level "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_subdir "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_author "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_comment "" ] = None <TAB> <TAB> return ssdict <TAB> else : <TAB> <TAB> return None",if patchid in self . patches :,if patchid :,False,97.7,73.44,,,
"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB> <TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB> <TAB> if self . defaultValue is not self . __optionalNotMatched : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB> <TAB> <TAB> <TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tokens = [ self . defaultValue ] <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens = [ ] <TAB> return loc , tokens",if self . expr . resultsName :,if self . expr . resultsName :,True,100.0,74.53,,,
"def _find_exceptions ( ) : <TAB> for _name , obj in iteritems ( globals ( ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> is_http_exception = issubclass ( obj , HTTPException ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> is_http_exception = False <TAB> <TAB> if not is_http_exception or obj . code is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> __all__ . append ( obj . __name__ ) <TAB> <TAB> old_obj = default_exceptions . get ( obj . code , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> default_exceptions [ obj . code ] = obj",if old_obj is not None and obj . code != old_obj :,"if old_obj is not None and issubclass ( obj , old_obj ) :",False,96.1,71.44,,,
"def generator ( self , data ) : <TAB> for ( proc_as , key_buf_ptr ) in data : <TAB> <TAB> key_buf = proc_as . read ( key_buf_ptr , 24 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> key = "" "" . join ( "" %02X "" % ord ( k ) for k in key_buf ) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> str ( key ) , <TAB> <TAB> <TAB> ] , <TAB> <TAB> )",if not key_buf :,if not key_buf :,True,100.0,74.33,,,
"def calculateEnableMargins ( self ) : <TAB> self . cnc . resetEnableMargins ( ) <TAB> for block in self . blocks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> CNC . vars [ "" xmin "" ] = min ( CNC . vars [ "" xmin "" ] , block . xmin ) <TAB> <TAB> <TAB> CNC . vars [ "" ymin "" ] = min ( CNC . vars [ "" ymin "" ] , block . ymin ) <TAB> <TAB> <TAB> CNC . vars [ "" zmin "" ] = min ( CNC . vars [ "" zmin "" ] , block . zmin ) <TAB> <TAB> <TAB> CNC . vars [ "" xmax "" ] = max ( CNC . vars [ "" xmax "" ] , block . xmax ) <TAB> <TAB> <TAB> CNC . vars [ "" ymax "" ] = max ( CNC . vars [ "" ymax "" ] , block . ymax ) <TAB> <TAB> <TAB> CNC . vars [ "" zmax "" ] = max ( CNC . vars [ "" zmax "" ] , block . zmax )",if block . enable :,if block . enable :,True,100.0,74.65,,,
"def __init__ ( self , client , job_id , callback = None ) : <TAB> self . client = client <TAB> self . job_id = job_id <TAB> # If a job event has been received already then we must set an Event <TAB> # to wait for this job to finish. <TAB> # Otherwise we create a new stub for the job with the Event for when <TAB> # the job event arrives to use existing event. <TAB> with client._jobs_lock: <TAB> <TAB> job = client._jobs.get(job_id) <TAB> <TAB> self.event = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.event = job.get(""__ready"") <TAB> <TAB> if self.event is None: <TAB> <TAB> <TAB> self.event = job[""__ready""] = Event() <TAB> <TAB> job[""__callback""] = callback","if job . get ( ""__ready"" ) :",if job :,False,95.54,67.1,,,
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> if env . cache_static : <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> if path == paths [ - 1 ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )",if env . cache_static :,"if not os . path . exists ( fspath + "".spt"" ) :",False,94.41,65.71,,,
"def set_conf ( ) : <TAB> """""" Collapse all object_trail config into cherrypy.request.config. """""" <TAB> base = cherrypy . config . copy ( ) <TAB> # Note that we merge the config from each node <TAB> # even if that node was None. <TAB> for name, obj, conf, segleft in object_trail: <TAB> <TAB> base.update(conf) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> base[""tools.staticdir.section""] = ""/"" + ""/"".join( <TAB> <TAB> <TAB> <TAB> fullpath[0 : fullpath_len - segleft] <TAB> <TAB> <TAB> ) <TAB> return base",if segleft > 0 :,"if ""tools.staticdir.dir"" in conf :",False,93.98,96.44,,,
"def __init__ ( self ) : <TAB> self . setLayers ( None , None ) <TAB> self . interface = None <TAB> self . event_callbacks = { } <TAB> self . __stack = None <TAB> self . lock = threading . Lock ( ) <TAB> members = inspect . getmembers ( self , predicate = inspect . ismethod ) <TAB> for m in members : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fname = m [ 0 ] <TAB> <TAB> <TAB> fn = m [ 1 ] <TAB> <TAB> <TAB> self . event_callbacks [ fn . event_callback ] = getattr ( self , fname )","if m [ 0 ] == ""event"" :","if hasattr ( m [ 1 ] , ""event_callback"" ) :",False,92.35,70.32,,,
def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _tail_data + = data <TAB> <TAB> if len ( self . _tail_data ) == self . _base_number : <TAB> <TAB> <TAB> yield self . _tail_data <TAB> <TAB> <TAB> self . _tail_data = [ ],if len ( self . _tail_data ) < self . _max_length :,if len ( self . _tail_data ) < self . _base_number :,False,96.57,95.49,,,
"def replace_field_to_value ( layout , cb ) : <TAB> for i , lo in enumerate ( layout . fields ) : <TAB> <TAB> if isinstance ( lo , Field ) or issubclass ( lo . __class__ , Field ) : <TAB> <TAB> <TAB> layout . fields [ i ] = ShowField ( <TAB> <TAB> <TAB> <TAB> cb , * lo . fields , attrs = lo . attrs , wrapper_class = lo . wrapper_class <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance ( lo , basestring ) : <TAB> <TAB> <TAB> layout . fields [ i ] = ShowField ( cb , lo ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> replace_field_to_value ( lo , cb )","elif isinstance ( lo , Field ) :","elif hasattr ( lo , ""get_field_names"" ) :",False,94.28,64.11,,,
"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB> <TAB> <TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT : <TAB> <TAB> <TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB> <TAB> raise",if e . get_dbus_name ( ) == DBUS_NO_SUCH_SERVICE :,"if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) :",False,93.55,71.08,,,
"def results_iter ( self ) : <TAB> if self . connection . ops . oracle : <TAB> <TAB> from django . db . models . fields import DateTimeField <TAB> <TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB> <TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB> <TAB> for row in rows : <TAB> <TAB> <TAB> date = row [ offset ] <TAB> <TAB> <TAB> if self . connection . ops . oracle : <TAB> <TAB> <TAB> <TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp ( str ( date ) ) <TAB> <TAB> <TAB> yield date",if needs_string_cast :,elif needs_string_cast :,False,98.9,73.55,,,
"def handle_label ( self , path , * * options ) : <TAB> verbosity = int ( options . get ( "" verbosity "" , 1 ) ) <TAB> result = finders . find ( path , all = options [ "" all "" ] ) <TAB> path = smart_unicode ( path ) <TAB> if result : <TAB> <TAB> if not isinstance ( result , ( list , tuple ) ) : <TAB> <TAB> <TAB> result = [ result ] <TAB> <TAB> output = u "" \n "" . join ( <TAB> <TAB> <TAB> ( smart_unicode ( os . path . realpath ( path ) ) for path in result ) <TAB> <TAB> ) <TAB> <TAB> self . stdout . write ( smart_str ( u "" Found  ' %s '  here: \n %s \n "" % ( path , output ) ) ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . stderr . write ( smart_str ( "" No matching file found for  ' %s ' . \n "" % path ) )",if verbosity == 0 :,if verbosity >= 1 :,False,98.26,73.68,,,
"def name ( self ) : <TAB> """""" Get the enumeration name of this storage class. """""" <TAB> if self . _name_map is None : <TAB> <TAB> self . _name_map = { } <TAB> <TAB> for key , value in list ( StorageClass . __dict__ . items ( ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _name_map [ value ] = key <TAB> return self . _name_map [ self ]","if isinstance ( value , StorageClass ) :","if isinstance ( value , StorageClass ) :",True,100.0,99.24,,,
"def index ( self , value ) : <TAB> if self . _growing : <TAB> <TAB> if self . _start < = value < self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB> <TAB> <TAB> if r == self . _zero : <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB> <TAB> <TAB> if r == self . _zero : <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) )",if self . _start >= value < self . _stop :,if self . _start >= value > self . _stop :,False,98.78,73.66,,,
"def extract_cookie ( cookie_header , cookie_name ) : <TAB> inx = cookie_header . find ( cookie_name ) <TAB> if inx > = 0 : <TAB> <TAB> end_inx = cookie_header . find ( "" ; "" , inx ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = cookie_header [ inx : end_inx ] <TAB> <TAB> else : <TAB> <TAB> <TAB> value = cookie_header [ inx : ] <TAB> <TAB> return value <TAB> return "" """,if end_inx >= 0 :,if end_inx > 0 :,False,98.12,72.58,,,
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> if isinstance(elem, str): <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> elif isinstance(elem, int): <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size","elif isinstance ( elem , ( float , int ) ) :","elif isinstance ( elem , np . ndarray ) :",False,97.07,71.57,,,
"def createFields ( self ) : <TAB> size = self . size / 8 <TAB> if size > 2 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield UInt8 ( self , "" cs "" , "" 10ms units, values from 0 to 199 "" ) <TAB> <TAB> yield Bits ( self , "" 2sec "" , 5 , "" seconds/2 "" ) <TAB> <TAB> yield Bits ( self , "" min "" , 6 , "" minutes "" ) <TAB> <TAB> yield Bits ( self , "" hour "" , 5 , "" hours "" ) <TAB> yield Bits ( self , "" day "" , 5 , "" (1-31) "" ) <TAB> yield Bits ( self , "" month "" , 4 , "" (1-12) "" ) <TAB> yield Bits ( self , "" year "" , 7 , "" (0 = 1980, 127 = 2107) "" )",if size & 0x01 :,if size > 4 :,False,98.22,73.45,,,
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" incap_ses|visid_incap "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = re . search ( r "" Incapsula "" , headers . get ( "" X-CDN "" , "" "" ) , re . I ) is not None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",if retval :,if retval :,True,100.0,74.5,,,
"def _get_order_information ( self , node_id , timeout = 1200 , check_interval = 5 ) : <TAB> mask = { <TAB> <TAB> "" billingItem "" : "" "" , <TAB> <TAB> "" powerState "" : "" "" , <TAB> <TAB> "" operatingSystem "" : { "" passwords "" : "" "" } , <TAB> <TAB> "" provisionDate "" : "" "" , <TAB> } <TAB> for i in range ( 0 , timeout , check_interval ) : <TAB> <TAB> res = self . connection . request ( <TAB> <TAB> <TAB> "" SoftLayer_Virtual_Guest "" , "" getObject "" , id = node_id , object_mask = mask <TAB> <TAB> ) . object <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return res <TAB> <TAB> time . sleep ( check_interval ) <TAB> raise SoftLayerException ( "" Timeout on getting node details "" )","if res [ ""status"" ] == ""available"" :","if res . get ( ""provisionDate"" , None ) :",False,95.03,69.29,,,
"def _process_param_change ( self , msg ) : <TAB> msg = super ( Select , self ) . _process_param_change ( msg ) <TAB> labels , values = self . labels , self . values <TAB> if "" value "" in msg : <TAB> <TAB> msg [ "" value "" ] = [ <TAB> <TAB> <TAB> labels [ indexOf ( v , values ) ] for v in msg [ "" value "" ] if isIn ( v , values ) <TAB> <TAB> ] <TAB> if "" options "" in msg : <TAB> <TAB> msg [ "" options "" ] = labels <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . value = [ v for v in self . value if isIn ( v , values ) ] <TAB> return msg",if self . value :,"if any ( not isIn ( v , values ) for v in self . value ) :",False,91.54,68.86,,,
"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB> <TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB> <TAB> if not o . name : <TAB> <TAB> <TAB> continue <TAB> <TAB> if o . name . lower ( ) == name . lower ( ) : <TAB> <TAB> <TAB> return o <TAB> if check_symlinks : <TAB> <TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = m [ 0 ] <TAB> <TAB> return self . get_object_from_name ( name , False )",if m :,if m :,True,100.0,74.57,,,
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if v [ "" _class "" ] == "" User "" : <TAB> <TAB> <TAB> if v [ "" email "" ] == "" "" : <TAB> <TAB> <TAB> <TAB> v [ "" email "" ] = None <TAB> <TAB> <TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB> <TAB> <TAB> <TAB> v [ "" ip "" ] = None <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",True,100.0,74.41,,,
"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB> <TAB> for ent_id , ent_desc in _md . items ( ) : <TAB> <TAB> <TAB> if descriptor in ent_desc : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ent_id) <TAB> return res",if ent_id in res :,if ent_id in res :,True,100.0,74.3,,,
"def test_add_participant ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> share_history_time = datetime . utcnow ( ) <TAB> <TAB> <TAB> share_history_time = share_history_time . replace ( tzinfo = TZ_UTC ) <TAB> <TAB> <TAB> new_participant = ChatThreadParticipant ( <TAB> <TAB> <TAB> <TAB> user = self . new_user , <TAB> <TAB> <TAB> <TAB> display_name = "" name "" , <TAB> <TAB> <TAB> <TAB> share_history_time = share_history_time , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> await self . chat_thread_client . add_participant ( new_participant ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self . chat_client . delete_chat_thread ( self . thread_id )",if self . is_active :,if not self . is_playback ( ) :,False,97.28,71.73,,,
"def url ( regex , view , kwargs = None , name = None , prefix = "" "" ) : <TAB> if isinstance ( view , ( list , tuple ) ) : <TAB> <TAB> # For include(...) processing. <TAB> <TAB> urlconf_module, app_name, namespace = view <TAB> <TAB> return RegexURLResolver( <TAB> <TAB> <TAB> regex, urlconf_module, kwargs, app_name=app_name, namespace=namespace <TAB> <TAB> ) <TAB> else: <TAB> <TAB> if isinstance(view, basestring): <TAB> <TAB> <TAB> if not view: <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured( <TAB> <TAB> <TAB> <TAB> <TAB> ""Empty URL pattern view name not permitted (for pattern %r)"" % regex <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> view = prefix + ""."" + view <TAB> <TAB> return RegexURLPattern(regex, view, kwargs, name)",if prefix :,if prefix :,True,100.0,74.51,,,
"def tx ( ) : <TAB> # Sync receiver ready to avoid loss of first packets <TAB> while not sub_ready.ready(): <TAB> <TAB> pub.send(b""test BEGIN"") <TAB> <TAB> eventlet.sleep(0.005) <TAB> for i in range(1, 101): <TAB> <TAB> msg = ""test {0}"".format(i).encode() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pub.send(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> pub.send(b""test LAST"") <TAB> <TAB> <TAB> sub_last.wait() <TAB> <TAB> # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB> <TAB> # just yield eventlet.sleep(0) doesn't cut it <TAB> <TAB> eventlet.sleep(0.001) <TAB> pub.send(b""done DONE"")",if sub_ready . ready ( ) :,if i != 50 :,False,96.31,71.43,,,
"def remove_tmp_snapshot_file ( self , files ) : <TAB> for filepath in files : <TAB> <TAB> path = Path ( filepath ) <TAB> <TAB> if path . is_dir ( ) and path . exists ( ) : <TAB> <TAB> <TAB> shutil . rmtree ( path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path . unlink ( )",elif path . is_file ( ) and path . is_symlink ( ) :,elif path . is_file ( ) and path . exists ( ) :,False,95.72,72.29,,,
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> if count == 1 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> eol = view . line ( s . b ) . b <TAB> <TAB> <TAB> <TAB> return R ( s . b , eol ) <TAB> <TAB> <TAB> return s <TAB> return s",if s . b != eol :,if view . line ( s . b ) . size ( ) > 0 :,False,87.91,65.4,,,
"def get_ids ( self , * * kwargs ) : <TAB> id = [ ] <TAB> if "" id "" in kwargs : <TAB> <TAB> id = kwargs [ "" id "" ] <TAB> <TAB> # Coerce ids to list <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> id = id.split("","") <TAB> <TAB> # Ensure ids are integers <TAB> <TAB> try: <TAB> <TAB> <TAB> id = list(map(int, id)) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> decorators.error(""Invalid id"") <TAB> return id","if "","" in id :","if not isinstance ( id , list ) :",False,94.91,64.32,,,
"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return token.stripped_value <TAB> <TAB> if token.token_type == ""quoted-string"": <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> if token.token_type == ""bare-quoted-string"": <TAB> <TAB> <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token.stripped_value <TAB> return """"","if token . token_type == ""bare-quoted-string"" :","if token . token_type == ""value"" :",False,97.53,71.65,,,
"def get_all_start_methods ( self ) : <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> return [ "" spawn "" ] <TAB> else : <TAB> <TAB> methods = [ "" spawn "" , "" fork "" ] if sys . platform == "" darwin "" else [ "" fork "" , "" spawn "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> methods . append ( "" forkserver "" ) <TAB> <TAB> return methods",if self . server :,if reduction . HAVE_SEND_HANDLE :,False,92.88,71.58,,,
"def _process_watch ( self , watched_event ) : <TAB> logger . debug ( "" process_watch:  %r "" , watched_event ) <TAB> with handle_exception ( self . _tree . _error_listeners ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert self . _parent is None , "" unexpected CREATED on non-root "" <TAB> <TAB> <TAB> self . on_created ( ) <TAB> <TAB> elif watched_event . type == EventType . DELETED : <TAB> <TAB> <TAB> self . on_deleted ( ) <TAB> <TAB> elif watched_event . type == EventType . CHANGED : <TAB> <TAB> <TAB> self . _refresh_data ( ) <TAB> <TAB> elif watched_event . type == EventType . CHILD : <TAB> <TAB> <TAB> self . _refresh_children ( )",if watched_event . type == EventType . CREATED :,if watched_event . type == EventType . CREATED :,True,100.0,74.49,,,
"def assert_open ( self , sock , * rest ) : <TAB> if isinstance ( sock , fd_types ) : <TAB> <TAB> self . __assert_fd_open ( sock ) <TAB> else : <TAB> <TAB> fileno = sock . fileno ( ) <TAB> <TAB> assert isinstance ( fileno , fd_types ) , fileno <TAB> <TAB> sockname = sock . getsockname ( ) <TAB> <TAB> assert isinstance ( sockname , tuple ) , sockname <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __assert_fd_open ( fileno ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _assert_sock_open ( sock ) <TAB> if rest : <TAB> <TAB> self . assert_open ( rest [ 0 ] , * rest [ 1 : ] )",if fileno :,if not WIN :,False,98.2,72.89,,,
"def assert_open ( self , sock , * rest ) : <TAB> if isinstance ( sock , fd_types ) : <TAB> <TAB> self . __assert_fd_open ( sock ) <TAB> else : <TAB> <TAB> fileno = sock . fileno ( ) <TAB> <TAB> assert isinstance ( fileno , fd_types ) , fileno <TAB> <TAB> sockname = sock . getsockname ( ) <TAB> <TAB> assert isinstance ( sockname , tuple ) , sockname <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __assert_fd_open ( fileno ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _assert_sock_open ( sock ) <TAB> if rest : <TAB> <TAB> self . assert_open ( rest [ 0 ] , * rest [ 1 : ] )",if fileno :,if key in self . _targets,False,96.19,71.73,,,
"def gather_metrics ( dry_run = False ) : <TAB> today = datetime . date . today ( ) <TAB> first = today . replace ( day = 1 ) <TAB> last_month = first - datetime . timedelta ( days = 1 ) <TAB> filename = "" form_types_ {} .csv "" . format ( last_month . strftime ( "" % Y- % m "" ) ) <TAB> with connection . cursor ( ) as cursor : <TAB> <TAB> cursor . execute ( REGISTRATION_METRICS_SQL ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for row in cursor . fetchall ( ) : <TAB> <TAB> <TAB> <TAB> logger . info ( encode_row ( row ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> write_raw_data ( cursor = cursor , filename = filename )",if dry_run :,if dry_run :,True,100.0,74.51,,,
"def cat ( tensors , dim = 0 ) : <TAB> assert isinstance ( tensors , list ) , "" input to cat must be a list "" <TAB> if len ( tensors ) == 1 : <TAB> <TAB> return tensors [ 0 ] <TAB> from . autograd_cryptensor import AutogradCrypTensor <TAB> if any ( isinstance ( t , AutogradCrypTensor ) for t in tensors ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tensors [ 0 ] = AutogradCrypTensor ( tensors [ 0 ] , requires_grad = False ) <TAB> <TAB> return tensors [ 0 ] . cat ( * tensors [ 1 : ] , dim = dim ) <TAB> else : <TAB> <TAB> return get_default_backend ( ) . cat ( tensors , dim = dim )",if len ( tensors ) == 1 :,"if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :",False,94.07,70.7,,,
"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB> <TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB> if not installed: <TAB> <TAB> <TAB> status = self.legacy_get_dlc_status(dlc_title) <TAB> <TAB> <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> installed = True <TAB> return installed","if self . legacy_get_dlc_status ( ""version"" , """" ) == ""updatable"" :",if self . install_dir and os . path . exists ( self . install_dir ) :,False,90.43,64.07,,,
"def on_copy ( self ) : <TAB> source_objects = self . __getSelection ( ) <TAB> for source in source_objects : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_obj = model . Phrase ( "" "" , "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_obj = model . Script ( "" "" , "" "" ) <TAB> <TAB> new_obj . copy ( source ) <TAB> <TAB> self . cutCopiedItems . append ( new_obj )",if self . cutCopiedItems :,"if isinstance ( source , model . Phrase ) :",False,92.87,68.78,,,
"def FetchFn ( type_name ) : <TAB> """""" Fetches all hunt results of a given type. """""" <TAB> offset = 0 <TAB> while True : <TAB> <TAB> results = data_store . REL_DB . ReadHuntResults ( <TAB> <TAB> <TAB> hunt_id , offset = offset , count = self . _RESULTS_PAGE_SIZE , with_type = type_name <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> for r in results : <TAB> <TAB> <TAB> msg = r . AsLegacyGrrMessage ( ) <TAB> <TAB> <TAB> msg . source_urn = source_urn <TAB> <TAB> <TAB> yield msg <TAB> <TAB> offset + = self . _RESULTS_PAGE_SIZE",if not results :,if not results :,True,100.0,99.4,,,
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_TINYBLOB :,if length <= self . LENGTH_LIMIT_TINYBLOB :,True,100.0,74.22,,,
"def decode ( cls , data ) : <TAB> while data : <TAB> <TAB> ( <TAB> <TAB> <TAB> length , <TAB> <TAB> <TAB> atype , <TAB> <TAB> ) = unpack ( cls . Header . PACK , data [ : cls . Header . LEN ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AttributesError ( "" Buffer underrun  %d  <  %d "" % ( len ( data ) , length ) ) <TAB> <TAB> payload = data [ cls . Header . LEN : length ] <TAB> <TAB> yield atype , payload <TAB> <TAB> data = data [ int ( ( length + 3 ) / 4 ) * 4 : ]",if length < cls . Header . LEN :,if len ( data ) < length :,False,95.15,71.35,,,
"def test_join_diffs ( db , series_of_diffs , expected ) : <TAB> diffs = [ ] <TAB> for changes in series_of_diffs : <TAB> <TAB> tracker = DBDiffTracker ( ) <TAB> <TAB> for key , val in changes . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del tracker [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tracker [ key ] = val <TAB> <TAB> diffs . append ( tracker . diff ( ) ) <TAB> DBDiff . join ( diffs ) . apply_to ( db ) <TAB> assert db == expected",if key in tracker :,if val is None :,False,97.24,71.88,,,
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == LEO :,elif col == UNSEEN :,False,99.16,73.99,,,
"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB> if not response.ok: <TAB> <TAB> <TAB> status = location.Status(response.status_code, response.text) <TAB> <TAB> else: <TAB> <TAB> <TAB> status = location.Status(response.status_code) <TAB> else: <TAB> <TAB> status = location.Status(500, message) <TAB> if response is None or not response.ok: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return completion_routine(status) <TAB> <TAB> raise IOError(response.text) <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> completion_routine(status) <TAB> return location.Status(200, response.content)",if completion_routine :,if completion_routine :,True,100.0,74.4,,,
"def _generate_examples ( self , src_path = None , tgt_path = None , replace_unk = None ) : <TAB> """""" Yields examples. """""" <TAB> with tf . io . gfile . GFile ( src_path ) as f_d , tf . io . gfile . GFile ( tgt_path ) as f_s : <TAB> <TAB> for i , ( doc_text , sum_text ) in enumerate ( zip ( f_d , f_s ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield i , { <TAB> <TAB> <TAB> <TAB> <TAB> _DOCUMENT : doc_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB> <TAB> <TAB> <TAB> <TAB> _SUMMARY : sum_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield i , { _DOCUMENT : doc_text . strip ( ) , _SUMMARY : sum_text . strip ( ) }",if replace_unk :,if replace_unk :,True,100.0,99.63,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text",if newline :,if newline :,True,100.0,74.68,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text",if newline :,"if url . startswith ( ""http:"" ) or url . startswith ( ""https:"" ) :",False,92.81,71.12,,,
"def SConsignFile ( self , name = "" .sconsign "" , dbm_module = None ) : <TAB> if name is not None : <TAB> <TAB> name = self . subst ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = os . path . join ( str ( self . fs . SConstruct_dir ) , name ) <TAB> if name : <TAB> <TAB> name = os . path . normpath ( name ) <TAB> <TAB> sconsign_dir = os . path . dirname ( name ) <TAB> <TAB> if sconsign_dir and not os . path . exists ( sconsign_dir ) : <TAB> <TAB> <TAB> self . Execute ( SCons . Defaults . Mkdir ( sconsign_dir ) ) <TAB> SCons . SConsign . File ( name , dbm_module )",if self . fs . SConstruct_dir :,if not os . path . isabs ( name ) :,False,94.71,70.85,,,
"def on_train_start ( self , trainer : Trainer , pl_module : LightningModule ) - > None : <TAB> super ( ) . on_train_start ( trainer , pl_module ) <TAB> submodule_dict = dict ( pl_module . named_modules ( ) ) <TAB> self . _hook_handles = [ ] <TAB> for name in self . _get_submodule_names ( pl_module ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> f "" { name }  is not a valid identifier for a submodule in  { pl_module . __class__ . __name__ } , "" <TAB> <TAB> <TAB> <TAB> ""  skipping this key. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> handle = self . _register_hook ( name , submodule_dict [ name ] ) <TAB> <TAB> self . _hook_handles . append ( handle )",if name not in submodule_dict :,if name not in submodule_dict :,True,100.0,74.55,,,
"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> super ( ) . validate_configuration ( configuration ) <TAB> if configuration is None : <TAB> <TAB> configuration = self . configuration <TAB> try : <TAB> <TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB> <TAB> ) , "" value_set must be a list or a set "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB> <TAB> <TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key. ' <TAB> except AssertionError as e : <TAB> <TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",True,100.0,74.63,,,
"def check_refcounts ( expected , timeout = 10 ) : <TAB> start = time . time ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> _check_refcounts ( expected ) <TAB> <TAB> <TAB> break <TAB> <TAB> except AssertionError as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 )",if time . time ( ) - start > timeout :,if time . time ( ) - start > timeout :,True,100.0,74.23,,,
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if prog . match ( line ) : <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None",if not line :,if not line :,True,100.0,74.65,,,
def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp . search ( line ) <TAB> <TAB> if r : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> f . close ( ) <TAB> <TAB> return False,if not line . strip ( ) :,"if line [ 0 ] == ""#"" :",False,92.01,51.19,,,
"def link_pantsrefs ( soups , precomputed ) : <TAB> """""" Transorm soups: <a pantsref= "" foo "" > becomes <a href= "" ../foo_page.html#foo "" > """""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB> <TAB> for a in soup . find_all ( "" a "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a [ "" pantsref "" ] <TAB> <TAB> <TAB> if pantsref not in precomputed . pantsref : <TAB> <TAB> <TAB> <TAB> raise TaskError ( <TAB> <TAB> <TAB> <TAB> <TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] )","if a [ ""type"" ] != ""pantsmark"" :","if not a . has_attr ( ""pantsref"" ) :",False,95.19,84.63,,,
"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB> <TAB> self . querylist = [ ] <TAB> else : <TAB> <TAB> self . querylist = querylist <TAB> <TAB> for query in self . querylist : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . query_id = query . query_id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if self . query_id != query . query_id : <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" query in list must be same query_id "" )",if self . query_id == - 1 :,if self . query_id == - 1 :,True,100.0,74.44,,,
"def _draw_number ( <TAB> screen , x_offset , y_offset , number , token = Token . Clock , transparent = False ) : <TAB> "" Write number at position. "" <TAB> fg = Char ( "" "" , token ) <TAB> bg = Char ( "" "" , Token ) <TAB> for y , row in enumerate ( _numbers [ number ] ) : <TAB> <TAB> screen_row = screen . data_buffer [ y + y_offset ] <TAB> <TAB> for x , n in enumerate ( row ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> screen_row [ x + x_offset ] = fg <TAB> <TAB> <TAB> elif not transparent : <TAB> <TAB> <TAB> <TAB> screen_row [ x + x_offset ] = bg",if n == token :,"if n == ""#"" :",False,97.72,68.52,,,
"def init ( self ) : <TAB> self . sock . setblocking ( True ) <TAB> if self . parser is None : <TAB> <TAB> # wrap the socket if needed <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.sock = ssl.wrap_socket( <TAB> <TAB> <TAB> <TAB> self.sock, server_side=True, **self.cfg.ssl_options <TAB> <TAB> <TAB> ) <TAB> <TAB> # initialize the parser <TAB> <TAB> self.parser = http.RequestParser(self.cfg, self.sock)",if self . cfg . ssl_options :,if self . cfg . is_ssl :,False,97.21,72.29,,,
"def intersect_face ( pt ) : <TAB> # todo: rewrite! inefficient! <TAB> nonlocal vis_faces2D <TAB> for f, vs in vis_faces2D: <TAB> <TAB> v0 = vs[0] <TAB> <TAB> for v1, v2 in iter_pairs(vs[1:], False): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return f <TAB> return None",if v0 == v1 and pt == v2 :,"if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) :",False,85.81,64.8,,,
"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB> <TAB> if not self . futuresAllowed : <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation )",if alias . importStarred :,"if alias . name == ""*"" :",False,96.87,67.52,,,
"def PyObject_Bytes ( obj ) : <TAB> if type ( obj ) == bytes : <TAB> <TAB> return obj <TAB> if hasattr ( obj , "" __bytes__ "" ) : <TAB> <TAB> res = obj . __bytes__ ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" __bytes__ returned non-bytes (type  %s ) "" % type ( res ) . __name__ <TAB> <TAB> <TAB> ) <TAB> return PyBytes_FromObject ( obj )","if not isinstance ( res , bytes ) :","if not isinstance ( res , bytes ) :",True,100.0,74.27,,,
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . current_provider . on_file ( query )",elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :,True,100.0,74.49,,,
"def remove ( self , name ) : <TAB> for s in [ self . __storage ( self . __category ) , self . __storage ( None ) ] : <TAB> <TAB> for i , b in enumerate ( s ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del s [ i ] <TAB> <TAB> <TAB> <TAB> if b . persistent : <TAB> <TAB> <TAB> <TAB> <TAB> self . __save ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> raise KeyError ( name )",if b . name == name :,if b . name == name :,True,100.0,74.33,,,
"def _wrapper ( data , axis = None , keepdims = False ) : <TAB> if not keepdims : <TAB> <TAB> return func ( data , axis = axis ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> axis = axis if isinstance ( axis , int ) else axis [ 0 ] <TAB> <TAB> <TAB> out_shape = list ( data . shape ) <TAB> <TAB> <TAB> out_shape [ axis ] = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> out_shape = [ 1 for _ in range ( len ( data . shape ) ) ] <TAB> <TAB> return func ( data , axis = axis ) . reshape ( out_shape )",if axis is not None :,if axis is not None :,True,100.0,74.5,,,
"def authn_info ( self ) : <TAB> res = [ ] <TAB> for astat in self . assertion . authn_statement : <TAB> <TAB> context = astat . authn_context <TAB> <TAB> try : <TAB> <TAB> <TAB> authn_instant = astat . authn_instant <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> authn_instant = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> aclass = context . authn_context_class_ref . text <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> aclass = "" "" <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> authn_auth = [ a . text for a in context . authenticating_authority ] <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> authn_auth = [ ] <TAB> <TAB> <TAB> res . append ( ( aclass , authn_auth , authn_instant ) ) <TAB> return res",if context . authn_context_class_ref :,if context :,False,96.5,73.68,,,
"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB> <TAB> if self . posts : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> if self . stories : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path )",if self . include_location :,if self . latest :,False,96.54,73.04,,,
"def update_record_image_detail ( input_image_record , updated_image_detail , session = None ) : <TAB> if not session : <TAB> <TAB> session = db . Session <TAB> image_record = { } <TAB> image_record . update ( input_image_record ) <TAB> image_record . pop ( "" created_at "" , None ) <TAB> image_record . pop ( "" last_updated "" , None ) <TAB> if image_record [ "" image_type "" ] == "" docker "" : <TAB> <TAB> for tag_record in updated_image_detail : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> image_record [ "" image_detail "" ] . append ( tag_record ) <TAB> <TAB> <TAB> <TAB> return update_record ( image_record , session = session ) <TAB> return image_record","if tag_record [ ""image_type"" ] == ""image"" :","if tag_record not in image_record [ ""image_detail"" ] :",False,96.09,67.42,,,
"def backup ( self ) : <TAB> for ds in [ ( "" activedirectory "" , "" AD "" ) , ( "" ldap "" , "" LDAP "" ) , ( "" nis "" , "" NIS "" ) ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ds_cache = self . middleware . call_sync ( "" cache.get "" , f "" { ds [ 1 ] } _cache "" ) <TAB> <TAB> <TAB> <TAB> with open ( f "" /var/db/system/. { ds [ 1 ] } _cache_backup "" , "" wb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> pickle . dump ( ds_cache , f ) <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> self . logger . debug ( "" No cache exists for directory service [ %s ]. "" , ds [ 0 ] )","if ds [ 0 ] . endswith ( "".cache"" ) :","if ( self . middleware . call_sync ( f""{ds[0]}.config"" ) ) [ ""enable"" ] :",False,90.07,68.3,,,
"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB> <TAB> contents = self.setup_cfg.read_text() <TAB> <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB> <TAB> try: <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> if six.PY2: <TAB> <TAB> <TAB> <TAB> contents = self.setup_cfg.read_bytes() <TAB> <TAB> <TAB> parsed = parse_setup_cfg(contents, base_dir) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return {} <TAB> <TAB> return parsed <TAB> return {}",if parsed is None :,if not parsed :,False,98.24,71.79,,,
"def parts ( ) : <TAB> for l in lists . leaves : <TAB> <TAB> head_name = l . get_head_name ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield l . leaves <TAB> <TAB> elif head_name != "" System`Missing "" : <TAB> <TAB> <TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l )","if head_name == ""System`List"" :","if head_name == ""System`List"" :",True,100.0,74.0,,,
"def _get_callback_and_order ( self , hook ) : <TAB> if callable ( hook ) : <TAB> <TAB> return hook , None <TAB> elif isinstance ( hook , tuple ) and len ( hook ) == 2 : <TAB> <TAB> callback , order = hook <TAB> <TAB> # test that callback is a callable <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError(""Hook callback is not a callable"") <TAB> <TAB> # test that number is an int <TAB> <TAB> try: <TAB> <TAB> <TAB> int(order) <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> raise ValueError(""Hook order is not a number"") <TAB> <TAB> return callback, order <TAB> else: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Invalid hook definition, neither a callable nor a 2-tuple (callback, order): {!r}"".format( <TAB> <TAB> <TAB> <TAB> hook <TAB> <TAB> <TAB> ) <TAB> <TAB> )",if not callable ( callback ) :,if not callable ( callback ) :,True,100.0,74.57,,,
"def _resize_masks ( self , results ) : <TAB> """""" Resize masks with ``results[ ' scale ' ]`` """""" <TAB> for key in results . get ( "" mask_fields "" , [ ] ) : <TAB> <TAB> if results [ key ] is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results [ key ] = results [ key ] . rescale ( results [ "" scale "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> results [ key ] = results [ key ] . resize ( results [ "" img_shape "" ] [ : 2 ] )",if results [ key ] . scale is not None :,if self . keep_ratio :,False,93.68,93.56,,,
"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> if not c . isVisible ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nPoints = c . getNPoints ( ) <TAB> <TAB> <TAB> for j in range ( nPoints ) : <TAB> <TAB> <TAB> <TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB> <TAB> return Double . NaN <TAB> return result",if self . chart . isVisible ( ) :,if c . getYAxis ( ) == Y_AXIS :,False,94.38,71.64,,,
"def _check_token ( self ) : <TAB> if settings . app . sso_client_cache and self . server_auth_token : <TAB> <TAB> doc = self . sso_client_cache_collection . find_one ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" user_id "" : self . user . id , <TAB> <TAB> <TAB> <TAB> "" server_id "" : self . server . id , <TAB> <TAB> <TAB> <TAB> "" device_id "" : self . device_id , <TAB> <TAB> <TAB> <TAB> "" device_name "" : self . device_name , <TAB> <TAB> <TAB> <TAB> "" auth_token "" : self . server_auth_token , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . has_token = True",if doc :,if doc :,True,100.0,74.43,,,
"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [] <TAB> properties = [] <TAB> num_points = None <TAB> while b""end_header"" not in line and line != b"""": <TAB> <TAB> line = plyfile.readline() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> num_points = int(line[2]) <TAB> <TAB> elif b""property"" in line: <TAB> <TAB> <TAB> line = line.split() <TAB> <TAB> <TAB> properties.append((line[2].decode(), ext + ply_dtypes[line[1]])) <TAB> return num_points, properties","if b""num_points"" in line :","if b""element"" in line :",False,97.7,97.15,,,
"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB> <TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB> <TAB> for finfo in self . data : <TAB> <TAB> <TAB> self . __update_editor_margins ( finfo . editor ) <TAB> <TAB> <TAB> finfo . cleanup_analysis_results ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if current_finfo is not finfo : <TAB> <TAB> <TAB> <TAB> <TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 )",if self . __test_mode_changed ( finfo ) :,if ( run_pyflakes or run_pep8 ) and current_finfo is not None :,False,91.05,67.71,,,
"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB> <TAB> line = line and line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line . split ( ) <TAB> <TAB> for module in line_modules : <TAB> <TAB> <TAB> if module . endswith ( self . default_indicator ) : <TAB> <TAB> <TAB> <TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB> <TAB> <TAB> module_parts = module . split ( "" / "" ) <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len ( module_parts ) == 2 : <TAB> <TAB> <TAB> <TAB> module_version = module_parts [ 1 ] <TAB> <TAB> <TAB> module_name = module_parts [ 0 ] <TAB> <TAB> <TAB> yield module_name , module_version",if not line :,"if not line or line . startswith ( ""-"" ) :",False,96.25,66.21,,,
"def _set_trailing_size ( self , size ) : <TAB> if self . is_free ( ) : <TAB> <TAB> next_chunk = self . next_chunk ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . state . memory . store ( next_chunk . base , size , self . state . arch . bytes )",if next_chunk . base != self . state . memory . get_base ( ) :,if next_chunk is not None :,False,83.39,66.1,,,
"def _execute_for_all_tables ( self , app , bind , operation , skip_tables = False ) : <TAB> app = self . get_app ( app ) <TAB> if bind == "" __all__ "" : <TAB> <TAB> binds = [ None ] + list ( app . config . get ( "" SQLALCHEMY_BINDS "" ) or ( ) ) <TAB> elif isinstance ( bind , string_types ) or bind is None : <TAB> <TAB> binds = [ bind ] <TAB> else : <TAB> <TAB> binds = bind <TAB> for bind in binds : <TAB> <TAB> extra = { } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tables = self . get_tables_for_bind ( bind ) <TAB> <TAB> <TAB> extra [ "" tables "" ] = tables <TAB> <TAB> op = getattr ( self . Model . metadata , operation ) <TAB> <TAB> op ( bind = self . get_engine ( app , bind ) , * * extra )",if skip_tables :,if not skip_tables :,False,98.94,73.7,,,
"def getFileName ( ) : <TAB> extension = "" .json "" <TAB> file = "" %s -stats "" % self . clusterName <TAB> counter = 0 <TAB> while True : <TAB> <TAB> suffix = str ( counter ) . zfill ( 3 ) + extension <TAB> <TAB> fullName = os . path . join ( self . statsPath , file + suffix ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return fullName <TAB> <TAB> counter + = 1",if not os . path . exists ( fullName ) :,if not os . path . exists ( fullName ) :,True,100.0,74.27,,,
def logic ( ) : <TAB> # direction <TAB> if goRight == ACTIVE: <TAB> <TAB> dir.next = DirType.RIGHT <TAB> <TAB> run.next = True <TAB> elif goLeft == ACTIVE: <TAB> <TAB> dir.next = DirType.LEFT <TAB> <TAB> run.next = True <TAB> # stop <TAB> if stop == ACTIVE: <TAB> <TAB> run.next = False <TAB> # counter action <TAB> if run: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> q.next[4:1] = q[3:] <TAB> <TAB> <TAB> q.next[0] = not q[3] <TAB> <TAB> else: <TAB> <TAB> <TAB> q.next[3:] = q[4:1] <TAB> <TAB> <TAB> q.next[3] = not q[0],if q . next [ 0 ] == q [ 3 ] :,if dir == DirType . LEFT :,False,94.49,69.9,,,
"def test_broadcast ( self ) : <TAB> """""" Test example broadcast functionality. """""" <TAB> self . create_lang_connection ( "" 1000000000 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000001 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000002 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000003 "" , "" es "" ) <TAB> self . create_lang_connection ( "" 1000000004 "" , "" es "" ) <TAB> app . lang_broadcast ( ) <TAB> self . assertEqual ( 2 , len ( self . outbound ) ) <TAB> for message in self . outbound : <TAB> <TAB> if message . text == "" hello "" : <TAB> <TAB> <TAB> self . assertEqual ( 3 , len ( message . connections ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( 2 , len ( message . connections ) )","elif message . text == ""hello2"" :","elif message . text == ""hola"" :",False,98.9,73.79,,,
"def get_ovf_env ( dirname ) : <TAB> env_names = ( "" ovf-env.xml "" , "" ovf_env.xml "" , "" OVF_ENV.XML "" , "" OVF-ENV.XML "" ) <TAB> for fname in env_names : <TAB> <TAB> full_fn = os . path . join ( dirname , fname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> contents = util . load_file ( full_fn ) <TAB> <TAB> <TAB> <TAB> return ( fname , contents ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> util . logexc ( LOG , "" Failed loading ovf file  %s "" , full_fn ) <TAB> return ( None , False )",if os . path . isfile ( full_fn ) :,if os . path . isfile ( full_fn ) :,True,100.0,74.47,,,
"def _calc_offsets_children ( self , offset , is_last ) : <TAB> if self . elems : <TAB> <TAB> elem_last = self . elems [ - 1 ] <TAB> <TAB> for elem in self . elems : <TAB> <TAB> <TAB> offset = elem . _calc_offsets ( offset , ( elem is elem_last ) ) <TAB> <TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> elif not self . props or self . id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> return offset",if is_last :,if not is_last :,False,98.39,72.72,,,
"def publish_state ( cls , payload , state ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if state == action_constants . LIVEACTION_STATUS_REQUESTED : <TAB> <TAB> <TAB> <TAB> cls . process ( payload ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> print ( payload )",if state :,"if isinstance ( payload , LiveActionDB ) :",False,94.39,69.52,,,
"def log_predictive_density ( self , x_test , y_test , Y_metadata = None ) : <TAB> if isinstance ( x_test , list ) : <TAB> <TAB> x_test , y_test , ind = util . multioutput . build_XY ( x_test , y_test ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> Y_metadata = { "" output_index "" : ind , "" trials "" : np . ones ( ind . shape ) } <TAB> return super ( MultioutputGP , self ) . log_predictive_density ( x_test , y_test , Y_metadata )",if Y_metadata is None :,if Y_metadata is None :,True,100.0,74.3,,,
"def minimalBases ( classes ) : <TAB> """""" Reduce a list of base classes to its ordered minimum equivalent """""" <TAB> if not __python3 : # pragma: no cover <TAB> <TAB> classes = [c for c in classes if c is not ClassType] <TAB> candidates = [] <TAB> for m in classes: <TAB> <TAB> for n in classes: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB> if m in candidates: <TAB> <TAB> <TAB> <TAB> candidates.remove(m) # ensure that we're later in the list <TAB> <TAB> <TAB> candidates.append(m) <TAB> return candidates",if n is not ClassType :,"if issubclass ( n , m ) and m is not n :",False,94.3,69.68,,,
"def apply ( self , operations , rotations = None , * * kwargs ) : <TAB> rotations = rotations or [ ] <TAB> # apply the circuit operations <TAB> for i, operation in enumerate(operations): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise DeviceError( <TAB> <TAB> <TAB> <TAB> ""Operation {} cannot be used after other Operations have already been applied "" <TAB> <TAB> <TAB> <TAB> ""on a {} device."".format(operation.name, self.short_name) <TAB> <TAB> <TAB> ) <TAB> for operation in operations: <TAB> <TAB> self._apply_operation(operation) <TAB> # store the pre-rotated state <TAB> self._pre_rotated_state = self._state <TAB> # apply the circuit rotations <TAB> for operation in rotations: <TAB> <TAB> self._apply_operation(operation)",if i % 2 == 0 :,"if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) :",False,93.66,68.51,,,
"def __str__ ( self ) : <TAB> txt = str ( self . _called ) <TAB> if self . call_gas or self . call_value : <TAB> <TAB> gas = f "" gas:  { self . call_gas } "" if self . call_gas else "" "" <TAB> <TAB> value = f "" value:  { self . call_value } "" if self . call_value else "" "" <TAB> <TAB> salt = f "" salt:  { self . call_salt } "" if self . call_salt else "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> options = [ gas , value , salt ] <TAB> <TAB> <TAB> txt + = "" { "" + "" , "" . join ( [ o for o in options if o != "" "" ] ) + "" } "" <TAB> return txt + "" ( "" + "" , "" . join ( [ str ( a ) for a in self . _arguments ] ) + "" ) """,if self . call_salt :,if gas or value or salt :,False,97.59,72.57,,,
"def pop ( self ) : <TAB> """""" Pop a nonterminal. (Internal) """""" <TAB> popdfa , popstate , popnode = self . stack . pop ( ) <TAB> newnode = self . convert ( self . grammar , popnode ) <TAB> if newnode is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dfa , state , node = self . stack [ - 1 ] <TAB> <TAB> <TAB> node . children . append ( newnode ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rootnode = newnode","if popstate == ""terminal"" :",if self . stack :,False,94.45,77.96,,,
"def pollpacket ( self , wait ) : <TAB> self . _stage0 ( ) <TAB> if len ( self . buffer ) < self . bufneed : <TAB> <TAB> r , w , x = select . select ( [ self . sock . fileno ( ) ] , [ ] , [ ] , wait ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> try : <TAB> <TAB> <TAB> s = self . sock . recv ( BUFSIZE ) <TAB> <TAB> except socket . error : <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> if len ( s ) == 0 : <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> self . buffer + = s <TAB> <TAB> self . _stage0 ( ) <TAB> return self . _stage1 ( )",if r == - 1 :,if len ( r ) == 0 :,False,96.23,72.04,,,
"def increaseToolReach ( self ) : <TAB> if self . draggingFace is not None : <TAB> <TAB> d = ( 1 , - 1 ) [ self . draggingFace & 1 ] <TAB> <TAB> <IF-STMT> # xxxxx y <TAB> <TAB> <TAB> d = -d <TAB> <TAB> self.draggingY += d <TAB> <TAB> x, y, z = self.editor.mainViewport.cameraPosition <TAB> <TAB> pos = [x, y, z] <TAB> <TAB> pos[self.draggingFace >> 1] += d <TAB> <TAB> self.editor.mainViewport.cameraPosition = tuple(pos) <TAB> else: <TAB> <TAB> self.cloneCameraDistance = self.editor._incrementReach(self.cloneCameraDistance) <TAB> return True",if self . draggingY < 0 :,if self . draggingFace >> 1 != 1 :,False,95.3,70.88,,,
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> if box == self . level . bounds : <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB> <TAB> <TAB> remove = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if remove :,if remove and not add :,False,97.61,72.48,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ProjectForm , self ) . __init__ ( * args , * * kwargs ) <TAB> if self . instance . id : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . fields [ "" localfiletype "" ] . widget . attrs [ "" disabled "" ] = True <TAB> <TAB> <TAB> self . fields [ "" localfiletype "" ] . required = False <TAB> <TAB> if ( <TAB> <TAB> <TAB> self . instance . treestyle != "" auto "" <TAB> <TAB> <TAB> and self . instance . translationproject_set . count ( ) <TAB> <TAB> <TAB> and self . instance . treestyle == self . instance . _detect_treestyle ( ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . fields [ "" treestyle "" ] . widget . attrs [ "" disabled "" ] = True <TAB> <TAB> <TAB> self . fields [ "" treestyle "" ] . required = False","if self . instance . localfiletype != ""auto"" :",if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) :,False,91.99,66.78,,,
"def _infer_return_type ( * args ) : <TAB> """""" Look at the type of all args and divine their implied return type. """""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if return_type is None :,if return_type is str :,False,98.99,91.48,,,
"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB> <TAB> inst . add ( gadget . _gadget ) <TAB> <TAB> if len ( inst ) > count : <TAB> <TAB> <TAB> count = len ( inst ) <TAB> <TAB> <TAB> toReturn . append ( gadget ) <TAB> <TAB> <TAB> added = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB> <TAB> <TAB> added = False <TAB> return toReturn",if callback :,if callback :,True,100.0,74.5,,,
"def send_all ( self , data : bytes ) : <TAB> with self . _conflict_detector : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise _core . ClosedResourceError ( "" this pipe is already closed "" ) <TAB> <TAB> if not data : <TAB> <TAB> <TAB> await _core . checkpoint ( ) <TAB> <TAB> <TAB> return <TAB> <TAB> try : <TAB> <TAB> <TAB> written = await _core . write_overlapped ( self . _handle_holder . handle , data ) <TAB> <TAB> except BrokenPipeError as ex : <TAB> <TAB> <TAB> raise _core . BrokenResourceError from ex <TAB> <TAB> # By my reading of MSDN, this assert is guaranteed to pass so long <TAB> <TAB> # as the pipe isn't in nonblocking mode, but... let's just <TAB> <TAB> # double-check. <TAB> <TAB> assert written == len(data)",if self . _closed :,if self . _handle_holder . closed :,False,97.56,72.97,,,
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> elif isinstance ( value , float ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value",if self . sv_get ( ) :,if self . use_prop or self . get_prop_name ( ) :,False,94.33,71.61,,,
"def collect_active_inst_idx_list ( inst_beams , word_prob , inst_idx_to_position_map ) : <TAB> active_inst_idx_list = [ ] <TAB> for inst_idx , inst_position in inst_idx_to_position_map . items ( ) : <TAB> <TAB> is_inst_complete = inst_beams [ inst_idx ] . advance ( word_prob [ inst_position ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> active_inst_idx_list + = [ inst_idx ] <TAB> return active_inst_idx_list",if is_inst_complete :,if not is_inst_complete :,False,98.3,71.64,,,
"def compare_member_req_resp_without_key ( self , request , response ) : <TAB> for user_response in resp_json ( response ) [ "" data "" ] : <TAB> <TAB> for user_request in request : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> assert user_request [ "" role "" ] == user_response [ "" role "" ]","if ""role"" in user_request and ""role"" in user_response :","if user_request [ ""user_id"" ] == user_response [ ""user_id"" ] :",False,82.87,66.2,,,
"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB> <TAB> if name . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . module_names . add ( name [ : - 3 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . module_names . add ( name )","elif not name . startswith ( ""_"" ) :","elif ""."" not in name :",False,91.71,69.64,,,
"def _read_filter ( self , data ) : <TAB> if data : <TAB> <TAB> if self . expected_inner_sha256 : <TAB> <TAB> <TAB> self . inner_sha . update ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . inner_md5 . update ( data ) <TAB> return data",if self . expected_inner_md5 :,if self . expected_inner_md5sum :,False,97.15,71.31,,,
"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB> <TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if s . consume_re ( _newline_esc_re ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB> <TAB> <TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> s . expect_re ( _escapes_re ) <TAB> <TAB> <TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res )",if s . last ( ) . group ( 1 ) == _eol_esc_re :,"if not s . consume ( ""\\"" ) :",False,92.85,62.24,,,
"def process_response ( self , request , response ) : <TAB> if ( <TAB> <TAB> response . status_code == 404 <TAB> <TAB> and request . path_info . endswith ( "" / "" ) <TAB> <TAB> and not is_valid_path ( request . path_info ) <TAB> <TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request.path[:-1] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with safe_query_string(request): <TAB> <TAB> <TAB> <TAB> newurl += ""?"" + request.META.get(""QUERY_STRING"", """") <TAB> <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> else: <TAB> <TAB> return response","if request . META . get ( ""QUERY_STRING"" , """" ) :",if request . GET :,False,93.81,59.9,,,
"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB> <TAB> del obj [ k ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> k = dumps ( k ) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB> if Types.KEYS not in obj: <TAB> <TAB> <TAB> <TAB> obj[Types.KEYS] = [] <TAB> <TAB> <TAB> obj[Types.KEYS].append(k) <TAB> <TAB> obj[k] = convertObjects(v) <TAB> return obj","if isinstance ( k , dict ) :","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) :",False,91.99,67.35,,,
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> if self . error ( ) is None : <TAB> <TAB> <TAB> <TAB> if self . value ( ) is self : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False",if self . computed :,if self . is_computed ( ) :,False,97.86,73.39,,,
"def allocate_network ( ipv = "" ipv4 "" ) : <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try : <TAB> <TAB> cx = httplib . HTTPConnection ( "" localhost:7623 "" ) <TAB> <TAB> cx . request ( "" POST "" , "" /v1/network/ %s / "" % ipv , body = dtcd_uuid ) <TAB> <TAB> resp = cx . getresponse ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> network = netaddr . IPNetwork ( resp . read ( ) . decode ( "" utf-8 "" ) ) <TAB> <TAB> cx . close ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> if network is None : <TAB> <TAB> network = network_pool [ ipv ] . pop ( ) <TAB> <TAB> allocations [ network ] = True <TAB> return network",if resp . status == 200 :,if resp . status == 200 :,True,100.0,74.57,,,
"def allocate_network ( ipv = "" ipv4 "" ) : <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try : <TAB> <TAB> cx = httplib . HTTPConnection ( "" localhost:7623 "" ) <TAB> <TAB> cx . request ( "" POST "" , "" /v1/network/ %s / "" % ipv , body = dtcd_uuid ) <TAB> <TAB> resp = cx . getresponse ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> network = netaddr . IPNetwork ( resp . read ( ) . decode ( "" utf-8 "" ) ) <TAB> <TAB> cx . close ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> if network is None : <TAB> <TAB> network = network_pool [ ipv ] . pop ( ) <TAB> <TAB> allocations [ network ] = True <TAB> return network",if resp . status == 200 :,"if "":"" in line and len ( line ) > 0 :",False,93.83,66.63,,,
"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> print ( "" killing  %s "" % member ) <TAB> <TAB> <TAB> proc = hosts [ member ] [ "" proc "" ] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> if sys.platform in (""win32"", ""cygwin""): <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, sig) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> print(""%s already dead?"" % member)",if member not in hosts :,if ha_tools_debug :,False,94.65,71.01,,,
"def check ( self ) : <TAB> for path in self . paths : <TAB> <TAB> response = self . http_request ( <TAB> <TAB> <TAB> method = "" GET "" , <TAB> <TAB> <TAB> path = path , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if any ( <TAB> <TAB> <TAB> map ( <TAB> <TAB> <TAB> <TAB> lambda x : x in response . text , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.name "" , <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.sa.pass "" , <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.user.pass "" , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . valid = path <TAB> <TAB> <TAB> return True # target is vulnerable <TAB> return False # target not vulnerable",if response is None :,if response is None :,True,100.0,74.58,,,
"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB> <TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB> <TAB> if r . ok : <TAB> <TAB> <TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB> <TAB> <TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB> <TAB> <TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB> <TAB> <TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB> <TAB> <TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB> <TAB> <TAB> time . sleep ( 1 ) # spider rule <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> return result","if r . status_code == ""ok"" :",if not last_date :,False,96.0,69.89,,,
"def button_press_cb ( self , tdw , event ) : <TAB> self . _update_zone_and_cursors ( tdw , event . x , event . y ) <TAB> if self . _zone in ( _EditZone . CREATE_FRAME , _EditZone . REMOVE_FRAME ) : <TAB> <TAB> button = event . button <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _click_info = ( button , self . _zone ) <TAB> <TAB> <TAB> return False <TAB> return super ( FrameEditMode , self ) . button_press_cb ( tdw , event )",if button == _EditZone . BUTTON_BUTTON_CLICK :,if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,False,90.82,68.07,,,
"def first_timestep ( ) : <TAB> assignment = self . has_previous . assign ( <TAB> <TAB> value = tf_util . constant ( value = True , dtype = "" bool "" ) , read_value = False <TAB> ) <TAB> with tf . control_dependencies ( control_inputs = ( assignment , ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> current = x <TAB> <TAB> else : <TAB> <TAB> <TAB> current = tf . expand_dims ( input = x , axis = ( self . axis + 1 ) ) <TAB> <TAB> multiples = tuple ( <TAB> <TAB> <TAB> self . length if dims == self . axis + 1 else 1 <TAB> <TAB> <TAB> for dims in range ( self . output_spec ( ) . rank + 1 ) <TAB> <TAB> ) <TAB> <TAB> return tf . tile ( input = current , multiples = multiples )",if self . axis == 0 :,if self . concatenate :,False,97.52,73.43,,,
"def main ( ) - > None : <TAB> onefuzz = Onefuzz ( ) <TAB> jobs = onefuzz . jobs . list ( ) <TAB> for job in jobs : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" job: "" , <TAB> <TAB> <TAB> str ( job . job_id ) [ : 8 ] , <TAB> <TAB> <TAB> "" : "" . join ( [ job . config . project , job . config . name , job . config . build ] ) , <TAB> <TAB> ) <TAB> <TAB> for task in onefuzz . tasks . list ( job_id = job . job_id ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> ""  <TAB>  "" , <TAB> <TAB> <TAB> <TAB> str ( task . task_id ) [ : 8 ] , <TAB> <TAB> <TAB> <TAB> task . config . task . type , <TAB> <TAB> <TAB> <TAB> task . config . task . target_exe , <TAB> <TAB> <TAB> )","if task . config . task . type != ""task"" :","if task . state in [ ""stopped"" , ""stopping"" ] :",False,95.87,67.8,,,
"def update_stack ( self , full_name , template_url , parameters , tags ) : <TAB> """""" Updates an existing stack in CloudFormation. """""" <TAB> try : <TAB> <TAB> logger . info ( "" Attempting to update stack  %s . "" , full_name ) <TAB> <TAB> self . conn . cloudformation . update_stack ( <TAB> <TAB> <TAB> full_name , <TAB> <TAB> <TAB> template_url = template_url , <TAB> <TAB> <TAB> parameters = parameters , <TAB> <TAB> <TAB> tags = tags , <TAB> <TAB> <TAB> capabilities = [ "" CAPABILITY_IAM "" ] , <TAB> <TAB> ) <TAB> <TAB> return SUBMITTED <TAB> except BotoServerError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . info ( "" Stack  %s  did not change, not updating. "" , full_name ) <TAB> <TAB> <TAB> return SKIPPED <TAB> <TAB> raise","if e . response [ ""Error"" ] [ ""Code"" ] == ""StackNotFoundException"" :","if ""No updates are to be performed."" in e . message :",False,92.73,92.6,,,
"def header_tag_files ( env , files , legal_header , script_files = False ) : <TAB> """""" Apply the legal_header to the list of files """""" <TAB> try : <TAB> <TAB> import apply_legal_header <TAB> except : <TAB> <TAB> xbc . cdie ( "" XED ERROR: mfile.py could not find scripts directory "" ) <TAB> for g in files : <TAB> <TAB> print ( "" G:  "" , g ) <TAB> <TAB> for f in mbuild . glob ( g ) : <TAB> <TAB> <TAB> print ( "" F:  "" , f ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> apply_legal_header . apply_header_to_data_file ( legal_header , f ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> apply_legal_header . apply_header_to_source_file ( legal_header , f )",if script_files :,if script_files :,True,100.0,74.51,,,
"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB> <TAB> if reverseConn not in cmd : <TAB> <TAB> <TAB> cmds = cmd . split ( "" & "" ) <TAB> <TAB> <TAB> for c in cmds : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB> <TAB> else : <TAB> <TAB> <TAB> b64cmd = base64 . b64encode ( cmd ) <TAB> <TAB> <TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB> <TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd",if c != reverseConn :,if len ( c ) > 0 :,False,96.71,71.96,,,
"def test_form ( self ) : <TAB> n_qubits = 6 <TAB> random_operator = get_fermion_operator ( random_interaction_operator ( n_qubits ) ) <TAB> chemist_operator = chemist_ordered ( random_operator ) <TAB> for term , _ in chemist_operator . terms . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertTrue ( term [ 0 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 2 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertFalse ( term [ 1 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertFalse ( term [ 3 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 0 ] [ 0 ] > term [ 2 ] [ 0 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 1 ] [ 0 ] > term [ 3 ] [ 0 ] )",if term [ 0 ] [ 1 ] == 1 :,if len ( term ) == 2 or not len ( term ) :,False,94.64,70.62,,,
"def do ( server , handler , config , modargs ) : <TAB> data = [ ] <TAB> clients = server . get_clients ( handler . default_filter ) <TAB> if not clients : <TAB> <TAB> return <TAB> for client in clients : <TAB> <TAB> tags = config . tags ( client . node ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tags . remove ( * modargs . remove ) <TAB> <TAB> if modargs . add : <TAB> <TAB> <TAB> tags . add ( * modargs . add ) <TAB> <TAB> data . append ( { "" ID "" : client . node ( ) , "" TAGS "" : tags } ) <TAB> config . save ( project = modargs . write_project , user = modargs . write_user ) <TAB> handler . display ( Table ( data ) )",if modargs . remove :,if modargs . remove :,True,100.0,74.56,,,
"def validate ( self ) : <TAB> if self . data . get ( "" state "" ) == "" enabled "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PolicyValidationError ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> "" redshift logging enablement requires `bucket`  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" and `prefix` specification on  %s "" % ( self . manager . data , ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return self","if self . data . get ( ""bucket"" ) and self . data . get ( ""prefix"" ) is None :","if ""bucket"" not in self . data :",False,87.05,63.28,,,
"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB> <TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sx , sy = m . groups ( ) <TAB> <TAB> <TAB> x = colname2num ( sx ) <TAB> <TAB> <TAB> y = int ( sy ) <TAB> <TAB> <TAB> if x1 < = x < = x2 and y1 < = y < = y2 : <TAB> <TAB> <TAB> <TAB> part = cellname ( x + dx , y + dy ) <TAB> <TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment )",if m :,if m is not None :,False,98.03,72.81,,,
"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB> <TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB> <TAB> if v is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str ( v ) <TAB> <TAB> if len ( v ) == 0 and not allow_empty : <TAB> <TAB> <TAB> continue <TAB> <TAB> contents [ k ] = v <TAB> <TAB> updated_am + = 1 <TAB> if updated_am : <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str ( contents ) , <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB> <TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 )",if exists :,if not exists :,False,99.04,73.76,,,
"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB> <TAB> if desc . getAttributeNS ( RDF_NAMESPACE , "" about "" ) == aboutUri : <TAB> <TAB> <TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB> <TAB> <TAB> <TAB> yield element",if attr is not None :,if attr != None :,False,97.44,72.74,,,
"def get_store_name_from_connection_string ( connection_string ) : <TAB> if is_valid_connection_string ( connection_string ) : <TAB> <TAB> segments = dict ( seg . split ( "" = "" , 1 ) for seg in connection_string . split ( "" ; "" ) ) <TAB> <TAB> endpoint = segments . get ( "" Endpoint "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return endpoint . split ( "" // "" ) [ 1 ] . split ( "" . "" ) [ 0 ] <TAB> return None",if endpoint :,if endpoint :,True,100.0,74.27,,,
"def insertLoopTemplate ( self , layout ) : <TAB> col = layout . column ( align = True ) <TAB> for socket in self . activeNode . outputs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> props = col . operator ( <TAB> <TAB> <TAB> <TAB> "" an.insert_loop_for_iterator "" , <TAB> <TAB> <TAB> <TAB> text = "" Loop through  {} "" . format ( repr ( socket . getDisplayedName ( ) ) ) , <TAB> <TAB> <TAB> <TAB> icon = "" MOD_ARRAY "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> props . nodeIdentifier = self . activeNode . identifier <TAB> <TAB> <TAB> props . socketIndex = socket . getIndex ( )",if socket . isLoopFor ( ) :,if not socket . hide and isList ( socket . bl_idname ) :,False,93.37,69.91,,,
"def do_task ( self , task ) : <TAB> self . running_task + = 1 <TAB> result = yield gen . Task ( self . fetcher . fetch , task ) <TAB> type , task , response = result . args <TAB> self . processor . on_task ( task , response ) <TAB> # do with message <TAB> while not self.processor.inqueue.empty(): <TAB> <TAB> _task, _response = self.processor.inqueue.get() <TAB> <TAB> self.processor.on_task(_task, _response) <TAB> # do with results <TAB> while not self.processor.result_queue.empty(): <TAB> <TAB> _task, _result = self.processor.result_queue.get() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.result_worker.on_result(_task, _result) <TAB> self.running_task -= 1",if _result is not None :,if self . result_worker :,False,97.31,71.98,,,
"def _parse_config_result ( data ) : <TAB> command_list = ""  ;  "" . join ( [ x . strip ( ) for x in data [ 0 ] ] ) <TAB> config_result = data [ 1 ] <TAB> if isinstance ( config_result , list ) : <TAB> <TAB> result = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for key in config_result [ 0 ] : <TAB> <TAB> <TAB> <TAB> result + = config_result [ 0 ] [ key ] <TAB> <TAB> <TAB> config_result = result <TAB> <TAB> else : <TAB> <TAB> <TAB> config_result = config_result [ 0 ] <TAB> return [ command_list , config_result ]","if isinstance ( config_result [ 0 ] , dict ) :","if isinstance ( config_result [ 0 ] , dict ) :",True,100.0,74.46,,,
"def load_api_handler ( self , mod_name ) : <TAB> for name , hdl in API_HANDLERS : <TAB> <TAB> name = name . lower ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> handler = self . mods . get ( name ) <TAB> <TAB> <TAB> if not handler : <TAB> <TAB> <TAB> <TAB> handler = hdl ( self . emu ) <TAB> <TAB> <TAB> <TAB> self . mods . update ( { name : handler } ) <TAB> <TAB> <TAB> return handler <TAB> return None",if name . startswith ( mod_name ) :,if mod_name and name == mod_name . lower ( ) :,False,92.0,69.65,,,
def heal ( self ) : <TAB> if not self . doctors : <TAB> <TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess.objects.get(id=proc_id) <TAB> <TAB> if not proc.is_alive or proc.is_frozen: <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self.doctors: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dr.cure(proc) <TAB> <TAB> <TAB> <TAB> break,if dr . can_be_cure ( proc ) :,if dr . confirm ( proc ) :,False,96.35,97.8,,,
"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB> <TAB> if len ( kwargs ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> cls . __name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return super ( ) . __new__ ( cls ) <TAB> <TAB> if isinstance ( args [ 0 ] , cls ) : <TAB> <TAB> <TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )","if isinstance ( args [ 0 ] , cls ) :",if not args [ 0 ] :,False,96.38,72.19,,,
"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB> <TAB> A, B = self[0], other[0] <TAB> <TAB> # uses logical clock value first <TAB> <TAB> <IF-STMT> # use logical clock if available <TAB> <TAB> <TAB> if A == B: # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self[2] < other[2] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self[1] < other[1] # ... or use timestamp <TAB> except IndexError: <TAB> <TAB> return NotImplemented",if A != B :,if A and B :,False,97.96,72.85,,,
"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB> <TAB> if str . lower ( key ) == str . lower ( resource_provider ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient ( <TAB> <TAB> <TAB> <TAB> <TAB> key , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" api_version "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" support_list_or_not "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" resource_get_api_version "" ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value ( ) <TAB> raise CLIError ( <TAB> <TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> )","if value [ ""resource_provider"" ] == str . lower ( resource_provider ) :","if isinstance ( value , dict ) :",False,93.19,67.25,,,
"def test_progressbar_format_pos ( runner , pos , length ) : <TAB> with _create_progress ( length , length_known = length != 0 , pos = pos ) as progress : <TAB> <TAB> result = progress . format_pos ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert result == f "" { pos } / { length } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> assert result == str ( pos )",if runner . is_running ( ) :,if progress . length_known :,False,93.28,70.74,,,
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> if not Placeholder . check_resolved ( v . size ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed",if height != 0 and width != 0 :,if not v . has_attribute ( SplitTarget ) :,False,94.42,70.62,,,
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",if col == NONE :,if col == LAND :,False,99.16,73.99,,,
"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB> <TAB> if self . __conn is not None : <TAB> <TAB> <TAB> self . __conn . close ( ) <TAB> <TAB> <TAB> self . __conn = None <TAB> <TAB> for _ , l in self . _library_cache . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB> <TAB> <TAB> <TAB> l . _reset ( ) # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth",if l . _is_authenticated ( ) :,"if hasattr ( l , ""_reset"" ) and callable ( l . _reset ) :",False,91.81,63.4,,,
"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB> <TAB> x = cand . creator <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if x not in fan_out : <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq.heappush(cand_funcs, (-x.rank, len(fan_out), x)) <TAB> <TAB> fan_out[x] += 1",if x . rank != 2 :,if x is None :,False,95.4,70.1,,,
"def on_task_modify ( self , task , config ) : <TAB> for entry in task . entries : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size = entry [ "" torrent "" ] . size / 1024 / 1024 <TAB> <TAB> <TAB> log . debug ( "" %s  size:  %s  MB "" % ( entry [ "" title "" ] , size ) ) <TAB> <TAB> <TAB> entry [ "" content_size "" ] = size","if entry [ ""torrent"" ] . size :","if ""torrent"" in entry :",False,93.18,70.47,,,
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> if self . do_corr_and_slope : <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> if self . do_manders : <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ]",if self . do_costs :,if self . do_costes :,False,99.09,73.87,,,
"def create_root ( cls , site = None , title = "" Root "" , request = None , * * kwargs ) : <TAB> if not site : <TAB> <TAB> site = Site . objects . get_current ( ) <TAB> root_nodes = cls . objects . root_nodes ( ) . filter ( site = site ) <TAB> if not root_nodes : <TAB> <TAB> article = Article ( ) <TAB> <TAB> revision = ArticleRevision ( title = title , * * kwargs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> revision . set_from_request ( request ) <TAB> <TAB> article . add_revision ( revision , save = True ) <TAB> <TAB> article . save ( ) <TAB> <TAB> root = cls . objects . create ( site = site , article = article ) <TAB> <TAB> article . add_object_relation ( root ) <TAB> else : <TAB> <TAB> root = root_nodes [ 0 ] <TAB> return root",if request :,if request :,True,100.0,74.59,,,
"def get ( self , key ) : <TAB> filename = self . _get_filename ( key ) <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> pickle_time = pickle . load ( f ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return pickle . load ( f ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> <TAB> <TAB> <TAB> return None <TAB> except ( IOError , OSError , pickle . PickleError ) : <TAB> <TAB> return None",if pickle_time > self . _max_age :,if pickle_time == 0 or pickle_time >= time ( ) :,False,92.87,69.95,,,
"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_body ( message , value ) <TAB> <TAB> elif name == "" EMAIL_ATTACHMENT "" : <TAB> <TAB> <TAB> self . add_attachment ( message , value ) <TAB> <TAB> else : # From, To, Subject, etc. <TAB> <TAB> <TAB> self.set_option(message, name, value, target) <TAB> return message","if name == ""CONTENT_LENGTH"" :","if name == ""EMAIL_BODY"" :",False,97.2,72.91,,,
"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . append ( data ) <TAB> <TAB> elif mode == "" add "" : <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB> <TAB> core . config . globalVariables [ name ] = data","if mode == ""add"" :","if mode == ""append"" :",False,97.7,72.61,,,
"def insert_errors ( <TAB> el , <TAB> errors , <TAB> form_id = None , <TAB> form_index = None , <TAB> error_class = "" error "" , <TAB> error_creator = default_error_creator , ) : <TAB> el = _find_form ( el , form_id = form_id , form_index = form_index ) <TAB> for name , error in errors . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for error_el , message in _find_elements_for_name ( el , name , error ) : <TAB> <TAB> <TAB> assert isinstance ( message , ( basestring , type ( None ) , ElementBase ) ) , ( <TAB> <TAB> <TAB> <TAB> "" Bad message:  %r "" % message <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> _insert_error ( error_el , message , error_class , error_creator )","if name . startswith ( ""_"" ) :",if error is None :,False,96.05,65.31,,,
"def read ( self , item , recursive = False , sort = False ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _store [ item ] <TAB> <TAB> <TAB> raise KeyError ( item ) <TAB> <TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> else : <TAB> <TAB> return self . _read_dir ( item , recursive = recursive , sort = sort )",if recursive :,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,False,82.02,65.08,,,
"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB> <TAB> for s in states : <TAB> <TAB> <TAB> ns = state_func ( s ) <TAB> <TAB> <TAB> if isinstance ( ns , SimState ) : <TAB> <TAB> <TAB> <TAB> split . append ( ns ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> split . extend ( ns ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB> <TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB> <TAB> keep = states <TAB> return keep , split","elif isinstance ( ns , list ) :","elif isinstance ( ns , ( list , tuple , set ) ) :",False,96.15,71.55,,,
"def run ( self ) : <TAB> while self . runflag : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with self . lock : <TAB> <TAB> <TAB> <TAB> tasks = list ( self . queue ) <TAB> <TAB> <TAB> <TAB> self . queue . clear ( ) <TAB> <TAB> <TAB> while len ( tasks ) > 0 : <TAB> <TAB> <TAB> <TAB> pathname , remotepath = tasks . pop ( 0 ) <TAB> <TAB> <TAB> <TAB> self . bcloud_app . upload_page . add_bg_task ( pathname , remotepath ) <TAB> <TAB> <TAB> self . last = time ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sleep ( 1 )",if self . last is None :,if time ( ) - self . last > 5 and self . qsize ( ) > 0 :,False,91.29,67.6,,,
"def _append_patch ( self , patch_dir , patch_files ) : <TAB> for patch in patch_files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tmp = patch <TAB> <TAB> <TAB> patch = { } <TAB> <TAB> <TAB> for key in tmp . keys ( ) : <TAB> <TAB> <TAB> <TAB> patch [ os . path . join ( patch_dir , key ) ] = tmp [ key ] <TAB> <TAB> <TAB> self . patches . append ( patch ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . patches . append ( os . path . join ( patch_dir , patch ) )","if isinstance ( patch , dict ) :",if type ( patch ) is dict :,False,96.24,71.33,,,
"def __remote_port ( self ) : <TAB> port = 22 <TAB> if self . git_has_remote : <TAB> <TAB> m = re . match ( r "" ^(.*?)?@([^/:]*):?([0-9]+)? "" , self . git_remote . url ) <TAB> <TAB> if m : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> port = m . group ( 3 ) <TAB> return int ( port )",if m . group ( 3 ) :,if m . group ( 3 ) :,True,100.0,74.08,,,
"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len(kwargs) > 0 <TAB> kwargs.update(infer_mode=infer_mode) <TAB> is_training = not infer_mode if infer_mode is not None else self.training <TAB> helper = self._train_helper if is_training else self._infer_helper <TAB> if prefer_new or helper is None: <TAB> <TAB> helper = self.create_helper(**kwargs) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._train_helper = helper <TAB> <TAB> elif not is_training and self._infer_helper is None: <TAB> <TAB> <TAB> self._infer_helper = helper <TAB> return helper",if is_training and self . _train_helper is None :,if is_training and self . _train_helper is None :,True,100.0,74.48,,,
"def flushChangeClassifications ( self , schedulerid , less_than = None ) : <TAB> if less_than is not None : <TAB> <TAB> classifications = self . classifications . setdefault ( schedulerid , { } ) <TAB> <TAB> for changeid in list ( classifications ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del classifications [ changeid ] <TAB> else : <TAB> <TAB> self . classifications [ schedulerid ] = { } <TAB> return defer . succeed ( None )",if less_than [ changeid ] < classifications [ changeid ] :,if changeid < less_than :,False,91.58,70.39,,,
"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> pid = int ( pid ) <TAB> <TAB> <TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB> <TAB> <TAB> if name in pname : <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name )","if cmdline == ""-P"" :","if name in cmdline . split ( "" "" , 1 ) [ 0 ] :",False,91.75,67.64,,,
"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> if part . type == "" body "" : <TAB> <TAB> <TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB> <TAB> <TAB> yield f ( id , msg , write , flush ) <TAB> <TAB> if part is not query [ - 1 ] : <TAB> <TAB> <TAB> space ( ) <TAB> if uid and not seenUID : <TAB> <TAB> space ( ) <TAB> <TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( )",if not seenUID :,"if part . type == ""uid"" :",False,95.75,66.73,,,
"def rx ( ) : <TAB> while True : <TAB> <TAB> rx_i = rep . recv ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rep . send ( b "" done "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> rep . send ( b "" i "" )","if rx_i == b""done"" :","if rx_i == b""1000"" :",False,97.01,71.38,,,
"def test_search_incorrect_base_exception_1 ( self ) : <TAB> self . connection_1c . bind ( ) <TAB> try : <TAB> <TAB> result = self . connection_1c . search ( <TAB> <TAB> <TAB> "" o=nonexistant "" , "" (cn=*) "" , search_scope = SUBTREE , attributes = [ "" cn "" , "" sn "" ] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _ , result = self . connection_1c . get_response ( result ) <TAB> <TAB> self . fail ( "" exception not raised "" ) <TAB> except LDAPNoSuchObjectResult : <TAB> <TAB> pass",if result :,if not self . connection_1c . strategy . sync :,False,92.99,69.56,,,
"def value_from_datadict ( self , data , files , prefix ) : <TAB> count = int ( data [ "" %s -count "" % prefix ] ) <TAB> values_with_indexes = [ ] <TAB> for i in range ( 0 , count ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> values_with_indexes . append ( <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> int ( data [ "" %s - %d -order "" % ( prefix , i ) ] ) , <TAB> <TAB> <TAB> <TAB> self . child_block . value_from_datadict ( <TAB> <TAB> <TAB> <TAB> <TAB> data , files , "" %s - %d -value "" % ( prefix , i ) <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> values_with_indexes . sort ( ) <TAB> return [ v for ( i , v ) in values_with_indexes ]",if i >= count :,"if data [ ""%s-%d-deleted"" % ( prefix , i ) ] :",False,93.81,66.04,,,
"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB> <TAB> if not self . _nchannels : <TAB> <TAB> <TAB> raise Error ( "" # channels not specified "" ) <TAB> <TAB> if not self . _sampwidth : <TAB> <TAB> <TAB> raise Error ( "" sample width not specified "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Error ( "" sampling rate not specified "" ) <TAB> <TAB> self . _write_header ( datasize )",if not self . _samprate :,if not self . _framerate :,False,98.1,72.87,,,
def wait_til_ready ( cls ) : <TAB> while True : <TAB> <TAB> now = time . time ( ) <TAB> <TAB> next_iteration = now / / 1.0 + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> await cls . _clock . run_til ( next_iteration ) <TAB> <TAB> await asyncio . sleep ( 1.0 ),if cls . _clock . is_alive ( ) :,if cls . connector . ready :,False,91.97,67.02,,,
"def lookup_actions ( self , resp ) : <TAB> actions = { } <TAB> for action , conditions in self . actions . items ( ) : <TAB> <TAB> for condition , opts in conditions : <TAB> <TAB> <TAB> for key , val in condition : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if resp . match ( key [ : - 1 ] , val ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> if not resp . match ( key , val ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> actions [ action ] = opts <TAB> return actions","if key . endswith ( ""/"" ) :","if key [ - 1 ] == ""!"" :",False,95.58,71.8,,,
"def close ( self , wait = True , abort = False ) : <TAB> """""" Close the socket connection. """""" <TAB> if not self . closed and not self . closing : <TAB> <TAB> self . closing = True <TAB> <TAB> self . server . _trigger_event ( "" disconnect "" , self . sid , run_async = False ) <TAB> <TAB> if not abort : <TAB> <TAB> <TAB> self . send ( packet . Packet ( packet . CLOSE ) ) <TAB> <TAB> self . closed = True <TAB> <TAB> self . queue . put ( None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . queue . join ( )",if wait :,if wait :,True,100.0,99.47,,,
"def model_parse ( self ) : <TAB> for name , submodel in self . model . named_modules ( ) : <TAB> <TAB> for op_type in SUPPORTED_OP_TYPE : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . target_layer [ name ] = submodel <TAB> <TAB> <TAB> <TAB> self . already_pruned [ name ] = 0",if submodel . op_type == op_type :,"if isinstance ( submodel , op_type ) :",False,90.78,68.38,,,
"def pack_identifier ( self ) : <TAB> """""" Return a combined identifier for the whole pack if this has more than one episode. """""" <TAB> # Currently only supports ep mode <TAB> if self.id_type == ""ep"": <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""S%02dE%02d-E%02d"" % ( <TAB> <TAB> <TAB> <TAB> self.season, <TAB> <TAB> <TAB> <TAB> self.episode, <TAB> <TAB> <TAB> <TAB> self.episode + self.episodes - 1, <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.identifier <TAB> else: <TAB> <TAB> return self.identifier",if self . episode < self . episodes :,if self . episodes > 1 :,False,96.99,71.68,,,
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> if type ( f ) == unicode : <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> elif not args . content_only : <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res )",if type ( v ) == unicode :,if type ( v ) == unicode :,True,100.0,74.56,,,
"def _enable_contours_changed ( self , value ) : <TAB> """""" Turns on and off the contours. """""" <TAB> if self . module_manager is None : <TAB> <TAB> return <TAB> if value : <TAB> <TAB> self . actor . inputs = [ self . contour ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . actor . mapper . scalar_mode = "" use_cell_data "" <TAB> else : <TAB> <TAB> self . actor . inputs = [ self . grid_plane ] <TAB> <TAB> self . actor . mapper . scalar_mode = "" default "" <TAB> self . render ( )",if self . grid_plane is None :,if self . contour . filled_contours :,False,96.12,83.31,,,
"def _apply_abs_paths ( data , script_dir ) : <TAB> for flag_data in data . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> default = flag_data . get ( "" default "" ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> not default <TAB> <TAB> <TAB> or not isinstance ( default , six . string_types ) <TAB> <TAB> <TAB> or os . path . sep not in default <TAB> <TAB> ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> abs_path = os . path . join ( script_dir , default ) <TAB> <TAB> if os . path . exists ( abs_path ) : <TAB> <TAB> <TAB> flag_data [ "" default "" ] = abs_path","if flag_data . get ( ""enabled"" ) :","if not isinstance ( flag_data , dict ) :",False,95.83,64.78,,,
"def button_release ( self , mapper ) : <TAB> self . pressed = False <TAB> if self . waiting_task and self . active is None and not self . action : <TAB> <TAB> # In HoldModifier, button released before timeout <TAB> <TAB> mapper.cancel_task(self.waiting_task) <TAB> <TAB> self.waiting_task = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.normalaction.button_press(mapper) <TAB> <TAB> <TAB> mapper.schedule(0.02, self.normalaction.button_release) <TAB> elif self.active: <TAB> <TAB> # Released held button <TAB> <TAB> self.active.button_release(mapper) <TAB> <TAB> self.active = None",if self . normalaction :,if self . normalaction :,True,100.0,74.26,,,
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """""" Select the next marked node. """""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> if p and p . isMarked ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> elif wrapped : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",if p :,elif p :,False,98.8,86.52,,,
"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB> <TAB> if self . script_running and self . script_running [ 1 ] == name : <TAB> <TAB> <TAB> return self . script_running [ 1 : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . script_last [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( error )",elif self . script_last and self . script_last [ 0 ] == name :,elif self . script_last and self . script_last [ 1 ] == name :,False,98.16,72.93,,,
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama : <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False",if curses :,if curses :,True,100.0,74.59,,,
"def main ( ) : <TAB> configFilename = "" twitterbot.ini "" <TAB> if sys . argv [ 1 : ] : <TAB> <TAB> configFilename = sys . argv [ 1 ] <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( ) <TAB> <TAB> load_config ( configFilename ) <TAB> except Exception as e : <TAB> <TAB> print ( "" Error while loading ini file  %s "" % ( configFilename ) , file = sys . stderr ) <TAB> <TAB> print ( e , file = sys . stderr ) <TAB> <TAB> print ( __doc__ , file = sys . stderr ) <TAB> <TAB> sys . exit ( 1 ) <TAB> bot = TwitterBot ( configFilename ) <TAB> return bot . run ( )",if not load_ini ( configFilename ) :,if not os . path . exists ( configFilename ) :,False,96.55,72.17,,,
def safe_to_kill ( request ) : <TAB> if os . path . exists ( DRAIN_FILE ) : <TAB> <TAB> with open ( DRAIN_FILE ) as f : <TAB> <TAB> <TAB> dt = datetime . datetime . fromtimestamp ( float ( f . read ( ) ) ) <TAB> <TAB> <TAB> delta = datetime . datetime . now ( ) - dt <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return Response ( status_int = 200 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return Response ( status_int = 400 ) <TAB> else : <TAB> <TAB> return Response ( status_int = 400 ),if delta > 0 :,if delta . seconds > 2 :,False,96.99,69.94,,,
"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> class_name = parent . name <TAB> <TAB> elif isinstance ( parent , pytest . Module ) : <TAB> <TAB> <TAB> module_name = parent . module . __name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #  are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #  the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB> <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB> <TAB> return module_name","if isinstance ( parent , pytest . Class ) :","if isinstance ( parent , pytest . Class ) :",True,100.0,74.57,,,
"def getAllFitsLite ( ) : <TAB> fits = eos . db . getFitListLite ( ) <TAB> shipMap = { f . shipID : None for f in fits } <TAB> for shipID in shipMap : <TAB> <TAB> ship = eos . db . getItem ( shipID ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shipMap [ shipID ] = ( ship . name , ship . getShortName ( ) ) <TAB> fitsToPurge = set ( ) <TAB> for fit in fits : <TAB> <TAB> try : <TAB> <TAB> <TAB> fit . shipName , fit . shipNameShort = shipMap [ fit . shipID ] <TAB> <TAB> except ( KeyError , TypeError ) : <TAB> <TAB> <TAB> fitsToPurge . add ( fit ) <TAB> for fit in fitsToPurge : <TAB> <TAB> fits . remove ( fit ) <TAB> return fits",if ship . name :,if ship is not None :,False,97.66,72.66,,,
"def _process ( self , event_data ) : <TAB> self . machine . callbacks ( self . machine . prepare_event , event_data ) <TAB> _LOGGER . debug ( <TAB> <TAB> "" %s Executed machine preparation callbacks before conditions. "" , self . machine . name <TAB> ) <TAB> try : <TAB> <TAB> for trans in self . transitions [ event_data . state . name ] : <TAB> <TAB> <TAB> event_data . transition = trans <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> event_data . result = True <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as err : <TAB> <TAB> event_data . error = err <TAB> <TAB> raise <TAB> finally : <TAB> <TAB> self . machine . callbacks ( self . machine . finalize_event , event_data ) <TAB> <TAB> _LOGGER . debug ( "" %s Executed machine finalize callbacks "" , self . machine . name ) <TAB> return event_data . result",if event_data . transition . state == self . states . active :,if trans . execute ( event_data ) :,False,94.65,71.7,,,
"def fetch_comments ( self , force = False , limit = None ) : <TAB> comments = [ ] <TAB> if ( force is True ) or ( self . badges [ "" comments "" ] > 0 ) : <TAB> <TAB> query_params = { "" filter "" : "" commentCard,copyCommentCard "" } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> query_params [ "" limit "" ] = limit <TAB> <TAB> comments = self . client . fetch_json ( <TAB> <TAB> <TAB> "" /cards/ "" + self . id + "" /actions "" , query_params = query_params <TAB> <TAB> ) <TAB> <TAB> return sorted ( comments , key = lambda comment : comment [ "" date "" ] ) <TAB> return comments",if limit is not None :,if limit is not None :,True,100.0,74.51,,,
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> if result == self . source : <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> if start < last_end : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( )",if end < start :,if not self . _is_expression ( ) :,False,96.03,72.02,,,
"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> if builtins . __xonsh__ . env . get ( "" FORCE_POSIX_PATHS "" ) : <TAB> <TAB> <TAB> x = x . replace ( os . sep , os . altsep ) <TAB> <TAB> return x <TAB> else : <TAB> <TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> return x",if home :,if x . startswith ( home ) :,False,93.95,70.04,,,
"def project_review ( plans ) : <TAB> for plan in plans : <TAB> <TAB> print ( "" Inspecting  {}  plan "" . format ( plan ) ) <TAB> <TAB> branches = get_branches_from_plan ( plan ) <TAB> <TAB> for branch in branches : <TAB> <TAB> <TAB> build_results = get_results_from_branch ( branch ) <TAB> <TAB> <TAB> for build in build_results : <TAB> <TAB> <TAB> <TAB> build_key = build . get ( "" buildResultKey "" ) or None <TAB> <TAB> <TAB> <TAB> print ( "" Inspecting build -  {} "" . format ( build_key ) ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> for status in STATUS_CLEANED_RESULTS : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> remove_build_result ( build_key = build_key , status = status )",if build_key :,if build_key :,True,100.0,74.51,,,
"def _check_for_batch_clashes ( xs ) : <TAB> """""" Check that batch names do not overlap with sample names. """""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB> <TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB> <TAB> if batches : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> batches = [ batches ] <TAB> <TAB> <TAB> for batch in batches : <TAB> <TAB> <TAB> <TAB> if batch in names : <TAB> <TAB> <TAB> <TAB> <TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB> <TAB> <TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB> <TAB> )","if not isinstance ( batches , ( list , tuple ) ) :","if not isinstance ( batches , ( list , tuple ) ) :",True,100.0,99.65,,,
"def _check_signal ( self ) : <TAB> """""" Checks if a signal was received and issues a message. """""" <TAB> proc_signal = getattr ( self . proc , "" signal "" , None ) <TAB> if proc_signal is None : <TAB> <TAB> return <TAB> sig , core = proc_signal <TAB> sig_str = SIGNAL_MESSAGES . get ( sig ) <TAB> if sig_str : <TAB> <TAB> if core : <TAB> <TAB> <TAB> sig_str + = ""  (core dumped) "" <TAB> <TAB> print ( sig_str , file = sys . stderr ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . errors + = sig_str + "" \n """,if self . errors :,if self . errors is not None :,False,97.49,72.04,,,
"def loadLabelFile ( self , labelpath ) : <TAB> labeldict = { } <TAB> if not os . path . exists ( labelpath ) : <TAB> <TAB> f = open ( labelpath , "" w "" , encoding = "" utf-8 "" ) <TAB> else : <TAB> <TAB> with open ( labelpath , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> data = f . readlines ( ) <TAB> <TAB> <TAB> for each in data : <TAB> <TAB> <TAB> <TAB> file , label = each . split ( "" \t "" ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> label = label . replace ( "" false "" , "" False "" ) <TAB> <TAB> <TAB> <TAB> <TAB> label = label . replace ( "" true "" , "" True "" ) <TAB> <TAB> <TAB> <TAB> <TAB> labeldict [ file ] = eval ( label ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> labeldict [ file ] = [ ] <TAB> return labeldict",if self . _test_test :,if label :,False,97.28,73.69,,,
"def exists_col_to_many ( self , select_columns : List [ str ] ) - > bool : <TAB> for column in select_columns : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> root_relation = get_column_root_relation ( column ) <TAB> <TAB> <TAB> if self . is_relation_many_to_many ( <TAB> <TAB> <TAB> <TAB> root_relation <TAB> <TAB> <TAB> ) or self . is_relation_one_to_many ( root_relation ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if self . is_column_exists ( column ) :,if is_column_dotted ( column ) :,False,96.17,71.82,,,
"def check_sequence_matches ( seq , template ) : <TAB> i = 0 <TAB> for pattern in template : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pattern = { pattern } <TAB> <TAB> got = set ( seq [ i : i + len ( pattern ) ] ) <TAB> <TAB> assert got == pattern <TAB> <TAB> i + = len ( got )","if not isinstance ( pattern , dict ) :","if not isinstance ( pattern , set ) :",False,97.47,72.31,,,
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> if module is None or not hasattr ( module , attr ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases : <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( )","if hasattr ( module , ""aliases"" ) :","if hasattr ( module , ""aliases"" ) :",True,100.0,74.63,,,
"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R, V = rays, virtual_rays <TAB> if V is not None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> V = normalize_rays(V, lattice) <TAB> <TAB> if check: <TAB> <TAB> <TAB> R = PointCollection(V, lattice) <TAB> <TAB> <TAB> V = PointCollection(V, lattice) <TAB> <TAB> <TAB> d = lattice.dimension() <TAB> <TAB> <TAB> if len(V) != d - R.dim() or (R + V).dim() != d: <TAB> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> <TAB> ""virtual rays must be linearly "" <TAB> <TAB> <TAB> <TAB> <TAB> ""independent and with other rays span the ambient space."" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan(cones, R, lattice, is_complete, V)",if normalize :,if normalize :,True,100.0,74.48,,,
"def communicate ( self , _input = None , _timeout = None ) - > Tuple [ bytes , bytes ] : <TAB> if parse_args ( ) . print_commands : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print_stderr ( <TAB> <TAB> <TAB> <TAB> color_line ( "" =>  "" , 14 ) + "" "" . join ( str ( arg ) for arg in self . args ) <TAB> <TAB> <TAB> ) <TAB> stdout , stderr = super ( ) . communicate ( _input , _timeout ) <TAB> self . stdout_text = stdout . decode ( "" utf-8 "" ) if stdout else None <TAB> self . stderr_text = stderr . decode ( "" utf-8 "" ) if stderr else None <TAB> return stdout , stderr",if self . args :,if self . args != get_sudo_refresh_command ( ) :,False,93.28,72.51,,,
"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.append((d[0], None, d[1])) <TAB> <TAB> elif isinstance(d, basestring): <TAB> <TAB> <TAB> result.append(d) <TAB> return result","if isinstance ( d , tuple ) :","if isinstance ( d , tuple ) and len ( d ) == 2 :",False,91.3,66.29,,,
"def validate ( self , value ) : <TAB> try : <TAB> <TAB> value = [ <TAB> <TAB> <TAB> datetime . datetime . strptime ( range , "" % Y- % m- %d % H: % M: % S "" ) <TAB> <TAB> <TAB> for range in value . split ( ""  to  "" ) <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> except ValueError : <TAB> <TAB> return False",if len ( value ) == 2 :,if ( len ( value ) == 2 ) and ( value [ 0 ] <= value [ 1 ] ) :,False,88.03,66.15,,,
"def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB> <TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB> <TAB> return # do not clear link - we can get out of dir <TAB> for f in os.listdir(dirname): <TAB> <TAB> if f in (""."", ""..""): <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os.sep + f <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rmdir(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> os.unlink(path) <TAB> os.rmdir(dirname)",if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,True,100.0,74.41,,,
"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB> <TAB> if not l : <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l . split ( "" : "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setSlides ( res )",if len ( l ) != 2 :,if len ( l ) != 2 :,True,100.0,74.35,,,
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> if "" init "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if isinstance ( item , pytest . mark ) :","if item . nodeid . startswith ( ""tests/infer"" ) :",False,91.22,64.93,,,
"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB> <TAB> if name == "" EMAIL_BODY "" : <TAB> <TAB> <TAB> self . add_body ( message , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_attachment ( message , value ) <TAB> <TAB> else : # From, To, Subject, etc. <TAB> <TAB> <TAB> self.set_option(message, name, value, target) <TAB> return message","elif name == ""EMAIL_ATTACHMENT"" :","elif name == ""EMAIL_ATTACHMENT"" :",True,100.0,74.3,,,
def extend_with_zeroes ( b ) : <TAB> try : <TAB> <TAB> for x in b : <TAB> <TAB> <TAB> x = to_constant ( x ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield ( x ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield ( 0 ) <TAB> <TAB> for _ in range ( 32 ) : <TAB> <TAB> <TAB> yield ( 0 ) <TAB> except Exception as e : <TAB> <TAB> return,if x != 0 :,"if isinstance ( x , int ) :",False,94.94,56.36,,,
"def _start_cluster ( * , cleanup_atexit = True ) : <TAB> global _default_cluster <TAB> if _default_cluster is None : <TAB> <TAB> cluster_addr = os . environ . get ( "" EDGEDB_TEST_CLUSTER_ADDR "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conn_spec = json . loads ( cluster_addr ) <TAB> <TAB> <TAB> _default_cluster = edgedb_cluster . RunningCluster ( * * conn_spec ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data_dir = os . environ . get ( "" EDGEDB_TEST_DATA_DIR "" ) <TAB> <TAB> <TAB> _default_cluster = _init_cluster ( <TAB> <TAB> <TAB> <TAB> data_dir = data_dir , cleanup_atexit = cleanup_atexit <TAB> <TAB> <TAB> ) <TAB> return _default_cluster",if cluster_addr :,if cluster_addr :,True,100.0,74.41,,,
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> if line [ 0 ] == "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" )",if not line :,if not line :,True,100.0,74.56,,,
"def is_entirely_italic ( line ) : <TAB> style = subs . styles . get ( line . style , SSAStyle . DEFAULT_STYLE ) <TAB> for fragment , sty in parse_tags ( line . text , style , subs . styles ) : <TAB> <TAB> fragment = fragment . replace ( r "" \ h "" , "" "" ) <TAB> <TAB> fragment = fragment . replace ( r "" \ n "" , "" \n "" ) <TAB> <TAB> fragment = fragment . replace ( r "" \ N "" , "" \n "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True","if not is_italic ( fragment , sty ) :",if not sty . italic and fragment and not fragment . isspace ( ) :,False,92.62,69.2,,,
def __get_all_nodes ( self ) : <TAB> nodes = [ ] <TAB> next_level = [ self . __tree . get_root ( ) ] <TAB> while len ( next_level ) != 0 : <TAB> <TAB> cur_level = next_level <TAB> <TAB> nodes + = next_level <TAB> <TAB> next_level = [ ] <TAB> <TAB> for cur_node in cur_level : <TAB> <TAB> <TAB> children = cur_node . get_children ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> next_level + = children <TAB> return nodes,if children :,if children is not None :,False,97.21,71.24,,,
"def _openvpn_stdout ( self ) : <TAB> while True : <TAB> <TAB> line = self . process . stdout . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> time . sleep ( 0.05 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield <TAB> <TAB> try : <TAB> <TAB> <TAB> self . server . output . push_output ( line ) <TAB> <TAB> except : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Failed to push vpn output "" , <TAB> <TAB> <TAB> <TAB> "" server "" , <TAB> <TAB> <TAB> <TAB> server_id = self . server . id , <TAB> <TAB> <TAB> ) <TAB> <TAB> yield",if self . server . output . is_output_empty ( ) :,if self . process . poll ( ) is not None or self . is_interrupted ( ) :,False,94.24,69.44,,,
"def payment_received_handler ( event ) : <TAB> if isinstance ( event . message . action , types . MessageActionPaymentSentMe ) : <TAB> <TAB> payment : types . MessageActionPaymentSentMe = event . message . action <TAB> <TAB> # do something after payment was received <TAB> <TAB> if payment.payload.decode(""UTF-8"") == ""product A"": <TAB> <TAB> <TAB> await bot.send_message( <TAB> <TAB> <TAB> <TAB> event.message.from_id, ""Thank you for buying product A!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await bot.send_message( <TAB> <TAB> <TAB> <TAB> event.message.from_id, ""Thank you for buying product B!"" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise events.StopPropagation","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :","elif payment . payload . decode ( ""UTF-8"" ) == ""product B"" :",True,100.0,74.42,,,
"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB> <TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> elif min != - 1 and spaces < min : <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB> <TAB> <TAB> )",if max != - 1 and spaces > max :,if max != - 1 and spaces > max :,True,100.0,74.58,,,
"def seek_to_block ( self , pos ) : <TAB> baseofs = 0 <TAB> ofs = 0 <TAB> for b in self . blocks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current_block = b <TAB> <TAB> <TAB> break <TAB> <TAB> baseofs + = b . compressed_size <TAB> <TAB> ofs + = b . uncompressed_size <TAB> else : <TAB> <TAB> self . current_block = None <TAB> <TAB> self . current_stream = BytesIO ( b "" "" ) <TAB> <TAB> return <TAB> self . current_block_start = ofs <TAB> self . stream . seek ( self . basepos + baseofs ) <TAB> buf = BytesIO ( self . stream . read ( self . current_block . compressed_size ) ) <TAB> self . current_stream = self . current_block . decompress ( buf )",if b . pos == pos :,if ofs + b . uncompressed_size > pos :,False,95.95,72.11,,,
"def rewrite_hunks ( hunks ) : <TAB> # type: (List[Hunk]) -> Iterator[Hunk] <TAB> # Assumes `hunks` are sorted, and from the same file <TAB> deltas = (hunk.b_length - hunk.a_length for hunk in hunks) <TAB> offsets = accumulate(deltas, initial=0) <TAB> for hunk, offset in zip(hunks, offsets): <TAB> <TAB> new_b = hunk.a_start + offset <TAB> <TAB> if hunk_of_additions_only(hunk): <TAB> <TAB> <TAB> new_b += 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_b -= 1 <TAB> <TAB> yield hunk._replace(b_start=new_b)",if hunk_of_removals_only ( hunk ) :,elif hunk_of_removals_only ( hunk ) :,False,98.7,72.47,,,
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret","if isinstance ( value , ( list , tuple ) ) :",if len ( q ) == 1 :,False,95.91,71.9,,,
"def get_url ( token , base_url ) : <TAB> """""" Parse an <url> token. """""" <TAB> if token . type == "" url "" : <TAB> <TAB> return _get_url_tuple ( token . value , base_url ) <TAB> elif token . type == "" function "" : <TAB> <TAB> if token . name == "" attr "" : <TAB> <TAB> <TAB> return check_attr_function ( token , "" url "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Ignore url modifiers <TAB> <TAB> <TAB> # See https://drafts.csswg.org/css-values-3/#urls <TAB> <TAB> <TAB> return _get_url_tuple(token.arguments[0].value, base_url)","elif token . name == ""url"" :","elif token . name == ""url"" and len ( token . arguments ) in ( 1 , 2 ) :",False,92.93,69.92,,,
"def read ( self , count ) : <TAB> if self . closed : <TAB> <TAB> return self . upstream . read ( count ) <TAB> try : <TAB> <TAB> while len ( self . upstream ) < count : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> with self . buf_in : <TAB> <TAB> <TAB> <TAB> <TAB> self . transport . downstream_recv ( self . buf_in ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return self . upstream . read ( count ) <TAB> except : <TAB> <TAB> logger . debug ( traceback . format_exc ( ) )",if self . buf_in :,if self . buf_in or self . _poll_read ( 10 ) :,False,93.73,70.69,,,
"def get_timestamp_for_block ( <TAB> self , block_hash : HexBytes , max_tries : Optional [ int ] = 10 ) - > int : <TAB> counter = 0 <TAB> block : AttributeDict = None <TAB> if block_hash in self . _block_cache . keys ( ) : <TAB> <TAB> block = self . _block_cache . get ( block_hash ) <TAB> else : <TAB> <TAB> while block is None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError ( f "" Block hash  { block_hash . hex ( ) }  does not exist. "" ) <TAB> <TAB> <TAB> counter + = 1 <TAB> <TAB> <TAB> block = self . _block_cache . get ( block_hash ) <TAB> <TAB> <TAB> await asyncio . sleep ( 0.5 ) <TAB> return block . get ( "" timestamp "" )",if counter >= max_tries :,if counter == max_tries :,False,98.86,73.65,,,
"def reader ( ) : <TAB> batch_out = [ ] <TAB> for video_name in self . video_list : <TAB> <TAB> video_idx = self . video_list . index ( video_name ) <TAB> <TAB> video_feat = self . load_file ( video_name ) <TAB> <TAB> batch_out . append ( ( video_feat , video_idx ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield batch_out <TAB> <TAB> <TAB> batch_out = [ ]",if len ( batch_out ) == self . batch_size :,if len ( batch_out ) == self . batch_size :,True,100.0,74.16,,,
"def cleanup ( ) : <TAB> gscript . message ( _ ( "" Erasing temporary files... "" ) ) <TAB> for temp_map , maptype in temp_maps : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gscript . run_command ( <TAB> <TAB> <TAB> <TAB> "" g.remove "" , flags = "" f "" , type = maptype , name = temp_map , quiet = True <TAB> <TAB> <TAB> )",if temp_map not in temp_maps :,"if gscript . find_file ( temp_map , element = maptype ) [ ""name"" ] :",False,84.75,60.33,,,
"def run ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt ( ) : <TAB> <TAB> <TAB> <TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self . _flow_type == BATCH : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> elif self . _flow_type == REALTIME : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = False ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> continue",if raw_inputs is None :,if self . _has_stop_signal ( raw_inputs ) :,False,95.84,72.35,,,
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB> <TAB> <TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sent . append ( self . handle_word ( child ) ) <TAB> <TAB> elif child . tag not in self . tags_to_ignore : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent )","elif child . tag == ""w"" :","elif child . tag in ( ""w"" , ""c"" ) :",False,94.46,68.45,,,
"def bind_subscribers_to_graphql_type ( self , graphql_type ) : <TAB> for field , subscriber in self . _subscribers . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Field  %s  is not defined on type  %s "" % ( field , self . name ) ) <TAB> <TAB> graphql_type . fields [ field ] . subscribe = subscriber",if field not in graphql_type . fields :,if field not in graphql_type . fields :,True,100.0,74.12,,,
"def _get_from_json ( self , * , name , version ) : <TAB> url = urljoin ( self . url , posixpath . join ( name , str ( version ) , "" json "" ) ) <TAB> async with aiohttp_session ( auth = self . auth ) as session : <TAB> <TAB> async with session . get ( url ) as response : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise PackageNotFoundError ( package = name , url = url ) <TAB> <TAB> <TAB> response . raise_for_status ( ) <TAB> <TAB> <TAB> response = await response . json ( ) <TAB> dist = response [ "" info "" ] [ "" requires_dist "" ] or [ ] <TAB> if dist : <TAB> <TAB> return dist <TAB> # If no requires_dist then package metadata can be broken. <TAB> # Let's check distribution files. <TAB> return await self._get_from_files(response[""urls""])","if response [ ""status"" ] == 404 :",if response . status == 404 :,False,97.35,68.32,,,
"def is_active ( self ) : <TAB> if not self . pk : <TAB> <TAB> log_level = get_setting ( "" LOG_MISSING_SWITCHES "" ) <TAB> <TAB> if log_level : <TAB> <TAB> <TAB> logger . log ( log_level , "" Switch  %s  not found "" , self . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> switch , _created = Switch . objects . get_or_create ( <TAB> <TAB> <TAB> <TAB> name = self . name , defaults = { "" active "" : get_setting ( "" SWITCH_DEFAULT "" ) } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cache = get_cache ( ) <TAB> <TAB> <TAB> cache . set ( self . _cache_key ( self . name ) , switch ) <TAB> <TAB> return get_setting ( "" SWITCH_DEFAULT "" ) <TAB> return self . active",if self . active :,"if get_setting ( ""CREATE_MISSING_SWITCHES"" ) :",False,94.19,68.6,,,
"def add_requirements ( self , requirements ) : <TAB> if self . _legacy : <TAB> <TAB> self . _legacy . add_requirements ( requirements ) <TAB> else : <TAB> <TAB> run_requires = self . _data . setdefault ( "" run_requires "" , [ ] ) <TAB> <TAB> always = None <TAB> <TAB> for entry in run_requires : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> always = entry <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if always is None : <TAB> <TAB> <TAB> always = { "" requires "" : requirements } <TAB> <TAB> <TAB> run_requires . insert ( 0 , always ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rset = set ( always [ "" requires "" ] ) | set ( requirements ) <TAB> <TAB> <TAB> always [ "" requires "" ] = sorted ( rset )","if entry [ ""requires"" ] == requirements :","if ""environment"" not in entry and ""extra"" not in entry :",False,94.27,66.71,,,
"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """""" Display a failure for a single method / endpoint. """""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB> <TAB> message : Optional [ str ] <TAB> <TAB> if check . message : <TAB> <TAB> <TAB> message = f "" { idx } .  { check . message } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast ( Case , check . example ) # filtered in `_get_unique_failures` <TAB> <TAB> display_example(example, check.name, message, result.seed) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> click.echo(""\n"")",if idx > 0 :,if idx != len ( checks ) :,False,96.85,97.23,,,
"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code . co_name == "" trace_types "" <TAB> <TAB> or self . should_trace <TAB> <TAB> and not self . should_trace ( code ) <TAB> ) : <TAB> <TAB> return self <TAB> try : <TAB> <TAB> if event == EVENT_CALL : <TAB> <TAB> <TAB> self . handle_call ( frame ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . handle_return ( frame , arg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self",elif event == EVENT_RETURN :,elif event == EVENT_RETURN :,True,100.0,74.58,,,
"def get_maps ( test ) : <TAB> pages = set ( ) <TAB> for addr in test [ "" pre "" ] [ "" memory "" ] . keys ( ) : <TAB> <TAB> pages . add ( addr >> 12 ) <TAB> for addr in test [ "" pos "" ] [ "" memory "" ] . keys ( ) : <TAB> <TAB> pages . add ( addr >> 12 ) <TAB> maps = [ ] <TAB> for p in sorted ( pages ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> maps [ - 1 ] = ( maps [ - 1 ] [ 0 ] , maps [ - 1 ] [ 1 ] + 0x1000 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> maps . append ( ( p << 12 , 0x1000 ) ) <TAB> return maps",if p == 0 :,if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 :,False,85.3,65.99,,,
"def process_rotate_aes_key ( self ) : <TAB> if hasattr ( self . options , "" rotate_aes_key "" ) and isinstance ( <TAB> <TAB> self . options . rotate_aes_key , six . string_types <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . options . rotate_aes_key = True <TAB> <TAB> elif self . options . rotate_aes_key . lower ( ) == "" false "" : <TAB> <TAB> <TAB> self . options . rotate_aes_key = False","if self . options . rotate_aes_key . lower ( ) == ""true"" :","if self . options . rotate_aes_key . lower ( ) == ""true"" :",True,100.0,74.27,,,
"def apply_figure ( self , figure ) : <TAB> super ( legend_text_legend , self ) . apply_figure ( figure ) <TAB> properties = self . properties . copy ( ) <TAB> with suppress ( KeyError ) : <TAB> <TAB> del properties [ "" margin "" ] <TAB> with suppress ( KeyError ) : <TAB> <TAB> texts = figure . _themeable [ "" legend_text_legend "" ] <TAB> <TAB> for text in texts : <TAB> <TAB> <TAB> <IF-STMT> # textarea <TAB> <TAB> <TAB> <TAB> text = text._text <TAB> <TAB> <TAB> text.set(**properties)","if isinstance ( text , TextArea ) :","if not hasattr ( text , ""_x"" ) :",False,94.4,65.31,,,
"def tearDown ( self ) : <TAB> for i in range ( len ( self . tree ) - 1 , - 1 , - 1 ) : <TAB> <TAB> s = os . path . join ( self . root , self . tree [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . rmdir ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . remove ( s ) <TAB> os . rmdir ( self . root )",if os . path . isdir ( s ) :,"if not ""."" in s :",False,92.38,61.54,,,
"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> if type != fields [ - 2 ] : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> itype = fields [ - 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id",if itype != fields [ - 1 ] :,if type != itype :,False,96.74,72.97,,,
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon : <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> if s . siblingAbove is None : <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",if s . isAncestorOf ( self ) :,if matchSelf :,False,97.11,73.1,,,
"def records ( account_id ) : <TAB> """""" Fetch locks data """""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB> <TAB> if "" LockDate "" in r : <TAB> <TAB> <TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) )","if ""RevisionDate"" in r :","if ""RevisionDate"" in r :",True,100.0,99.54,,,
"def _handle_errors ( errors ) : <TAB> """""" Log out and possibly reraise errors during import. """""" <TAB> if not errors : <TAB> <TAB> return <TAB> log_all = True # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB> <TAB> err_str = str(err) <TAB> <TAB> if log_all: <TAB> <TAB> <TAB> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""From module %s"" % module) <TAB> <TAB> <TAB> raise err",if module not in data_generators :,"if not _is_import_err_msg ( err_str , module ) :",False,92.36,95.24,,,
"def find_needle ( self , tree , focused = None ) : <TAB> if isinstance ( tree , list ) : <TAB> <TAB> for el in tree : <TAB> <TAB> <TAB> res = self . find_needle ( el , focused ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return res <TAB> elif isinstance ( tree , dict ) : <TAB> <TAB> nodes = tree . get ( "" nodes "" , [ ] ) + tree . get ( "" floating_nodes "" , [ ] ) <TAB> <TAB> if focused : <TAB> <TAB> <TAB> for node in nodes : <TAB> <TAB> <TAB> <TAB> if node [ "" id "" ] == focused [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return tree <TAB> <TAB> elif tree [ "" focused "" ] : <TAB> <TAB> <TAB> return tree <TAB> <TAB> return self . find_needle ( nodes , focused ) <TAB> return { }",if res :,if res :,True,100.0,74.61,,,
"def available_datasets ( self ) : <TAB> """""" Automatically determine datasets provided by this file """""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB> <TAB> if isinstance ( val , netCDF4 . Variable ) : <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB> <TAB> <TAB> <TAB> "" resolution "" : res , <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ds_info [ "" coordinates "" ] = coordinates <TAB> <TAB> <TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info",if val . coordinates :,if not self . is_geo :,False,96.74,79.77,,,
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB> if end_slash >= 0: <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB> if not sub: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",if test_path . startswith ( parent_path ) :,if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) :,False,96.18,70.05,,,
"def default ( self , o ) : <TAB> try : <TAB> <TAB> if type ( o ) == datetime . datetime : <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> if hasattr(o, ""services_config""): <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)","if hasattr ( o , ""credentials"" ) :","if hasattr ( o , ""credentials"" ) :",True,100.0,74.49,,,
"def submit ( self , fn , * args , * * kwargs ) : <TAB> with self . _shutdown_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot schedule new futures after shutdown "" ) <TAB> <TAB> f = _base . Future ( ) <TAB> <TAB> w = _WorkItem ( f , fn , args , kwargs ) <TAB> <TAB> self . _work_queue . put ( w ) <TAB> <TAB> self . _adjust_thread_count ( ) <TAB> <TAB> return f",if self . _shutdown :,if self . _shutdown :,True,100.0,74.26,,,
"def __viewerKeyPress ( viewer , event ) : <TAB> view = viewer . view ( ) <TAB> if not isinstance ( view , GafferSceneUI . SceneView ) : <TAB> <TAB> return False <TAB> if event == __editSourceKeyPress : <TAB> <TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> __editSourceNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB> <TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> __editTweaksNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB> <TAB> return True",if selectedPath :,if selectedPath is not None :,False,95.13,70.23,,,
"def _split_to_option_groups_and_paths ( self , args ) : <TAB> opt_groups = [ ] <TAB> current = [ ] <TAB> for arg in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> opts = self . _arg_parser . parse_args ( current ) [ 0 ] <TAB> <TAB> <TAB> opt_groups . append ( opts ) <TAB> <TAB> <TAB> current = [ ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current . append ( arg ) <TAB> if opt_groups : <TAB> <TAB> return opt_groups , current <TAB> raise ValueError ( "" Nothing to split "" )","if arg == ""groups"" :","if arg . replace ( ""-"" , """" ) == """" and len ( arg ) >= 3 :",False,87.85,60.68,,,
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed",if value != False :,if value :,False,97.98,73.57,,,
"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB> <TAB> <TAB> if target_pid == pid : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out """,if e . errno == errno . EPERM :,if e . args [ 0 ] == errno . ECHILD :,False,95.94,71.27,,,
"def _get_os_version_lsb_release ( ) : <TAB> try : <TAB> <TAB> output = subprocess . check_output ( "" lsb_release -sri "" , shell = True ) <TAB> <TAB> lines = output . strip ( ) . split ( ) <TAB> <TAB> name , version = lines <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> version = "" "" <TAB> <TAB> return name , version <TAB> except : <TAB> <TAB> return _get_os_version_uname ( )","if version == """" :","if version . lower ( ) == ""rolling"" :",False,93.95,63.84,,,
"def _check_snapshot_status_healthy ( self , snapshot_uuid ) : <TAB> status = "" "" <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> status , locked = self . _get_snapshot_status ( snapshot_uuid ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> eventlet . sleep ( 2 ) <TAB> except Exception : <TAB> <TAB> with excutils . save_and_reraise_exception ( ) : <TAB> <TAB> <TAB> LOG . exception ( "" Failed to get snapshot status. [ %s ] "" , snapshot_uuid ) <TAB> LOG . debug ( <TAB> <TAB> "" Lun [ %(snapshot)s ], status [ %(status)s ]. "" , <TAB> <TAB> { "" snapshot "" : snapshot_uuid , "" status "" : status } , <TAB> ) <TAB> return status == "" Healthy """,if locked :,if not locked :,False,98.9,73.42,,,
"def CountButtons ( self ) : <TAB> """""" Returns the number of visible buttons in the docked pane. """""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMaximizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasPinButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> return n",if self . HasMinimizeButton ( ) :,if self . HasCloseButton ( ) :,False,98.66,98.52,,,
"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB> <TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( key , bytes ) : <TAB> <TAB> <TAB> key = text_type ( key ) . encode ( charset ) <TAB> <TAB> if not isinstance ( value , bytes ) : <TAB> <TAB> <TAB> value = text_type ( value ) . encode ( charset ) <TAB> <TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value )",if key not in encode_keys :,if value is None :,False,96.4,72.35,,,
"def get_response ( self , exc_fmt = None ) : <TAB> self . callback = None <TAB> if __debug__ : <TAB> <TAB> self . parent . _log ( 3 , "" %s : %s .ready.wait "" % ( self . name , self . tag ) ) <TAB> self . ready . wait ( ) <TAB> if self . aborted is not None : <TAB> <TAB> typ , val = self . aborted <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exc_fmt = "" %s  -  %% s "" % typ <TAB> <TAB> raise typ ( exc_fmt % str ( val ) ) <TAB> return self . response",if exc_fmt is None :,if exc_fmt is None :,True,100.0,74.45,,,
"def extract_items ( self ) : <TAB> responses = self . fetch ( ) <TAB> items = [ ] <TAB> for response in responses : <TAB> <TAB> page_key = response . meta . get ( "" page_key "" ) or response . url <TAB> <TAB> item = { "" key "" : page_key , "" items "" : None , "" templates "" : None } <TAB> <TAB> extracted_items = [ <TAB> <TAB> <TAB> dict ( i ) for i in self . spider . parse ( response ) if not isinstance ( i , Request ) <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> item [ "" items "" ] = extracted_items <TAB> <TAB> <TAB> item [ "" templates "" ] = [ <TAB> <TAB> <TAB> <TAB> i [ "" _template "" ] for i in extracted_items if i . get ( "" _template "" ) <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items","if item [ ""items"" ] :",if extracted_items :,False,97.11,70.18,,,
"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB> <TAB> if self . with_centering : <TAB> <TAB> <TAB> self . median [ i ] . update ( xi ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . iqr [ i ] . update ( xi ) <TAB> return self",elif self . with_iqr :,if self . with_scaling :,False,94.59,70.09,,,
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right",if allowed_chars and text [ left ] in allowed_chars :,elif not self . word_boundary_char ( text [ left - 1 ] ) :,False,92.61,69.69,,,
"def _validate_duplicate_detection_history_time_window ( namespace ) : <TAB> if namespace . duplicate_detection_history_time_window : <TAB> <TAB> if iso8601pattern . match ( namespace . duplicate_detection_history_time_window ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> raise CLIError ( <TAB> <TAB> <TAB> <TAB> "" --duplicate-detection-history-time-window Value Error :  {0}  value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> namespace . duplicate_detection_history_time_window <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",elif time_range . match ( namespace . duplicate_detection_history_time_window ) :,elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) :,False,98.01,73.31,,,
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB> if end_slash >= 0: <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",if sub == parent_path :,if not sub :,False,97.36,72.39,,,
"def generator ( self , data ) : <TAB> <IF-STMT> <TAB> <TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB> <TAB> for var , val in task . environment_variables ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if var in silent_vars : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int ( task . UniqueProcessId ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( task . ImageFileName ) , <TAB> <TAB> <TAB> <TAB> <TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( var ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( val ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> )",if self . _is_silent :,if self . _config . SILENT :,False,96.87,71.72,,,
"def start_requests ( self ) : <TAB> if self . fail_before_yield : <TAB> <TAB> 1 / 0 <TAB> for s in range ( 100 ) : <TAB> <TAB> qargs = { "" total "" : 10 , "" seed "" : s } <TAB> <TAB> url = self . mockserver . url ( "" /follow? %s "" ) % urlencode ( qargs , doseq = 1 ) <TAB> <TAB> yield Request ( url , meta = { "" seed "" : s } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> 2 / 0 <TAB> assert self . seedsseen , "" All start requests consumed before any download happened """,if self . fail_before_yield :,if self . fail_yielding :,False,97.12,73.33,,,
"def populateGridlines ( self ) : <TAB> cTicks = self . getSystemCurve ( self . ticksId ) <TAB> cGridlines = self . getSystemCurve ( self . gridlinesId ) <TAB> cGridlines . clearPoints ( ) <TAB> nTicks = cTicks . getNPoints ( ) <TAB> for iTick in range ( nTicks ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p = cTicks . getPoint ( iTick ) <TAB> <TAB> <TAB> cGridlines . addPoint ( p . getX ( ) , p . getY ( ) )",if cTicks . hasPoint ( iTick ) :,if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 :,False,88.29,67.39,,,
"def handle_before_events ( request , event_list ) : <TAB> if not event_list : <TAB> <TAB> return "" "" <TAB> if not hasattr ( event_list , "" __iter__ "" ) : <TAB> <TAB> project = event_list . project <TAB> <TAB> event_list = [ event_list ] <TAB> else : <TAB> <TAB> projects = set ( e . project for e in event_list ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> project = projects . pop ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> project = None <TAB> for plugin in plugins . for_project ( project ) : <TAB> <TAB> safe_execute ( plugin . before_events , request , event_list ) <TAB> return "" """,if projects :,if len ( projects ) == 1 :,False,95.79,71.48,,,
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> <TAB> if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 : <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args )",if self . multiple and len ( opts [ self . name ] ) > 1 :,if self . mutually_exclusive . intersection ( opts ) :,False,90.11,68.95,,,
"def current_word ( cursor_offset , line ) : <TAB> """""" the object.attribute.attribute just before or under the cursor """""" <TAB> pos = cursor_offset <TAB> start = pos <TAB> end = pos <TAB> word = None <TAB> for m in current_word_re . finditer ( line ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> start = m . start ( 1 ) <TAB> <TAB> <TAB> end = m . end ( 1 ) <TAB> <TAB> <TAB> word = m . group ( 1 ) <TAB> if word is None : <TAB> <TAB> return None <TAB> return LinePart ( start , end , word )",if m . start ( 1 ) == start and m . end ( 1 ) == end :,if m . start ( 1 ) < pos and m . end ( 1 ) >= pos :,False,95.13,95.59,,,
"def query_to_script_path ( path , query ) : <TAB> if path != "" * "" : <TAB> <TAB> script = os . path . join ( path , query . split ( "" "" ) [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IOError ( "" Script  ' {} '  not found in script directory "" . format ( query ) ) <TAB> <TAB> return os . path . join ( path , query ) . split ( "" "" ) <TAB> return query",if not script . exists ( ) :,if not os . path . exists ( script ) :,False,94.58,70.89,,,
"def expand ( self , pbegin ) : <TAB> # TODO(b/151921205): we have to do an identity map for unmodified <TAB> # PCollections below because otherwise we get an error from beam. <TAB> identity_map = ""Identity"" >> beam.Map(lambda x: x) <TAB> if self._dataset_key.is_flattened_dataset_key(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self._flat_pcollection | identity_map <TAB> <TAB> else: <TAB> <TAB> <TAB> return list( <TAB> <TAB> <TAB> <TAB> self._pcollection_dict.values() <TAB> <TAB> <TAB> ) | ""FlattenAnalysisInputs"" >> beam.Flatten(pipeline=pbegin.pipeline) <TAB> else: <TAB> <TAB> return self._pcollection_dict[self._dataset_key] | identity_map",if self . _flat_pcollection :,if self . _flat_pcollection :,True,100.0,74.28,,,
"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB> <TAB> for _dir , offsets in faceDirections : <TAB> <TAB> <TAB> if _dir == FaceYIncreasing : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx , dy , dz = offsets <TAB> <TAB> <TAB> p = ( x + dx , y + dy , z + dz ) <TAB> <TAB> <TAB> if p not in box : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx , ny , nz = p <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB> <TAB> <TAB> <TAB> newcoords . append ( p ) <TAB> return newcoords",if nx != nx and ny != nz :,"if level . blockAt ( nx , ny , nz ) == 0 :",False,94.08,70.22,,,
"def delete_byfilter ( userId , remove = True , session = None , * * dbfilter ) : <TAB> if not session : <TAB> <TAB> session = db . Session <TAB> ret = False <TAB> results = session . query ( ObjectStorageMetadata ) . filter_by ( * * dbfilter ) <TAB> if results : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> session . delete ( result ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" record_state_key "" : "" to_delete "" , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" record_state_val "" : str ( time . time ( ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ret = True <TAB> return ret",if remove :,if remove :,True,100.0,74.58,,,
"def fields ( self , fields ) : <TAB> fields_xml = "" "" <TAB> for field in fields : <TAB> <TAB> field_dict = DEFAULT_FIELD . copy ( ) <TAB> <TAB> field_dict . update ( field ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field_dict [ "" required "" ] = "" true "" <TAB> <TAB> fields_xml + = FIELD_XML_TEMPLATE % field_dict + "" \n "" <TAB> self . xml = force_unicode ( <TAB> <TAB> force_unicode ( self . xml ) . replace ( <TAB> <TAB> <TAB> u "" <!-- REPLACE FIELDS --> "" , force_unicode ( fields_xml ) <TAB> <TAB> ) <TAB> )",if field . required :,"if self . unique_key_field == field [ ""name"" ] :",False,91.44,66.42,,,
"def get_all_users ( self , access_token , timeout = None ) : <TAB> if timeout is None : <TAB> <TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self . retrieve_header ( access_token ) <TAB> try : <TAB> <TAB> response = await self . standard_request ( <TAB> <TAB> <TAB> "" get "" , "" /walkoff/api/users "" , timeout = DEFAULT_TIMEOUT , headers = headers <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resp = await response . json ( ) <TAB> <TAB> <TAB> return resp , "" Success "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" Invalid Credentials "" <TAB> except asyncio . CancelledError : <TAB> <TAB> return False , "" TimedOut """,if response . status == 200 :,if response . status == 200 :,True,100.0,74.5,,,
"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB> <TAB> row = model [ idx ] <TAB> <TAB> if value and row [ 0 ] == value : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB> <TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB> <TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB> <TAB> return None",if idx == len ( model ) - 1 :,if idx == len ( os_widget . get_model ( ) ) - 1 :,False,94.35,71.73,,,
"def translate_module_name ( module : str , relative : int ) - > Tuple [ str , int ] : <TAB> for pkg in VENDOR_PACKAGES : <TAB> <TAB> for alt in "" six.moves "" , "" six "" : <TAB> <TAB> <TAB> substr = "" {} . {} "" . format ( pkg , alt ) <TAB> <TAB> <TAB> if module . endswith ( "" . "" + substr ) or ( module == substr and relative ) : <TAB> <TAB> <TAB> <TAB> return alt , 0 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return alt + "" . "" + module . partition ( "" . "" + substr + "" . "" ) [ 2 ] , 0 <TAB> return module , relative",elif module . endswith ( substr ) or ( module == substr and relative ) :,"if ""."" + substr + ""."" in module :",False,91.33,66.82,,,
"def escape ( m ) : <TAB> all , tail = m . group ( 0 , 1 ) <TAB> assert all . startswith ( "" \\ "" ) <TAB> esc = simple_escapes . get ( tail ) <TAB> if esc is not None : <TAB> <TAB> return esc <TAB> if tail . startswith ( "" x "" ) : <TAB> <TAB> hexes = tail [ 1 : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB> <TAB> try : <TAB> <TAB> <TAB> i = int ( hexes , 16 ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> i = int ( tail , 8 ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" invalid octal string escape ( ' \\ %s ' ) "" % tail ) <TAB> return chr ( i )","if hexes . startswith ( ""x"" ) :",if len ( hexes ) < 2 :,False,96.78,68.51,,,
"def __get_k8s_container_name ( self , job_wrapper ) : <TAB> # These must follow a specific regex for Kubernetes. <TAB> raw_id = job_wrapper.job_destination.id <TAB> if isinstance(raw_id, str): <TAB> <TAB> cleaned_id = re.sub(""[^-a-z0-9]"", ""-"", raw_id) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cleaned_id = ""x%sx"" % cleaned_id <TAB> <TAB> return cleaned_id <TAB> return ""job-container""","if cleaned_id . startswith ( ""kubernetes-container-"" ) :","if cleaned_id . startswith ( ""-"" ) or cleaned_id . endswith ( ""-"" ) :",False,91.24,62.64,,,
"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB> <TAB> yc / / = 10 <TAB> <TAB> ye + = 1 <TAB> if xc == 1 : <TAB> <TAB> xe * = yc <TAB> <TAB> while xe % 10 == 0 : <TAB> <TAB> <TAB> xe / / = 10 <TAB> <TAB> <TAB> ye + = 1 <TAB> <TAB> if ye < 0 : <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 * * ye <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else : <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5",if exponent > 0 :,if y and xe :,False,97.82,72.67,,,
"def lpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB> <TAB> _client . lpush ( key , * vals ) <TAB> else : <TAB> <TAB> pipe = _client . pipeline ( ) <TAB> <TAB> pipe . lpush ( key , * vals ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pipe . ltrim ( key , 0 , cap ) <TAB> <TAB> if ttl : <TAB> <TAB> <TAB> pipe . expire ( key , ttl ) <TAB> <TAB> pipe . execute ( )",if cap :,if cap :,True,100.0,74.46,,,
"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b "" Content-Disposition: form-data;  "" , <TAB> <TAB> <TAB> format_form_param ( "" name "" , self . name ) , <TAB> <TAB> ] <TAB> <TAB> if self . filename : <TAB> <TAB> <TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB> <TAB> <TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> content_type = self . content_type . encode ( ) <TAB> <TAB> <TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB> <TAB> parts . append ( b "" \r \n \r \n "" ) <TAB> <TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers",if self . content_type :,if self . content_type is not None :,False,98.24,72.86,,,
"def validate_custom_field_data ( field_type : int , field_data : ProfileFieldData ) - > None : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Choice type field must have at least have one choice <TAB> <TAB> <TAB> if len(field_data) < 1: <TAB> <TAB> <TAB> <TAB> raise JsonableError(_(""Field must have at least one choice."")) <TAB> <TAB> <TAB> validate_choice_field_data(field_data) <TAB> <TAB> elif field_type == CustomProfileField.EXTERNAL_ACCOUNT: <TAB> <TAB> <TAB> validate_external_account_field_data(field_data) <TAB> except ValidationError as error: <TAB> <TAB> raise JsonableError(error.message)",if field_type == CustomProfileField . Choice :,if field_type == CustomProfileField . CHOICE :,False,98.72,72.76,,,
"def get_data ( self , path ) : <TAB> """""" Gross hack to contort loader to deal w/ load_*() ' s bad API. """""" <TAB> if self . file and path == self . path : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> file = self . file <TAB> <TAB> else : <TAB> <TAB> <TAB> self . file = file = open ( self . path , "" r "" ) <TAB> <TAB> with file : <TAB> <TAB> <TAB> # Technically should be returning bytes, but <TAB> <TAB> <TAB> # SourceLoader.get_code() just passed what is returned to <TAB> <TAB> <TAB> # compile() which can handle str. And converting to bytes would <TAB> <TAB> <TAB> # require figuring out the encoding to decode to and <TAB> <TAB> <TAB> # tokenize.detect_encoding() only accepts bytes. <TAB> <TAB> <TAB> return file.read() <TAB> else: <TAB> <TAB> return super().get_data(path)","if isinstance ( self . file , str ) :",if not self . file . closed :,False,96.96,77.69,,,
"def handle_read ( self ) : <TAB> """""" Called when there is data waiting to be read. """""" <TAB> try : <TAB> <TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB> <TAB> pass <TAB> except socket . error : <TAB> <TAB> self . handle_error ( ) <TAB> else : <TAB> <TAB> self . tot_bytes_received + = len ( chunk ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . transfer_finished = True <TAB> <TAB> <TAB> # self.close() # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> if self._data_wrapper is not None: <TAB> <TAB> <TAB> chunk = self._data_wrapper(chunk) <TAB> <TAB> try: <TAB> <TAB> <TAB> self.file_obj.write(chunk) <TAB> <TAB> except OSError as err: <TAB> <TAB> <TAB> raise _FileReadWriteError(err)",if self . tot_bytes_received >= self . ac_in_buffer_size :,if not chunk :,False,93.07,94.73,,,
"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB> <TAB> <TAB> if not ( "" < "" in line or line in dep ) : <TAB> <TAB> <TAB> <TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ]","if line . startswith ( ""dependency"" ) :","if line . startswith ( ""#include"" ) or line . startswith ( ""%include"" ) :",False,91.19,91.37,,,
"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB> <TAB> if not self . editing : <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets )",elif self . editing and self . start_display_at > 0 :,elif scroll_if_editing :,False,90.96,71.07,,,
"def test_getline ( self ) : <TAB> with tokenize . open ( self . file_name ) as fp : <TAB> <TAB> for index , line in enumerate ( fp ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> line + = "" \n "" <TAB> <TAB> <TAB> cached_line = linecache . getline ( self . file_name , index + 1 ) <TAB> <TAB> <TAB> self . assertEqual ( line , cached_line )",if line :,"if not line . endswith ( ""\n"" ) :",False,90.85,62.15,,,
"def selectRow ( self , rowNumber , highlight = None ) : <TAB> if rowNumber == "" h "" : <TAB> <TAB> rowNumber = 0 <TAB> else : <TAB> <TAB> rowNumber = int ( rowNumber ) + 1 <TAB> if 1 > rowNumber > = len ( self . cells ) + 1 : <TAB> <TAB> raise Exception ( "" Invalid row number. "" ) <TAB> else : <TAB> <TAB> selected = self . cells [ rowNumber ] [ 0 ] . selected <TAB> <TAB> for cell in self . cells [ rowNumber ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if selected : <TAB> <TAB> <TAB> <TAB> <TAB> cell . deselect ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> cell . select ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if highlight : <TAB> <TAB> <TAB> <TAB> <TAB> cell . mouseEnter ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> cell . mouseLeave ( )",if cell . isVisible ( ) :,if highlight is None :,False,97.74,72.89,,,
"def put ( self , session ) : <TAB> with sess_lock : <TAB> <TAB> self . parent . put ( session ) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self.skip_paths: <TAB> <TAB> <TAB> if request.path.startswith(sp): <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> del self._cache[session.sid] <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self._cache[session.sid] = session <TAB> self._normalize()",if session . sid in self . _cache :,if session . sid in self . _cache :,True,100.0,74.31,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 18 :,if tt == 18 :,True,100.0,74.56,,,
"def extract ( self , zip ) : <TAB> max_nb = maxNbFile ( self ) <TAB> for index , field in enumerate ( zip . array ( "" file "" ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . warning ( <TAB> <TAB> <TAB> <TAB> "" ZIP archive contains many files, but only first  %s  files are processed "" <TAB> <TAB> <TAB> <TAB> % max_nb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . processFile ( field )",if index > max_nb :,if max_nb is not None and max_nb <= index :,False,91.24,68.71,,,
"def get_norm ( norm , out_channels ) : <TAB> if isinstance ( norm , str ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> norm = { <TAB> <TAB> <TAB> "" BN "" : BatchNorm2d , <TAB> <TAB> <TAB> "" GN "" : lambda channels : nn . GroupNorm ( 32 , channels ) , <TAB> <TAB> <TAB> "" nnSyncBN "" : nn . SyncBatchNorm , # keep for debugging <TAB> <TAB> <TAB> """": lambda x: x, <TAB> <TAB> }[norm] <TAB> return norm(out_channels)","if norm == ""nnBatchNorm2d"" :",if len ( norm ) == 0 :,False,95.13,65.98,,,
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self . _dicts : <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr",elif self . _aggregates :,elif self . _aggregate_rows :,False,98.22,73.73,,,
"def emitIpToDomainsData ( self , data , event ) : <TAB> self . emitRawRirData ( data , event ) <TAB> domains = data . get ( "" domains "" ) <TAB> if isinstance ( domains , list ) : <TAB> <TAB> for domain in domains : <TAB> <TAB> <TAB> if self . checkForStop ( ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> domain = domain . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . emitHostname ( domain , event )",if domain :,if domain :,True,100.0,74.31,,,
"def delete ( self ) : <TAB> from weblate . trans . models import Change , Suggestion , Vote <TAB> fast_deletes = [ ] <TAB> for item in self . fast_deletes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fast_deletes . append ( Vote . objects . filter ( suggestion__in = item ) ) <TAB> <TAB> <TAB> fast_deletes . append ( Change . objects . filter ( suggestion__in = item ) ) <TAB> <TAB> fast_deletes . append ( item ) <TAB> self . fast_deletes = fast_deletes <TAB> return super ( ) . delete ( )",if Suggestion . objects . filter ( suggestion__in = item ) . exists ( ) :,if item . model is Suggestion :,False,88.92,69.38,,,
"def token ( self ) : <TAB> if not self . _token : <TAB> <TAB> try : <TAB> <TAB> <TAB> cookie_token = self . state [ "" request "" ] . headers . cookie [ CSRF_TOKEN ] . value <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> cookie_token = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _token = cookie_token <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _token = get_random_string ( TOKEN_LENGTH ) <TAB> return self . _token",if cookie_token :,if len ( cookie_token ) == TOKEN_LENGTH :,False,92.78,70.28,,,
"def get_logs ( last_file = None , last_time = None ) : <TAB> try : <TAB> <TAB> response = client . get_logs ( last_file = last_file , last_time = last_time ) <TAB> <TAB> get_logs_streamer ( <TAB> <TAB> <TAB> show_timestamp = not hide_time , <TAB> <TAB> <TAB> all_containers = all_containers , <TAB> <TAB> <TAB> all_info = all_info , <TAB> <TAB> ) ( response ) <TAB> <TAB> return response <TAB> except ( ApiException , HTTPError ) as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> handle_cli_error ( <TAB> <TAB> <TAB> <TAB> e , <TAB> <TAB> <TAB> <TAB> message = "" Could not get logs for run ` {} `. "" . format ( client . run_uuid ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 )",if show_error :,if not follow :,False,98.18,73.08,,,
"def update ( self , targets ) : <TAB> Section . update ( self , targets ) <TAB> outputNames = set ( ) <TAB> for target in targets : <TAB> <TAB> g = target . globals ( ) <TAB> <TAB> outputNames . update ( [ k for k in g . keys ( ) if k . startswith ( "" output: "" ) ] ) <TAB> rows = [ ] <TAB> outputNames = sorted ( outputNames ) <TAB> for outputName in outputNames : <TAB> <TAB> row = self . __rows . get ( outputName ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> row = _OutputRow ( outputName ) <TAB> <TAB> <TAB> self . __rows [ outputName ] = row <TAB> <TAB> row . update ( targets ) <TAB> <TAB> row . setAlternate ( len ( rows ) % 2 ) <TAB> <TAB> rows . append ( row ) <TAB> self . _mainColumn ( ) [ : ] = rows",if row is None :,if row is None :,True,100.0,74.61,,,
"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB> <TAB> if git_branch_line . startswith ( "" * "" ) : <TAB> <TAB> <TAB> git_branch_line = git_branch_line [ 1 : ] <TAB> <TAB> git_branch_line = git_branch_line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB> <TAB> <TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned",if BRANCH_ALIAS_MARKER in git_branch_line :,if BRANCH_ALIAS_MARKER in git_branch_line :,True,100.0,74.46,,,
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len ( line . strip ( ) ) == 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if linenum == 0 :,"if linenum > 0 and line [ 0 ] not in ""\t "" :",False,94.89,61.63,,,
"def resolve_references ( self , note , reflist ) : <TAB> assert len ( note [ "" ids "" ] ) == 1 <TAB> id = note [ "" ids "" ] [ 0 ] <TAB> for ref in reflist : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ref . delattr ( "" refname "" ) <TAB> <TAB> ref [ "" refid "" ] = id <TAB> <TAB> assert len ( ref [ "" ids "" ] ) == 1 <TAB> <TAB> note . add_backref ( ref [ "" ids "" ] [ 0 ] ) <TAB> <TAB> ref . resolved = 1 <TAB> note . resolved = 1",if ref . refname == id :,if ref . resolved :,False,96.57,72.94,,,
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist : <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None : <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide )",if guideDist < minDist :,"if dist ( currentPos , self . ends [ color ] ) == 1 :",False,93.45,70.18,,,
"def __hierarchyViewKeyPress ( hierarchyView , event ) : <TAB> if event == __editSourceKeyPress : <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> __editSourceNode ( <TAB> <TAB> <TAB> <TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> __editTweaksNode ( <TAB> <TAB> <TAB> <TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True",if selectedPath :,if selectedPath is not None :,False,95.34,69.59,,,
"def getSubsegments ( self ) : <TAB> for num , localdata in self . lfh . LocalData : <TAB> <TAB> for bucket , seginfo in localdata . SegmentInfo : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield Win32Subsegment ( self . trace , self . heap , seginfo . ActiveSubsegment )",if seginfo . Bucket != bucket :,if seginfo . ActiveSubsegment == 0 :,False,93.96,70.44,,,
"def test_full_hd_bluray ( self ) : <TAB> cur_test = "" full_hd_bluray "" <TAB> cur_qual = common . Quality . FULLHDBLURAY <TAB> for name , tests in iteritems ( self . test_cases ) : <TAB> <TAB> for test in tests : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( cur_qual , common . Quality . name_quality ( test ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertNotEqual ( cur_qual , common . Quality . name_quality ( test ) )",if name == cur_test :,if name == cur_test :,True,100.0,74.31,,,
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res","elif self . op == ""/"" :","elif self . op == ""/"" :",True,100.0,74.66,,,
"def strip_export_type ( path ) : <TAB> matched = re . search ( r "" #([a-zA-Z0-9 \ -]+ \\ +[a-zA-Z0-9 \ -]+)?$ "" , path . encode ( "" utf-8 "" ) ) <TAB> mime_type = None <TAB> if matched : <TAB> <TAB> fragment = matched . group ( 0 ) <TAB> <TAB> mime_type = matched . group ( 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mime_type = mime_type . replace ( "" + "" , "" / "" ) <TAB> <TAB> path = path [ : - len ( fragment ) ] <TAB> return ( path , mime_type )","if fragment . endswith ( ""/"" ) :",if mime_type is not None :,False,94.39,65.86,,,
"def _save_as_module ( file , data , binary = False ) : <TAB> if not data : <TAB> <TAB> return <TAB> with open ( file , "" w "" ) as f : <TAB> <TAB> f . write ( "" DATA= "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f . write ( ' "" ' ) <TAB> <TAB> <TAB> f . write ( base64 . b64encode ( data ) . decode ( "" ascii "" ) ) <TAB> <TAB> <TAB> f . write ( ' "" ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . write ( str ( data ) . replace ( "" \\ \\ "" , "" \\ "" ) ) <TAB> <TAB> f . flush ( )",if binary :,if binary :,True,100.0,74.5,,,
"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB> <TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if len ( self . _scopeStrictModes ) > 0 : <TAB> <TAB> <TAB> <TAB> self . _scopeStrictModes . pop ( ) <TAB> <TAB> <TAB> self . _useStrictCurrent = True <TAB> <TAB> <TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent )",if text == self . _text :,"if text == '""use strict""' or text == ""'use strict'"" :",False,89.34,62.89,,,
"def run ( self , ttl = None ) : <TAB> self . zeroconf = zeroconf . Zeroconf ( ) <TAB> zeroconf . ServiceBrowser ( self . zeroconf , self . domain , MDNSHandler ( self ) ) <TAB> if ttl : <TAB> <TAB> gobject . timeout_add ( ttl * 1000 , self . shutdown ) <TAB> self . __running = True <TAB> self . __mainloop = gobject . MainLoop ( ) <TAB> context = self . __mainloop . get_context ( ) <TAB> while self . __running : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> context . iteration ( True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> break <TAB> self . zeroconf . close ( ) <TAB> logger . debug ( "" MDNSListener.run() quit "" )",if context . running ( ) :,if context . pending ( ) :,False,98.92,73.78,,,
"def topology_change_notify ( self , port_state ) : <TAB> notice = False <TAB> if port_state is PORT_STATE_FORWARD : <TAB> <TAB> for port in self . ports . values ( ) : <TAB> <TAB> <TAB> if port . role is DESIGNATED_PORT : <TAB> <TAB> <TAB> <TAB> notice = True <TAB> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> notice = True <TAB> if notice : <TAB> <TAB> self . send_event ( EventTopologyChange ( self . dp ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _transmit_tc_bpdu ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _transmit_tcn_bpdu ( )",if port_state == PORT_STATE_STATE_FORWARD :,if self . is_root_bridge :,False,93.51,72.33,,,
def close_open_fds ( keep = None ) : # noqa <TAB> keep = [maybe_fileno(f) for f in (keep or []) if maybe_fileno(f) is not None] <TAB> for fd in reversed(range(get_fdmax(default=2048))): <TAB> <TAB> if fd not in keep: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.close(fd) <TAB> <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise,if exc . errno != errno . EPERM :,if exc . errno != errno . EBADF :,False,98.42,72.49,,,
"def collect_attributes ( options , node , master_list ) : <TAB> """""" Collect all attributes """""" <TAB> for ii in node . instructions : <TAB> <TAB> if field_check ( ii , "" attributes "" ) : <TAB> <TAB> <TAB> s = getattr ( ii , "" attributes "" ) <TAB> <TAB> <TAB> if isinstance ( s , list ) : <TAB> <TAB> <TAB> <TAB> for x in s : <TAB> <TAB> <TAB> <TAB> <TAB> if x not in master_list : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> master_list . append ( x ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> master_list . append ( s ) <TAB> for nxt in node . next . values ( ) : <TAB> <TAB> collect_attributes ( options , nxt , master_list )","elif isinstance ( s , dict ) :",elif s != None and s not in master_list :,False,94.62,94.13,,,
"def remove_test_run_directories ( expiry_time : int = 60 * 60 ) - > int : <TAB> removed = 0 <TAB> directories = glob . glob ( os . path . join ( UUID_VAR_DIR , "" test-backend "" , "" run_* "" ) ) <TAB> for test_run in directories : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( test_run ) <TAB> <TAB> <TAB> <TAB> removed + = 1 <TAB> <TAB> <TAB> except FileNotFoundError : <TAB> <TAB> <TAB> <TAB> pass <TAB> return removed",if os . path . exists ( test_run ) :,if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time :,False,89.34,66.86,,,
"def read_work_titles ( fields ) : <TAB> found = [ ] <TAB> if "" 240 "" in fields : <TAB> <TAB> for line in fields [ "" 240 "" ] : <TAB> <TAB> <TAB> title = join_subfield_values ( line , [ "" a "" , "" m "" , "" n "" , "" p "" , "" r "" ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> found . append ( title ) <TAB> if "" 130 "" in fields : <TAB> <TAB> for line in fields [ "" 130 "" ] : <TAB> <TAB> <TAB> title = "" "" . join ( get_lower_subfields ( line ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> found . append ( title ) <TAB> return { "" work_titles "" : found } if found else { }",if title not in found :,if title not in found :,True,100.0,74.59,,,
"def _process_v1_msg ( prot , msg ) : <TAB> header = None <TAB> body = msg [ 1 ] <TAB> if not isinstance ( body , ( binary_type , mmap , memoryview ) ) : <TAB> <TAB> raise ValidationError ( body , "" Body must be a bytestream. "" ) <TAB> if len ( msg ) > 2 : <TAB> <TAB> header = msg [ 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError ( header , "" Header must be a dict. "" ) <TAB> <TAB> for k , v in header . items ( ) : <TAB> <TAB> <TAB> header [ k ] = msgpack . unpackb ( v ) <TAB> ctx = MessagePackMethodContext ( prot , MessagePackMethodContext . SERVER ) <TAB> ctx . in_string = [ body ] <TAB> ctx . transport . in_header = header <TAB> return ctx","if not isinstance ( header , dict ) :","if not isinstance ( header , dict ) :",True,100.0,74.58,,,
"def find ( self , node ) : <TAB> typename = type ( node ) . __name__ <TAB> method = getattr ( self , "" find_ {} "" . format ( typename ) , None ) <TAB> if method is None : <TAB> <TAB> fields = getattr ( node , "" _fields "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> for field in fields : <TAB> <TAB> <TAB> value = getattr ( node , field ) <TAB> <TAB> <TAB> for result in self . find ( value ) : <TAB> <TAB> <TAB> <TAB> yield result <TAB> else : <TAB> <TAB> for result in method ( node ) : <TAB> <TAB> <TAB> yield result",if fields is None :,if fields is None :,True,100.0,74.51,,,
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> if param . type : <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out",if param . name :,if param . name :,True,100.0,74.58,,,
"def _get_image ( self , image_list , source ) : <TAB> if source . startswith ( "" wx "" ) : <TAB> <TAB> img = wx . ArtProvider_GetBitmap ( source , wx . ART_OTHER , _SIZE ) <TAB> else : <TAB> <TAB> path = os . path . join ( _BASE , source ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> img = wx . Image ( path , wx . BITMAP_TYPE_GIF ) . ConvertToBitmap ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> img = wx . Image ( path , wx . BITMAP_TYPE_PNG ) . ConvertToBitmap ( ) <TAB> return image_list . Add ( img )",if wx . GetBitmapType ( path ) == wx . BITMAP_TYPE_GIF :,"if source . endswith ( ""gif"" ) :",False,91.06,63.86,,,
"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB> <TAB> if type ( submob ) != AnnularSector : <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self.opacity_function(r) <TAB> <TAB> submob.set_fill(opacity=alpha)",if submob . is_sector ( ) :,if type ( submob ) == AnnularSector :,False,95.85,71.49,,,
"def _sqlite_post_configure_engine ( url , engine , follower_ident ) : <TAB> from sqlalchemy import event <TAB> @event . listens_for ( engine , "" connect "" ) <TAB> def connect ( dbapi_connection , connection_record ) : <TAB> <TAB> # use file DBs in all cases, memory acts kind of strangely <TAB> <TAB> # as an attached <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dbapi_connection.execute('ATTACH DATABASE ""test_schema.db"" AS test_schema') <TAB> <TAB> else: <TAB> <TAB> <TAB> dbapi_connection.execute( <TAB> <TAB> <TAB> <TAB> 'ATTACH DATABASE ""%s_test_schema.db"" AS test_schema' % follower_ident <TAB> <TAB> <TAB> )","if follower_ident == ""file"" :",if not follower_ident :,False,95.87,66.29,,,
"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB> <TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB> <TAB> if conf_file : <TAB> <TAB> <TAB> with open ( conf_file ) as conf_handle : <TAB> <TAB> <TAB> <TAB> value = fn ( conf_handle ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return value <TAB> return None",if value is not None :,if value :,False,96.59,71.83,,,
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None : <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if a . ptr == b . ptr : <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0",if b is None :,if len ( a ) != b . len :,False,95.66,71.59,,,
"def _get_initialized_app ( app ) : <TAB> """""" Returns a reference to an initialized App instance. """""" <TAB> if app is None : <TAB> <TAB> return firebase_admin . get_app ( ) <TAB> if isinstance ( app , firebase_admin . App ) : <TAB> <TAB> initialized_app = firebase_admin . get_app ( app . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Illegal app argument. App instance not  "" <TAB> <TAB> <TAB> <TAB> "" initialized via the firebase module. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return app <TAB> raise ValueError ( <TAB> <TAB> "" Illegal app argument. Argument must be of type  "" <TAB> <TAB> '  firebase_admin.App, but given  "" {0} "" . ' . format ( type ( app ) ) <TAB> )",if initialized_app is None :,if app is not initialized_app :,False,97.6,70.04,,,
def compiled_query ( self ) : <TAB> <IF-STMT> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . compiled_query_ = CompiledQuery ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . compiled_query_,if self . compiled_query_ is None :,if self . compiled_query_ is None :,True,100.0,99.11,,,
"def clean_subevent ( event , subevent ) : <TAB> if event . has_subevents : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" Subevent cannot be null for event series. "" ) ) <TAB> <TAB> if event != subevent . event : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) <TAB> else : <TAB> <TAB> if subevent : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) )",if subevent is None :,if not subevent :,False,96.89,72.27,,,
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,if length <= self . LENGTH_LIMIT_MEDIUMBLOB :,True,100.0,74.22,,,
"def decompress ( self , data ) : <TAB> if not data : <TAB> <TAB> return data <TAB> if not self . _first_try : <TAB> <TAB> return self . _obj . decompress ( data ) <TAB> self . _data + = data <TAB> try : <TAB> <TAB> decompressed = self . _obj . decompress ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _first_try = False <TAB> <TAB> <TAB> self . _data = None <TAB> <TAB> return decompressed <TAB> except zlib . error : <TAB> <TAB> self . _first_try = False <TAB> <TAB> self . _obj = zlib . decompressobj ( - zlib . MAX_WBITS ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . decompress ( self . _data ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _data = None",if decompressed is not None :,if decompressed :,False,98.02,73.49,,,
"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB> <TAB> self . events [ path ] . append ( events ) <TAB> <TAB> if events | pyuv . fs . UV_RENAME : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . watches . pop ( path ) . close ( )",if path in self . watches :,if not os . path . exists ( path ) :,False,90.47,67.38,,,
"def __init__ ( self , duration , batch_shape , event_shape , validate_args = None ) : <TAB> if duration is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Infer duration from event_shape. <TAB> <TAB> <TAB> duration = event_shape[0] <TAB> elif duration != event_shape[0]: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""duration, event_shape mismatch: {} vs {}"".format(duration, event_shape) <TAB> <TAB> <TAB> ) <TAB> <TAB> # Infer event_shape from duration. <TAB> <TAB> event_shape = torch.Size((duration,) + event_shape[1:]) <TAB> self._duration = duration <TAB> super().__init__(batch_shape, event_shape, validate_args)",if event_shape [ 0 ] is not None :,if event_shape [ 0 ] != 1 :,False,96.34,70.6,,,
"def _CheckPrerequisites ( self ) : <TAB> """""" Exits if any of the prerequisites is not met. """""" <TAB> if not FLAGS . kubectl : <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> "" Please provide path to kubectl tool using --kubectl  "" "" flag. Exiting. "" <TAB> <TAB> ) <TAB> if not FLAGS . kubeconfig : <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> "" Please provide path to kubeconfig using --kubeconfig  "" "" flag. Exiting. "" <TAB> <TAB> ) <TAB> if self . disk_specs and self . disk_specs [ 0 ] . disk_type == disk . STANDARD : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Please provide a list of Ceph Monitors using  "" "" --ceph_monitors flag. "" <TAB> <TAB> <TAB> )",if not FLAGS . ceph_monitors :,if not FLAGS . ceph_monitors :,True,100.0,74.55,,,
"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self.isSystemCurveIndex(iFirstCurve): <TAB> <TAB> return <TAB> nCurves = self.getNCurves() <TAB> for i in range(iFirstCurve, nCurves): <TAB> <TAB> c = self.getSystemCurve(i) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> c.invalidate() <TAB> <TAB> elif i == iFirstCurve: <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices",if c . isDependent ( ) :,"if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) :",False,90.66,66.18,,,
"def find_backwards ( self , offset ) : <TAB> try : <TAB> <TAB> for _ , token_type , token_value in reversed ( self . tokens [ self . offset : offset ] ) : <TAB> <TAB> <TAB> if token_type in ( "" comment "" , "" linecomment "" ) : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> prefix , comment = token_value . split ( None , 1 ) <TAB> <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return [ comment . rstrip ( ) ] <TAB> <TAB> return [ ] <TAB> finally : <TAB> <TAB> self . offset = offset",if prefix == self . prefix :,if prefix in self . comment_tags :,False,96.8,72.49,,,
"def parse_column_definitions ( self , elem ) : <TAB> for column_elem in elem . findall ( "" column "" ) : <TAB> <TAB> name = column_elem . get ( "" name "" , None ) <TAB> <TAB> assert name is not None , "" Required  ' name '  attribute missing from column def "" <TAB> <TAB> index = column_elem . get ( "" index "" , None ) <TAB> <TAB> assert index is not None , "" Required  ' index '  attribute missing from column def "" <TAB> <TAB> index = int ( index ) <TAB> <TAB> self . columns [ name ] = index <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . largest_index = index <TAB> assert "" value "" in self . columns , "" Required  ' value '  column missing from column def "" <TAB> if "" name "" not in self . columns : <TAB> <TAB> self . columns [ "" name "" ] = self . columns [ "" value "" ]",if index > self . largest_index :,if index > self . largest_index :,True,100.0,74.65,,,
"def __find_smallest ( self ) : <TAB> """""" Find the smallest uncovered value in the matrix. """""" <TAB> minval = sys . maxsize <TAB> for i in range ( self . n ) : <TAB> <TAB> for j in range ( self . n ) : <TAB> <TAB> <TAB> if ( not self . row_covered [ i ] ) and ( not self . col_covered [ j ] ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> minval = self . C [ i ] [ j ] <TAB> return minval",if self . C [ i ] [ j ] < minval :,if minval > self . C [ i ] [ j ] :,False,96.88,95.18,,,
"def includes_tools_for_display_in_tool_panel ( self ) : <TAB> if self . includes_tools : <TAB> <TAB> tool_dicts = self . metadata [ "" tools "" ] <TAB> <TAB> for tool_dict in tool_dicts : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if tool_dict [ ""display_in_tool_panel"" ] :","if tool_dict . get ( ""add_to_tool_panel"" , True ) :",False,88.28,65.82,,,
"def commit ( self , notify = False ) : <TAB> if self . editing : <TAB> <TAB> text = self . _text <TAB> <TAB> if text : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> value = self . type ( text ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> value = self . clamp_value ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = self . empty <TAB> <TAB> <TAB> if value is NotImplemented : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self . value = value <TAB> <TAB> self . insertion_point = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . change_text ( unicode ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _text = unicode ( value ) <TAB> <TAB> self . editing = False <TAB> else : <TAB> <TAB> self . insertion_point = None",if notify :,if notify :,True,100.0,74.6,,,
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self.plugin_args.start: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if start > self . plugin_args . end :,if start > self . plugin_args . end :,True,100.0,74.45,,,
"def _check_for_duplicate_host_entries ( self , task_entries ) : <TAB> non_host_statuses = ( <TAB> <TAB> models . HostQueueEntry . Status . PARSING , <TAB> <TAB> models . HostQueueEntry . Status . ARCHIVING , <TAB> ) <TAB> for task_entry in task_entries : <TAB> <TAB> using_host = ( <TAB> <TAB> <TAB> task_entry . host is not None and task_entry . status not in non_host_statuses <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _assert_host_has_no_agent ( task_entry )",if using_host :,if using_host :,True,100.0,74.22,,,
"def get_biggest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> <TAB> if lowest_wall < j [ "" wall_time "" ] : <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall",if lowest_wall is None :,if lowest_wall is None :,True,100.0,74.0,,,
"def log_change_report ( self , old_value , new_value , include_details = False ) : <TAB> from octoprint . util import map_boolean <TAB> with self . _check_mutex : <TAB> <TAB> self . _logger . info ( <TAB> <TAB> <TAB> "" Connectivity changed from  {}  to  {} "" . format ( <TAB> <TAB> <TAB> <TAB> map_boolean ( old_value , "" online "" , "" offline "" ) , <TAB> <TAB> <TAB> <TAB> map_boolean ( new_value , "" online "" , "" offline "" ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log_details ( )",if include_details :,if include_details :,True,100.0,74.38,,,
"def _include_block ( self , value , context = None ) : <TAB> if hasattr ( value , "" render_as_block "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_context = context . get_all ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_context = { } <TAB> <TAB> return jinja2 . Markup ( value . render_as_block ( context = new_context ) ) <TAB> return jinja2 . Markup ( value )",if context :,if context :,True,100.0,74.15,,,
"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try: <TAB> <TAB> A, B = self[0], other[0] <TAB> <TAB> # uses logical clock value first <TAB> <TAB> if A and B: # use logical clock if available <TAB> <TAB> <TAB> <IF-STMT> # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self[2] < other[2] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self[1] < other[1] # ... or use timestamp <TAB> except IndexError: <TAB> <TAB> return NotImplemented",if A == B :,if A == B :,True,100.0,74.35,,,
"def _get_port ( ) : <TAB> while True : <TAB> <TAB> port = 20000 + random . randint ( 1 , 9999 ) <TAB> <TAB> for i in range ( 5 ) : <TAB> <TAB> <TAB> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <TAB> <TAB> <TAB> result = sock . connect_ex ( ( "" 127.0.0.1 "" , port ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> else : <TAB> <TAB> <TAB> return port",if result == 0 :,if result == 0 :,True,100.0,74.31,,,
"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB> if type(targets) != list and type(targets) != tuple: <TAB> <TAB> <TAB> targets = tuple( <TAB> <TAB> <TAB> <TAB> targets, <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> targets = tuple(targets) <TAB> for target in targets: <TAB> <TAB> self._fetch_targets(api_client, q, target)",elif type ( targets ) != list and type ( targets ) != tuple :,elif type ( targets ) != tuple :,False,95.36,72.39,,,
"def migrate_node_facts ( facts ) : <TAB> """""" Migrate facts from various roles into node """""" <TAB> params = { <TAB> <TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB> <TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> if param in facts[role]: <TAB> <TAB> <TAB> <TAB> <TAB> facts[""node""][param] = facts[role].pop(param) <TAB> return facts","if role . startswith ( ""common"" ) :",if role in facts :,False,95.56,93.67,,,
"def build_dimension_param ( self , dimension , params ) : <TAB> prefix = "" Dimensions.member "" <TAB> i = 0 <TAB> for dim_name in dimension : <TAB> <TAB> dim_value = dimension [ dim_name ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( dim_value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> dim_value = [ dim_value ] <TAB> <TAB> <TAB> for value in dim_value : <TAB> <TAB> <TAB> <TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB> <TAB> <TAB> <TAB> params [ "" %s . %d .Value "" % ( prefix , i + 1 ) ] = value <TAB> <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB> <TAB> <TAB> i + = 1",if dim_value is not None :,if dim_value :,False,98.32,73.64,,,
"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> for typ , key in keys : <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if flag : <TAB> <TAB> <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] = keys",if typ == _typ and _key == key :,if _typ == typ and key is _key :,False,96.36,71.85,,,
"def run ( self ) : <TAB> while True : <TAB> <TAB> message = self . in_queue . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . reset ( ) <TAB> <TAB> elif message == EXIT : <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> index , transaction = message <TAB> <TAB> <TAB> self . results_queue . put ( ( index , self . validate ( transaction ) ) )",if message == START :,if message == RESET :,False,98.0,72.62,,,
"def __run ( self ) : <TAB> threads = self . parameters ( ) [ "" threads "" ] . getTypedValue ( ) <TAB> with IECore . tbb_global_control ( <TAB> <TAB> IECore . tbb_global_control . parameter . max_allowed_parallelism , <TAB> <TAB> IECore . hardwareConcurrency ( ) if threads == 0 else threads , <TAB> ) : <TAB> <TAB> self . _executeStartupFiles ( self . root ( ) . getName ( ) ) <TAB> <TAB> # Append DEBUG message with process information to all messages <TAB> <TAB> defaultMessageHandler = IECore.MessageHandler.getDefaultHandler() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> IECore.MessageHandler.setDefaultHandler( <TAB> <TAB> <TAB> <TAB> Gaffer.ProcessMessageHandler(defaultMessageHandler) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self._run(self.parameters().getValidatedValue())",if defaultMessageHandler :,"if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) :",False,95.24,70.04,,,
"def adjust_uri ( self , uri , relativeto ) : <TAB> """""" Adjust the given ``uri`` based on the given relative URI. """""" <TAB> key = ( uri , relativeto ) <TAB> if key in self . _uri_cache : <TAB> <TAB> return self . _uri_cache [ key ] <TAB> if uri [ 0 ] != "" / "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = self . _uri_cache [ key ] = posixpath . join ( <TAB> <TAB> <TAB> <TAB> posixpath . dirname ( relativeto ) , uri <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = self . _uri_cache [ key ] = "" / "" + uri <TAB> else : <TAB> <TAB> v = self . _uri_cache [ key ] = uri <TAB> return v",if relativeto :,if relativeto is not None :,False,97.93,96.35,,,
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> elif c == "" - "" and decode : <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> elif decode : <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )","if c == ""&"" and not decode :","if c == ""&"" and not decode :",True,100.0,74.66,,,
"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if line . startswith ( "" - "" ) : <TAB> <TAB> <TAB> args . extend ( self . _split_option ( line ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . append ( line ) <TAB> return args","elif line . startswith ( ""#"" ) :","elif line and not line . startswith ( ""#"" ) :",False,96.85,71.6,,,
"def _method_events_callback ( self , values ) : <TAB> try : <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB> <TAB> ) <TAB> <TAB> if previous_echoed . endswith ( "" foo1 "" ) : <TAB> <TAB> <TAB> return "" echo foo2 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB> <TAB> <TAB> return "" echo foo3 \n "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" exit \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB> <TAB> return "" echo foo1 \n ""","elif previous_echoed . endswith ( ""foo3"" ) :","elif previous_echoed . endswith ( ""foo3"" ) :",True,100.0,74.56,,,
"def __delete_hook ( self , rpc ) : <TAB> try : <TAB> <TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB> <TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( DELETE_SUCCESSFUL ) <TAB> <TAB> elif status == MemcacheDeleteResponse . NOT_FOUND : <TAB> <TAB> <TAB> result . append ( DELETE_ITEM_MISSING ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result",if status == MemcacheDeleteResponse . SUCCESSFUL :,if status == MemcacheDeleteResponse . DELETED :,False,98.52,73.09,,,
"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB> <TAB> randomNode = Gaffer . Random ( ) <TAB> <TAB> parentNode . addChild ( randomNode ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB> <TAB> elif isinstance ( plug , Gaffer . Color3fPlug ) : <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode )","if isinstance ( plug , Gaffer . Float3fPlug ) :","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) :",False,94.11,70.68,,,
"def escapeentities ( self , line ) : <TAB> "" Escape all Unicode characters to HTML entities. "" <TAB> result = "" "" <TAB> pos = TextPosition ( line ) <TAB> while not pos . finished ( ) : <TAB> <TAB> if ord ( pos . current ( ) ) > 128 : <TAB> <TAB> <TAB> codepoint = hex ( ord ( pos . current ( ) ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> codepoint = hex ( ord ( pos . next ( ) ) + 0xF800 ) <TAB> <TAB> <TAB> result + = "" &# "" + codepoint [ 1 : ] + "" ; "" <TAB> <TAB> else : <TAB> <TAB> <TAB> result + = pos . current ( ) <TAB> <TAB> pos . skipcurrent ( ) <TAB> return result",if codepoint == 0xF800 :,"if codepoint == ""0xd835"" :",False,97.72,69.23,,,
def get_and_set_all_aliases ( self ) : <TAB> all_aliases = [ ] <TAB> for page in self . pages : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> all_aliases . extend ( page . relations . aliases_norm ) <TAB> <TAB> if page . relations . aliases is not None : <TAB> <TAB> <TAB> all_aliases . extend ( page . relations . aliases ) <TAB> return set ( all_aliases ),if page . relations . aliases_norm is not None :,if page . relations . aliases_norm is not None :,True,100.0,99.21,,,
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> elif isinstance ( test , unittest . TestCase ) : <TAB> <TAB> <TAB> if support . match_test ( test ) : <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) )","if isinstance ( test , ( list , tuple ) ) :","if isinstance ( test , unittest . TestSuite ) :",False,93.76,70.0,,,
"def get_next_requests ( self , max_n_requests , * * kwargs ) : <TAB> next_pages = [ ] <TAB> partitions = set ( kwargs . pop ( "" partitions "" , [ ] ) ) <TAB> for partition_id in range ( 0 , self . queue_partitions ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> results = self . queue . get_next_requests ( max_n_requests , partition_id ) <TAB> <TAB> next_pages . extend ( results ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Got  %d  requests for partition id  %d "" , len ( results ) , partition_id <TAB> <TAB> ) <TAB> return next_pages",if partition_id not in partitions :,if partition_id not in partitions :,True,100.0,74.45,,,
"def __iter__ ( self ) : <TAB> if ( self . query is not None ) and sqlite . is_read_only_query ( self . query ) : <TAB> <TAB> cur = self . connection . cursor ( ) <TAB> <TAB> results = cur . execute ( self . query ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield [ col [ 0 ] for col in cur . description ] <TAB> <TAB> for i , row in enumerate ( results ) : <TAB> <TAB> <TAB> if i > = self . limit : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> yield [ val for val in row ] <TAB> else : <TAB> <TAB> yield",if results :,if self . headers :,False,97.43,72.62,,,
"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB> <TAB> if operation == "" insert "" : <TAB> <TAB> <TAB> values . remove ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> old_value , new_value = values <TAB> <TAB> <TAB> if new_value . full_filename != old_value . full_filename : <TAB> <TAB> <TAB> <TAB> os . unlink ( new_value . full_filename ) <TAB> <TAB> <TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( )","elif operation == ""update"" :","elif operation == ""update"" :",True,100.0,74.31,,,
"def index ( self , value ) : <TAB> if self . _growing : <TAB> <TAB> if self . _start < = value < self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> else : <TAB> <TAB> if self . _start > = value > self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) )",if r == 0 :,if r == self . _zero :,False,94.64,71.39,,,
"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB> <TAB> value = body . get ( attribute ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> body [ attribute ] = value . strip ( ) <TAB> <TAB> <TAB> if check_length : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> utils . check_string_length ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception . InvalidInput as error : <TAB> <TAB> <TAB> <TAB> <TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg )",if value :,if value is not None :,False,98.29,72.79,,,
"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB> <TAB> if m [ 0 ] == "" "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> output ( "" |} "" ) <TAB> <TAB> <TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else : <TAB> <TAB> <TAB> output ( "" |- "" ) <TAB> <TAB> <TAB> output ( <TAB> <TAB> <TAB> <TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB> <TAB> <TAB> <TAB> + m [ 0 ] <TAB> <TAB> <TAB> <TAB> + "" </tt></span> || ||  "" <TAB> <TAB> <TAB> <TAB> + m [ 1 ] <TAB> <TAB> <TAB> ) <TAB> output ( "" |} "" )",if firstHeading :,if firstHeading :,True,100.0,74.52,,,
"def _get_platforms ( data ) : <TAB> platform_list = [ ] <TAB> for item in data : <TAB> <TAB> if item . startswith ( "" PlatformEdit.html? "" ) : <TAB> <TAB> <TAB> parameter_list = item . split ( "" PlatformEdit.html? "" , 1 ) [ 1 ] . split ( "" & "" ) <TAB> <TAB> <TAB> for parameter in parameter_list : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> platform_list . append ( parameter . split ( "" = "" ) [ 1 ] ) <TAB> return platform_list","if parameter . startswith ( ""platform"" ) :","if parameter . startswith ( ""platformName"" ) :",False,98.4,73.08,,,
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","if name . startswith ( ""SCINTilla_"" ) :","if name . startswith ( ""SCE_"" ) :",False,98.76,73.61,,,
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",if operation_name is None :,if not operation_name :,False,98.01,73.21,,,
"def _insertNewItemAtParent ( self , targetIndex ) : <TAB> if not self . isContainer ( targetIndex ) : <TAB> <TAB> return <TAB> elif not self . isContainerOpen ( targetIndex ) : <TAB> <TAB> uri = self . _rows [ targetIndex ] . uri <TAB> <TAB> modelNode = self . getNodeForURI ( uri ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> modelNode . markForRefreshing ( ) <TAB> <TAB> return <TAB> self . refreshView ( targetIndex )",if modelNode :,if modelNode :,True,100.0,74.19,,,
"def _get_trace ( self , model , guide , args , kwargs ) : <TAB> model_trace , guide_trace = super ( ) . _get_trace ( model , guide , args , kwargs ) <TAB> # Mark all sample sites with require_backward to gather enumerated <TAB> # sites and adjust cond_indep_stack of all sample sites. <TAB> for node in model_trace.nodes.values(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log_prob = node[""packed""][""unscaled_log_prob""] <TAB> <TAB> <TAB> require_backward(log_prob) <TAB> self._saved_state = model, model_trace, guide_trace, args, kwargs <TAB> return model_trace, guide_trace","if ""unscaled_log_prob"" in node [ ""packed"" ] :","if node [ ""type"" ] == ""sample"" and not node [ ""is_observed"" ] :",False,90.79,63.61,,,
"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB> <TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( key , bytes ) : <TAB> <TAB> <TAB> key = text_type ( key ) . encode ( charset ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = text_type ( value ) . encode ( charset ) <TAB> <TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value )","if not isinstance ( value , bytes ) :","if not isinstance ( value , bytes ) :",True,100.0,74.52,,,
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> with augment_usage_errors ( ctx , param = self ) : <TAB> <TAB> value = self . consume_value ( ctx , opts ) <TAB> <TAB> try : <TAB> <TAB> <TAB> value = self . full_process_value ( ctx , value ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> value = None <TAB> <TAB> if self . callback is not None : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> value = invoke_param_callback ( self . callback , ctx , self , value ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> if self . expose_value : <TAB> <TAB> ctx . params [ self . name ] = value <TAB> return value , args",if self . fail_silently :,if not ctx . resilient_parsing :,False,94.75,71.06,,,
"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB> <TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB> <TAB> if pattern [ i ] not in dict : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB> <TAB> <TAB> set_value . add ( list_str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if dict [ pattern [ i ] ] != list_str [ i ] : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if set_value . intersection ( list_str [ i ] ) :,if list_str [ i ] in set_value :,False,96.24,72.25,,,
"def create ( self , path , wipe = False ) : <TAB> # type: (Text, bool) -> bool <TAB> _path = self.validatepath(path) <TAB> with ftp_errors(self, path): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> empty_file = io.BytesIO() <TAB> <TAB> <TAB> self.ftp.storbinary( <TAB> <TAB> <TAB> <TAB> str(""STOR "") + _encode(_path, self.ftp.encoding), empty_file <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> return False",if wipe :,if wipe or not self . isfile ( path ) :,False,94.0,67.21,,,
"def build_output_for_item ( self , item ) : <TAB> output = [ ] <TAB> for field in self . fields : <TAB> <TAB> values = self . _get_item ( item , field ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values = [ values ] <TAB> <TAB> for value in values : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> output . append ( self . build_output_for_single_value ( value ) ) <TAB> return "" "" . join ( output )","if not isinstance ( values , ( list , tuple ) ) :","if not isinstance ( values , list ) :",False,95.72,71.98,,,
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> if not name [ 0 ] . isupper ( ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action ( member ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods",if inspect . isclass ( member ) :,"if not name . startswith ( ""wait_until"" ) :",False,93.59,63.68,,,
"def get_command ( cls ) : <TAB> ifconfig_cmd = "" ifconfig "" <TAB> for path in [ "" /sbin "" , "" /usr/sbin "" , "" /bin "" , "" /usr/bin "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ifconfig_cmd = os . path . join ( path , ifconfig_cmd ) <TAB> <TAB> <TAB> break <TAB> ifconfig_cmd = ifconfig_cmd + ""  -a "" <TAB> return ifconfig_cmd","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) :",True,100.0,74.25,,,
"def main ( ) : <TAB> base_dir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "" .. "" , "" .. "" ) <TAB> for path in PATHS : <TAB> <TAB> path = os . path . join ( base_dir , path ) <TAB> <TAB> for root , _ , files in os . walk ( path ) : <TAB> <TAB> <TAB> for file in files : <TAB> <TAB> <TAB> <TAB> extension = os . path . splitext ( file ) [ 1 ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> path = os . path . join ( root , file ) <TAB> <TAB> <TAB> <TAB> <TAB> validate_header ( path )","if extension == "".py"" :",if extension in EXTENSIONS :,False,96.22,66.21,,,
"def auth_login ( request ) : <TAB> form = RegistrationForm ( request . POST or None ) <TAB> if form . is_valid ( ) : <TAB> <TAB> authed_user = authenticate ( <TAB> <TAB> <TAB> username = form . cleaned_data [ "" username "" ] , <TAB> <TAB> <TAB> password = form . cleaned_data [ "" password "" ] , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> login ( request , authed_user ) <TAB> <TAB> <TAB> return HttpResponse ( "" Success "" ) <TAB> raise Http404",if authed_user :,if authed_user :,True,100.0,74.29,,,
"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB> <TAB> user = self . users . get ( current_user . id , None ) <TAB> <TAB> if user is None : <TAB> <TAB> <TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> user [ "" session_count "" ] + = 1 <TAB> <TAB> <TAB> user [ "" key "" ] = _key",if _new_login :,if _new_login :,True,100.0,74.36,,,
"def fetch ( self , fingerprints ) : <TAB> to_fetch = [ f for f in fingerprints if f not in self . _cache ] <TAB> self . _logger . debug ( "" cache size  %s "" % len ( self . _cache ) ) <TAB> self . _logger . debug ( "" to fetch  %d  from  %d "" % ( len ( to_fetch ) , len ( fingerprints ) ) ) <TAB> [ self . _redis_pipeline . hgetall ( key ) for key in to_fetch ] <TAB> responses = self . _redis_pipeline . execute ( ) <TAB> for index , key in enumerate ( to_fetch ) : <TAB> <TAB> response = responses [ index ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _cache [ key ] = response [ FIELD_STATE ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _cache [ key ] = self . NOT_CRAWLED",if response [ FIELD_STATE ] :,if len ( response ) > 0 and FIELD_STATE in response :,False,94.74,71.04,,,
"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re.split(OUTPUT_SPLIT_REGEX, data) <TAB> for part in parts: <TAB> <TAB> if part: # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re.split( <TAB> <TAB> <TAB> <TAB> ""(.{%d,})"" % (self._get_squeeze_threshold() + 1), part <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self._queued_io_events.append((block, stream_name))",if block :,if block :,True,100.0,74.43,,,
"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB> <TAB> path = os . path . join ( path , self . index_file ) <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> <TAB> except IsDirectoryError : <TAB> <TAB> <TAB> if os . path . isfile ( os . path . join ( path , self . index_file ) ) : <TAB> <TAB> <TAB> <TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path )","if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",if os . path . isfile ( path ) :,False,94.21,72.51,,,
"def module_list ( target , fast ) : <TAB> """""" Find the list of modules to be compiled """""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB> <TAB> module_name , ext = os . path . splitext ( name ) <TAB> <TAB> if ext == "" .py "" or ext == "" "" and os . path . isdir ( os . path . join ( basedir , name ) ) : <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> modules . append ( module_name ) <TAB> return set ( modules )",if fast :,if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) :,False,93.04,70.96,,,
"def housenumber ( self ) : <TAB> if self . address : <TAB> <TAB> expression = r "" \ d+ "" <TAB> <TAB> pattern = re . compile ( expression ) <TAB> <TAB> match = pattern . search ( self . address ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return int ( match . group ( 0 ) )",if match :,if match :,True,100.0,73.95,,,
"def get_pip_version ( import_path = BASE_IMPORT_PATH ) : <TAB> try : <TAB> <TAB> pip = importlib . import_module ( import_path ) <TAB> except ImportError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return get_pip_version ( import_path = "" pip "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> import subprocess <TAB> <TAB> <TAB> version = subprocess . check_output ( [ "" pip "" , "" --version "" ] ) <TAB> <TAB> <TAB> if version : <TAB> <TAB> <TAB> <TAB> version = version . decode ( "" utf-8 "" ) . split ( ) [ 1 ] <TAB> <TAB> <TAB> <TAB> return version <TAB> <TAB> <TAB> return "" 0.0.0 "" <TAB> version = getattr ( pip , "" __version__ "" , None ) <TAB> return version","if sys . platform == ""win32"" :","if import_path != ""pip"" :",False,96.52,72.42,,,
"def __animate_progress ( self ) : <TAB> """""" Change the status message, mostly used to animate progress. """""" <TAB> while True : <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> with self . __progress_lock : <TAB> <TAB> <TAB> if not self . __progress_status : <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . __progress_status . show_as_ready ( ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time.sleep(sleep_time)",elif self . __current_operation_name :,elif self . __show_animation :,False,97.74,98.5,,,
"def range_key_names ( self ) : <TAB> keys = [ self . range_key_attr ] <TAB> for index in self . global_indexes : <TAB> <TAB> range_key = None <TAB> <TAB> for key in index . schema : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> range_key = keys . append ( key [ "" AttributeName "" ] ) <TAB> <TAB> keys . append ( range_key ) <TAB> return keys","if key [ ""Type"" ] == ""RangeKey"" :","if key [ ""KeyType"" ] == ""RANGE"" :",False,96.01,71.01,,,
"def run ( self ) : <TAB> dist = self . distribution <TAB> commands = dist . command_options . keys ( ) <TAB> settings = { } <TAB> for cmd in commands : <TAB> <TAB> if cmd == "" saveopts "" : <TAB> <TAB> <TAB> continue # don't save our own options! <TAB> <TAB> for opt, (src, val) in dist.get_option_dict(cmd).items(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> settings.setdefault(cmd, {})[opt] = val <TAB> edit_config(self.filename, settings, self.dry_run)","if src == ""default"" :","if src == ""command line"" :",False,97.88,72.1,,,
"def parse_move ( self , node ) : <TAB> old , new = "" "" , "" "" <TAB> for child in node : <TAB> <TAB> tag , text = child . tag , child . text <TAB> <TAB> text = text . strip ( ) if text else None <TAB> <TAB> if tag == "" Old "" and text : <TAB> <TAB> <TAB> old = text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new = text <TAB> return Move ( old , new )","elif tag == ""New"" and text :","elif tag == ""New"" and text :",True,100.0,74.32,,,
"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB> <TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB> <TAB> for finfo in self . data : <TAB> <TAB> <TAB> self . __update_editor_margins ( finfo . editor ) <TAB> <TAB> <TAB> finfo . cleanup_analysis_results ( ) <TAB> <TAB> <TAB> if ( run_pyflakes or run_pep8 ) and current_finfo is not None : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 )",if finfo . is_codeanalysis ( ) :,if current_finfo is not finfo :,False,95.69,70.98,,,
"def tchg ( var , width ) : <TAB> "" Convert time string to given length "" <TAB> ret = "" %2d h %02d "" % ( var / 60 , var % 60 ) <TAB> <IF-STMT> <TAB> <TAB> ret = "" %2d h "" % ( var / 60 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret = "" %2d d "" % ( var / 60 / 24 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret = "" %2d w "" % ( var / 60 / 24 / 7 ) <TAB> return ret",if width :,if len ( ret ) > width :,False,87.3,66.17,,,
"def spider_log_activity ( self , messages ) : <TAB> for i in range ( 0 , messages ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . sp_sl_p . send ( <TAB> <TAB> <TAB> <TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , <TAB> <TAB> <TAB> <TAB> b "" http://helloworld.com/way/to/the/sun/ "" + b "" 0 "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . sp_sl_p . send ( <TAB> <TAB> <TAB> <TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , b "" http://way.to.the.sun "" + b "" 0 "" <TAB> <TAB> <TAB> ) <TAB> self . sp_sl_p . flush ( )",if i == 0 :,if i % 2 == 0 :,False,98.43,73.05,,,
"def decode_serial ( self , offset ) : <TAB> serialnum = ( <TAB> <TAB> ( self . cache [ offset + 3 ] << 24 ) <TAB> <TAB> + ( self . cache [ offset + 2 ] << 16 ) <TAB> <TAB> + ( self . cache [ offset + 1 ] << 8 ) <TAB> <TAB> + self . cache [ offset ] <TAB> ) <TAB> serialstr = "" "" <TAB> is_alnum = True <TAB> for i in range ( 4 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> is_alnum = False <TAB> <TAB> <TAB> break <TAB> <TAB> serialstr + = chr ( self . cache [ offset + 3 - i ] ) <TAB> serial = serialstr if is_alnum else str ( serialnum ) <TAB> self . ann_field ( offset , offset + 3 , "" Serial  "" + serial )",if self . cache [ offset + 3 - i ] == 0 :,if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) :,False,95.08,71.15,,,
def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB> <TAB> if child . nodeType == child . TEXT_NODE : <TAB> <TAB> <TAB> yield child . nodeValue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for item in gettext ( child ) : <TAB> <TAB> <TAB> <TAB> yield item,"elif isinstance ( child , Node ) :",if child . nodeType == child . ELEMENT_NODE :,False,86.98,40.95,,,
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints","if text [ 0 ] not in ""\n\x85\u2028\u2029"" :","elif len ( text ) == 1 or text [ - 2 ] in ""\n\x85\u2028\u2029"" :",False,90.75,67.41,,,
"def _infer_return_type ( * args ) : <TAB> """""" Look at the type of all args and divine their implied return type. """""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str # tempfile APIs return a str by default. <TAB> return return_type","if isinstance ( arg , bytes ) :","if isinstance ( arg , bytes ) :",True,100.0,99.61,,,
"def as_iconbitmap ( cls , rkey ) : <TAB> """""" Get image path for use in iconbitmap property """""" <TAB> img = None <TAB> if rkey in cls . _stock : <TAB> <TAB> data = cls . _stock [ rkey ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fpath = data [ "" filename "" ] <TAB> <TAB> <TAB> fname = os . path . basename ( fpath ) <TAB> <TAB> <TAB> name , file_ext = os . path . splitext ( fname ) <TAB> <TAB> <TAB> file_ext = str ( file_ext ) . lower ( ) <TAB> <TAB> <TAB> if file_ext in TK_BITMAP_FORMATS : <TAB> <TAB> <TAB> <TAB> img = BITMAP_TEMPLATE . format ( fpath ) <TAB> return img","if data [ ""type"" ] == ""image"" :","if data [ ""type"" ] not in ( ""stock"" , ""data"" , ""image"" ) :",False,92.95,93.58,,,
"def anonymize_ip ( ip ) : <TAB> if ip : <TAB> <TAB> match = RE_FIRST_THREE_OCTETS_OF_IP . findall ( str ( ip ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" %s %s "" % ( match [ 0 ] [ 0 ] , "" 0 "" ) <TAB> return "" """,if match :,if match :,True,100.0,73.84,,,
"def serialize_tail ( self ) : <TAB> msg = bytearray ( ) <TAB> for v in self . info : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = v [ "" value "" ] . encode ( "" utf-8 "" ) <TAB> <TAB> elif v [ "" type "" ] == BMP_TERM_TYPE_REASON : <TAB> <TAB> <TAB> value = struct . pack ( "" !H "" , v [ "" value "" ] ) <TAB> <TAB> v [ "" len "" ] = len ( value ) <TAB> <TAB> msg + = struct . pack ( self . _TLV_PACK_STR , v [ "" type "" ] , v [ "" len "" ] ) <TAB> <TAB> msg + = value <TAB> return msg","if v [ ""type"" ] == BMP_TERM_TYPE_TEXT :","if v [ ""type"" ] == BMP_TERM_TYPE_STRING :",False,98.68,73.53,,,
"def serialize_tail ( self ) : <TAB> msg = bytearray ( ) <TAB> for v in self . info : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = v [ "" value "" ] . encode ( "" utf-8 "" ) <TAB> <TAB> elif v [ "" type "" ] == BMP_TERM_TYPE_REASON : <TAB> <TAB> <TAB> value = struct . pack ( "" !H "" , v [ "" value "" ] ) <TAB> <TAB> v [ "" len "" ] = len ( value ) <TAB> <TAB> msg + = struct . pack ( self . _TLV_PACK_STR , v [ "" type "" ] , v [ "" len "" ] ) <TAB> <TAB> msg + = value <TAB> return msg","if v [ ""type"" ] == BMP_TERM_TYPE_TEXT :","if text [ end - 2 : end ] == ""#}"" :",False,92.45,70.59,,,
"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB> <TAB> if not win . ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> if win . Class ( ) != "" ComboBox "" or win . ref . Class ( ) != "" ComboBox "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bugs . append ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win , <TAB> <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> <TAB> <TAB> { } , <TAB> <TAB> <TAB> <TAB> <TAB> testname , <TAB> <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs",if win . DropdownHeight ( ) != win . DropdownHeight ( ) :,if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) :,False,94.73,70.11,,,
"def testBadModeArgument ( self ) : <TAB> # verify that we get a sensible error message for bad mode argument <TAB> bad_mode = ""qwerty"" <TAB> try: <TAB> <TAB> f = self.open(TESTFN, bad_mode) <TAB> except ValueError as msg: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s = str(msg) <TAB> <TAB> <TAB> if TESTFN in s or bad_mode not in s: <TAB> <TAB> <TAB> <TAB> self.fail(""bad error message for invalid mode: %s"" % s) <TAB> <TAB> # if msg.args[0] == 0, we're probably on Windows where there may be <TAB> <TAB> # no obvious way to discover why open() failed. <TAB> else: <TAB> <TAB> f.close() <TAB> <TAB> self.fail(""no error for invalid mode: %s"" % bad_mode)",if msg . args [ 0 ] != 0 :,if msg . args [ 0 ] != 0 :,True,100.0,74.49,,,
"def command_group_expired ( self , command_group_name ) : <TAB> try : <TAB> <TAB> deprecate_info = self . _command_loader . command_group_table [ <TAB> <TAB> <TAB> command_group_name <TAB> <TAB> ] . group_kwargs . get ( "" deprecate_info "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return deprecate_info . expired ( ) <TAB> except AttributeError : <TAB> <TAB> # Items with only token presence in the command table will not have any data. They can't be expired. <TAB> <TAB> pass <TAB> return False",if deprecate_info :,if deprecate_info :,True,100.0,74.28,,,
"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB> <TAB> if val == 0 : <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert False",elif val == 1 :,elif val == 1 :,True,100.0,74.5,,,
"def get_labels ( directory ) : <TAB> cache = get_labels . __cache <TAB> if directory not in cache : <TAB> <TAB> l = { } <TAB> <TAB> for t in get_visual_configs ( directory ) [ 0 ] [ LABEL_SECTION ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> Messager . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> "" In configuration, labels for  ' %s '  defined more than once. Only using the last set. "" <TAB> <TAB> <TAB> <TAB> <TAB> % t . storage_form ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> - 1 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> # first is storage for, rest are labels. <TAB> <TAB> <TAB> l[t.storage_form()] = t.terms[1:] <TAB> <TAB> cache[directory] = l <TAB> return cache[directory]",if t . storage_form ( ) in l :,if t . storage_form ( ) in l :,True,100.0,74.53,,,
"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int ( i , 2 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB> <TAB> ret = bytes ( ret ) <TAB> <TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB> <TAB> return ret",if val < 0 or val > 255 :,if val > 255 or val < 0 :,False,97.47,72.53,,,
"def setCellValue ( self , row_idx , col , value ) : <TAB> assert col . id == "" repls-marked "" <TAB> with self . _lock : <TAB> <TAB> rgroup = self . events [ row_idx ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> rgroup . _marked = value == "" true "" and True or False <TAB> if self . _tree : <TAB> <TAB> self . _tree . invalidateCell ( row_idx , col )",if rgroup . _marked is None :,"if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",False,92.01,68.48,,,
"def create ( cls , settlement_manager , resource_id ) : <TAB> """""" Create a production chain that can produce the given resource. """""" <TAB> resource_producer = { } <TAB> for abstract_building in AbstractBuilding . buildings . values ( ) : <TAB> <TAB> for resource , production_line in abstract_building . lines . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> resource_producer [ resource ] = [ ] <TAB> <TAB> <TAB> resource_producer [ resource ] . append ( ( production_line , abstract_building ) ) <TAB> return ProductionChain ( settlement_manager , resource_id , resource_producer )",if resource not in resource_producer :,if resource not in resource_producer :,True,100.0,99.38,,,
"def create ( cls , settlement_manager , resource_id ) : <TAB> """""" Create a production chain that can produce the given resource. """""" <TAB> resource_producer = { } <TAB> for abstract_building in AbstractBuilding . buildings . values ( ) : <TAB> <TAB> for resource , production_line in abstract_building . lines . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> resource_producer [ resource ] = [ ] <TAB> <TAB> <TAB> resource_producer [ resource ] . append ( ( production_line , abstract_building ) ) <TAB> return ProductionChain ( settlement_manager , resource_id , resource_producer )",if resource not in resource_producer :,"if isinstance ( schedule_def , PartitionScheduleDefinition )",False,94.4,88.69,,,
"def _sendDatapointsNow ( self , datapoints ) : <TAB> metrics = { } <TAB> payload_pb = Payload ( ) <TAB> for metric , datapoint in datapoints : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> metric_pb = payload_pb . metrics . add ( ) <TAB> <TAB> <TAB> metric_pb . metric = metric <TAB> <TAB> <TAB> metrics [ metric ] = metric_pb <TAB> <TAB> else : <TAB> <TAB> <TAB> metric_pb = metrics [ metric ] <TAB> <TAB> point_pb = metric_pb . points . add ( ) <TAB> <TAB> point_pb . timestamp = int ( datapoint [ 0 ] ) <TAB> <TAB> point_pb . value = datapoint [ 1 ] <TAB> self . sendString ( payload_pb . SerializeToString ( ) )",if metric not in metrics :,if metric not in metrics :,True,100.0,74.47,,,
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self . _aggregate_rows : <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr",elif self . _dicts :,elif self . _dicts :,True,100.0,74.58,,,
"def get_metrics ( ) : <TAB> classifier , feature_labels = load_classifier ( ) <TAB> available_metrics = ImgageMetrics . get_metric_classes ( ) <TAB> # todo review: DONE IN DOCS <TAB> # effective_metrics isn't used after filling it with values <TAB> # in the loops below <TAB> effective_metrics = [] <TAB> for metric in available_metrics: <TAB> <TAB> for label in feature_labels: <TAB> <TAB> <TAB> for label_part in metric.get_labels(): <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> effective_metrics.append(metric) <TAB> return (classifier, feature_labels, available_metrics)",if label_part in effective_metrics :,if label_part == label and metric not in effective_metrics :,False,95.95,70.53,,,
"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB> <TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB> <TAB> if "" pseudo-interface "" in nic . replace ( "" "" , "" - "" ) . lower ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic )",if out in nic . lower ( ) :,if nic not in out :,False,95.78,72.18,,,
"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result: <TAB> <TAB> if replace: <TAB> <TAB> <TAB> self[key] = result <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.parent = self <TAB> <TAB> <TAB> result.key = key <TAB> return result",if result . parent is None :,"if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) :",False,89.75,66.39,,,
"def _EvaluateFile ( self , test_list , file ) : <TAB> ( name , ext ) = os . path . splitext ( file ) <TAB> if ext == "" .cc "" or ext == "" .cpp "" or ext == "" .c "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . SilentLog ( "" Found native test file  %s "" % file ) <TAB> <TAB> <TAB> test_list . append ( name )",if name in self . native_test_files :,"if re . search ( ""_test$|_test_$|_unittest$|_unittest_$|^test_|Tests$"" , name ) :",False,75.22,64.43,,,
"def leading_whitespace ( self , inputstring ) : <TAB> """""" Get leading whitespace. """""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> leading_ws . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> <TAB> if self . indchar is None : <TAB> <TAB> <TAB> self . indchar = c <TAB> <TAB> elif c != self . indchar : <TAB> <TAB> <TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws )",if c in self . whitespace :,if c in legal_indent_chars :,False,96.38,95.91,,,
"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> idents = getattr(wrapped, ""ident_values"", None) <TAB> <TAB> <TAB> if idents: <TAB> <TAB> <TAB> <TAB> value = [self._wrap_hash(ident) for ident in idents] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ## <TAB> ident = self.ident <TAB> <TAB> <TAB> ## <TAB> if ident is not None: <TAB> <TAB> <TAB> ## <TAB> <TAB> value = [ident] <TAB> <TAB> self._ident_values = value <TAB> return value",if self . _prefix :,if not self . orig_prefix :,False,98.17,72.5,,,
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if name not in found_names : <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> if not scoperef : <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )","if isinstance ( expr , ast . Symbol ) :",if name . startswith ( expr ) :,False,97.1,72.58,,,
"def pid_from_name ( name ) : <TAB> # quick and dirty, works with all linux not depending on ps output <TAB> for pid in os.listdir(""/proc""): <TAB> <TAB> try: <TAB> <TAB> <TAB> int(pid) <TAB> <TAB> except: <TAB> <TAB> <TAB> continue <TAB> <TAB> pname = """" <TAB> <TAB> with open(""/proc/%s/cmdline"" % pid, ""r"") as f: <TAB> <TAB> <TAB> pname = f.read() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return int(pid) <TAB> raise ProcessException(""No process with such name: %s"" % name)",if pname == name :,if name in pname :,False,97.2,96.62,,,
"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . parent ( ) . touch ( ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB> <TAB> if self . watcher : <TAB> <TAB> <TAB> self . watcher . emit ( "" created "" , self )",if not node :,if not node . isdir :,False,97.69,72.74,,,
"def setUp ( self ) : <TAB> BaseTestCase . setUp ( self ) <TAB> self . rawData = [ ] <TAB> self . dataByKey = { } <TAB> for i in range ( 1 , 11 ) : <TAB> <TAB> stringCol = "" String  %d "" % i <TAB> <TAB> fixedCharCol = ( "" Fixed Char  %d "" % i ) . ljust ( 40 ) <TAB> <TAB> rawCol = "" Raw  %d "" % i <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nullableCol = "" Nullable  %d "" % i <TAB> <TAB> else : <TAB> <TAB> <TAB> nullableCol = None <TAB> <TAB> dataTuple = ( i , stringCol , rawCol , fixedCharCol , nullableCol ) <TAB> <TAB> self . rawData . append ( dataTuple ) <TAB> <TAB> self . dataByKey [ i ] = dataTuple",if i % 2 :,if i % 2 :,True,100.0,74.53,,,
"def GenerateVector ( self , hits , vector , level ) : <TAB> """""" Generate possible hit vectors which match the rules. """""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> if vector : <TAB> <TAB> <TAB> if item < vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result",if level == 0 :,if level + 1 == len ( hits ) :,False,96.07,79.69,,,
"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . keydata : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB> <TAB> elif hasattr ( self . key , k ) : <TAB> <TAB> <TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB> <TAB> attrs . append ( "" private "" ) <TAB> return "" < %s  @0x %x %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) )","if hasattr ( self . key , k ) :","if k == ""p"" :",False,94.75,67.36,,,
"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if get_osx_theme ( ) == 1 : <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else : <TAB> <TAB> <TAB> theme = self . guess_system_theme ( ) <TAB> <TAB> <TAB> if theme == Dark : <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else : # user settings have highest priority <TAB> <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)",if self . _app . config . USE_DARK :,"if sys . platform == ""darwin"" :",False,94.33,64.12,,,
"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB> <TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB> <TAB> c = s [ pos ] <TAB> <TAB> if c == "" { "" : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif c == "" } "" : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB> <TAB> return pos <TAB> return None",if depth == 0 :,if depth == 0 :,True,100.0,74.51,,,
"def update_meter ( self , output , target , meters = { "" accuracy "" } ) : <TAB> output = self . __to_tensor ( output ) <TAB> target = self . __to_tensor ( target ) <TAB> for meter in meters : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __addmeter ( meter ) <TAB> <TAB> if meter in [ "" ap "" , "" map "" , "" confusion "" ] : <TAB> <TAB> <TAB> target_th = self . _ver2tensor ( target ) <TAB> <TAB> <TAB> self . meter [ meter ] . add ( output , target_th ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . meter [ meter ] . add ( output , target )",if not self . has_meter ( meter ) :,if meter not in self . meter . keys ( ) :,False,95.33,70.94,,,
"def _reinit_optimizers_with_oss ( self ) : <TAB> optimizers = self . lightning_module . trainer . optimizers <TAB> for x , optimizer in enumerate ( optimizers ) : <TAB> <TAB> if is_lightning_optimizer ( optimizer ) : <TAB> <TAB> <TAB> optimizer = optimizer . _optimizer <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> optim_class = type ( optimizer ) <TAB> <TAB> <TAB> zero_optimizer = OSS ( <TAB> <TAB> <TAB> <TAB> params = optimizer . param_groups , optim = optim_class , * * optimizer . defaults <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> optimizers [ x ] = zero_optimizer <TAB> <TAB> <TAB> del optimizer <TAB> trainer = self . lightning_module . trainer <TAB> trainer . optimizers = optimizers <TAB> trainer . convert_to_lightning_optimizers ( )","if isinstance ( optimizer , OSS ) :","if not isinstance ( optimizer , OSS ) :",False,98.86,73.35,,,
"def OnSelChanged ( self , event ) : <TAB> self . item = event . GetItem ( ) <TAB> if self . item : <TAB> <TAB> self . log . write ( "" OnSelChanged:  %s "" % self . GetItemText ( self . item ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . write ( <TAB> <TAB> <TAB> <TAB> "" , BoundingRect:  %s \n "" % self . GetBoundingRect ( self . item , True ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . log . write ( "" \n "" ) <TAB> event . Skip ( )",if self . GetBoundingRect ( ) :,"if wx . Platform == ""__WXMSW__"" :",False,92.03,66.64,,,
"def parse_batch ( args ) : <TAB> errmsg = "" Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1). "" <TAB> if args . batch is not None : <TAB> <TAB> rule , batchdef = parse_key_value_arg ( args . batch , errmsg = errmsg ) <TAB> <TAB> try : <TAB> <TAB> <TAB> batch , batches = batchdef . split ( "" / "" ) <TAB> <TAB> <TAB> batch = int ( batch ) <TAB> <TAB> <TAB> batches = int ( batches ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( errmsg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( errmsg ) <TAB> <TAB> return Batch ( rule , batch , batches ) <TAB> return None",if len ( batch ) != batches :,if batch > batches or batch < 1 :,False,96.21,71.58,,,
"def get_foreign_key_columns ( self , engine , table_name ) : <TAB> foreign_keys = set ( ) <TAB> table = db_utils . get_table ( engine , table_name ) <TAB> inspector = reflection . Inspector . from_engine ( engine ) <TAB> for column_dict in inspector . get_columns ( table_name ) : <TAB> <TAB> column_name = column_dict [ "" name "" ] <TAB> <TAB> column = getattr ( table . c , column_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> foreign_keys . add ( column_name ) <TAB> return foreign_keys",if column . foreign_key :,if column . foreign_keys :,False,98.37,72.89,,,
"def update ( self , t ) : <TAB> l = int ( t * self . nr_of_tiles ) <TAB> for i in range ( self . nr_of_tiles ) : <TAB> <TAB> t = self . tiles_order [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . turn_off_tile ( t ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . turn_on_tile ( t )",if t < l :,if i < l :,False,97.78,72.26,,,
"def read ( self , amt = None ) : <TAB> # the _rbuf test is only in this first if for speed. It's not <TAB> # logically necessary <TAB> if self._rbuf and not amt is None: <TAB> <TAB> L = len(self._rbuf) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> amt -= L <TAB> <TAB> else: <TAB> <TAB> <TAB> s = self._rbuf[:amt] <TAB> <TAB> <TAB> self._rbuf = self._rbuf[amt:] <TAB> <TAB> <TAB> return s <TAB> s = self._rbuf + self._raw_read(amt) <TAB> self._rbuf = b"""" <TAB> return s",if L > amt :,if amt > L :,False,97.92,72.15,,,
"def draw_menu_button ( self , context , layout , node , text ) : <TAB> if ( <TAB> <TAB> hasattr ( node . id_data , "" sv_show_socket_menus "" ) <TAB> <TAB> and node . id_data . sv_show_socket_menus <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> layout . menu ( "" SV_MT_SocketOptionsMenu "" , text = "" "" , icon = "" TRIA_DOWN "" )","if text == ""Socket Options"" :",if self . is_output or self . is_linked or not self . use_prop :,False,84.8,59.97,,,
"def __enter__ ( self ) : <TAB> with DB . connection_context ( ) : <TAB> <TAB> session_record = SessionRecord ( ) <TAB> <TAB> session_record . f_session_id = self . _session_id <TAB> <TAB> session_record . f_engine_name = self . _engine_name <TAB> <TAB> session_record . f_engine_type = EngineType . STORAGE <TAB> <TAB> # TODO: engine address <TAB> <TAB> session_record.f_engine_address = {} <TAB> <TAB> session_record.f_create_time = current_timestamp() <TAB> <TAB> rows = session_record.save(force_insert=True) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception(f""create session record {self._session_id} failed"") <TAB> <TAB> LOGGER.debug(f""save session {self._session_id} record"") <TAB> self.create() <TAB> return self",if not rows :,if rows != 1 :,False,97.85,72.12,,,
"def tearDown ( self ) : <TAB> """""" Shutdown the server. """""" <TAB> try : <TAB> <TAB> if self . server : <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self )",if self . sl_hdlr :,if self . sl_hdlr :,True,100.0,74.14,,,
"def _dec_device ( self , srcdev , dstdev ) : <TAB> if srcdev : <TAB> <TAB> self . srcdevs [ srcdev ] - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . srcdevs [ srcdev ] <TAB> <TAB> self . _set_limits ( "" read "" , self . srcdevs ) <TAB> if dstdev : <TAB> <TAB> self . dstdevs [ dstdev ] - = 1 <TAB> <TAB> if self . dstdevs [ dstdev ] == 0 : <TAB> <TAB> <TAB> del self . dstdevs [ dstdev ] <TAB> <TAB> self . _set_limits ( "" write "" , self . dstdevs )",if self . srcdevs [ srcdev ] == 0 :,if self . srcdevs [ srcdev ] == 0 :,True,100.0,74.43,,,
"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _tail <TAB> <TAB> node = self . _root <TAB> <TAB> level = self . _shift <TAB> <TAB> while level > 0 : <TAB> <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> <TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB> <TAB> <TAB> level - = 5 <TAB> <TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" )",if self . _tail :,if i >= self . tailoff ( ) :,False,94.75,70.97,,,
"def convert_tensor ( self , offsets , sizes ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( offsets ) : <TAB> <TAB> utterances = [ ] <TAB> <TAB> for p , utt in enumerate ( batch ) : <TAB> <TAB> <TAB> size = sizes [ b ] [ p ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> utterances . append ( utt [ 0 : size ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> utterances . append ( torch . tensor ( [ ] , dtype = torch . int ) ) <TAB> <TAB> results . append ( utterances ) <TAB> return results",if size > 0 :,if sizes [ b ] [ p ] > 0 :,False,95.12,71.07,,,
"def _predict_proba ( self , X , preprocess = True ) : <TAB> if preprocess : <TAB> <TAB> X = self . preprocess ( X ) <TAB> if self . problem_type == REGRESSION : <TAB> <TAB> return self . model . predict ( X ) <TAB> y_pred_proba = self . model . predict_proba ( X ) <TAB> if self . problem_type == BINARY : <TAB> <TAB> if len ( y_pred_proba . shape ) == 1 : <TAB> <TAB> <TAB> return y_pred_proba <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return y_pred_proba [ : , 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return y_pred_proba <TAB> elif y_pred_proba . shape [ 1 ] > 2 : <TAB> <TAB> return y_pred_proba <TAB> else : <TAB> <TAB> return y_pred_proba [ : , 1 ]",elif len ( y_pred_proba . shape ) == 2 :,elif y_pred_proba . shape [ 1 ] > 1 :,False,96.31,71.73,,,
def timeout ( self ) : <TAB> now = ptime . time ( ) <TAB> dt = now - self . lastPlayTime <TAB> if dt < 0 : <TAB> <TAB> return <TAB> n = int ( self . playRate * dt ) <TAB> if n != 0 : <TAB> <TAB> self . lastPlayTime + = float ( n ) / self . playRate <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . play ( 0 ) <TAB> <TAB> self . jumpFrames ( n ),if n == 1 :,"if self . currentIndex + n > self . image . shape [ self . axes [ ""t"" ] ] :",False,83.06,46.83,,,
"def __init__ ( self , data , weights = None , ddof = 0 ) : <TAB> self . data = np . asarray ( data ) <TAB> if weights is None : <TAB> <TAB> self . weights = np . ones ( self . data . shape [ 0 ] ) <TAB> else : <TAB> <TAB> self . weights = np . asarray ( weights ) . astype ( float ) <TAB> <TAB> # TODO: why squeeze? <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.weights = self.weights.squeeze() <TAB> self.ddof = ddof",if self . weights . squeeze ( ) :,if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 :,False,88.49,66.39,,,
"def writerow ( self , row ) : <TAB> unicode_row = [ ] <TAB> for col in row : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unicode_row . append ( col . encode ( "" utf-8 "" ) . strip ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> unicode_row . append ( col ) <TAB> self . writer . writerow ( unicode_row ) <TAB> # Fetch UTF-8 output from the queue ... <TAB> data = self.queue.getvalue() <TAB> data = data.decode(""utf-8"") <TAB> # ... and reencode it into the target encoding <TAB> data = self.encoder.encode(data) <TAB> # write to the target stream <TAB> self.stream.write(data) <TAB> # empty queue <TAB> self.queue.truncate(0)","if isinstance ( col , str ) :",if type ( col ) == str or type ( col ) == unicode :,False,92.82,69.03,,,
"def __init__ ( self , choices , allow_blank = False , * * kwargs ) : <TAB> self . choiceset = choices <TAB> self . allow_blank = allow_blank <TAB> self . _choices = dict ( ) <TAB> # Unpack grouped choices <TAB> for k, v in choices: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k2, v2 in v: <TAB> <TAB> <TAB> <TAB> self._choices[k2] = v2 <TAB> <TAB> else: <TAB> <TAB> <TAB> self._choices[k] = v <TAB> super().__init__(**kwargs)","if isinstance ( v , ( list , tuple ) ) :","if type ( v ) in [ list , tuple ] :",False,94.56,68.89,,,
"def simp_ext ( _ , expr ) : <TAB> if expr . op . startswith ( "" zeroExt_ "" ) : <TAB> <TAB> arg = expr . args [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return arg <TAB> <TAB> return ExprCompose ( arg , ExprInt ( 0 , expr . size - arg . size ) ) <TAB> if expr . op . startswith ( "" signExt_ "" ) : <TAB> <TAB> arg = expr . args [ 0 ] <TAB> <TAB> add_size = expr . size - arg . size <TAB> <TAB> new_expr = ExprCompose ( <TAB> <TAB> <TAB> arg , <TAB> <TAB> <TAB> ExprCond ( <TAB> <TAB> <TAB> <TAB> arg . msb ( ) , ExprInt ( size2mask ( add_size ) , add_size ) , ExprInt ( 0 , add_size ) <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> return new_expr <TAB> return expr",if arg . msb ( ) == 0 :,if expr . size == arg . size :,False,96.7,72.23,,,
"def mark_differences ( value : str , compare_against : str ) : <TAB> result = [ ] <TAB> for i , char in enumerate ( value ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result . append ( ' <font color= "" red "" > {} </font> ' . format ( char ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result . append ( char ) <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> result . append ( char ) <TAB> return "" "" . join ( result )",if compare_against [ i ] :,if char != compare_against [ i ] :,False,97.26,72.75,,,
"def run_query ( self , query , user ) : <TAB> url = "" %s %s "" % ( self . base_url , "" & "" . join ( query . split ( "" \n "" ) ) ) <TAB> error = None <TAB> data = None <TAB> try : <TAB> <TAB> response = requests . get ( url , auth = self . auth , verify = self . verify ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = _transform_result ( response ) <TAB> <TAB> else : <TAB> <TAB> <TAB> error = "" Failed getting results ( %d ) "" % response . status_code <TAB> except Exception as ex : <TAB> <TAB> data = None <TAB> <TAB> error = str ( ex ) <TAB> return data , error",if response . status_code == 200 :,if response . status_code == 200 :,True,100.0,74.53,,,
"def on_enter ( self ) : <TAB> """""" Fired when mouse enter the bbox of the widget. """""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB> <TAB> else : <TAB> <TAB> <TAB> if not self . focus_color : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = self . focus_color",if self . focus_color :,"if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",False,93.02,81.67,,,
"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . storage_account_name is not None : <TAB> <TAB> <TAB> <TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( )",if self . hosted_service_name is not None :,if self . hosted_service_name is not None :,True,100.0,74.53,,,
"def name2cp ( k ) : <TAB> if k == "" apos "" : <TAB> <TAB> return ord ( "" ' "" ) <TAB> if hasattr ( htmlentitydefs , "" name2codepoint "" ) : # requires Python 2.3 <TAB> <TAB> return htmlentitydefs.name2codepoint[k] <TAB> else: <TAB> <TAB> k = htmlentitydefs.entitydefs[k] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return int(k[2:-1]) # not in latin-1 <TAB> <TAB> return ord(codecs.latin_1_decode(k)[0])","if k . startswith ( ""x-"" ) :","if k . startswith ( ""&#"" ) and k . endswith ( "";"" ) :",False,91.47,63.76,,,
"def _para_set ( self , params , part ) : <TAB> if len ( params ) == 0 : <TAB> <TAB> result = suggest ( [ i . get_name ( ) for i in self . _options ] , part ) <TAB> <TAB> return result <TAB> elif len ( params ) == 1 : <TAB> <TAB> paramName = params [ 0 ] <TAB> <TAB> if paramName not in self . _options : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> opt = self . _options [ paramName ] <TAB> <TAB> paramType = opt . get_type ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values = [ opt . get_default_value ( ) == "" True "" and "" False "" or "" True "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> values = self . _memory [ paramName ] <TAB> <TAB> return suggest ( values , part ) <TAB> else : <TAB> <TAB> return [ ]","if paramType == ""boolean"" :","if paramType == ""boolean"" :",True,100.0,74.62,,,
"def hexcmp ( x , y ) : <TAB> try : <TAB> <TAB> a = int ( x , 16 ) <TAB> <TAB> b = int ( y , 16 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> if a > b : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> return cmp ( x , y )",if a < b :,if a < b :,True,100.0,74.16,,,
"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> if arguments : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement , arguments ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement ) <TAB> <TAB> except sqlite3 . OperationalError as ex : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB> <TAB> return self . cursor . fetchall ( )",if ex . errno != errno . EEXIST :,"if ""locked"" not in getSafeExString ( ex ) :",False,94.56,64.07,,,
"def _test_forever ( self , tests ) : <TAB> while True : <TAB> <TAB> for test_name in tests : <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if self . ns . fail_env_changed and self . environment_changed : <TAB> <TAB> <TAB> <TAB> return",if self . ns . fail_test_changed and self . environment_changed :,if self . bad :,False,87.85,69.44,,,
"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> user = self . _users [ username ] <TAB> <TAB> if user . room : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> self . _users . pop ( username ) <TAB> <TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB> <TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB> <TAB> self . _client . lastLeftTime = time . time ( ) <TAB> <TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( )","if user . room . isSideOf ( ""South"" ) :",if self . isRoomSame ( user . room ) :,False,95.82,63.8,,,
"def AutoTest ( ) : <TAB> with open ( sys . argv [ 1 ] , "" rb "" ) as f : <TAB> <TAB> for line in f . read ( ) . split ( b "" \n "" ) : <TAB> <TAB> <TAB> line = BYTES2SYSTEMSTR ( line . strip ( ) ) <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> <TAB> print ( line ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print ( "" >>>  "" + line ) <TAB> <TAB> <TAB> <TAB> os . system ( line ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( "" \n press enter to continue... "" ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> input ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raw_input ( ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( "" \n "" )",if sys . stdin . isatty ( ) :,if PY3 :,False,97.21,73.12,,,
"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> elif hasattr ( layout_object , "" get_field_names "" ) : <TAB> <TAB> <TAB> gf = get_first_field ( layout_object , clz ) <TAB> <TAB> <TAB> if gf : <TAB> <TAB> <TAB> <TAB> return gf","if hasattr ( layout_object , ""get_field_names"" ) :","if issubclass ( layout_object . __class__ , clz ) :",False,91.18,60.28,,,
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB> if key not in valid_keys: <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> if isinstance(kwargs.get(""event_data"", {}).get(key), str): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )","if kwargs [ ""event_data"" ] [ key ] . isdigit ( ) :","if len ( kwargs [ ""event_data"" ] [ key ] ) > 1024 :",False,96.76,70.2,,,
"def visit_productionlist ( self , node ) : <TAB> self . new_state ( ) <TAB> names = [ ] <TAB> for production in node : <TAB> <TAB> names . append ( production [ "" tokenname "" ] ) <TAB> maxlen = max ( len ( name ) for name in names ) <TAB> for production in node : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_text ( production [ "" tokenname "" ] . ljust ( maxlen ) + ""  ::= "" ) <TAB> <TAB> <TAB> lastname = production [ "" tokenname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . add_text ( "" %s  <TAB>  "" % ( "" "" * len ( lastname ) ) ) <TAB> <TAB> self . add_text ( production . astext ( ) + self . nl ) <TAB> self . end_state ( wrap = False ) <TAB> raise nodes . SkipNode","if production [ ""tokenname"" ] :","if production [ ""tokenname"" ] :",True,100.0,74.59,,,
"def uuid ( self ) : <TAB> if not getattr ( self , "" _uuid "" , None ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _uuid = self . repository . _kp_uuid ( <TAB> <TAB> <TAB> <TAB> self . path <TAB> <TAB> <TAB> ) # Use repository UUID (even if None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self._uuid = str(uuid.uuid4()) <TAB> return self._uuid",if self . repository :,if self . repository is not None :,False,96.54,70.48,,,
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> if v == "" ANY "" : <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> elif v in self . _definition : <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )",if self . _definition == v :,"if isinstance ( self . _definition , dict ) :",False,96.97,72.39,,,
"def make ( self ) : <TAB> pygments_dir = join ( self . dir , "" externals "" , "" pygments "" ) <TAB> if exists ( pygments_dir ) : <TAB> <TAB> run_in_dir ( "" hg pull "" , pygments_dir , self . log . info ) <TAB> <TAB> run_in_dir ( "" hg update "" , pygments_dir , self . log . info ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( dirname ( pygments_dir ) ) <TAB> <TAB> run_in_dir ( <TAB> <TAB> <TAB> "" hg clone http://dev.pocoo.org/hg/pygments-main  %s "" <TAB> <TAB> <TAB> % basename ( pygments_dir ) , <TAB> <TAB> <TAB> dirname ( pygments_dir ) , <TAB> <TAB> <TAB> self . log . info , <TAB> <TAB> )",if not os . path . isdir ( dirname ( pygments_dir ) ) :,if not exists ( dirname ( pygments_dir ) ) :,False,97.2,72.85,,,
def set_field ( self ) : <TAB> i = 0 <TAB> for string in self . display_string : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . config [ self . field + str ( i ) ] = self . conversion_fn ( self . str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . config [ self . field + str ( i ) ] = self . str [ i ] <TAB> <TAB> i = i + 1,if self . conversion_fn :,if self . conversion_fn :,True,100.0,99.26,,,
"def cleanup ( self ) : <TAB> with self . lock : <TAB> <TAB> for proc in self . processes : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> proc . join ( ) <TAB> <TAB> <TAB> self . processes . remove ( proc ) <TAB> <TAB> <TAB> log . debug ( "" Subprocess  %s  cleaned up "" , proc . name )",if proc . is_alive ( ) :,if proc . is_alive ( ) :,True,100.0,74.14,,,
"def setup ( self , gen ) : <TAB> Node . setup ( self , gen ) <TAB> for c in self . children : <TAB> <TAB> c . setup ( gen ) <TAB> if not self . accepts_epsilon : <TAB> <TAB> # If it's not already accepting epsilon, it might now do so. <TAB> <TAB> for c in self.children: <TAB> <TAB> <TAB> # any non-epsilon means all is non-epsilon <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> self.accepts_epsilon = 1 <TAB> <TAB> <TAB> gen.changed()",if c . accept_epsilon and c . accept_epsilon :,if not c . accepts_epsilon :,False,94.33,71.06,,,
"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack + = 1 <TAB> <TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB> <TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack - = 1 <TAB> <TAB> message . ack ( ) <TAB> <TAB> self . completed_calls + = 1 <TAB> <TAB> if self . completed_calls > = self . _resolve_at_msg_count : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . done_future . set_result ( None )",if self . done_future :,if not self . done_future . done ( ) :,False,96.48,71.37,,,
"def build_canned_image_list ( path ) : <TAB> layers_path = get_bitbake_var ( "" BBLAYERS "" ) <TAB> canned_wks_layer_dirs = [ ] <TAB> if layers_path is not None : <TAB> <TAB> for layer_path in layers_path . split ( ) : <TAB> <TAB> <TAB> for wks_path in ( WIC_DIR , SCRIPTS_CANNED_IMAGE_DIR ) : <TAB> <TAB> <TAB> <TAB> cpath = os . path . join ( layer_path , wks_path ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> cpath = os . path . join ( path , CANNED_IMAGE_DIR ) <TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> return canned_wks_layer_dirs",if os . path . isdir ( cpath ) :,if os . path . isdir ( cpath ) :,True,100.0,74.46,,,
"def _recv_loop ( self ) - > None : <TAB> async with self . _ws as connection : <TAB> <TAB> self . _connected = True <TAB> <TAB> self . connection = connection <TAB> <TAB> while self . _connected : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> resp = await self . connection . recv ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> await self . _on_message ( resp ) <TAB> <TAB> <TAB> except ( websockets . ConnectionClosed , ConnectionResetError ) : <TAB> <TAB> <TAB> <TAB> logger . info ( "" connection closed "" ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> await asyncio . sleep ( 0 ) <TAB> if self . _connected : <TAB> <TAB> self . _loop . create_task ( self . dispose ( ) )",if resp :,if resp :,True,100.0,74.55,,,
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> if start in line : <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line : <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ]",if end is not None and line . strip ( ) . startswith ( end ) :,if end and end in line :,False,89.62,68.82,,,
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB> <TAB> if self . mutually_exclusive . intersection ( opts ) : <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args )",elif self . exclusive_equal . intersection ( opts ) :,if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 :,False,85.54,63.24,,,
"def write ( self , s ) : <TAB> if self . interactive : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . active_mode . write ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> component . get ( "" CmdLine "" ) . add_line ( s , False ) <TAB> <TAB> <TAB> self . events . append ( s ) <TAB> else : <TAB> <TAB> print ( colors . strip_colors ( s ) )",if self . active_mode :,"if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) :",False,86.09,64.65,,,
"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> if name.startswith(""."") or name == ""lastsnap.jpg"": <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os.path.join(path, name) <TAB> <TAB> st = os.lstat(pathname) <TAB> <TAB> mode = st.st_mode <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> files.extend(findfiles(pathname)) <TAB> <TAB> elif stat.S_ISREG(mode): <TAB> <TAB> <TAB> files.append((pathname, name, st)) <TAB> return files",if stat . S_ISDIR ( mode ) :,if stat . S_ISDIR ( mode ) :,True,100.0,74.3,,,
"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB> <TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> if startswith is not None and not key.startswith(startswith): <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> names.append(key) <TAB> return names","if getattr ( command , ""_PARAMS"" , None ) :","if getattr ( command , ""positional_arg"" , False ) :",False,95.91,71.94,,,
"def fix_newlines ( lines ) : <TAB> """""" Convert newlines to unix. """""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB> <TAB> elif line . endswith ( "" \r "" ) : <TAB> <TAB> <TAB> lines [ i ] = line [ : - 1 ] + "" \n ""","if line . endswith ( ""\n"" ) :","if line . endswith ( ""\r\n"" ) :",False,97.7,61.58,,,
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self.plugin_args.start: <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self.plugin_args.end: <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if utils . IsValidVtop ( vaddr ) :,if self . plugin_args . start <= vaddr <= self . plugin_args . end :,False,91.27,68.54,,,
"def get_shape_at_node ( self , node , assumptions ) : <TAB> for k , v in assumptions . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return v <TAB> if node . inputs : <TAB> <TAB> return node . container . shape ( <TAB> <TAB> <TAB> input_shapes = [ <TAB> <TAB> <TAB> <TAB> self . get_shape_at_node ( input_node , assumptions ) <TAB> <TAB> <TAB> <TAB> for input_node in node . inputs <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return node . container . shape ( None )",if k . is_shape ( ) :,if k in node . names :,False,95.84,71.65,,,
"def fix_doc ( self , doc ) : <TAB> type = doc . get ( "" type "" , { } ) . get ( "" key "" ) <TAB> if type == "" /type/work "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # some record got empty author records because of an error <TAB> <TAB> <TAB> # temporary hack to fix <TAB> <TAB> <TAB> doc[""authors""] = [ <TAB> <TAB> <TAB> <TAB> a for a in doc[""authors""] if ""author"" in a and ""key"" in a[""author""] <TAB> <TAB> <TAB> ] <TAB> elif type == ""/type/edition"": <TAB> <TAB> # get rid of title_prefix. <TAB> <TAB> if ""title_prefix"" in doc: <TAB> <TAB> <TAB> title = doc[""title_prefix""].strip() + "" "" + doc.get(""title"", """") <TAB> <TAB> <TAB> doc[""title""] = title.strip() <TAB> <TAB> <TAB> del doc[""title_prefix""] <TAB> return doc","if ""authors"" in doc :","if doc . get ( ""authors"" ) :",False,97.29,97.1,,,
"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB> <TAB> gate = column [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif isinstance ( gate , ParityControlCell ) : <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column[i] = None <TAB> <TAB> <TAB> self._basis_change += gate._basis_change <TAB> <TAB> <TAB> self.qubits += gate.qubits <TAB> <TAB> elif gate is not None: <TAB> <TAB> <TAB> column[i] = gate.controlled_by(self.qubits[0])","if isinstance ( gate , Cell ) :",if gate is self :,False,96.63,71.89,,,
"def onSync ( self , auto = False , reload = True ) : <TAB> if not auto or ( <TAB> <TAB> self . pm . profile [ "" syncKey "" ] and self . pm . profile [ "" autoSync "" ] and not self . safeMode <TAB> ) : <TAB> <TAB> from aqt . sync import SyncManager <TAB> <TAB> if not self . unloadCollection ( ) : <TAB> <TAB> <TAB> return <TAB> <TAB> # set a sync state so the refresh timer doesn't fire while deck <TAB> <TAB> # unloaded <TAB> <TAB> self.state = ""sync"" <TAB> <TAB> self.syncer = SyncManager(self, self.pm) <TAB> <TAB> self.syncer.sync() <TAB> if reload: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.loadCollection()","if self . pm . profile [ ""syncKey"" ] :",if not self . col :,False,94.68,65.9,,,
"def _has_url_match ( self , match , request_url ) : <TAB> url = match [ "" url "" ] <TAB> if _is_string ( url ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _has_strict_url_match ( url , request_url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url_without_qs = request_url . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> return url == url_without_qs <TAB> elif isinstance ( url , re . _pattern_type ) and url . match ( request_url ) : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return False",if self . strict :,"if match [ ""match_querystring"" ] :",False,94.8,66.06,,,
"def pool_image ( self , image ) : <TAB> if self . count < self . pool_size : <TAB> <TAB> self . pool . append ( image ) <TAB> <TAB> self . count + = 1 <TAB> <TAB> return image <TAB> else : <TAB> <TAB> p = random . random ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> random_id = random . randint ( 0 , self . pool_size - 1 ) <TAB> <TAB> <TAB> temp = self . pool [ random_id ] <TAB> <TAB> <TAB> self . pool [ random_id ] = image <TAB> <TAB> <TAB> return temp <TAB> <TAB> else : <TAB> <TAB> <TAB> return image",if p < self . pool_size :,if p > 0.5 :,False,95.93,72.46,,,
"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB> <TAB> <TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB> <TAB> if operation [ "" type "" ] == "" resize "" : <TAB> <TAB> <TAB> width = operation [ "" width "" ] <TAB> <TAB> <TAB> height = operation [ "" height "" ] <TAB> return ( width , height )","if operation [ ""type"" ] == ""resize"" :","if operation [ ""type"" ] == ""crop"" :",False,98.43,73.32,,,
"def validate_matrix ( matrix ) : <TAB> if not matrix : <TAB> <TAB> return None <TAB> for key , value in matrix . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> "" ` {} ` defines a non uniform distribution,  "" <TAB> <TAB> <TAB> <TAB> "" and it cannot be used with bayesian optimization. "" . format ( key ) <TAB> <TAB> <TAB> ) <TAB> return matrix",if not np . isscalar ( value ) :,if value . is_distribution and not value . is_uniform :,False,90.46,69.07,,,
"def scm_to_conandata ( self ) : <TAB> try : <TAB> <TAB> scm_to_conandata = get_env ( "" CONAN_SCM_TO_CONANDATA "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scm_to_conandata = self . get_item ( "" general.scm_to_conandata "" ) <TAB> <TAB> return scm_to_conandata . lower ( ) in ( "" 1 "" , "" true "" ) <TAB> except ConanException : <TAB> <TAB> return False",if not scm_to_conandata :,if scm_to_conandata is None :,False,95.99,70.33,,,
"def _link_vrf_table ( self , vrf_table , rt_list ) : <TAB> route_family = vrf_table . route_family <TAB> for rt in rt_list : <TAB> <TAB> rt_rf_id = rt + "" : "" + str ( route_family ) <TAB> <TAB> table_set = self . _tables_for_rt . get ( rt_rf_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> table_set = set ( ) <TAB> <TAB> <TAB> self . _tables_for_rt [ rt_rf_id ] = table_set <TAB> <TAB> table_set . add ( vrf_table ) <TAB> <TAB> LOG . debug ( "" Added VrfTable  %s  to import RT table list:  %s "" , vrf_table , rt )",if table_set is None :,if table_set is None :,True,100.0,74.39,,,
"def add_tags ( <TAB> self , cve_results : Dict [ str , Dict [ str , Dict [ str , str ] ] ] , file_object : FileObject ) : <TAB> # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB> for component in cve_results: <TAB> <TAB> for cve_id in cve_results[component]: <TAB> <TAB> <TAB> entry = cve_results[component][cve_id] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.add_analysis_tag( <TAB> <TAB> <TAB> <TAB> <TAB> file_object, ""CVE"", ""critical CVE"", TagColor.RED, True <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return","if entry [ ""score2"" ] == ""6.4"" :",if self . _entry_has_critical_rating ( entry ) :,False,93.44,63.7,,,
"def _validate ( self ) : <TAB> try : <TAB> <TAB> super ( CustomClassifier , self ) . _validate ( ) <TAB> except UnsupportedDataType : <TAB> <TAB> if self . dtype in FACTOR_DTYPES : <TAB> <TAB> <TAB> raise UnsupportedDataType ( <TAB> <TAB> <TAB> <TAB> typename = type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> dtype = self . dtype , <TAB> <TAB> <TAB> <TAB> hint = "" Did you mean to create a CustomFactor? "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise UnsupportedDataType ( <TAB> <TAB> <TAB> <TAB> typename = type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> dtype = self . dtype , <TAB> <TAB> <TAB> <TAB> hint = "" Did you mean to create a CustomFilter? "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> raise",if self . dtype not in FILTER_DTYPES :,elif self . dtype in FILTER_DTYPES :,False,98.0,72.86,,,
"def formatMessage ( self , record ) : <TAB> recordcopy = copy ( record ) <TAB> levelname = recordcopy . levelname <TAB> seperator = "" "" * ( 8 - len ( recordcopy . levelname ) ) <TAB> if self . use_colors : <TAB> <TAB> levelname = self . color_level_name ( levelname , recordcopy . levelno ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> recordcopy . msg = recordcopy . __dict__ [ "" color_message "" ] <TAB> <TAB> <TAB> recordcopy . __dict__ [ "" message "" ] = recordcopy . getMessage ( ) <TAB> recordcopy . __dict__ [ "" levelprefix "" ] = levelname + "" : "" + seperator <TAB> return super ( ) . formatMessage ( recordcopy )","if ""color_message"" in recordcopy . __dict__ :","if ""color_message"" in recordcopy . __dict__ :",True,100.0,74.48,,,
"def dumpregs ( self ) : <TAB> for reg in ( <TAB> <TAB> list ( self . regs . retaddr ) <TAB> <TAB> + list ( self . regs . misc ) <TAB> <TAB> + list ( self . regs . common ) <TAB> <TAB> + list ( self . regs . flags ) <TAB> ) : <TAB> <TAB> enum = self . get_reg_enum ( reg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> debug ( "" # Could not dump register  %r "" % reg ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = "" U.x86_const.UC_X86_REG_ %s "" % reg . upper ( ) <TAB> <TAB> value = self . uc . reg_read ( enum ) <TAB> <TAB> debug ( "" uc.reg_read( %(name)s ) ==>  %(value)x "" % locals ( ) )",if enum is None :,if not reg or enum is None :,False,97.98,72.67,,,
"def filter ( self , lexer , stream ) : <TAB> current_type = None <TAB> current_value = None <TAB> for ttype , value in stream : <TAB> <TAB> if ttype is current_type : <TAB> <TAB> <TAB> current_value + = value <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield current_type , current_value <TAB> <TAB> <TAB> current_type = ttype <TAB> <TAB> <TAB> current_value = value <TAB> <IF-STMT> <TAB> <TAB> yield current_type , current_value",if current_type is not None :,if current_type is not None :,True,100.0,74.33,,,
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line : <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line : <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ]",if start and start in line :,if start in line :,False,97.95,73.28,,,
"def parse_git_config ( path ) : <TAB> """""" Parse git config file. """""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> if line . startswith ( "" [ "" ) : <TAB> <TAB> <TAB> <TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> config [ section ] = dict ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB> <TAB> <TAB> <TAB> config [ section ] [ key ] = value <TAB> return config",if section :,elif section :,False,98.88,98.63,,,
"def test_has_arg ( fn , name , accept_all , expected ) : <TAB> if isinstance ( fn , str ) : <TAB> <TAB> context = dict ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> exec ( "" def  {} : pass "" . format ( fn ) , context ) <TAB> <TAB> except SyntaxError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> pytest . skip ( "" Function is not compatible with Python 2 "" ) <TAB> <TAB> # Sometimes exec adds builtins to the context <TAB> <TAB> context.pop(""__builtins__"", None) <TAB> <TAB> (fn,) = context.values() <TAB> assert has_arg(fn, name, accept_all) is expected","if sys . version_info < ( 2 , 3 , 5 ) :","if sys . version_info >= ( 3 , ) :",False,96.41,71.95,,,
"def ObjectExpression ( self , properties , * * kwargs ) : <TAB> data = [ ] <TAB> for prop in properties : <TAB> <TAB> self . emit ( prop [ "" value "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise NotImplementedError ( <TAB> <TAB> <TAB> <TAB> "" ECMA 5.1 does not support computed object properties! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> data . append ( ( to_key ( prop [ "" key "" ] ) , prop [ "" kind "" ] [ 0 ] ) ) <TAB> self . emit ( "" LOAD_OBJECT "" , tuple ( data ) )","if prop [ ""kind"" ] == ""computed"" :","if prop [ ""computed"" ] :",False,95.09,68.65,,,
"def run ( self ) : <TAB> for domain , locale , po in self . locales : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = os . path . join ( "" locale "" , locale , "" LC_MESSAGES "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> path = os . path . join ( self . build_dir , locale , "" LC_MESSAGES "" ) <TAB> <TAB> mo = os . path . join ( path , "" %s .mo "" % domain ) <TAB> <TAB> self . mkpath ( path ) <TAB> <TAB> self . spawn ( [ "" msgfmt "" , "" -o "" , mo , po ] )","if domain == ""en"" :",if self . inplace :,False,95.35,68.6,,,
"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB> <TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB> <TAB> if second_byte == None : <TAB> <TAB> <TAB> return "" XED_ILD_MAP1 "" <TAB> <TAB> if second_byte == 0x38 : <TAB> <TAB> <TAB> return "" XED_ILD_MAP2 "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" XED_ILD_MAP3 "" <TAB> <TAB> if second_byte == 0x0F and self . amd_enabled : <TAB> <TAB> <TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) )",if second_byte == 0x0F and self . amd_enabled :,if second_byte == 0x3A :,False,95.98,72.41,,,
"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> buf . append ( c ) <TAB> <TAB> elif c == "" \\ "" : <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> elif c == "" > "" : <TAB> <TAB> <TAB> return "" "" . join ( buf ) <TAB> <TAB> else : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) )",if escaped :,if escaped :,True,100.0,74.41,,,
"def print_pairs ( attrs = None , offset_y = 0 ) : <TAB> fmt = ""  ( {0} : {1} )  "" <TAB> fmt_len = len ( fmt ) <TAB> for bg , fg in get_fg_bg ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> color = curses . color_pair ( pair_number ( fg , bg ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for attr in attrs : <TAB> <TAB> <TAB> <TAB> <TAB> color | = attr <TAB> <TAB> <TAB> screen . addstr ( offset_y + bg , fg * fmt_len , fmt . format ( fg , bg ) , color ) <TAB> <TAB> <TAB> pass <TAB> <TAB> except curses . error : <TAB> <TAB> <TAB> pass",if attrs :,if not attrs is None :,False,97.49,72.06,,,
"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 : # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> axis = int(inputs[1]) <TAB> <TAB> elif _is_int_seq(inputs[1]): <TAB> <TAB> <TAB> axis = inputs[1] <TAB> <TAB> else: <TAB> <TAB> <TAB> axis = list(_infer_shape(inputs[1])) <TAB> <TAB> keepdims = bool(inputs[2]) <TAB> return get_relay_op(name)(data, axis=axis, keepdims=keepdims)",if _is_int_seq ( inputs [ 1 ] ) :,"if isinstance ( inputs [ 1 ] , int ) :",False,95.6,70.88,,,
"def run ( self , args , * * kwargs ) : <TAB> # Filtering options <TAB> if args.trace_tag: <TAB> <TAB> kwargs[""trace_tag""] = args.trace_tag <TAB> if args.trigger_instance: <TAB> <TAB> kwargs[""trigger_instance""] = args.trigger_instance <TAB> if args.execution: <TAB> <TAB> kwargs[""execution""] = args.execution <TAB> if args.rule: <TAB> <TAB> kwargs[""rule""] = args.rule <TAB> if args.sort_order: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs[""sort_asc""] = True <TAB> <TAB> elif args.sort_order in [""desc"", ""descending""]: <TAB> <TAB> <TAB> kwargs[""sort_desc""] = True <TAB> return self.manager.query_with_count(limit=args.last, **kwargs)","if args . sort_order in [ ""asc"" , ""descending"" ] :","if args . sort_order in [ ""asc"" , ""ascending"" ] :",False,98.97,72.88,,,
def retaddr ( ) : <TAB> sp = pwndbg . regs . sp <TAB> stack = pwndbg . vmmap . find ( sp ) <TAB> # Enumerate all return addresses <TAB> frame = gdb.newest_frame() <TAB> addresses = [] <TAB> while frame: <TAB> <TAB> addresses.append(frame.pc()) <TAB> <TAB> frame = frame.older() <TAB> # Find all of them on the stack <TAB> start = stack.vaddr <TAB> stop = start + stack.memsz <TAB> while addresses and start < sp < stop: <TAB> <TAB> value = pwndbg.memory.u(sp) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> index = addresses.index(value) <TAB> <TAB> <TAB> del addresses[:index] <TAB> <TAB> <TAB> print(pwndbg.chain.format(sp)) <TAB> <TAB> sp += pwndbg.arch.ptrsize,if value in addresses :,if value in addresses :,True,100.0,99.42,,,
"def update_from_dictio ( self , dictio_item ) : <TAB> for index , dictio_payload in enumerate ( dictio_item , 1 ) : <TAB> <TAB> fuzz_payload = None <TAB> <TAB> for fuzz_payload in self . payloads [ index ] : <TAB> <TAB> <TAB> fuzz_payload . content = dictio_payload . content <TAB> <TAB> <TAB> fuzz_payload . type = dictio_payload . type <TAB> <TAB> # payload generated not used in seed but in filters <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.add( <TAB> <TAB> <TAB> <TAB> {""full_marker"": None, ""word"": None, ""index"": index, ""field"": None}, <TAB> <TAB> <TAB> <TAB> dictio_item[index - 1], <TAB> <TAB> <TAB> )",if fuzz_payload is not None :,if fuzz_payload is None :,False,98.83,73.45,,,
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","if isinstance ( result , str ) :","if isinstance ( result , str ) :",True,100.0,74.62,,,
"def execute_sql ( self , sql , params = None , commit = True ) : <TAB> try : <TAB> <TAB> cursor = super ( RetryOperationalError , self ) . execute_sql ( sql , params , commit ) <TAB> except OperationalError : <TAB> <TAB> if not self . is_closed ( ) : <TAB> <TAB> <TAB> self . close ( ) <TAB> <TAB> with __exception_wrapper__ : <TAB> <TAB> <TAB> cursor = self . cursor ( ) <TAB> <TAB> <TAB> cursor . execute ( sql , params or ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . commit ( ) <TAB> return cursor",if commit :,if commit and not self . in_transaction ( ) :,False,93.96,70.52,,,
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",if operation and definition . name . value == operation_name :,if operation :,False,95.24,72.8,,,
"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB> <TAB> if self . is_ws ( aList [ i ] ) : <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self . skip_ws ( aList , i ) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList[j:i] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else: <TAB> <TAB> <TAB> i += 1",if aList [ j ] == aList [ j ] :,"if i >= len ( aList ) or aList [ i ] == ""\n"" :",False,91.27,59.39,,,
"def _process_filter ( self , query , host_state ) : <TAB> """""" Recursively parse the query structure. """""" <TAB> if not query : <TAB> <TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> arg = self . _process_filter ( arg , host_state ) <TAB> <TAB> elif isinstance ( arg , basestring ) : <TAB> <TAB> <TAB> arg = self . _parse_string ( arg , host_state ) <TAB> <TAB> if arg is not None : <TAB> <TAB> <TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result","if isinstance ( arg , ( list , tuple ) ) :","if isinstance ( arg , list ) :",False,97.04,96.52,,,
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB> <TAB> <TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB> <TAB> elif child . tag in ( "" w "" , "" c "" ) : <TAB> <TAB> <TAB> sent . append ( self . handle_word ( child ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent )","elif child . tag != ""h"" :",elif child . tag not in self . tags_to_ignore :,False,94.2,68.69,,,
"def get_display_price ( <TAB> base : Union [ TaxedMoney , TaxedMoneyRange ] , display_gross : bool = False ) - > Money : <TAB> """""" Return the price amount that should be displayed based on settings. """""" <TAB> if not display_gross : <TAB> <TAB> display_gross = display_gross_prices ( ) <TAB> if isinstance ( base , TaxedMoneyRange ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> base = MoneyRange ( start = base . start . gross , stop = base . stop . gross ) <TAB> <TAB> else : <TAB> <TAB> <TAB> base = MoneyRange ( start = base . start . net , stop = base . stop . net ) <TAB> if isinstance ( base , TaxedMoney ) : <TAB> <TAB> base = base . gross if display_gross else base . net <TAB> return base",if base . start . gross is None :,if display_gross :,False,95.94,96.06,,,
"def check_classes ( self , node ) : <TAB> if isinstance ( node , nodes . Element ) : <TAB> <TAB> for class_value in node [ "" classes "" ] [ : ] : <TAB> <TAB> <TAB> if class_value in self . strip_classes : <TAB> <TAB> <TAB> <TAB> node [ "" classes "" ] . remove ( class_value ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return 1","if len ( node [ ""classes"" ] ) == 0 :",if class_value in self . strip_elements :,False,89.14,61.76,,,
"def validate ( outfile = sys . stdout , silent_success = False ) : <TAB> "" Validates all installed models. "" <TAB> try : <TAB> <TAB> num_errors = get_validation_errors ( outfile ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> outfile . write ( <TAB> <TAB> <TAB> "" %s  error %s  found. \n "" % ( num_errors , num_errors != 1 and "" s "" or "" "" ) <TAB> <TAB> ) <TAB> except ImproperlyConfigured : <TAB> <TAB> outfile . write ( "" Skipping validation because things aren ' t configured properly. "" )",if silent_success :,if silent_success and num_errors == 0 :,False,94.68,71.52,,,
"def check_basename_conflicts ( self , targets ) : <TAB> """""" Apps '  basenames are used as bundle directory names. Ensure they are all unique. """""" <TAB> basename_seen = { } <TAB> for target in targets : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise self . BasenameConflictError ( <TAB> <TAB> <TAB> <TAB> "" Basename must be unique, found two targets use  "" <TAB> <TAB> <TAB> <TAB> "" the same basename:  {} ' \n \t {}  and  \n \t {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> target . basename , <TAB> <TAB> <TAB> <TAB> <TAB> basename_seen [ target . basename ] . address . spec , <TAB> <TAB> <TAB> <TAB> <TAB> target . address . spec , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> basename_seen [ target . basename ] = target",if target . basename in basename_seen :,if target . basename in basename_seen :,True,100.0,99.55,,,
"def __init__ ( self , api_version_str ) : <TAB> try : <TAB> <TAB> self . latest = self . preview = False <TAB> <TAB> self . yyyy = self . mm = self . dd = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . latest = True <TAB> <TAB> else : <TAB> <TAB> <TAB> if "" preview "" in api_version_str : <TAB> <TAB> <TAB> <TAB> self . preview = True <TAB> <TAB> <TAB> parts = api_version_str . split ( "" - "" ) <TAB> <TAB> <TAB> self . yyyy = int ( parts [ 0 ] ) <TAB> <TAB> <TAB> self . mm = int ( parts [ 1 ] ) <TAB> <TAB> <TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB> <TAB> )","if api_version_str == ""latest"" :","if api_version_str == ""latest"" :",True,100.0,74.63,,,
"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB> <TAB> y = self . _curve . b <TAB> else : <TAB> <TAB> result = self . sqrtp ( <TAB> <TAB> <TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y = result [ 0 ] <TAB> <TAB> elif len ( result ) == 2 : <TAB> <TAB> <TAB> y1 , y2 = result <TAB> <TAB> <TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return ec . Point ( self . _curve , x , y )",if len ( result ) == 1 :,if len ( result ) == 1 :,True,100.0,74.63,,,
"def _visit_import_alike ( self , node : Union [ cst . Import , cst . ImportFrom ] ) - > bool : <TAB> names = node . names <TAB> if isinstance ( names , cst . ImportStar ) : <TAB> <TAB> return False <TAB> # make sure node.names is Sequence[ImportAlias] <TAB> for name in names: <TAB> <TAB> self.provider.set_metadata(name, self.scope) <TAB> <TAB> asname = name.asname <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name_values = _gen_dotted_names(cst.ensure_type(asname.name, cst.Name)) <TAB> <TAB> else: <TAB> <TAB> <TAB> name_values = _gen_dotted_names(name.name) <TAB> <TAB> for name_value, _ in name_values: <TAB> <TAB> <TAB> self.scope.record_assignment(name_value, node) <TAB> return False","if isinstance ( asname , cst . Name ) :",if asname is not None :,False,96.07,70.55,,,
"def test_sanity_no_unmatched_parentheses ( CorpusType : Type [ ColumnCorpus ] ) : <TAB> corpus = CorpusType ( ) <TAB> unbalanced_entities = [ ] <TAB> for sentence in corpus . get_all_sentences ( ) : <TAB> <TAB> entities = sentence . get_spans ( "" ner "" ) <TAB> <TAB> for entity in entities : <TAB> <TAB> <TAB> entity_text = "" "" . join ( t . text for t in entity . tokens ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> unbalanced_entities . append ( entity_text ) <TAB> assert unbalanced_entities == [ ]",if entity_text not in unbalanced_entities :,if not has_balanced_parantheses ( entity_text ) :,False,93.51,71.3,,,
"def _learn_rate_adjust ( self ) : <TAB> if self . learn_rate_decays == 1.0 : <TAB> <TAB> return <TAB> learn_rate_decays = self . _vp ( self . learn_rate_decays ) <TAB> learn_rate_minimums = self . _vp ( self . learn_rate_minimums ) <TAB> for index , decay in enumerate ( learn_rate_decays ) : <TAB> <TAB> new_learn_rate = self . net_ . learnRates [ index ] * decay <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . net_ . learnRates [ index ] = new_learn_rate <TAB> if self . verbose > = 2 : <TAB> <TAB> print ( "" Learn rates:  {} "" . format ( self . net_ . learnRates ) )",if new_learn_rate < self . learn_rate_minimums :,if new_learn_rate >= learn_rate_minimums [ index ] :,False,95.98,71.75,,,
"def set_attr_from_xmp_tag ( self , attr , xmp_tags , tags , cast = None ) : <TAB> v = self . get_xmp_tag ( xmp_tags , tags ) <TAB> if v is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( self , attr , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Handle fractions <TAB> <TAB> <TAB> if (cast == float or cast == int) and ""/"" in v: <TAB> <TAB> <TAB> <TAB> v = self.try_parse_fraction(v) <TAB> <TAB> <TAB> setattr(self, attr, cast(v))",if cast is None :,if cast is None :,True,100.0,74.34,,,
"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB> <TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> if re . match ( "" [0-9] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB> <TAB> <TAB> i - = 1 <TAB> return tokens",if i == 0 :,"if not re . match ( ""[0-9]"" , str ( tokens [ s ] ) ) :",False,91.38,66.12,,,
"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> executable = winpymap . get ( name , None ) <TAB> <TAB> <TAB> if executable : <TAB> <TAB> <TAB> <TAB> executable = py . path . local ( executable ) <TAB> <TAB> <TAB> <TAB> if executable . check ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable",if name in winpymap :,"if sys . platform == ""win32"" :",False,94.13,64.59,,,
"def set_meta ( self , dataset , overwrite = True , * * kwd ) : <TAB> super ( ) . set_meta ( dataset , overwrite = overwrite , * * kwd ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with tarfile . open ( dataset . file_name , "" r "" ) as temptar : <TAB> <TAB> <TAB> <TAB> dataset . metadata . fast5_count = sum ( <TAB> <TAB> <TAB> <TAB> <TAB> 1 for f in temptar if f . name . endswith ( "" .fast5 "" ) <TAB> <TAB> <TAB> <TAB> ) <TAB> except Exception as e : <TAB> <TAB> log . warning ( "" %s , set_meta Exception:  %s "" , self , e )",if dataset . file_name :,if dataset and tarfile . is_tarfile ( dataset . file_name ) :,False,94.1,70.91,,,
"def run ( self ) : <TAB> for k in list ( iterkeys ( self . objs ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> v = self . objs [ k ] <TAB> <TAB> if v [ "" _class "" ] == "" User "" : <TAB> <TAB> <TAB> self . split_user ( k , v ) <TAB> <TAB> elif v [ "" _class "" ] in [ <TAB> <TAB> <TAB> "" Message "" , <TAB> <TAB> <TAB> "" PrintJob "" , <TAB> <TAB> <TAB> "" Question "" , <TAB> <TAB> <TAB> "" Submission "" , <TAB> <TAB> <TAB> "" UserTest "" , <TAB> <TAB> ] : <TAB> <TAB> <TAB> v [ "" participation "" ] = v [ "" user "" ] <TAB> <TAB> <TAB> del v [ "" user "" ] <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",True,100.0,74.58,,,
"def _findInTree ( t , n ) : <TAB> ret = [ ] <TAB> if type ( t ) is dict : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( t ) <TAB> <TAB> for k , v in t . items ( ) : <TAB> <TAB> <TAB> ret + = _findInTree ( v , n ) <TAB> if type ( t ) is list : <TAB> <TAB> for v in t : <TAB> <TAB> <TAB> ret + = _findInTree ( v , n ) <TAB> return ret",if n and len ( t ) == n :,"if ""_name"" in t and t [ ""_name"" ] == n :",False,89.72,63.06,,,
"def parseArrayPattern ( self ) : <TAB> node = Node ( ) <TAB> elements = [ ] <TAB> self . expect ( "" [ "" ) <TAB> while not self . match ( "" ] "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . lex ( ) <TAB> <TAB> <TAB> elements . append ( null ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if self . match ( "" ... "" ) : <TAB> <TAB> <TAB> <TAB> restNode = Node ( ) <TAB> <TAB> <TAB> <TAB> self . lex ( ) <TAB> <TAB> <TAB> <TAB> rest = self . parseVariableIdentifier ( ) <TAB> <TAB> <TAB> <TAB> elements . append ( restNode . finishRestElement ( rest ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> elements . append ( self . parsePatternWithDefault ( ) ) <TAB> <TAB> <TAB> if not self . match ( "" ] "" ) : <TAB> <TAB> <TAB> <TAB> self . expect ( "" , "" ) <TAB> self . expect ( "" ] "" ) <TAB> return node . finishArrayPattern ( elements )","if self . match ( "","" ) :","if self . match ( "","" ) :",True,100.0,74.67,,,
"def _set_log_writer ( self ) : <TAB> if self . config [ "" logging "" ] : <TAB> <TAB> config = self . config [ "" log_writer_config "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log_writer = LogWriter ( * * config ) <TAB> <TAB> elif config [ "" writer "" ] == "" tensorboard "" : <TAB> <TAB> <TAB> self . log_writer = TensorBoardWriter ( * * config ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( f "" Unrecognized writer option:  { config [ ' writer ' ] } "" ) <TAB> else : <TAB> <TAB> self . log_writer = None","if config [ ""writer"" ] == ""log"" :","if config [ ""writer"" ] == ""json"" :",False,98.58,73.34,,,
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> if not len ( head ) : <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB> <TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB> <TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries",if not line :,if not len ( line . strip ( ) ) :,False,96.12,71.93,,,
"def get_all_values ( self , project ) : <TAB> if isinstance ( project , models . Model ) : <TAB> <TAB> project_id = project . id <TAB> else : <TAB> <TAB> project_id = project <TAB> if project_id not in self . __cache : <TAB> <TAB> cache_key = self . _make_key ( project_id ) <TAB> <TAB> result = cache . get ( cache_key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = self . reload_cache ( project_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __cache [ project_id ] = result <TAB> return self . __cache . get ( project_id , { } )",if result is None :,if result is None :,True,100.0,74.43,,,
"def needed_libraries ( self ) : <TAB> for cmd in self . load_commands_of_type ( 0xC ) : # LC_LOAD_DYLIB <TAB> <TAB> tname = self._get_typename(""dylib_command"") <TAB> <TAB> dylib_command = cmd.cast(tname) <TAB> <TAB> name_addr = cmd.obj_offset + dylib_command.name <TAB> <TAB> dylib_name = self.obj_vm.read(name_addr, 256) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> idx = dylib_name.find(""\x00"") <TAB> <TAB> <TAB> if idx != -1: <TAB> <TAB> <TAB> <TAB> dylib_name = dylib_name[:idx] <TAB> <TAB> <TAB> yield dylib_name","if dylib_name . find ( ""\x00"" ) != - 1 :",if dylib_name :,False,93.55,63.82,,,
"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_year "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> if data_list [ 0 ] in forms . fields . EMPTY_VALUES : <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_month "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> year = int ( data_list [ 1 ] ) <TAB> <TAB> month = int ( data_list [ 0 ] ) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange(year, month)[1] <TAB> <TAB> return date(year, month, day) <TAB> return None",if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,if data_list [ 1 ] in forms . fields . EMPTY_VALUES :,True,100.0,74.54,,,
"def put ( self , obj , block = True , timeout = None ) : <TAB> assert not self . _closed <TAB> if not self . _sem . acquire ( block , timeout ) : <TAB> <TAB> raise Full <TAB> with self . _notempty : <TAB> <TAB> with self . _cond : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _start_thread ( ) <TAB> <TAB> <TAB> self . _buffer . append ( obj ) <TAB> <TAB> <TAB> self . _unfinished_tasks . release ( ) <TAB> <TAB> <TAB> self . _notempty . notify ( )",if self . _closed :,if self . _thread is None :,False,97.19,71.95,,,
"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB> <TAB> module_directory = join ( directory , module ) <TAB> <TAB> has_module_directory = isdir ( module_directory ) <TAB> <TAB> if not version : <TAB> <TAB> <TAB> has_module = has_module_directory or exists ( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> ) # could be a bare modulefile <TAB> <TAB> else: <TAB> <TAB> <TAB> modulefile = join(module_directory, version) <TAB> <TAB> <TAB> has_modulefile = exists(modulefile) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return has_module",if not has_module :,if has_module :,False,98.86,73.47,,,
"def expanduser ( path ) : <TAB> if path [ : 1 ] == "" ~ "" : <TAB> <TAB> c = path [ 1 : 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return gethome ( ) <TAB> <TAB> if c == os . sep : <TAB> <TAB> <TAB> return asPyString ( File ( gethome ( ) , path [ 2 : ] ) . getPath ( ) ) <TAB> return path",if c == os . path . expanduser ( ) :,if not c :,False,89.98,69.82,,,
"def mock_touch ( self , bearer , version = None , revision = None , * * kwargs ) : <TAB> if version : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . versions [ int ( version ) - 1 ] <TAB> <TAB> <TAB> except ( IndexError , ValueError ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return file_models . FileVersion ( )",if int ( version ) > 0 :,if self . versions :,False,94.45,70.87,,,
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value","elif member [ 0 ] == ""wildcard"" :","elif member [ 0 ] == ""wildcards"" :",False,99.0,73.65,,,
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if contains :,if contains :,True,100.0,74.62,,,
"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB> <TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB> <TAB> <TAB> self . _cancel_editing ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _update_value ( ) <TAB> <TAB> elif event . GetKeyCode ( ) == wx . WXK_DELETE : <TAB> <TAB> <TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event.Skip()",elif event . GetKeyCode ( ) == wx . WXK_PUT :,elif event . GetKeyCode ( ) == wx . WXK_RETURN :,False,98.68,73.48,,,
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr ( module , "" aliases "" ) : <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases : <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( )","if not hasattr ( module , attr ) :","if module is None or not hasattr ( module , attr ) :",False,97.93,72.68,,,
def eventIterator ( ) : <TAB> while True : <TAB> <TAB> yield eventmodule . wait ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> event = eventmodule . poll ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield event,if event is None :,if event . type == NOEVENT :,False,93.58,66.42,,,
"def _get_state_without_padding ( self , state_with_padding , padding ) : <TAB> lean_state = { } <TAB> for key , value in state_with_padding . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lean_length = value . numel ( ) - padding <TAB> <TAB> <TAB> lean_state [ key ] = value [ : lean_length ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lean_state [ key ] = value <TAB> return lean_state",if padding :,if torch . is_tensor ( value ) :,False,93.01,69.45,,,
"def _get_validate ( data ) : <TAB> """""" Retrieve items to validate, from single samples or from combined joint calls. """""" <TAB> if data . get ( "" vrn_file "" ) and tz . get_in ( [ "" config "" , "" algorithm "" , "" validate "" ] , data ) : <TAB> <TAB> return utils . deepish_copy ( data ) <TAB> elif "" group_orig "" in data : <TAB> <TAB> for sub in multi . get_orig_items ( data ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sub_val = utils . deepish_copy ( sub ) <TAB> <TAB> <TAB> <TAB> sub_val [ "" vrn_file "" ] = data [ "" vrn_file "" ] <TAB> <TAB> <TAB> <TAB> return sub_val <TAB> return None","if sub . get ( ""vrn_file"" ) :","if ""validate"" in sub [ ""config"" ] [ ""algorithm"" ] :",False,92.74,94.08,,,
"def OnPopup ( self , form , popup_handle ) : <TAB> for num , action_name , menu_name , shortcut in self . actions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ida_kernwin . attach_action_to_popup ( form , popup_handle , None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> handler = command_handler_t ( self , num , 2 ) <TAB> <TAB> <TAB> desc = ida_kernwin . action_desc_t ( action_name , menu_name , handler , shortcut ) <TAB> <TAB> <TAB> ida_kernwin . attach_dynamic_action_to_popup ( form , popup_handle , desc )",if num == 0 :,if menu_name is None :,False,96.12,71.46,,,
"def show ( self , indent = 0 ) : <TAB> """""" Pretty print this structure. """""" <TAB> if indent == 0 : <TAB> <TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> offset = "" 0x?? "" <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB> <TAB> print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB> <TAB> if isinstance ( field . type , Structure ) : <TAB> <TAB> <TAB> field . type . show ( indent + 1 )",if field . offset is None :,if field . offset is None :,True,100.0,99.54,,,
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation: <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition.name and definition.name.value == operation_name: <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation",if definition . name and definition . name . value == operation_name :,"if isinstance ( definition , ast . OperationDefinition ) :",False,94.17,71.1,,,
"def getSubMenu ( self , callingWindow , context , mainItem , selection , rootMenu , i , pitem ) : <TAB> msw = True if "" wxMSW "" in wx . PlatformInfo else False <TAB> self . context = context <TAB> self . abilityIds = { } <TAB> sub = wx . Menu ( ) <TAB> for ability in self . fighter . abilities : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> menuItem = self . addAbility ( rootMenu if msw else sub , ability ) <TAB> <TAB> sub . Append ( menuItem ) <TAB> <TAB> menuItem . Check ( ability . active ) <TAB> return sub",if ability . active :,if not ability . effect . isImplemented :,False,95.44,71.47,,,
"def consume ( self , event : Dict [ str , Any ] ) - > None : <TAB> with self . lock : <TAB> <TAB> logging . debug ( "" Received missedmessage_emails event:  %s "" , event ) <TAB> <TAB> # When we process an event, just put it into the queue and ensure we have a timer going. <TAB> <TAB> user_profile_id = event[""user_profile_id""] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.batch_start_by_recipient[user_profile_id] = time.time() <TAB> <TAB> self.events_by_recipient[user_profile_id].append(event) <TAB> <TAB> self.ensure_timer()",if user_profile_id not in self . batch_start_by_recipient :,if user_profile_id not in self . batch_start_by_recipient :,True,100.0,74.28,,,
"def __init__ ( self , start_enabled = False , use_hardware = True ) : <TAB> self . _use_hardware = use_hardware <TAB> if use_hardware : <TAB> <TAB> self . _button = Button ( BUTTON_GPIO_PIN ) <TAB> <TAB> self . _enabled = start_enabled <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _button . when_pressed = self . _enable",if self . _enable :,if not start_enabled :,False,95.14,70.31,,,
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . combine : <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . agg : <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else : # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",if op . stage == OperandStage . map :,if op . stage == OperandStage . map :,True,100.0,74.46,,,
"def load_package ( name , path ) : <TAB> if os . path . isdir ( path ) : <TAB> <TAB> extensions = machinery . SOURCE_SUFFIXES [ : ] + machinery . BYTECODE_SUFFIXES [ : ] <TAB> <TAB> for extension in extensions : <TAB> <TAB> <TAB> init_path = os . path . join ( path , "" __init__ "" + extension ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> path = init_path <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" {!r}  is not a package "" . format ( path ) ) <TAB> spec = util . spec_from_file_location ( name , path , submodule_search_locations = [ ] ) <TAB> if name in sys . modules : <TAB> <TAB> return _exec ( spec , sys . modules [ name ] ) <TAB> else : <TAB> <TAB> return _load ( spec )",if os . path . exists ( init_path ) :,if os . path . exists ( init_path ) :,True,100.0,74.61,,,
def setup ( level = None ) : <TAB> from pipeline . logging import pipeline_logger as logger <TAB> from pipeline . log . handlers import EngineLogHandler <TAB> if level in set ( logging . _levelToName . values ( ) ) : <TAB> <TAB> logger . setLevel ( level ) <TAB> logging . _acquireLock ( ) <TAB> try : <TAB> <TAB> for hdl in logger . handlers : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> hdl = EngineLogHandler ( ) <TAB> <TAB> <TAB> hdl . setLevel ( logger . level ) <TAB> <TAB> <TAB> logger . addHandler ( hdl ) <TAB> finally : <TAB> <TAB> logging . _releaseLock ( ),if hdl . isEnabledFor ( logging . DEBUG ) :,"if isinstance ( hdl , EngineLogHandler ) :",False,95.79,58.51,,,
"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB> <TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB> <TAB> p , q = i . as_numer_denom ( ) <TAB> <TAB> tol = c / q * * 2 <TAB> <TAB> if abs ( i - x ) < = tol : <TAB> <TAB> <TAB> return i <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return x",if p == 0 :,if tol < machine_epsilon :,False,95.56,71.84,,,
"def resolve ( <TAB> self , debug : bool = False , silent : bool = False , level : Optional [ int ] = None ) - > bool : <TAB> if silent : <TAB> <TAB> spinner = nullcontext ( type ( "" Mock "" , ( ) , { } ) ) <TAB> else : <TAB> <TAB> spinner = yaspin ( text = "" resolving... "" ) <TAB> with spinner as spinner : <TAB> <TAB> while True : <TAB> <TAB> <TAB> resolved = self . _resolve ( <TAB> <TAB> <TAB> <TAB> debug = debug , silent = silent , level = level , spinner = spinner <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . graph . clear ( ) # remove unused deps from graph <TAB> <TAB> <TAB> return resolved",if resolved is None :,if resolved is None :,True,100.0,74.58,,,
"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == ""MOV"": <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""LSR"" <TAB> <TAB> elif instr.mnemonic.startswith(""lsl""): <TAB> <TAB> <TAB> return ""LSL"" <TAB> <TAB> elif instr.mnemonic.startswith(""asr""): <TAB> <TAB> <TAB> return ""ASR"" <TAB> return OP_NAME_MAP.get(name, name)","if instr . mnemonic . startswith ( ""lsr"" ) :","if instr . mnemonic . startswith ( ""lsr"" ) :",True,100.0,74.21,,,
"def run_all ( rule_list , defined_variables , defined_actions , stop_on_first_trigger = False ) : <TAB> rule_was_triggered = False <TAB> for rule in rule_list : <TAB> <TAB> result = run ( rule , defined_variables , defined_actions ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> rule_was_triggered = True <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return rule_was_triggered",if stop_on_first_trigger :,if stop_on_first_trigger :,True,100.0,74.05,,,
"def get_filters ( self , request ) : <TAB> filter_specs = [ ] <TAB> if self . lookup_opts . admin . list_filter and not self . opts . one_to_one_field : <TAB> <TAB> filter_fields = [ <TAB> <TAB> <TAB> self . lookup_opts . get_field ( field_name ) <TAB> <TAB> <TAB> for field_name in self . lookup_opts . admin . list_filter <TAB> <TAB> ] <TAB> <TAB> for f in filter_fields : <TAB> <TAB> <TAB> spec = FilterSpec . create ( f , request , self . params , self . model ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> filter_specs . append ( spec ) <TAB> return filter_specs , bool ( filter_specs )",if spec . is_valid ( ) :,if spec and spec . has_output ( ) :,False,96.72,72.28,,,
"def get_type ( type_ref ) : <TAB> kind = type_ref . get ( "" kind "" ) <TAB> if kind == TypeKind . LIST : <TAB> <TAB> item_ref = type_ref . get ( "" ofType "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB> <TAB> return GraphQLList ( get_type ( item_ref ) ) <TAB> elif kind == TypeKind . NON_NULL : <TAB> <TAB> nullable_ref = type_ref . get ( "" ofType "" ) <TAB> <TAB> if not nullable_ref : <TAB> <TAB> <TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB> <TAB> return GraphQLNonNull ( get_type ( nullable_ref ) ) <TAB> return get_named_type ( type_ref [ "" name "" ] )",if not item_ref :,if not item_ref :,True,100.0,74.52,,,
"def _1_0_cloud_ips_cip_jsjc5_map ( self , method , url , body , headers ) : <TAB> if method == "" POST "" : <TAB> <TAB> body = json . loads ( body ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . test_response ( httplib . ACCEPTED , "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = ' { "" error_name "" : "" bad destination "" ,  "" errors "" : [ "" Bad destination "" ]} ' <TAB> <TAB> <TAB> return self . test_response ( httplib . BAD_REQUEST , data )","if body [ ""error_name"" ] == ""origin"" :","if ""destination"" in body :",False,91.52,67.75,,,
"def _get_prefixed_values ( data , prefix ) : <TAB> """""" Collect lines which start with prefix; with trimming """""" <TAB> matches = [ ] <TAB> for line in data . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> match = line [ len ( prefix ) : ] <TAB> <TAB> <TAB> match = match . strip ( ) <TAB> <TAB> <TAB> matches . append ( match ) <TAB> return matches",if line . startswith ( prefix ) :,if line . startswith ( prefix ) :,True,100.0,99.28,,,
"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB> <TAB> yc / / = 10 <TAB> <TAB> ye + = 1 <TAB> if xc == 1 : <TAB> <TAB> xe * = yc <TAB> <TAB> while xe % 10 == 0 : <TAB> <TAB> <TAB> xe / / = 10 <TAB> <TAB> <TAB> ye + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 * * ye <TAB> <TAB> if y and xe : <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else : <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5",if ye == 1 :,if ye < 0 :,False,97.83,73.19,,,
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> if idx > = len ( selections ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i > = 0 and i < len ( selections ) : <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx, value in enumerate(selections): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values.append(value) <TAB> self.stack = values",if idx != 0 and idx != 0 and idx != len ( selections ) :,if len ( values ) + 1 < idx :,False,93.1,71.28,,,
"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB> <TAB> if fit is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> <TAB> <TAB> fit . clearFactorReloadDependentData ( ) <TAB> <TAB> <TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs",if fit . useGlobalForceReload :,if fit . calculated :,False,98.53,73.43,,,
"def init_weights ( self ) : <TAB> """""" Initialize model weights. """""" <TAB> for m in self . predict_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> <TAB> elif isinstance ( m , nn . Linear ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 )","elif isinstance ( m , nn . BatchNorm2d ) :","elif isinstance ( m , nn . BatchNorm2d ) :",True,100.0,74.27,,,
"def _unzip_file ( self , filepath , ext ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> zf = zipfile . ZipFile ( filepath ) <TAB> <TAB> <TAB> zf . extractall ( os . path . dirname ( filepath ) ) <TAB> <TAB> <TAB> zf . close ( ) <TAB> <TAB> elif ext == "" .tar "" : <TAB> <TAB> <TAB> tf = tarfile . open ( filepath ) <TAB> <TAB> <TAB> tf . extractall ( os . path . dirname ( filepath ) ) <TAB> <TAB> <TAB> tf . close ( ) <TAB> except Exception as e : <TAB> <TAB> raise ValueError ( "" Error reading file  %r ! \n %s "" % ( filepath , e ) )","if ext == "".zip"" :","if ext == "".zip"" :",True,100.0,74.49,,,
"def add_multiple_tasks ( data , parent ) : <TAB> data = json . loads ( data ) <TAB> new_doc = { <TAB> <TAB> "" doctype "" : "" Task "" , <TAB> <TAB> "" parent_task "" : parent if parent != "" All Tasks "" else "" "" , <TAB> } <TAB> new_doc [ "" project "" ] = frappe . db . get_value ( "" Task "" , { "" name "" : parent } , "" project "" ) or "" "" <TAB> for d in data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> new_doc [ "" subject "" ] = d . get ( "" subject "" ) <TAB> <TAB> new_task = frappe . get_doc ( new_doc ) <TAB> <TAB> new_task . insert ( )","if d . get ( ""project"" ) != parent :","if not d . get ( ""subject"" ) :",False,95.95,72.16,,,
"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """""" Return a sorted list of keywords similar to the one given. """""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB> <TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict [ key ] = None <TAB> <TAB> if checkContained and keyword in key : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if kwdSndx == soundex ( key . encode ( "" ascii "" , "" ignore "" ) ) : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches )",if key in seenDict :,if key in seenDict :,True,100.0,99.61,,,
"def visit_If ( self , node ) : <TAB> self . newline ( ) <TAB> self . write ( "" if  "" ) <TAB> self . visit ( node . test ) <TAB> self . write ( "" : "" ) <TAB> self . body ( node . body ) <TAB> while True : <TAB> <TAB> else_ = node . orelse <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> node = else_ [ 0 ] <TAB> <TAB> <TAB> self . newline ( ) <TAB> <TAB> <TAB> self . write ( "" elif  "" ) <TAB> <TAB> <TAB> self . visit ( node . test ) <TAB> <TAB> <TAB> self . write ( "" : "" ) <TAB> <TAB> <TAB> self . body ( node . body ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . newline ( ) <TAB> <TAB> <TAB> self . write ( "" else: "" ) <TAB> <TAB> <TAB> self . body ( else_ ) <TAB> <TAB> <TAB> break","if isinstance ( else_ [ 0 ] , If ) :","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) :",False,96.06,72.15,,,
"def _eyeLinkHardwareAndSoftwareVersion ( self ) : <TAB> try : <TAB> <TAB> tracker_software_ver = 0 <TAB> <TAB> eyelink_ver = self . _eyelink . getTrackerVersion ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tvstr = self . _eyelink . getTrackerVersionString ( ) <TAB> <TAB> <TAB> vindex = tvstr . find ( "" EYELINK CL "" ) <TAB> <TAB> <TAB> tracker_software_ver = int ( <TAB> <TAB> <TAB> <TAB> float ( tvstr [ ( vindex + len ( "" EYELINK CL "" ) ) : ] . strip ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return eyelink_ver , tracker_software_ver <TAB> except Exception : <TAB> <TAB> print2err ( "" EYELINK Error during _eyeLinkHardwareAndSoftwareVersion: "" ) <TAB> <TAB> printExceptionDetailsToStdErr ( ) <TAB> <TAB> return EyeTrackerConstants . EYETRACKER_ERROR",if eyelink_ver == EyeTrackerConstants . EYETRACKER_VERSION :,if eyelink_ver == 3 :,False,97.03,73.13,,,
"def execute ( self , context ) : <TAB> for monad in context . blend_data . node_groups : <TAB> <TAB> if monad . bl_idname == "" SverchGroupTreeType "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> monad . update_cls ( ) <TAB> <TAB> <TAB> <TAB> except Exception as err : <TAB> <TAB> <TAB> <TAB> <TAB> print ( err ) <TAB> <TAB> <TAB> <TAB> <TAB> print ( "" {}  group class could not be created "" . format ( monad . name ) ) <TAB> return { "" FINISHED "" }","if monad . bl_idname == ""SverchGroupTreeType"" :","if not getattr ( bpy . types , monad . cls_bl_idname , None ) :",False,91.13,62.37,,,
"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB> <TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB> <TAB> if pattern [ i ] not in dict : <TAB> <TAB> <TAB> if list_str [ i ] in set_value : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB> <TAB> <TAB> set_value . add ( list_str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if list_str [ i ] not in dict :,if dict [ pattern [ i ] ] != list_str [ i ] :,False,94.74,70.8,,,
"def decorator_handle ( tokens ) : <TAB> """""" Process decorators. """""" <TAB> defs = [ ] <TAB> decorates = [ ] <TAB> for i , tok in enumerate ( tokens ) : <TAB> <TAB> if "" simple "" in tok and len ( tok ) == 1 : <TAB> <TAB> <TAB> decorates . append ( "" @ "" + tok [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> varname = decorator_var + "" _ "" + str ( i ) <TAB> <TAB> <TAB> defs . append ( varname + ""  =  "" + tok [ 0 ] ) <TAB> <TAB> <TAB> decorates . append ( "" @ "" + varname ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise CoconutInternalException ( "" invalid decorator tokens "" , tok ) <TAB> return "" \n "" . join ( defs + decorates ) + "" \n ""","elif ""variable"" in tok and len ( tok ) == 1 :","elif ""test"" in tok and len ( tok ) == 1 :",False,98.88,73.81,,,
"def wait_impl ( self , cpid ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB> <TAB> # in the forking tests. This is an attempt to fix the problem. <TAB> <TAB> spid, status, rusage = os.wait3(os.WNOHANG) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> time.sleep(1.0) <TAB> self.assertEqual(spid, cpid) <TAB> self.assertEqual(status, 0, ""cause = %d, exit = %d"" % (status & 0xFF, status >> 8)) <TAB> self.assertTrue(rusage)",if status == 0 :,if spid == cpid :,False,97.18,71.88,,,
"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> elif val == 1 : <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert False",if val == 0 :,if val == 0 :,True,100.0,74.5,,,
"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB> if self.stopframe and frame.f_code.co_flags & CO_GENERATOR: <TAB> <TAB> <TAB> return self.trace_dispatch <TAB> <TAB> try: <TAB> <TAB> <TAB> self.frame_returning = frame <TAB> <TAB> <TAB> self.user_return(frame, arg) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.frame_returning = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB> <TAB> <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",if self . stopframe :,if self . quitting :,False,98.96,73.38,,,
"def mouse ( self , button , mods , x , y ) : <TAB> if button == 1 : <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . hit = i <TAB> elif button == - 1 : <TAB> <TAB> self . hit = None <TAB> elif self . hit != None : <TAB> <TAB> self . coords [ self . hit ] = ( x , y ) <TAB> <TAB> self . view . dirty ( )","if mods [ i ] == ( x , y ) :","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 :",False,82.7,63.37,,,
"def __init__ ( self , * commands ) : <TAB> self . all_cmds = list ( <TAB> <TAB> map ( lambda cmd : cmd [ 0 ] if isinstance ( cmd , list ) else cmd , commands ) <TAB> ) <TAB> for command in commands : <TAB> <TAB> self . cmd = command if isinstance ( command , list ) else [ command ] <TAB> <TAB> self . cmd_path = pwndbg . which . which ( self . cmd [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if self . cmd_path is None :,if self . cmd_path :,False,97.37,73.04,,,
"def _recv_obj ( self , suppress_error = False ) : <TAB> """""" Receive a (picklable) object """""" <TAB> if self . conn . closed : <TAB> <TAB> raise OSError ( "" handle is closed "" ) <TAB> try : <TAB> <TAB> buf = self . conn . recv_bytes ( ) <TAB> except ( ConnectionError , EOFError ) as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> logger . debug ( "" receive has failed "" , exc_info = e ) <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _set_remote_close_cause ( e ) <TAB> <TAB> <TAB> raise PipeShutdownError ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _close ( ) <TAB> obj = RemoteObjectUnpickler . loads ( buf , self ) <TAB> logger . debug ( "" received  %r "" , obj ) <TAB> return obj",if suppress_error :,if suppress_error :,True,100.0,99.57,,,
"def act ( self , obs ) : <TAB> with chainer . no_backprop_mode ( ) : <TAB> <TAB> batch_obs = self . batch_states ( [ obs ] , self . xp , self . phi ) <TAB> <TAB> action_distrib = self . model ( batch_obs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return chainer . cuda . to_cpu ( action_distrib . most_probable . array ) [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return chainer . cuda . to_cpu ( action_distrib . sample ( ) . array ) [ 0 ]",if self . act_only :,if self . act_deterministically :,False,98.32,73.05,,,
"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB> <TAB> for node in level : <TAB> <TAB> <TAB> if node . binary == BINARY_MISSING : <TAB> <TAB> <TAB> <TAB> missing . append ( node ) <TAB> <TAB> <TAB> elif node . binary == BINARY_INVALID : <TAB> <TAB> <TAB> <TAB> invalid . append ( node ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads",elif node . binary == BINARY_DOWNLOADING :,"elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) :",False,93.81,70.74,,,
"def persist ( self , * _ ) : <TAB> for key , obj in self . _objects . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> state = obj . get_state ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> md5 = hashlib . md5 ( state ) . hexdigest ( ) <TAB> <TAB> <TAB> if self . _last_state . get ( key ) == md5 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _persist_provider . store ( key , state ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> system_log . exception ( "" PersistHelper.persist fail "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _last_state [ key ] = md5",if state == self . _last_state . get ( key ) :,if not state :,False,93.38,71.75,,,
"def enter ( self , doc , * * kwds ) : <TAB> """""" Enters the mode, arranging for necessary grabs ASAP """""" <TAB> super ( ColorPickMode , self ) . enter ( doc , * * kwds ) <TAB> if self . _started_from_key_press : <TAB> <TAB> # Pick now using the last recorded event position <TAB> <TAB> doc = self.doc <TAB> <TAB> tdw = self.doc.tdw <TAB> <TAB> t, x, y = doc.get_last_event_info(tdw) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._pick_color_mode(tdw, x, y, self._pickmode) <TAB> <TAB> # Start the drag when possible <TAB> <TAB> self._start_drag_on_next_motion_event = True <TAB> <TAB> self._needs_drag_start = True","if t == ""Color"" :","if None not in ( x , y ) :",False,95.67,94.65,,,
"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB> <TAB> name = f . get_basename ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name . endswith ( "" .sccprofile "" ) : <TAB> <TAB> <TAB> name = name [ 0 : - 11 ] <TAB> <TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 )",if name in model :,"if name . endswith ( "".mod"" ) :",False,94.08,65.71,,,
"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB> <TAB> if completed_process . stdout is not None : <TAB> <TAB> <TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB> <TAB> if raise_error : <TAB> <TAB> <TAB> raise PipxError ( <TAB> <TAB> <TAB> <TAB> f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" )",elif completed_process . stderr is not None :,if completed_process . stderr is not None :,False,98.96,73.7,,,
"def test_connect ( <TAB> ipaddr , port , device , partition , method , path , headers = None , query_string = None ) : <TAB> if path == "" /a "" : <TAB> <TAB> for k , v in headers . iteritems ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> test_errors . append ( "" %s :  %s  not in  %s "" % ( test_header , test_value , headers ) )",if k == test_header :,if k . lower ( ) == test_header . lower ( ) and v == test_value :,False,87.62,66.85,,,
"def test_stat_result_pickle ( self ) : <TAB> result = os . stat ( self . fname ) <TAB> for proto in range ( pickle . HIGHEST_PROTOCOL + 1 ) : <TAB> <TAB> p = pickle . dumps ( result , proto ) <TAB> <TAB> self . assertIn ( b "" stat_result "" , p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIn ( b "" cos \n stat_result \n "" , p ) <TAB> <TAB> unpickled = pickle . loads ( p ) <TAB> <TAB> self . assertEqual ( result , unpickled )",if proto == pickle . HIGHEST_PROTOCOL :,if proto < 4 :,False,94.19,72.1,,,
"def run_sql ( sql ) : <TAB> table = sql . split ( "" "" ) [ 5 ] <TAB> logger . info ( "" Updating table  {} "" . format ( table ) ) <TAB> with transaction . atomic ( ) : <TAB> <TAB> with connection . cursor ( ) as cursor : <TAB> <TAB> <TAB> cursor . execute ( sql ) <TAB> <TAB> <TAB> rows = cursor . fetchall ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception ( "" Sentry notification that  {}  is migrated "" . format ( table ) )",if rows [ 0 ] == 0 :,if not rows :,False,94.28,71.66,,,
"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB> <TAB> if x < self . box [ 0 ] : <TAB> <TAB> <TAB> self . box [ 0 ] = x <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . box [ 2 ] = x <TAB> <TAB> if y < self . box [ 1 ] : <TAB> <TAB> <TAB> self . box [ 1 ] = y <TAB> <TAB> if y > self . box [ 3 ] : <TAB> <TAB> <TAB> self . box [ 3 ] = y",if x > self . box [ 2 ] :,if x > self . box [ 2 ] :,True,100.0,74.48,,,
"def _packageFocusOutViaKeyPress ( self , row , column , txt ) : <TAB> if txt : <TAB> <TAB> self . _set_current_cell ( row + 1 , column ) <TAB> else : <TAB> <TAB> widget = self . cellWidget ( row + 1 , column ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _delete_cell ( row , column ) <TAB> <TAB> new_request = self . get_request ( ) <TAB> <TAB> self . context_model . set_request ( new_request ) <TAB> <TAB> self . _update_request_column ( column , self . context_model )",if widget is not None :,"if widget and isinstance ( widget , PackageSelectWidget ) :",False,94.59,69.89,,,
"def parse_bash_set_output ( output ) : <TAB> """""" Parse Bash-like  ' set '  output """""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output.replace(""\\\n"", """") <TAB> environ = {} <TAB> for line in output.splitlines(0): <TAB> <TAB> line = line.rstrip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue # skip black lines <TAB> <TAB> item = _ParseBashEnvStr(line) <TAB> <TAB> if item: <TAB> <TAB> <TAB> environ[item[0]] = item[1] <TAB> return environ",if not line :,if not line :,True,100.0,74.47,,,
"def _get ( self , domain ) : <TAB> with self . lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> record = self . cache [ domain ] <TAB> <TAB> <TAB> time_now = time . time ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> record = None <TAB> <TAB> if not record : <TAB> <TAB> <TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record","if time_now - record [ ""r"" ] > self . cache_max_age :","if time_now - record [ ""update"" ] > self . ttl :",False,95.43,72.42,,,
"def test_filehash ( self ) : <TAB> """""" tests the hashes of the files in data/ """""" <TAB> fp = self . get_data_path ( ) <TAB> for fn in os . listdir ( fp ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # file used for something else <TAB> <TAB> <TAB> continue <TAB> <TAB> expected_hash = fn <TAB> <TAB> fullp = os.path.join(fp, fn) <TAB> <TAB> output = self.run_command(""sha1sum "" + fullp, exitcode=0) <TAB> <TAB> result = output.split("" "")[0] <TAB> <TAB> self.assertEqual(result, expected_hash)","if fn . endswith ( "".py"" ) :","if ""."" in fn :",False,94.85,84.38,,,
"def test_new_vs_reference_code_stream_read_during_iter ( read_idx , read_len , bytecode ) : <TAB> reference = SlowCodeStream ( bytecode ) <TAB> latest = CodeStream ( bytecode ) <TAB> for index , ( actual , expected ) in enumerate ( zip ( latest , reference ) ) : <TAB> <TAB> assert actual == expected <TAB> <TAB> if index == read_idx : <TAB> <TAB> <TAB> readout_actual = latest . read ( read_len ) <TAB> <TAB> <TAB> readout_expected = reference . read ( read_len ) <TAB> <TAB> <TAB> assert readout_expected == readout_actual <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert latest . program_counter > = len ( reference ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert latest . program_counter == reference . program_counter",if index == read_idx :,if reference . program_counter >= len ( reference ) :,False,94.61,70.81,,,
"def setup_logging ( ) : <TAB> try : <TAB> <TAB> logconfig = config . get ( "" logging_config_file "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . config . fileConfig ( logconfig , disable_existing_loggers = False ) <TAB> <TAB> logger . info ( "" logging initialized "" ) <TAB> <TAB> logger . debug ( "" debug "" ) <TAB> except Exception as e : <TAB> <TAB> print ( "" Unable to set logging configuration: "" , str ( e ) , file = sys . stderr ) <TAB> <TAB> raise",if logconfig :,if logconfig and os . path . exists ( logconfig ) :,False,92.65,69.08,,,
"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> word = "" "" <TAB> <TAB> <TAB> if c . isalnum ( ) : <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c.lower() <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> if c.isalnum(): <TAB> <TAB> <TAB> <TAB> word += c.lower() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word",if start_char :,if start_char == True :,False,98.24,72.93,,,
"def _get_nonce ( self , url , new_nonce_url ) : <TAB> if not self . _nonces : <TAB> <TAB> logger . debug ( "" Requesting fresh nonce "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response = self . head ( url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # request a new nonce from the acme newNonce endpoint <TAB> <TAB> <TAB> response = self._check_response(self.head(new_nonce_url), content_type=None) <TAB> <TAB> self._add_nonce(response) <TAB> return self._nonces.pop()",if self . _is_fresh ( url ) :,if new_nonce_url is None :,False,94.2,70.01,,,
"def _get_nonce ( self , url , new_nonce_url ) : <TAB> if not self . _nonces : <TAB> <TAB> logger . debug ( "" Requesting fresh nonce "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response = self . head ( url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # request a new nonce from the acme newNonce endpoint <TAB> <TAB> <TAB> response = self._check_response(self.head(new_nonce_url), content_type=None) <TAB> <TAB> self._add_nonce(response) <TAB> return self._nonces.pop()",if self . _is_fresh ( url ) :,if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) :,False,90.07,65.02,,,
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """""" Convert args into gvariant. """""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> if isinstance ( arg , bool ) : <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> elif isinstance ( arg , str ) : <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( )","elif isinstance ( arg , int ) :","elif isinstance ( arg , ( int , float ) ) :",False,96.74,94.21,,,
"def _SkipGroup ( buffer , pos , end ) : <TAB> """""" Skip sub-group. Returns the new position. """""" <TAB> while 1 : <TAB> <TAB> ( tag_bytes , pos ) = ReadTag ( buffer , pos ) <TAB> <TAB> new_pos = SkipField ( buffer , pos , end , tag_bytes ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return pos <TAB> <TAB> pos = new_pos",if new_pos == pos :,if new_pos == - 1 :,False,96.85,77.28,,,
"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB> <TAB> if participant is None or participant == self . simulator_config . broadcast_part : <TAB> <TAB> <TAB> continue <TAB> <TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB> <TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB> <TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . participants_dict [ participant ] . refresh ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB> <TAB> self . update_view ( )",if self . participants_dict [ participant ] :,if participant in self . participants_dict :,False,97.27,72.45,,,
"def feature_reddit ( layer_data , graph ) : <TAB> feature = { } <TAB> times = { } <TAB> indxs = { } <TAB> for _type in layer_data : <TAB> <TAB> if len ( layer_data [ _type ] ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> idxs = np . array ( list ( layer_data [ _type ] . keys ( ) ) ) <TAB> <TAB> tims = np . array ( list ( layer_data [ _type ] . values ( ) ) ) [ : , 1 ] <TAB> <TAB> feature [ _type ] = np . array ( <TAB> <TAB> <TAB> list ( graph . node_feature [ _type ] . loc [ idxs , "" emb "" ] ) , dtype = np . float <TAB> <TAB> ) <TAB> <TAB> times [ _type ] = tims <TAB> <TAB> indxs [ _type ] = idxs <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attr = feature [ _type ] <TAB> return feature , times , indxs , attr",if _type in feature :,"if _type == ""def"" :",False,97.49,66.8,,,
"def _get_sort_map ( tags ) : <TAB> """""" See TAG_TO_SORT """""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> if tag . has_sort : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> if tag . internal : <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts",if tag . internal_sort :,if tag . user :,False,96.96,97.91,,,
"def max_radius ( iterator ) : <TAB> radius_result = dict ( ) <TAB> for k , v in iterator : <TAB> <TAB> if v [ 0 ] not in radius_result : <TAB> <TAB> <TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB> return radius_result",if v [ 1 ] not in radius_result :,elif v [ 1 ] >= radius_result [ v [ 0 ] ] :,False,88.57,66.74,,,
"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB> <TAB> main_vault_directory = os . path . join ( <TAB> <TAB> <TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB> <TAB> ) <TAB> <TAB> if os . path . exists ( main_vault_directory ) : <TAB> <TAB> <TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB> <TAB> <TAB> <TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB> <TAB> <TAB> <TAB> <TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found . append ( cred ) <TAB> return pwd_found",if cred :,if cred :,True,100.0,74.56,,,
"def disconnect_sync ( self , connection , close_connection = False ) : <TAB> key = id ( connection ) <TAB> ts = self . in_use . pop ( key ) <TAB> if close_connection : <TAB> <TAB> self . connections_map . pop ( key ) <TAB> <TAB> self . _connection_close_sync ( connection ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . connections_map . pop ( key ) <TAB> <TAB> <TAB> self . _connection_close_sync ( connection ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with self . _lock_sync : <TAB> <TAB> <TAB> <TAB> heapq . heappush ( self . connections_sync , ( ts , key ) )",if self . connections_map :,if self . stale_timeout and self . is_stale ( ts ) :,False,93.25,70.36,,,
"def _populate_tree ( self , element , d ) : <TAB> """""" Populates an etree with attributes & elements, given a dict. """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _populate_number ( element , k , v )","elif isinstance ( v , int ) :","elif type ( v ) in [ int , float , long , complex ] :",False,93.98,67.77,,,
"def readframes ( self , nframes ) : <TAB> if self . _ssnd_seek_needed : <TAB> <TAB> self . _ssnd_chunk . seek ( 0 ) <TAB> <TAB> dummy = self . _ssnd_chunk . read ( 8 ) <TAB> <TAB> pos = self . _soundpos * self . _framesize <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _ssnd_chunk . seek ( pos + 8 ) <TAB> <TAB> self . _ssnd_seek_needed = 0 <TAB> if nframes == 0 : <TAB> <TAB> return "" "" <TAB> data = self . _ssnd_chunk . read ( nframes * self . _framesize ) <TAB> if self . _convert and data : <TAB> <TAB> data = self . _convert ( data ) <TAB> self . _soundpos = self . _soundpos + len ( data ) / ( self . _nchannels * self . _sampwidth ) <TAB> return data","if dummy == ""\x00"" :",if pos :,False,96.21,65.0,,,
"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB> <TAB> <TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB> <TAB> <TAB> if __opts__ . get ( "" ssh_user "" ) : <TAB> <TAB> <TAB> <TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret","if __opts__ . get ( ""roster_defaults"" , { } ) :","if fnmatch . fnmatch ( tgt , host ) :",False,90.49,66.39,,,
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> if nodeid not in self . _nodes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> if attr not in node . attributes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value",if attval . value_callback :,if attval . value_callback :,True,100.0,74.61,,,
"def remove_property ( self , key ) : # type: (str) -> None <TAB> with self.secure() as config: <TAB> <TAB> keys = key.split(""."") <TAB> <TAB> current_config = config <TAB> <TAB> for i, key in enumerate(keys): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if i == len(keys) - 1: <TAB> <TAB> <TAB> <TAB> del current_config[key] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config[key]",if key not in current_config :,if key not in current_config :,True,100.0,74.22,,,
"def remove_property ( self , key ) : # type: (str) -> None <TAB> with self.secure() as config: <TAB> <TAB> keys = key.split(""."") <TAB> <TAB> current_config = config <TAB> <TAB> for i, key in enumerate(keys): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if i == len(keys) - 1: <TAB> <TAB> <TAB> <TAB> del current_config[key] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config[key]",if key not in current_config :,if sys . argv [ 1 : ] :,False,95.13,68.94,,,
"def get_only_text_part ( self , msg ) : <TAB> count = 0 <TAB> only_text_part = None <TAB> for part in msg . walk ( ) : <TAB> <TAB> if part . is_multipart ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> count + = 1 <TAB> <TAB> mimetype = part . get_content_type ( ) or "" text/plain "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> only_text_part = part <TAB> return only_text_part",if count > self . max_part and mimetype != self . max_part :,"if mimetype != ""text/plain"" or count != 1 :",False,90.52,62.07,,,
"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB> <TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB> <TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB> <TAB> if key == "" CI_KEEP_ALIVE "" : <TAB> <TAB> <TAB> ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result",if ci in ci_names :,if len ( ci_names ) == 0 or ci . lower ( ) in ci_names :,False,91.9,69.89,,,
"def _calc_block_io ( self , blkio ) : <TAB> """""" Calculate block IO stats. """""" <TAB> for stats in blkio [ "" io_service_bytes_recursive "" ] : <TAB> <TAB> if stats [ "" op "" ] == "" Read "" : <TAB> <TAB> <TAB> self . _blk_read + = stats [ "" value "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _blk_write + = stats [ "" value "" ]","if stats [ ""op"" ] == ""Write"" :","elif stats [ ""op"" ] == ""Write"" :",False,98.04,97.32,,,
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return six.text_type(value)",if USE_TZ :,if settings . USE_TZ :,False,97.8,71.75,,,
"def load_state_dict ( self , state_dict ) : <TAB> for module_name , module_state_dict in state_dict . items ( ) : <TAB> <TAB> if module_name in self . module_pool : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . module_pool [ module_name ] . module . load_state_dict ( module_state_dict ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . module_pool [ module_name ] . load_state_dict ( module_state_dict ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . info ( f "" Missing  { module_name }  in module_pool, skip it.. "" )","if isinstance ( self . module_pool [ module_name ] . module , Module ) :","if self . config [ ""dataparallel"" ] :",False,91.46,62.9,,,
"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB> <TAB> if i > = min ( len ( scales ) , len ( vidxs ) / / 2 ) : <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB> <TAB> <TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData",if i * 2 < len ( vidxs ) / 2 :,if not math . isnan ( scale ) :,False,93.17,70.51,,,
"def __init__ ( self , factors , contrast_matrices , num_columns ) : <TAB> self . factors = tuple ( factors ) <TAB> factor_set = frozenset ( factors ) <TAB> if not isinstance ( contrast_matrices , dict ) : <TAB> <TAB> raise ValueError ( "" contrast_matrices must be dict "" ) <TAB> for factor , contrast_matrix in six . iteritems ( contrast_matrices ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected factor in contrast_matrices dict "" ) <TAB> <TAB> if not isinstance ( contrast_matrix , ContrastMatrix ) : <TAB> <TAB> <TAB> raise ValueError ( "" Expected a ContrastMatrix, not  %r "" % ( contrast_matrix , ) ) <TAB> self . contrast_matrices = contrast_matrices <TAB> if not isinstance ( num_columns , six . integer_types ) : <TAB> <TAB> raise ValueError ( "" num_columns must be an integer "" ) <TAB> self . num_columns = num_columns",if factor not in factor_set :,if factor not in factor_set :,True,100.0,74.6,,,
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB> <TAB> <TAB> break","if message [ ""type"" ] == ""websocket.accept"" :","if message [ ""type"" ] == ""websocket.connect"" :",False,98.12,72.78,,,
"def value__set ( self , value ) : <TAB> for i , ( option , checked ) in enumerate ( self . options ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . selectedIndex = i <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Option  %r  not found (from  %s ) "" <TAB> <TAB> <TAB> % ( value , "" ,  "" . join ( [ repr ( o ) for o , c in self . options ] ) ) <TAB> <TAB> )",if value == option :,if option == str ( value ) :,False,94.95,70.99,,,
"def init_links ( self ) : <TAB> links = LinkCallback . find_links ( self ) <TAB> callbacks = [ ] <TAB> for link , src_plot , tgt_plot in links : <TAB> <TAB> cb = Link . _callbacks [ "" bokeh "" ] [ type ( link ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> callbacks . append ( cb ( self . root , link , src_plot , tgt_plot ) ) <TAB> return callbacks",if not cb :,if src_plot is None or ( link . _requires_target and tgt_plot is None ) :,False,83.39,65.41,,,
"def _validate_scalar_extensions ( self ) - > List [ str ] : <TAB> errors = [ ] <TAB> for extension in [ <TAB> <TAB> x for x in self . extensions if isinstance ( x , GraphQLScalarTypeExtension ) <TAB> ] : <TAB> <TAB> extended = self . type_definitions . get ( extension . name ) <TAB> <TAB> ext_errors = _validate_extension ( <TAB> <TAB> <TAB> extended , extension . name , GraphQLScalarType , "" SCALAR "" <TAB> <TAB> ) <TAB> <TAB> errors . extend ( ext_errors ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errors . extend ( _validate_extension_directives ( extension , extended , "" SCALAR "" ) ) <TAB> return errors",if extension . directives :,if not ext_errors :,False,96.88,72.53,,,
"def copy_tcltk ( src , dest , symlink ) : <TAB> """""" copy tcl/tk libraries on Windows (issue #93) """""" <TAB> for libversion in "" 8.5 "" , "" 8.6 "" : <TAB> <TAB> for libname in "" tcl "" , "" tk "" : <TAB> <TAB> <TAB> srcdir = join ( src , "" tcl "" , libname + libversion ) <TAB> <TAB> <TAB> destdir = join ( dest , "" tcl "" , libname + libversion ) <TAB> <TAB> <TAB> # Only copy the dirs from the above combinations that exist <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> copyfileordir(srcdir, destdir, symlink)",if isdir ( srcdir ) and isdir ( destdir ) :,if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :,False,92.01,93.7,,,
"def parse ( self , response ) : <TAB> try : <TAB> <TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB> <TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB> <TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB> <TAB> return <TAB> for item in content [ "" data "" ] : <TAB> <TAB> if "" objURL "" in item : <TAB> <TAB> <TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> img_url = item [ "" hoverURL "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict ( file_url = img_url )","elif ""hoverURL"" in item :","elif ""hoverURL"" in item :",True,100.0,74.56,,,
"def check_and_reload ( self ) : <TAB> # Check if tables have been modified, if so reload <TAB> for table_name, table_version in self._table_versions.items(): <TAB> <TAB> table = self.app.tool_data_tables.get(table_name, None) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self.reload_genomes()",if table . modified and table . modified and table . is_modified and table . is_modified :,if table is not None and not table . is_current_version ( table_version ) :,False,86.05,60.55,,,
"def _get_query_defaults ( self , query_defns ) : <TAB> defaults = { } <TAB> for k , v in query_defns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> defaults [ k ] = self . _get_default_obj ( v [ "" schema "" ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> defaults [ k ] = v [ "" schema "" ] [ "" default "" ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> return defaults","if isinstance ( v [ ""schema"" ] , dict ) :","if v [ ""schema"" ] [ ""type"" ] == ""object"" :",False,92.2,66.47,,,
"def ftp_login ( host , port , username = None , password = None , anonymous = False ) : <TAB> ret = False <TAB> try : <TAB> <TAB> ftp = ftplib . FTP ( ) <TAB> <TAB> ftp . connect ( host , port , timeout = 6 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ftp . login ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ftp . login ( username , password ) <TAB> <TAB> ret = True <TAB> <TAB> ftp . quit ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return ret",if anonymous :,if anonymous :,True,100.0,74.39,,,
"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB> <TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self._value in dynamicStrToScalar: <TAB> <TAB> return dynamicStrToScalar[self._value] <TAB> else: <TAB> <TAB> thisDynamic = self._value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB> if ""s"" in thisDynamic: <TAB> <TAB> <TAB> thisDynamic = thisDynamic[1:] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic[-1] == ""z"": <TAB> <TAB> <TAB> thisDynamic = thisDynamic[:-1] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return dynamicStrToScalar[thisDynamic] <TAB> <TAB> else: <TAB> <TAB> <TAB> return dynamicStrToScalar[None]",if thisDynamic in dynamicStrToScalar :,if thisDynamic in dynamicStrToScalar :,True,100.0,74.43,,,
"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB> <TAB> for _dir , offsets in faceDirections : <TAB> <TAB> <TAB> if _dir == FaceYIncreasing : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx , dy , dz = offsets <TAB> <TAB> <TAB> p = ( x + dx , y + dy , z + dz ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx , ny , nz = p <TAB> <TAB> <TAB> if level . blockAt ( nx , ny , nz ) == 0 : <TAB> <TAB> <TAB> <TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB> <TAB> <TAB> <TAB> newcoords . append ( p ) <TAB> return newcoords",if p . size ( ) != 4 :,if p not in box :,False,96.28,72.28,,,
"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB> <TAB> wstate = str ( target_widget [ "" state "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # change state temporarily <TAB> <TAB> <TAB> target_widget[""state""] = ""normal"" <TAB> <TAB> target_widget.delete(""0"", tk.END) <TAB> <TAB> target_widget.insert(""0"", value) <TAB> <TAB> target_widget[""state""] = wstate <TAB> else: <TAB> <TAB> super(EntryBaseBO, self)._set_property(target_widget, pname, value)","if wstate == ""normal"" :","if wstate != ""normal"" :",False,98.59,72.41,,,
"def teardown ( ) : <TAB> try : <TAB> <TAB> time . sleep ( 1 ) <TAB> except KeyboardInterrupt : <TAB> <TAB> return <TAB> while launchers : <TAB> <TAB> p = launchers . pop ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> p . stop ( ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> print ( "" cleaning up test process... "" ) <TAB> <TAB> <TAB> <TAB> p . signal ( SIGKILL ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> print ( "" couldn ' t shutdown process:  "" , p )",if p . isAlive ( ) :,if p . poll ( ) is None :,False,94.43,69.35,,,
"def checkAndRemoveDuplicate ( self , node ) : <TAB> for bucket in self . buckets : <TAB> <TAB> for n in bucket . getNodes ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . removeContact ( n )",if n . getContact ( ) == node :,"if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id :",False,66.85,54.17,,,
"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB> <TAB> if this . glob : <TAB> <TAB> <TAB> flags + = u "" g "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flags + = u "" i "" <TAB> <TAB> if this . multiline : <TAB> <TAB> <TAB> flags + = u "" m "" <TAB> except : <TAB> <TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags",if this . globglob :,if this . ignore_case :,False,96.9,73.08,,,
"def import_submodules ( package_name ) : <TAB> package = sys . modules [ package_name ] <TAB> results = { } <TAB> for loader , name , is_pkg in pkgutil . iter_modules ( package . __path__ ) : <TAB> <TAB> full_name = package_name + "" . "" + name <TAB> <TAB> module = importlib . import_module ( full_name ) <TAB> <TAB> setattr ( sys . modules [ __name__ ] , name , module ) <TAB> <TAB> results [ full_name ] = module <TAB> <TAB> if is_pkg : <TAB> <TAB> <TAB> valid_pkg = import_submodules ( full_name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> results . update ( valid_pkg ) <TAB> return results",if valid_pkg :,if valid_pkg :,True,100.0,74.43,,,
"def _call ( self , cmd ) : <TAB> what = cmd [ "" command "" ] <TAB> if what == "" list "" : <TAB> <TAB> name = cmd [ "" properties "" ] . get ( "" name "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return { "" watchers "" : [ "" one "" , "" two "" , "" three "" ] } <TAB> <TAB> return { "" pids "" : [ 123 , 456 ] } <TAB> elif what == "" dstats "" : <TAB> <TAB> return { "" info "" : { "" pid "" : 789 } } <TAB> elif what == "" listsockets "" : <TAB> <TAB> return { <TAB> <TAB> <TAB> "" status "" : "" ok "" , <TAB> <TAB> <TAB> "" sockets "" : [ { "" path "" : self . _unix , "" fd "" : 5 , "" name "" : "" XXXX "" , "" backlog "" : 2048 } ] , <TAB> <TAB> <TAB> "" time "" : 1369647058.967524 , <TAB> <TAB> } <TAB> raise NotImplementedError ( cmd )","if name == ""watchers"" :",if name is None :,False,97.44,72.07,,,
"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB> <TAB> xlib . XNextEvent ( self . _display , e ) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> if e.xany.type not in (xlib.KeyPress, xlib.KeyRelease): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> dispatch = self._window_map[e.xany.window] <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch(e)",if e . xany . window in self . _window_map :,"if xlib . XFilterEvent ( e , e . xany . window ) :",False,95.12,70.13,,,
"def translate ( self , line ) : <TAB> parsed = self . RE_LINE_PARSER . match ( line ) <TAB> if parsed : <TAB> <TAB> value = parsed . group ( 3 ) <TAB> <TAB> stage = parsed . group ( 1 ) <TAB> <TAB> <IF-STMT> # query string is rendered here <TAB> <TAB> <TAB> return ""\n# HTTP Request:\n"" + self.stripslashes(value) <TAB> <TAB> elif stage == ""reply"": <TAB> <TAB> <TAB> return ""\n\n# HTTP Response:\n"" + self.stripslashes(value) <TAB> <TAB> elif stage == ""header"": <TAB> <TAB> <TAB> return value + ""\n"" <TAB> <TAB> else: <TAB> <TAB> <TAB> return value <TAB> return line","if stage == ""query"" :","if stage == ""send"" :",False,98.75,73.21,,,
"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flags + = u "" g "" <TAB> <TAB> if this . ignore_case : <TAB> <TAB> <TAB> flags + = u "" i "" <TAB> <TAB> if this . multiline : <TAB> <TAB> <TAB> flags + = u "" m "" <TAB> except : <TAB> <TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags",if this . g_mode :,if this . glob :,False,96.94,73.08,,,
"def __exit__ ( self , * exc_info ) : <TAB> super ( WarningsChecker , self ) . __exit__ ( * exc_info ) <TAB> # only check if we're not currently handling an exception <TAB> if all(a is None for a in exc_info): <TAB> <TAB> if self.expected_warning is not None: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> __tracebackhide__ = True <TAB> <TAB> <TAB> <TAB> pytest.fail(""DID NOT WARN"")",if self . expected_warning is not None :,if not any ( r . category in self . expected_warning for r in self ) :,False,89.99,65.13,,,
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> if k . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if v [ "" email "" ] == "" "" : <TAB> <TAB> <TAB> <TAB> v [ "" email "" ] = None <TAB> <TAB> <TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB> <TAB> <TAB> <TAB> v [ "" ip "" ] = None <TAB> return self . objs","if v [ ""type"" ] == ""email"" :","if v [ ""_class"" ] == ""User"" :",False,96.12,72.11,,,
"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB> <TAB> if i < = start_after : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self . count < 4 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i",if i == 6 and self . count < 4 :,if i == 2 and self . count < 1 :,False,96.61,71.7,,,
"def check ( self ) : <TAB> tcp_client = self . tcp_create ( ) <TAB> if tcp_client . connect ( ) : <TAB> <TAB> tcp_client . send ( b "" ABCDE "" ) <TAB> <TAB> response = tcp_client . recv ( 5 ) <TAB> <TAB> tcp_client . close ( ) <TAB> <TAB> if response : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . endianness = "" > "" # BE <TAB> <TAB> <TAB> elif response.startswith(b""ScMM""): <TAB> <TAB> <TAB> <TAB> self.endianness = ""<"" # LE <TAB> <TAB> <TAB> return True # target is vulnerable <TAB> return False # target is not vulnerable","if response . startswith ( b""BMMM"" ) :","if response . startswith ( b""MMcS"" ) :",False,98.7,73.31,,,
"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB> <TAB> if src_root != src_dir : <TAB> <TAB> <TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rel_root = "" "" <TAB> <TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( dst_root ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) )",if not os . path . isdir ( dst_root ) :,if not os . path . exists ( dst_root ) :,False,98.99,73.77,,,
"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB> <TAB> i = host . rfind ( "" : "" ) <TAB> <TAB> j = host . rfind ( "" ] "" ) # ipv6 addresses have [...] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> port = int(host[i + 1 :]) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB> <TAB> <TAB> host = host[:i] <TAB> <TAB> else: <TAB> <TAB> <TAB> port = self.default_port <TAB> <TAB> if host and host[0] == ""["" and host[-1] == ""]"": <TAB> <TAB> <TAB> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port",if i >= 0 and j >= 0 :,if i > j :,False,96.8,72.45,,,
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value","if key == ""nw_src"" :","if key == ""nw_src"" :",True,100.0,74.54,,,
"def _clear_storage ( ) : <TAB> """""" Clear old files from storage. """""" <TAB> hacs = get_hacs ( ) <TAB> storagefiles = [ "" hacs "" ] <TAB> for s_f in storagefiles : <TAB> <TAB> path = f "" { hacs . core . config_path } /.storage/ { s_f } "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hacs . log . info ( f "" Cleaning up old storage file  { path } "" ) <TAB> <TAB> <TAB> os . remove ( path )",if os . path . exists ( path ) :,if os . path . isfile ( path ) :,False,98.18,97.96,,,
"def action_delete ( self , ids ) : <TAB> try : <TAB> <TAB> count = 0 <TAB> <TAB> # TODO: Optimize me <TAB> <TAB> for pk in ids: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> flash( <TAB> <TAB> <TAB> ngettext( <TAB> <TAB> <TAB> <TAB> ""Record was successfully deleted."", <TAB> <TAB> <TAB> <TAB> ""%(count)s records were successfully deleted."", <TAB> <TAB> <TAB> <TAB> count, <TAB> <TAB> <TAB> <TAB> count=count, <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> ""success"", <TAB> <TAB> ) <TAB> except Exception as ex: <TAB> <TAB> flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",if pk . exists ( ) :,if self . delete_model ( self . get_one ( pk ) ) :,False,94.14,69.56,,,
"def action_delete ( self , ids ) : <TAB> try : <TAB> <TAB> count = 0 <TAB> <TAB> # TODO: Optimize me <TAB> <TAB> for pk in ids: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> count += 1 <TAB> <TAB> flash( <TAB> <TAB> <TAB> ngettext( <TAB> <TAB> <TAB> <TAB> ""Record was successfully deleted."", <TAB> <TAB> <TAB> <TAB> ""%(count)s records were successfully deleted."", <TAB> <TAB> <TAB> <TAB> count, <TAB> <TAB> <TAB> <TAB> count=count, <TAB> <TAB> <TAB> ), <TAB> <TAB> <TAB> ""success"", <TAB> <TAB> ) <TAB> except Exception as ex: <TAB> <TAB> flash(gettext(""Failed to delete records. %(error)s"", error=str(ex)), ""error"")",if pk . exists ( ) :,"if test_predicate . do_include ( { ""volume_guid"" : val } ) :",False,92.91,65.92,,,
"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB> <TAB> attr_mod , attr_path = ( <TAB> <TAB> <TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB> <TAB> ) <TAB> <TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB> <TAB> op = import_module ( full_mod_path ) <TAB> <TAB> if attr_path : <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path.split("".""): <TAB> <TAB> <TAB> <TAB> op = getattr(op, part) <TAB> <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex",if checked :,if checked :,True,100.0,74.54,,,
"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . fusefat is not None : <TAB> <TAB> self . fusefat . send_signal ( signal . SIGINT ) <TAB> <TAB> # Allow 1s to return without sending terminate <TAB> <TAB> for count in range(10): <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fusefat.terminate() <TAB> <TAB> time.sleep(self.delay) <TAB> <TAB> assert not os.path.exists(self.canary) <TAB> self.dev_null.close() <TAB> shutil.rmtree(self.tmpdir)",if self . fusefat . wait ( 1 ) :,if self . fusefat . poll ( ) is not None :,False,96.59,70.14,,,
"def check_context_processors ( output ) : <TAB> with output . section ( "" Context processors "" ) as section : <TAB> <TAB> processors = list ( <TAB> <TAB> <TAB> chain ( <TAB> <TAB> <TAB> <TAB> * [ <TAB> <TAB> <TAB> <TAB> <TAB> template [ "" OPTIONS "" ] . get ( "" context_processors "" , [ ] ) <TAB> <TAB> <TAB> <TAB> <TAB> for template in settings . TEMPLATES <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> required_processors = ( "" cms.context_processors.cms_settings "" , ) <TAB> <TAB> for processor in required_processors : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> section . error ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  context processor must be in TEMPLATES option context_processors "" <TAB> <TAB> <TAB> <TAB> <TAB> % processor <TAB> <TAB> <TAB> <TAB> )",if processor not in processors :,if processor not in processors :,True,100.0,74.56,,,
"def test_converters ( self ) : <TAB> response = self . _get ( "" datatypes/converters "" ) <TAB> self . _assert_status_code_is ( response , 200 ) <TAB> converters_list = response . json ( ) <TAB> found_fasta_to_tabular = False <TAB> for converter in converters_list : <TAB> <TAB> self . _assert_has_key ( converter , "" source "" , "" target "" , "" tool_id "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> found_fasta_to_tabular = True <TAB> assert found_fasta_to_tabular","if converter . source . get ( ""tool_id"" ) == ""fasta"" :","if converter [ ""source"" ] == ""fasta"" and converter [ ""target"" ] == ""tabular"" :",False,88.76,63.89,,,
"def remove_pid ( self , watcher , pid ) : <TAB> if pid in self . _pids [ watcher ] : <TAB> <TAB> logger . debug ( "" Removing  %d  from  %s "" % ( pid , watcher ) ) <TAB> <TAB> self . _pids [ watcher ] . remove ( pid ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( "" Stopping the periodic callback for  {0} "" . format ( watcher ) ) <TAB> <TAB> <TAB> self . _callbacks [ watcher ] . stop ( )",if self . _callbacks [ watcher ] :,if len ( self . _pids [ watcher ] ) == 0 :,False,91.54,69.35,,,
"def _fc_layer ( self , sess , bottom , name , trainable = True , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB> <TAB> shape = bottom . get_shape ( ) . as_list ( ) <TAB> <TAB> dim = 1 <TAB> <TAB> for d in shape [ 1 : ] : <TAB> <TAB> <TAB> dim * = d <TAB> <TAB> x = tf . reshape ( bottom , [ - 1 , dim ] ) <TAB> <TAB> weight = self . _get_fc_weight ( sess , name , trainable = trainable ) <TAB> <TAB> bias = self . _get_bias ( sess , name , trainable = trainable ) <TAB> <TAB> fc = tf . nn . bias_add ( tf . matmul ( x , weight ) , bias ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fc = tf . nn . relu ( fc ) <TAB> <TAB> return fc",if relu :,if relu :,True,100.0,74.6,,,
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> if root_path : <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path : <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive",if config_root_path and config_root_path == root_path :,if config_root_path and root_path == config_root_path :,False,98.48,72.26,,,
"def rewire_init ( expr ) : <TAB> new_args = [ ] <TAB> if expr [ 0 ] == HySymbol ( "" setv "" ) : <TAB> <TAB> pairs = expr [ 1 : ] <TAB> <TAB> while len ( pairs ) > 0 : <TAB> <TAB> <TAB> k , v = ( pairs . pop ( 0 ) , pairs . pop ( 0 ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> v . append ( HySymbol ( "" None "" ) ) <TAB> <TAB> <TAB> new_args . append ( k ) <TAB> <TAB> <TAB> new_args . append ( v ) <TAB> <TAB> expr = HyExpression ( [ HySymbol ( "" setv "" ) ] + new_args ) . replace ( expr ) <TAB> return expr","if k == HySymbol ( ""None"" ) :","if k == HySymbol ( ""__init__"" ) :",False,96.76,73.59,,,
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if child . tagName == ""Directory"" :","if child . tagName == ""Directory"" :",True,100.0,74.55,,,
"def _v2_common ( self , cfg ) : <TAB> LOG . debug ( "" v2_common: handling config: \n %s "" , cfg ) <TAB> if "" nameservers "" in cfg : <TAB> <TAB> search = cfg . get ( "" nameservers "" ) . get ( "" search "" , [ ] ) <TAB> <TAB> dns = cfg . get ( "" nameservers "" ) . get ( "" addresses "" , [ ] ) <TAB> <TAB> name_cmd = { "" type "" : "" nameserver "" } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name_cmd . update ( { "" search "" : search } ) <TAB> <TAB> if len ( dns ) > 0 : <TAB> <TAB> <TAB> name_cmd . update ( { "" addresses "" : dns } ) <TAB> <TAB> LOG . debug ( "" v2(nameserver) -> v1(nameserver): \n %s "" , name_cmd ) <TAB> <TAB> self . handle_nameserver ( name_cmd )",if len ( search ) > 0 :,if len ( search ) > 0 :,True,100.0,74.59,,,
"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB> <TAB> if self . type : <TAB> <TAB> <TAB> for extension in self . extensions : <TAB> <TAB> <TAB> <TAB> self [ extension ] = self . type <TAB> <TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB> <TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB> <TAB> pattern = attrs [ "" pattern "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) )",if pattern :,"if pattern . startswith ( ""*."" ) :",False,94.39,67.32,,,
"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB> <TAB> if self . type : <TAB> <TAB> <TAB> for extension in self . extensions : <TAB> <TAB> <TAB> <TAB> self [ extension ] = self . type <TAB> <TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB> <TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB> <TAB> pattern = attrs [ "" pattern "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) )",if pattern :,"if x . attribute != ""Record"" and hasattr ( x , ""data_model"" )",False,88.27,64.94,,,
"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB> <TAB> if not metadata . get ( "" nargs "" ) : <TAB> <TAB> <TAB> v = quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB> <TAB> if not value : <TAB> <TAB> <TAB> return None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value","if metadata . get ( ""quote"" ) :","elif not metadata . get ( ""nargs"" ) :",False,96.66,71.72,,,
"def get_images ( self ) : <TAB> images = [ ] <TAB> try : <TAB> <TAB> tag = MP4 ( self [ "" ~filename "" ] ) <TAB> except Exception : <TAB> <TAB> return [ ] <TAB> for cover in tag . get ( "" covr "" , [ ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mime = "" image/jpeg "" <TAB> <TAB> elif cover . imageformat == MP4Cover . FORMAT_PNG : <TAB> <TAB> <TAB> mime = "" image/png "" <TAB> <TAB> else : <TAB> <TAB> <TAB> mime = "" image/ "" <TAB> <TAB> f = get_temp_cover_file ( cover ) <TAB> <TAB> images . append ( EmbeddedImage ( f , mime ) ) <TAB> return images",if cover . imageformat == MP4Cover . FORMAT_JPEG :,if cover . imageformat == MP4Cover . FORMAT_JPEG :,True,100.0,74.5,,,
"def run_cmd ( self , util , value ) : <TAB> state = util . state <TAB> if not state . argument_supplied : <TAB> <TAB> state . argument_supplied = True <TAB> <TAB> if value == "" by_four "" : <TAB> <TAB> <TAB> state . argument_value = 4 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> state . argument_negative = True <TAB> <TAB> else : <TAB> <TAB> <TAB> state . argument_value = value <TAB> elif value == "" by_four "" : <TAB> <TAB> state . argument_value * = 4 <TAB> elif isinstance ( value , int ) : <TAB> <TAB> state . argument_value * = 10 <TAB> <TAB> state . argument_value + = value <TAB> <IF-STMT> <TAB> <TAB> state . argument_value = - state . argument_value","elif value == ""by_four"" :","elif value == ""negative"" :",False,96.03,72.62,,,
"def finish_character_data ( self ) : <TAB> if self . character_data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line , column = self . character_pos <TAB> <TAB> <TAB> token = XmlToken ( <TAB> <TAB> <TAB> <TAB> XML_CHARACTER_DATA , self . character_data , None , line , column <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . tokens . append ( token ) <TAB> <TAB> self . character_data = "" """,if self . character_pos :,if not self . skip_ws or not self . character_data . isspace ( ) :,False,88.65,65.44,,,
"def check_syntax ( filename , raise_error = False ) : <TAB> """""" Return True if syntax is okay. """""" <TAB> with autopep8 . open_with_encoding ( filename ) as input_file : <TAB> <TAB> try : <TAB> <TAB> <TAB> compile ( input_file . read ( ) , "" <string> "" , "" exec "" , dont_inherit = True ) <TAB> <TAB> <TAB> return True <TAB> <TAB> except ( SyntaxError , TypeError , UnicodeDecodeError ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return False",if raise_error :,if raise_error :,True,100.0,74.38,,,
"def write ( self , file ) : <TAB> if not self . _been_written : <TAB> <TAB> self . _been_written = True <TAB> <TAB> for attribute , value in self . __dict__ . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . write_recursive ( value , file ) <TAB> <TAB> w = file . write <TAB> <TAB> w ( "" \t %s  =  { \n "" % self . _id ) <TAB> <TAB> w ( "" \t \t isa =  %s ; \n "" % self . __class__ . __name__ ) <TAB> <TAB> for attribute , value in self . __dict__ . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> w ( "" \t \t %s  =  %s ; \n "" % ( attribute , self . tostring ( value ) ) ) <TAB> <TAB> w ( "" \t }; \n \n "" )","if attribute . startswith ( ""isa"" ) :","if attribute [ 0 ] != ""_"" :",False,93.33,70.78,,,
"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB> <TAB> with db_transaction ( ) : <TAB> <TAB> <TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB> <TAB> <TAB> if name is not None : <TAB> <TAB> <TAB> <TAB> key . name = name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> key . metadata . update ( metadata ) <TAB> <TAB> <TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB> <TAB> raise ServiceKeyDoesNotExist",if metadata is not None :,if metadata is not None :,True,100.0,74.44,,,
"def fill_buf ( self , db , len_ = None ) : <TAB> with open ( "" /dev/urandom "" , "" rb "" ) as rfh : <TAB> <TAB> first = True <TAB> <TAB> for ( id_ , ) in db . query ( "" SELECT id FROM test "" ) : <TAB> <TAB> <TAB> if len_ is None and first : <TAB> <TAB> <TAB> <TAB> val = b "" "" # We always want to check this case <TAB> <TAB> <TAB> <TAB> first = False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> val = rfh.read(random.randint(0, 140)) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> val = rfh.read(len_) <TAB> <TAB> <TAB> db.execute(""UPDATE test SET buf=? WHERE id=?"", (val, id_))",elif len_ is None :,elif len_ is None :,True,100.0,74.51,,,
"def load_category_from_parser ( self , parser ) : <TAB> for cate in parser . keys ( ) : <TAB> <TAB> id = parser . get_id ( cate ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _data [ "" cates "" ] [ id ] = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _data [ "" cates "" ] [ id ] = self . count_unread ( id ) <TAB> self . _is_init = False <TAB> self . save ( )","if id not in self . _data [ ""cates"" ] :",if self . _is_init :,False,91.43,63.8,,,
"def after_insert ( self ) : <TAB> if self . prescription : <TAB> <TAB> frappe . db . set_value ( <TAB> <TAB> <TAB> "" Lab Prescription "" , self . prescription , "" lab_test_created "" , 1 <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . invoiced = True <TAB> if not self . lab_test_name and self . template : <TAB> <TAB> self . load_test_from_template ( ) <TAB> <TAB> self . reload ( )",if self . lab_test_created :,"if frappe . db . get_value ( ""Lab Prescription"" , self . prescription , ""invoiced"" ) :",False,85.36,60.76,,,
"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB> <TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB> <TAB> except UnitNotFound : <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB> if not add: <TAB> <TAB> <TAB> continue <TAB> <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB> <TAB> self.add_units(None, missing)",if not source . is_unit :,"if ""terminology"" not in source . all_flags :",False,95.27,64.38,,,
def refresh ( self ) : <TAB> if self . _obj : <TAB> <TAB> base = self . _db . get_media_from_handle ( self . _obj . get_reference_handle ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _title = base . get_description ( ) <TAB> <TAB> <TAB> self . _value = base . get_path ( ),if base :,if base :,True,100.0,98.9,,,
"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self._wb_parse_context: <TAB> <TAB> if tag == ""style"": <TAB> <TAB> <TAB> self._wb_parse_context = ""style"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self._allow_js_type(tag_attrs): <TAB> <TAB> <TAB> <TAB> self._wb_parse_context = ""script""","elif tag == ""script"" :","elif tag == ""script"" :",True,100.0,73.88,,,
"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB> <TAB> iterator = iter ( self . file ) <TAB> <TAB> head = next ( iterator , None ) <TAB> <TAB> if head is None : <TAB> <TAB> <TAB> self . repaired = [ ] <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError( <TAB> <TAB> <TAB> <TAB> ""Could not open source: %r (mode: %r)"" <TAB> <TAB> <TAB> <TAB> % (self.file, self.options[""mode""]) <TAB> <TAB> <TAB> ) <TAB> return False",elif head in self . repaired :,"if isinstance ( head , str ) :",False,96.7,71.6,,,
"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """""" Modifies HTTP headers to include a specified user-agent. """""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB> <TAB> if kwargs [ "" headers "" ] . get ( "" user-agent "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB> <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)","if user_agent in kwargs [ ""headers"" ] [ ""user-agent"" ] :","if user_agent not in kwargs [ ""headers"" ] [ ""user-agent"" ] :",False,99.07,98.35,,,
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self . _dicts : <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self . _aggregate_rows : <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr",elif self . _naive_rows :,elif self . _naive or not self . _joins or self . verify_naive ( ) :,False,93.87,69.7,,,
"def populate_data ( apps , schema_editor ) : <TAB> Menu = apps . get_model ( "" menu "" , "" Menu "" ) <TAB> for menu in Menu . objects . all ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> json_str = menu . json_content <TAB> <TAB> <TAB> while isinstance ( json_str , str ) : <TAB> <TAB> <TAB> <TAB> json_str = json . loads ( json_str ) <TAB> <TAB> <TAB> menu . json_content_new = json_str <TAB> <TAB> <TAB> menu . save ( )","if isinstance ( menu , Menu ) :","if isinstance ( menu . json_content , str ) :",False,95.35,71.54,,,
"def virtualenv_exists ( self ) : <TAB> if os . path . exists ( self . virtualenv_location ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> extra = [ "" Scripts "" , "" activate.bat "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> extra = [ "" bin "" , "" activate "" ] <TAB> <TAB> return os . path . isfile ( os . sep . join ( [ self . virtualenv_location ] + extra ) ) <TAB> return False",if os . path . isdir ( self . virtualenv_location ) :,"if os . name == ""nt"" :",False,91.04,66.02,,,
"def get_minkowski_function ( name , variable ) : <TAB> fn_name = name + get_postfix ( variable ) <TAB> if hasattr ( MEB , fn_name ) : <TAB> <TAB> return getattr ( MEB , fn_name ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" Function  { fn_name }  not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( f "" Function  { fn_name }  not available. "" )",if torch . cuda . is_available ( ) :,if variable . is_cuda :,False,94.96,71.19,,,
"def build_temp_workspace ( files ) : <TAB> tempdir = tempfile . mkdtemp ( prefix = "" yamllint-tests- "" ) <TAB> for path , content in files . items ( ) : <TAB> <TAB> path = os . path . join ( tempdir , path ) . encode ( "" utf-8 "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( os . path . dirname ( path ) ) <TAB> <TAB> if type ( content ) is list : <TAB> <TAB> <TAB> os . mkdir ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mode = "" wb "" if isinstance ( content , bytes ) else "" w "" <TAB> <TAB> <TAB> with open ( path , mode ) as f : <TAB> <TAB> <TAB> <TAB> f . write ( content ) <TAB> return tempdir",if not os . path . isdir ( os . path . dirname ( path ) ) :,if not os . path . exists ( os . path . dirname ( path ) ) :,False,98.82,73.8,,,
"def clean_form ( self , request , user , form , cleaned_data ) : <TAB> for field in self . get_fields ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> cleaned_data [ field . fieldname ] = field . clean ( <TAB> <TAB> <TAB> <TAB> request , user , cleaned_data [ field . fieldname ] <TAB> <TAB> <TAB> ) <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> form . add_error ( field . fieldname , e ) <TAB> return cleaned_data",if field . required :,if field . fieldname not in cleaned_data :,False,95.27,71.24,,,
"def setUp ( self ) : <TAB> self . realm = service . InMemoryWordsRealm ( "" realmname "" ) <TAB> self . checker = checkers . InMemoryUsernamePasswordDatabaseDontUse ( ) <TAB> self . portal = portal . Portal ( self . realm , [ self . checker ] ) <TAB> self . factory = service . IRCFactory ( self . realm , self . portal ) <TAB> c = [ ] <TAB> for nick in self . STATIC_USERS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nick = nick . decode ( "" utf-8 "" ) <TAB> <TAB> c . append ( self . realm . createUser ( nick ) ) <TAB> <TAB> self . checker . addUser ( nick , nick + "" _password "" ) <TAB> return DeferredList ( c )","if isinstance ( nick , bytes ) :","if isinstance ( nick , bytes ) :",True,100.0,74.52,,,
"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack + = 1 <TAB> <TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB> <TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack - = 1 <TAB> <TAB> message . ack ( ) <TAB> <TAB> self . completed_calls + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not self . done_future . done ( ) : <TAB> <TAB> <TAB> <TAB> self . done_future . set_result ( None )",if self . completed_calls == self . _pending_ack :,if self . completed_calls >= self . _resolve_at_msg_count :,False,95.28,72.71,,,
"def fill_in_standard_formats ( book ) : <TAB> for x in std_format_code_types . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ty = std_format_code_types [ x ] <TAB> <TAB> <TAB> # Note: many standard format codes (mostly CJK date formats) have <TAB> <TAB> <TAB> # format strings that vary by locale; xlrd does not (yet) <TAB> <TAB> <TAB> # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB> <TAB> <TAB> fmt_str = std_format_strings.get(x) <TAB> <TAB> <TAB> fmtobj = Format(x, ty, fmt_str) <TAB> <TAB> <TAB> book.format_map[x] = fmtobj",if x in book . format_map :,if x not in book . format_map :,False,98.78,72.99,,,
"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i <= 3: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if even_only and i % 2 != 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> result.append(i) <TAB> return result",if less_than_7_only and i >= 7 :,if less_than_7_only and i >= 7 :,True,100.0,74.41,,,
"def next_instruction_is_function_or_class ( lines ) : <TAB> """""" Is the first non-empty, non-commented line of the cell either a function or a class? """""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) : # empty line <TAB> <TAB> <TAB> if i > 0 and not lines[i - 1].strip(): <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line.startswith(""def "") or line.startswith(""class ""): <TAB> <TAB> <TAB> return True <TAB> <TAB> if line.startswith((""#"", ""@"", "" "", "")"")): <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False","if line . startswith ( ""#"" ) :",if parser . is_quoted ( ) :,False,97.1,65.59,,,
"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB> <TAB> if tag . name not in ( "" input "" , ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError",if key in self . _attributes :,"if ""name"" in tag . attrs and tag . attrs [ ""name"" ] in ( key , ) :",False,82.23,58.56,,,
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if obj.use_scope: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> elif obj.use_scope is None: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation","if name == ""layer"" :","if hasattr ( obj , ""use_scope"" ) :",False,95.62,70.99,,,
"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB> <TAB> if x < self . box [ 0 ] : <TAB> <TAB> <TAB> self . box [ 0 ] = x <TAB> <TAB> if x > self . box [ 2 ] : <TAB> <TAB> <TAB> self . box [ 2 ] = x <TAB> <TAB> if y < self . box [ 1 ] : <TAB> <TAB> <TAB> self . box [ 1 ] = y <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . box [ 3 ] = y",if y > self . box [ 3 ] :,if y > self . box [ 3 ] :,True,100.0,74.48,,,
"def find_shell ( ) : <TAB> global DEFAULT_SHELL <TAB> if not DEFAULT_SHELL : <TAB> <TAB> for shell in propose_shell ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> DEFAULT_SHELL = shell <TAB> <TAB> <TAB> <TAB> break <TAB> if not DEFAULT_SHELL : <TAB> <TAB> DEFAULT_SHELL = "" /bin/sh "" <TAB> return DEFAULT_SHELL","if shell . startswith ( ""/bin/sh"" ) :","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) :",False,83.88,52.92,,,
"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB> <TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB> <TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB> <TAB> for aggr in aggrs : <TAB> <TAB> <TAB> for c in cols : <TAB> <TAB> <TAB> <TAB> if not hasattr ( c , "" aggregators "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators = [ ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators + = [ aggr ]","if isinstance ( aggr , list ) :",if aggr and aggr not in c . aggregators :,False,95.06,70.55,,,
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . pathAbsoluteFromProjectEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" )",if len ( items ) > 1 :,if len ( items ) > 1 :,True,100.0,74.38,,,
"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = "" This account is already in use. "" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB> <TAB> elif not user : <TAB> <TAB> <TAB> user = social . user <TAB> return { <TAB> <TAB> "" social "" : social , <TAB> <TAB> "" user "" : user , <TAB> <TAB> "" is_new "" : user is None , <TAB> <TAB> "" new_association "" : social is None , <TAB> }","if backend . strategy . storage . user . is_active ( backend , uid ) :",if user and social . user != user :,False,91.84,70.45,,,
"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB> <TAB> if not typ : <TAB> <TAB> <TAB> out + = text <TAB> <TAB> elif typ == "" em "" : <TAB> <TAB> <TAB> out + = "" \\ fI %s \\ fR "" % text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out + = "" \\ fB %s \\ fR "" % text <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out","elif typ == ""emb"" :","elif typ in [ ""strong"" , ""code"" ] :",False,94.65,68.88,,,
"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB> <TAB> if not typ : <TAB> <TAB> <TAB> out + = text <TAB> <TAB> elif typ == "" em "" : <TAB> <TAB> <TAB> out + = "" \\ fI %s \\ fR "" % text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out + = "" \\ fB %s \\ fR "" % text <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out","elif typ == ""emb"" :",if self . rbFit . GetValue ( ),False,95.28,67.59,,,
"def hexdump ( data ) : <TAB> """""" yield lines with hexdump of data """""" <TAB> values = [ ] <TAB> ascii = [ ] <TAB> offset = 0 <TAB> for h , a in sixteen ( data ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( offset , "" "" . join ( [ "" "" . join ( values ) , "" "" . join ( ascii ) ] ) ) <TAB> <TAB> <TAB> del values [ : ] <TAB> <TAB> <TAB> del ascii [ : ] <TAB> <TAB> <TAB> offset + = 0x10 <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( h ) <TAB> <TAB> <TAB> ascii . append ( a )",if h == 0x0E :,if h is None :,False,97.5,95.97,,,
"def submit ( self ) : <TAB> bot_token = self . config [ "" bot_token "" ] <TAB> chat_ids = self . config [ "" chat_id "" ] <TAB> chat_ids = [ chat_ids ] if isinstance ( chat_ids , str ) else chat_ids <TAB> text = "" \n "" . join ( super ( ) . submit ( ) ) <TAB> if not text : <TAB> <TAB> logger . debug ( "" Not calling telegram API (no changes) "" ) <TAB> <TAB> return <TAB> result = None <TAB> for chunk in chunkstring ( text , self . MAX_LENGTH , numbering = True ) : <TAB> <TAB> for chat_id in chat_ids : <TAB> <TAB> <TAB> res = self . submitToTelegram ( bot_token , chat_id , chunk ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result = res <TAB> return result",if res :,if res . status_code != requests . codes . ok or res is None :,False,92.73,69.97,,,
"def onMessage ( self , payload , isBinary ) : <TAB> if not isBinary : <TAB> <TAB> self . result = "" Expected binary message with payload, but got binary. "" <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . result = ( <TAB> <TAB> <TAB> <TAB> "" Expected binary message with payload of length  %d , but got  %d . "" <TAB> <TAB> <TAB> <TAB> % ( self . DATALEN , len ( payload ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self.behavior = Case.OK <TAB> <TAB> <TAB> self.result = ""Received binary message of length %d."" % len(payload) <TAB> self.p.createWirelog = True <TAB> self.p.sendClose(self.p.CLOSE_STATUS_CODE_NORMAL)",if self . DATALEN != len ( payload ) :,if len ( payload ) != self . DATALEN :,False,97.64,72.53,,,
"def verify_output ( actual , expected ) : <TAB> actual = _read_file ( actual , "" Actual "" ) <TAB> expected = _read_file ( join ( CURDIR , expected ) , "" Expected "" ) <TAB> if len ( expected ) != len ( actual ) : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" Lengths differ. Expected  %d  lines but got  %d "" <TAB> <TAB> <TAB> % ( len ( expected ) , len ( actual ) ) <TAB> <TAB> ) <TAB> for exp , act in zip ( expected , actual ) : <TAB> <TAB> tester = fnmatchcase if "" * "" in exp else eq <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" Lines differ. \n Expected:  %s \n Actual: %s "" % ( exp , act ) <TAB> <TAB> <TAB> )",if not tester ( act ) :,"if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) :",False,94.96,71.0,,,
"def _in_out_vector_helper ( self , name1 , name2 , ceil ) : <TAB> vector = [ ] <TAB> stats = self . record <TAB> if ceil is None : <TAB> <TAB> ceil = self . _get_max_rate ( name1 , name2 ) <TAB> maxlen = self . config . get_stats_history_length ( ) <TAB> for n in [ name1 , name2 ] : <TAB> <TAB> for i in range ( maxlen + 1 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> vector . append ( float ( stats [ i ] [ n ] ) / ceil ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> vector . append ( 0.0 ) <TAB> return vector",if stats [ i ] [ n ] > 0.0 :,if i < len ( stats ) :,False,94.74,71.12,,,
"def _init_param ( param , mode ) : <TAB> if isinstance ( param , str ) : <TAB> <TAB> param = _resolve ( param ) <TAB> elif isinstance ( param , ( list , tuple ) ) : <TAB> <TAB> param = [ _init_param ( p , mode ) for p in param ] <TAB> elif isinstance ( param , dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> param = from_params ( param , mode = mode ) <TAB> <TAB> else : <TAB> <TAB> <TAB> param = { k : _init_param ( v , mode ) for k , v in param . items ( ) } <TAB> return param","if isinstance ( param , dict ) :","if { ""ref"" , ""class_name"" , ""config_path"" } . intersection ( param . keys ( ) ) :",False,85.67,62.76,,,
"def link_pantsrefs ( soups , precomputed ) : <TAB> """""" Transorm soups: <a pantsref= "" foo "" > becomes <a href= "" ../foo_page.html#foo "" > """""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB> <TAB> for a in soup . find_all ( "" a "" ) : <TAB> <TAB> <TAB> if not a . has_attr ( "" pantsref "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a [ "" pantsref "" ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TaskError ( <TAB> <TAB> <TAB> <TAB> <TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] )",if pantsref not in precomputed . pantsref :,if pantsref not in precomputed . pantsref :,True,100.0,99.6,,,
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> if not svalue : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return getint ( svalue ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> return value",if self . _is_float :,"elif ""."" in svalue :",False,94.94,62.79,,,
"def default ( self , o ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> if hasattr(o, ""credentials""): <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> if hasattr(o, ""services_config""): <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)","if isinstance ( o , ( dict , list ) ) :",if type ( o ) == datetime . datetime :,False,95.85,70.34,,,
"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ "" - %s "" % name ] <TAB> <TAB> elif value not in ( False , None ) : <TAB> <TAB> <TAB> if split_single_char_options : <TAB> <TAB> <TAB> <TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB> <TAB> elif value is not False and value is not None : <TAB> <TAB> <TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ]","if value in ( True , None ) :",if value is True :,False,94.42,71.37,,,
"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB> <TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB> <TAB> if context . rounding == ROUND_FLOOR : <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) )",if context . rounding == ROUND_FLOOR :,if context . rounding == ROUND_CEILING :,False,98.72,73.65,,,
"def OnLeftUp ( self , event ) : <TAB> # Stop Drawing <TAB> if self.Drawing: <TAB> <TAB> self.Drawing = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> world_rect = ( <TAB> <TAB> <TAB> <TAB> self.Canvas.PixelToWorld(self.RBRect[0]), <TAB> <TAB> <TAB> <TAB> self.Canvas.ScalePixelToWorld(self.RBRect[1]), <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> wx.CallAfter(self.CallBack, world_rect) <TAB> self.RBRect = None",if self . RBRect :,if self . RBRect :,True,100.0,73.86,,,
"def _map_answers ( answers ) : <TAB> result = [ ] <TAB> for a in answers . split ( "" | "" ) : <TAB> <TAB> user_answers = [ ] <TAB> <TAB> result . append ( dict ( sourcerAnswers = user_answers ) ) <TAB> <TAB> for r in a . split ( "" , "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> user_answers . append ( dict ( noAnswer = True ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> start_ , end_ = map ( int , r . split ( "" : "" ) ) <TAB> <TAB> <TAB> <TAB> user_answers . append ( dict ( s = start_ , e = end_ ) ) <TAB> return result","if r == """" :","if r == ""None"" :",False,98.74,68.53,,,
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> if parsed_drawing : <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> if bbox is None : <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox","if d . GetType ( ) == ""Edge"" :",if d . GetLayer ( ) == pcbnew . Edge_Cuts :,False,96.65,64.16,,,
"def get_size ( self ) : <TAB> size = self . start_size <TAB> for operation in self . ran_operations : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size = operation [ 1 ] [ 0 ] <TAB> <TAB> elif operation [ 0 ] == "" crop "" : <TAB> <TAB> <TAB> crop = operation [ 1 ] [ 0 ] <TAB> <TAB> <TAB> size = crop [ 2 ] - crop [ 0 ] , crop [ 3 ] - crop [ 1 ] <TAB> return size","if operation [ 0 ] == ""size"" :","if operation [ 0 ] == ""resize"" :",False,98.12,72.97,,,
"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB> <TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB> <TAB> else : <TAB> <TAB> <TAB> create_categories_for_folders ( account , db_session ) <TAB> <TAB> if account . discriminator == "" gmailaccount "" : <TAB> <TAB> <TAB> set_labels_for_imapuids ( account , db_session ) <TAB> <TAB> db_session . commit ( )","if account . discriminator == ""easfoldersyncstatus"" :","if account . discriminator == ""easaccount"" :",False,98.71,73.24,,,
"def OnEndDrag ( self , event ) : <TAB> self . StopDragging ( ) <TAB> dropTarget = event . GetItem ( ) <TAB> if not dropTarget : <TAB> <TAB> dropTarget = self . GetRootItem ( ) <TAB> if self . IsValidDropTarget ( dropTarget ) : <TAB> <TAB> self . UnselectAll ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . SelectItem ( dropTarget ) <TAB> <TAB> self . OnDrop ( dropTarget , self . _dragItem )",if self . IsValidDropTarget ( dropTarget ) :,if dropTarget != self . GetRootItem ( ) :,False,93.62,70.49,,,
"def validate ( self , frame , value ) : <TAB> if self . sep and isinstance ( value , string_types ) : <TAB> <TAB> value = value . split ( self . sep ) <TAB> if isinstance ( value , list ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ self . specs [ 0 ] . validate ( frame , v ) for v in value ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> [ s . validate ( frame , v ) for ( v , s ) in izip ( val , self . specs ) ] <TAB> <TAB> <TAB> <TAB> for val in value <TAB> <TAB> <TAB> ] <TAB> raise ValueError ( "" Invalid MultiSpec data:  %r "" % value )",if len ( self . specs ) == 1 :,if len ( self . specs ) == 1 :,True,100.0,74.57,,,
"def __init__ ( self , action_space = None , network = None , network_kwargs = None , hparams = None ) : <TAB> QNetBase . __init__ ( self , hparams = hparams ) <TAB> with tf . variable_scope ( self . variable_scope ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> action_space = Space ( low = 0 , high = self . _hparams . action_space , dtype = np . int32 ) <TAB> <TAB> self . _action_space = action_space <TAB> <TAB> self . _append_output_layer ( )",if action_space is None :,if action_space is None :,True,100.0,74.31,,,
"def n_weights ( self ) : <TAB> """""" Return the number of weights (parameters) in this network. """""" <TAB> n_weights = 0 <TAB> for i , w in enumerate ( self . all_weights ) : <TAB> <TAB> n = 1 <TAB> <TAB> # for s in p.eval().shape: <TAB> <TAB> for s in w.get_shape(): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> s = int(s) <TAB> <TAB> <TAB> except: <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> n = n * s <TAB> <TAB> n_weights = n_weights + n <TAB> # print(""num of weights (parameters) %d"" % n_weights) <TAB> return n_weights",if s != 0 :,if s :,False,98.01,98.29,,,
"def _arg_desc ( name , ctx ) : <TAB> for param in ctx . command . params : <TAB> <TAB> if param . name == name : <TAB> <TAB> <TAB> desc = param . opts [ - 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> desc = param . human_readable_name <TAB> <TAB> <TAB> return desc <TAB> raise AssertionError ( name )","if desc == """" :","if desc [ 0 ] != ""-"" :",False,93.12,61.23,,,
"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB> <TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB> <TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( directory , name ) <TAB> <TAB> if os . path . isdir ( full_name ) : <TAB> <TAB> <TAB> for file_path in walk ( full_name , path ) : <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield path",elif os . path . isfile ( full_name ) :,elif os . path . isfile ( full_name ) :,True,100.0,74.57,,,
"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB> <TAB> for dst , src in viewitems ( assignblk ) : <TAB> <TAB> <TAB> if dst . is_id ( "" IRDst "" ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst","if linenb and src . is_id ( ""IRSrc"" ) :",if final_dst is not None :,False,93.06,63.6,,,
"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB> <TAB> filters = { } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB> <TAB> if args . policy_type : <TAB> <TAB> <TAB> filters [ "" policy_type "" ] = args . policy_type <TAB> <TAB> filters . update ( * * kwargs ) <TAB> <TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB> <TAB> return self . manager . get_all ( * * kwargs )",if args . resource_ref :,if args . resource_ref :,True,100.0,74.41,,,
"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB> <TAB> duplicates = [ ] <TAB> <TAB> for other_folder , other_path in folders . items ( ) : <TAB> <TAB> <TAB> if other_folder == folder : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path : <TAB> <TAB> <TAB> <TAB> duplicates . append ( other_folder ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . duplicates [ folder ] = duplicates",if duplicates :,if len ( duplicates ) :,False,96.87,71.84,,,
"def limit_clause ( self , select , * * kw ) : <TAB> text = "" "" <TAB> if select . _limit_clause is not None : <TAB> <TAB> text + = "" \n  LIMIT  "" + self . process ( select . _limit_clause , * * kw ) <TAB> if select . _offset_clause is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text + = "" \n  LIMIT  "" + self . process ( sql . literal ( - 1 ) ) <TAB> <TAB> text + = ""  OFFSET  "" + self . process ( select . _offset_clause , * * kw ) <TAB> else : <TAB> <TAB> text + = ""  OFFSET  "" + self . process ( sql . literal ( 0 ) , * * kw ) <TAB> return text","if select . _limit_clause == ""LIMIT"" :",if select . _limit_clause is None :,False,96.62,68.66,,,
"def _get_activation ( self , act ) : <TAB> """""" Get activation block based on the name. """""" <TAB> if isinstance ( act , str ) : <TAB> <TAB> if act . lower ( ) == "" gelu "" : <TAB> <TAB> <TAB> return GELU ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return GELU ( approximate = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return gluon . nn . Activation ( act ) <TAB> assert isinstance ( act , gluon . Block ) <TAB> return act","elif act . lower ( ) == ""glu"" :","elif act . lower ( ) == ""approx_gelu"" :",False,96.94,73.09,,,
"def __eq__ ( self , other ) : <TAB> try : <TAB> <TAB> if self . type != other . type : <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . type == "" ASK "" : <TAB> <TAB> <TAB> return self . askAnswer == other . askAnswer <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . graph == other . graph <TAB> except : <TAB> <TAB> return False","elif self . type == ""VARIABLE"" :","elif self . type == ""SELECT"" :",False,98.42,73.14,,,
"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB> <TAB> if isinstance ( node , HtmlTag ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> open_tags + = 1 <TAB> <TAB> <TAB> elif node . tag_type == CLOSE_TAG : <TAB> <TAB> <TAB> <TAB> open_tags - = 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance ( node , HtmlDataFragment ) <TAB> <TAB> <TAB> and node . is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ) : <TAB> <TAB> <TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text",if node . tag_type == OPEN_TAG :,if node . tag_type == OPEN_TAG :,True,100.0,74.48,,,
"def test_do_change ( self ) : <TAB> """""" Test if VTK object changes when trait is changed. """""" <TAB> p = Prop ( ) <TAB> p . edge_visibility = not p . edge_visibility <TAB> p . representation = "" p "" <TAB> p . opacity = 0.5 <TAB> p . color = ( 0 , 1 , 0 ) <TAB> p . diffuse_color = ( 1 , 1 , 1 ) <TAB> p . specular_color = ( 1 , 1 , 0 ) <TAB> for t , g in p . _updateable_traits_ : <TAB> <TAB> val = getattr ( p . _vtk_obj , g ) ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( val , getattr ( p , t + "" _ "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( val , getattr ( p , t ) )","if t == ""edge"" :","if t == ""representation"" :",False,98.87,98.77,,,
"def update_item ( source_doc , target_doc , source_parent ) : <TAB> target_doc . t_warehouse = "" "" <TAB> if source_doc . material_request_item and source_doc . material_request : <TAB> <TAB> add_to_transit = frappe . db . get_value ( <TAB> <TAB> <TAB> "" Stock Entry "" , source_name , "" add_to_transit "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warehouse = frappe . get_value ( <TAB> <TAB> <TAB> <TAB> "" Material Request Item "" , source_doc . material_request_item , "" warehouse "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> target_doc . t_warehouse = warehouse <TAB> target_doc . s_warehouse = source_doc . t_warehouse <TAB> target_doc . qty = source_doc . qty - source_doc . transferred_qty",if add_to_transit :,if add_to_transit :,True,100.0,74.43,,,
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path : <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path : <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive",if root_path :,if root_path :,True,100.0,74.34,,,
"def f_freeze ( _ ) : <TAB> repos = utils . get_repos ( ) <TAB> for name , path in repos . items ( ) : <TAB> <TAB> url = "" "" <TAB> <TAB> cp = subprocess . run ( [ "" git "" , "" remote "" , "" -v "" ] , cwd = path , capture_output = True ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> url = cp . stdout . decode ( "" utf-8 "" ) . split ( "" \n "" ) [ 0 ] . split ( ) [ 1 ] <TAB> <TAB> print ( f "" { url } , { name } , { path } "" )",if cp . returncode == 0 :,if cp . returncode == 0 :,True,100.0,74.46,,,
"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if self . flags . f_contiguous : <TAB> <TAB> <TAB> order = "" F "" <TAB> <TAB> else : <TAB> <TAB> <TAB> order = "" C "" <TAB> <TAB> result = self . _new_like_me ( order = order ) <TAB> <TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB> <TAB> func . prepared_async_call ( <TAB> <TAB> <TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return self",if self . flags . c_contiguous :,if not self . flags . forc :,False,97.68,72.94,,,
"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB> <TAB> if function . is_implemented : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _explore ( function . entry_point , [ ] ) <TAB> <TAB> <TAB> function . context [ self . KEY ] = True",if self . KEY in function . context :,if self . KEY in function . context :,True,100.0,74.08,,,
"def test_default_configuration_no_encoding ( self ) : <TAB> transformations = [ ] <TAB> for i in range ( 2 ) : <TAB> <TAB> transformation , original = _test_preprocessing ( NoEncoding ) <TAB> <TAB> self . assertEqual ( transformation . shape , original . shape ) <TAB> <TAB> self . assertTrue ( ( transformation == original ) . all ( ) ) <TAB> <TAB> transformations . append ( transformation ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertTrue ( ( transformations [ - 1 ] == transformations [ - 2 ] ) . all ( ) )",if len ( transformations ) > 1 :,if len ( transformations ) > 1 :,True,100.0,74.36,,,
"def main ( ) : <TAB> """""" main function """""" <TAB> # todo: lookuo real description <TAB> parser = argparse.ArgumentParser(description=""Let a cow speak for you"") <TAB> parser.add_argument(""text"", nargs=""*"", default=None, help=""text to say"") <TAB> ns = parser.parse_args() <TAB> if (ns.text is None) or (len(ns.text) == 0): <TAB> <TAB> text = """" <TAB> <TAB> while True: <TAB> <TAB> <TAB> inp = sys.stdin.read(4096) <TAB> <TAB> <TAB> if inp.endswith(""\n""): <TAB> <TAB> <TAB> <TAB> inp = inp[:-1] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text += inp <TAB> else: <TAB> <TAB> text = "" "".join(ns.text) <TAB> cow = get_cow(text) <TAB> print(cow)","if inp == """" :",if not inp :,False,97.68,67.08,,,
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> if self . arch == "" i386 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> elif self . arch == "" amd64 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True )",if reg :,if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None :,False,88.87,66.97,,,
"def get_boarding_status ( project ) : <TAB> status = "" Pending "" <TAB> if project : <TAB> <TAB> doc = frappe . get_doc ( "" Project "" , project ) <TAB> <TAB> if flt ( doc . percent_complete ) > 0.0 and flt ( doc . percent_complete ) < 100.0 : <TAB> <TAB> <TAB> status = "" In Process "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> status = "" Completed "" <TAB> <TAB> return status",if doc . percent_complete > 0.0 and flt ( doc . percent_complete ) < 100.0 :,elif flt ( doc . percent_complete ) == 100.0 :,False,90.3,69.47,,,
"def set_weights ( self , new_weights ) : <TAB> weights = self . get_weights ( ) <TAB> if len ( weights ) != len ( new_weights ) : <TAB> <TAB> raise ValueError ( "" len of lists mismatch "" ) <TAB> tuples = [ ] <TAB> for w , new_w in zip ( weights , new_weights ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_w = new_w . reshape ( w . shape ) <TAB> <TAB> tuples . append ( ( w , new_w ) ) <TAB> nn . batch_set_value ( tuples )","if isinstance ( new_w , nn . BatchNorm ) :",if len ( w . shape ) != new_w . shape :,False,92.13,69.36,,,
"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( json_api_settings , setting , value ) <TAB> <TAB> elif hasattr ( json_api_settings , setting ) : <TAB> <TAB> <TAB> delattr ( json_api_settings , setting )",if value is not None :,if value is not None :,True,100.0,74.3,,,
"def knamn ( self , sup , cdict ) : <TAB> cname = cdict [ sup ] . class_name <TAB> if not cname : <TAB> <TAB> ( namesp , tag ) = cdict [ sup ] . name . split ( "" . "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctag = self . root . modul [ namesp ] . factory ( tag ) . __class__ . __name__ <TAB> <TAB> <TAB> cname = "" %s . %s "" % ( namesp , ctag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cname = tag + "" _ "" <TAB> return cname",if namesp in self . root . modul :,if namesp :,False,95.23,72.34,,,
"def setdefault ( self , key , default = None ) : <TAB> try : <TAB> <TAB> o = self . data [ key ] ( ) <TAB> except KeyError : <TAB> <TAB> o = None <TAB> if o is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _commit_removals ( ) <TAB> <TAB> self . data [ key ] = KeyedRef ( default , self . _remove , key ) <TAB> <TAB> return default <TAB> else : <TAB> <TAB> return o",if self . _commit_removals :,if self . _pending_removals :,False,98.07,72.88,,,
"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB> <TAB> module = self . get_event_module ( event ) <TAB> <TAB> self . __module_view . set_selection ( module . module_num ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . list_ctrl . deactivate_active_item ( ) <TAB> <TAB> <TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB> <TAB> <TAB> <TAB> if self . list_ctrl . IsSelected ( index ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( )",if self . __input_list_ctrl :,if event . EventObject is self . list_ctrl :,False,97.1,71.27,,,
"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB> <TAB> for j in range ( len ( nodes ) ) : <TAB> <TAB> <TAB> if i == j : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> graph . del_edge ( edge ) <TAB> <TAB> <TAB> graph . add_edge ( edge , 1 )",if edge in graph . edges ( ) :,if graph . has_edge ( edge ) :,False,95.4,71.49,,,
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default . lower ( ) == "" false "" : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> if type ( default ) == float : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default )","if default . lower ( ) == ""true"" :","if default . lower ( ) == ""true"" :",True,100.0,74.66,,,
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np.random.RandomState().get_state() <TAB> size = 0 <TAB> for elem in state: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size += len(elem) <TAB> <TAB> elif isinstance(elem, np.ndarray): <TAB> <TAB> <TAB> size += elem.size * elem.itemsize <TAB> <TAB> elif isinstance(elem, int): <TAB> <TAB> <TAB> size += np.dtype(""int"").itemsize <TAB> <TAB> elif isinstance(elem, float): <TAB> <TAB> <TAB> size += np.dtype(""float"").itemsize <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError() <TAB> return size","if isinstance ( elem , np . ndarray ) :","if isinstance ( elem , str ) :",False,97.97,72.52,,,
"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB> <TAB> for name , var in new_subst . items ( ) : <TAB> <TAB> <TAB> if name not in subst : <TAB> <TAB> <TAB> <TAB> subst [ name ] = var <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst","if isinstance ( subst [ name ] , Subst ) :",elif subst [ name ] is not var :,False,93.23,69.08,,,
"def _load_weights_if_possible ( self , model , init_weight_path = None ) : <TAB> """""" Loads model weights when it is provided. """""" <TAB> if init_weight_path : <TAB> <TAB> logging . info ( "" Load weights:  {} "" . format ( init_weight_path ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> checkpoint = tf . train . Checkpoint ( <TAB> <TAB> <TAB> <TAB> model = model , optimizer = self . _create_optimizer ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> checkpoint . restore ( init_weight_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> model . load_weights ( init_weight_path ) <TAB> else : <TAB> <TAB> logging . info ( "" Weights not loaded from path: {} "" . format ( init_weight_path ) )",if self . _checkpoint_model is not None :,if self . use_tpu :,False,96.38,96.94,,,
"def _cleanup_inactive_receivexlogs ( self , site ) : <TAB> if site in self . receivexlogs : <TAB> <TAB> if not self . receivexlogs [ site ] . running : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . receivexlogs [ site ] . join ( ) <TAB> <TAB> <TAB> del self . receivexlogs [ site ]",if self . receivexlogs [ site ] . running :,if self . receivexlogs [ site ] . is_alive ( ) :,False,93.43,70.83,,,
"def get_asset ( self , path ) : <TAB> """""" Loads an asset by path. """""" <TAB> clean_path = cleanup_path ( path ) . strip ( "" / "" ) <TAB> nodes = [ self . asset_root ] + self . theme_asset_roots <TAB> for node in nodes : <TAB> <TAB> for piece in clean_path . split ( "" / "" ) : <TAB> <TAB> <TAB> node = node . get_child ( piece ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if node is not None : <TAB> <TAB> <TAB> return node <TAB> return None",if node is None :,if node is None :,True,100.0,99.41,,,
"def get_asset ( self , path ) : <TAB> """""" Loads an asset by path. """""" <TAB> clean_path = cleanup_path ( path ) . strip ( "" / "" ) <TAB> nodes = [ self . asset_root ] + self . theme_asset_roots <TAB> for node in nodes : <TAB> <TAB> for piece in clean_path . split ( "" / "" ) : <TAB> <TAB> <TAB> node = node . get_child ( piece ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if node is not None : <TAB> <TAB> <TAB> return node <TAB> return None",if node is None :,if sub == sub [ : : - 1 ] :,False,93.28,84.8,,,
"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> l . append ( _names . get ( elt , elt ) ) <TAB> <TAB> elif isinstance ( elt , str ) : <TAB> <TAB> <TAB> l . append ( elt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l . append ( debug_tree ( elt ) ) <TAB> return l","if isinstance ( elt , dict ) :","if isinstance ( elt , ( int , long ) ) :",False,94.75,70.5,,,
"def shared_username ( account ) : <TAB> username = os . environ . get ( "" SHARED_USERNAME "" , "" PKKid "" ) <TAB> for user in account . users ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return username <TAB> <TAB> elif ( <TAB> <TAB> <TAB> user . username <TAB> <TAB> <TAB> and user . email <TAB> <TAB> <TAB> and user . id <TAB> <TAB> <TAB> and username . lower ( ) <TAB> <TAB> <TAB> in ( user . username . lower ( ) , user . email . lower ( ) , str ( user . id ) ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> return username <TAB> pytest . skip ( "" Shared user  %s  wasn`t found in your MyPlex account "" % username )",if user . username == username :,if user . title . lower ( ) == username . lower ( ) :,False,94.24,70.54,,,
"def process_schema_element ( self , e ) : <TAB> if e . name is None : <TAB> <TAB> return <TAB> self . debug1 ( "" adding element:  %s "" , e . name ) <TAB> t = self . get_type ( e . type ) <TAB> if t : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . pending_elements [ e . name ] <TAB> <TAB> self . retval [ self . tns ] . elements [ e . name ] = e <TAB> else : <TAB> <TAB> self . pending_elements [ e . name ] = e",if e . name in self . pending_elements :,if e . name in self . pending_elements :,True,100.0,74.41,,,
"def __setitem__ ( self , key , value ) : <TAB> with self . _lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> link = self . _get_link_and_move_to_front_of_ll ( key ) <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _set_key_and_add_to_front_of_ll ( key , value ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> evicted = self . _set_key_and_evict_last_in_ll ( key , value ) <TAB> <TAB> <TAB> <TAB> super ( LRI , self ) . __delitem__ ( evicted ) <TAB> <TAB> <TAB> super ( LRI , self ) . __setitem__ ( key , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> link [ VALUE ] = value",if self . _front_of_ll :,if len ( self ) < self . max_size :,False,95.77,70.98,,,
"def __delattr__ ( self , name ) : <TAB> if name == "" __dict__ "" : <TAB> <TAB> raise AttributeError ( <TAB> <TAB> <TAB> "" %r  object attribute  ' __dict__ '  is read-only "" % self . __class__ . __name__ <TAB> <TAB> ) <TAB> if name in self . _local_type_vars : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # A data descriptor, like a property or a slot. <TAB> <TAB> <TAB> type_attr = getattr(self._local_type, name, _marker) <TAB> <TAB> <TAB> type(type_attr).__delete__(type_attr, self) <TAB> <TAB> <TAB> return <TAB> # Otherwise it goes directly in the dict <TAB> # Begin inlined function _get_dict() <TAB> dct = _local_get_dict(self) <TAB> try: <TAB> <TAB> del dct[name] <TAB> except KeyError: <TAB> <TAB> raise AttributeError(name)","if hasattr ( self . _local_type , name ) :",if name in self . _local_type_del_descriptors :,False,96.77,71.55,,,
"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB> <TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB> <TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB> <TAB> if participant in self . participants_dict : <TAB> <TAB> <TAB> self . participants_dict [ participant ] . refresh ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB> <TAB> self . update_view ( )",if participant not in self . participants_dict :,if participant is None or participant == self . simulator_config . broadcast_part :,False,92.58,70.22,,,
"def insert_bigger_b_add ( node ) : <TAB> if node . op == theano . tensor . add : <TAB> <TAB> inputs = list ( node . inputs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> inputs [ - 1 ] = theano . tensor . concatenate ( ( inputs [ - 1 ] , inputs [ - 1 ] ) ) <TAB> <TAB> <TAB> return [ node . op ( * inputs ) ] <TAB> return False",if len ( inputs ) > 1 :,if inputs [ - 1 ] . owner is None :,False,91.31,68.1,,,
"def _activate_cancel_status ( self , cancel_status ) : <TAB> if self . _cancel_status is not None : <TAB> <TAB> self . _cancel_status . _tasks . remove ( self ) <TAB> self . _cancel_status = cancel_status <TAB> if self . _cancel_status is not None : <TAB> <TAB> self . _cancel_status . _tasks . add ( self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _attempt_delivery_of_any_pending_cancel ( )",if self . _is_delivery_of_any_pending_cancel ( ) :,if self . _cancel_status . effectively_cancelled :,False,90.56,71.15,,,
"def writeLibraryGeometry ( fp , meshes , config , shapes = None ) : <TAB> progress = Progress ( len ( meshes ) , None ) <TAB> fp . write ( "" \n  <library_geometries> \n "" ) <TAB> for mIdx , mesh in enumerate ( meshes ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shape = None <TAB> <TAB> else : <TAB> <TAB> <TAB> shape = shapes [ mIdx ] <TAB> <TAB> writeGeometry ( fp , mesh , config , shape ) <TAB> <TAB> progress . step ( ) <TAB> fp . write ( ""  </library_geometries> \n "" )",if mIdx == 0 :,if shapes is None :,False,96.34,71.89,,,
"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB> <TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> if module_json [ "" name "" ] not in config : <TAB> <TAB> <TAB> <TAB> config . add_section ( module_json [ "" name "" ] ) <TAB> <TAB> <TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config",if config_var . startswith ( config_path ) :,"if config_var not in config [ module_json [ ""name"" ] ] :",False,93.22,67.63,,,
"def get_const_defines ( flags , prefix = "" "" ) : <TAB> defs = [ ] <TAB> for k , v in globals ( ) . items ( ) : <TAB> <TAB> if isinstance ( v , int ) : <TAB> <TAB> <TAB> if v & flags : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if k . startswith ( prefix ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> defs . append ( k ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> defs . append ( k ) <TAB> return defs",if prefix :,if prefix :,True,100.0,74.38,,,
"def __init__ ( self , source , encoding = DEFAULT_ENCODING ) : <TAB> self . data = { } <TAB> with open ( source , encoding = encoding ) as file_ : <TAB> <TAB> for line in file_ : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> k , v = line . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> k = k . strip ( ) <TAB> <TAB> <TAB> v = v . strip ( ) <TAB> <TAB> <TAB> if len ( v ) > = 2 and ( <TAB> <TAB> <TAB> <TAB> ( v [ 0 ] == "" ' "" and v [ - 1 ] == "" ' "" ) or ( v [ 0 ] == ' "" ' and v [ - 1 ] == ' "" ' ) <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> v = v . strip ( "" ' \"" "" ) <TAB> <TAB> <TAB> self . data [ k ] = v",if not line :,"if not line or line . startswith ( ""#"" ) or ""="" not in line :",False,94.19,82.52,,,
"def __detect_console_logger ( self ) : <TAB> logger = self . log <TAB> while logger : <TAB> <TAB> for handler in logger . handlers [ : ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if handler . stream in ( sys . stdout , sys . stderr ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . logger_handlers . append ( handler ) <TAB> <TAB> if logger . root == logger : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> logger = logger . root","if isinstance ( handler , logging . StreamHandler ) :","if isinstance ( handler , StreamHandler ) :",False,97.77,73.07,,,
"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB> <TAB> name = heur [ "" name "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur [ "" sql "" ] <TAB> <TAB> if sql . lower ( ) . find ( name . lower ( ) ) == - 1 : <TAB> <TAB> <TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB> <TAB> <TAB> print ( sql ) <TAB> <TAB> <TAB> assert sql . find ( name ) != - 1 <TAB> <TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs )",if name in excluded :,if name in excluded :,True,100.0,74.59,,,
"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . seek_to_block ( self . cursor ) <TAB> <TAB> part = self . current_stream . read ( size ) <TAB> <TAB> if size > 0 : <TAB> <TAB> <TAB> if len ( part ) == 0 : <TAB> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> <TAB> size - = len ( part ) <TAB> <TAB> self . cursor + = len ( part ) <TAB> <TAB> buf + = part <TAB> return bytes ( buf )",if self . current_stream :,if not self . in_current_block ( self . cursor ) :,False,93.03,70.52,,,
"def get_project_dir ( env ) : <TAB> project_file = workon_home / env / "" .project "" <TAB> if project_file . exists ( ) : <TAB> <TAB> with project_file . open ( ) as f : <TAB> <TAB> <TAB> project_dir = f . readline ( ) . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return project_dir <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> err ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Corrupted or outdated: "" , <TAB> <TAB> <TAB> <TAB> <TAB> project_file , <TAB> <TAB> <TAB> <TAB> <TAB> "" \n Directory "" , <TAB> <TAB> <TAB> <TAB> <TAB> project_dir , <TAB> <TAB> <TAB> <TAB> <TAB> "" doesn ' t exist. "" , <TAB> <TAB> <TAB> <TAB> )",if os . path . isdir ( project_dir ) :,if os . path . exists ( project_dir ) :,False,99.02,73.56,,,
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """""" cache hidden states into memory. """""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> if prev_mem is None : <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> return tf . keras . backend . stop_gradient ( new_mem )",if reuse_len is not None :,if reuse_len is not None and reuse_len > 0 :,False,96.38,94.94,,,
"def cleanup_channel ( self , to_cleanup ) : <TAB> public_key , id_ = to_cleanup <TAB> # TODO: Maybe run it threaded? <TAB> try: <TAB> <TAB> with db_session: <TAB> <TAB> <TAB> channel = self.session.mds.ChannelMetadata.get_for_update( <TAB> <TAB> <TAB> <TAB> public_key=public_key, id_=id_ <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> channel.local_version = 0 <TAB> <TAB> <TAB> channel.contents.delete(bulk=True) <TAB> except Exception as e: <TAB> <TAB> self._logger.warning(""Exception while cleaning unsubscribed channel: %"", str(e))",if channel is None :,if not channel :,False,97.96,71.63,,,
"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <TAB> <TAB> if img.width == width and img.height == height: <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image",if img . width > width and img . height > height :,elif img . width >= width and img . width * img . height > image . width * image . height :,False,88.7,65.62,,,
"def add_peer_to_blob ( self , contact : "" KademliaPeer "" , key : bytes ) - > None : <TAB> now = self . loop . time ( ) <TAB> if key in self . _data_store : <TAB> <TAB> current = list ( filter ( lambda x : x [ 0 ] == contact , self . _data_store [ key ] ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _data_store [ key ] [ self . _data_store [ key ] . index ( current [ 0 ] ) ] = ( <TAB> <TAB> <TAB> <TAB> contact , <TAB> <TAB> <TAB> <TAB> now , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _data_store [ key ] . append ( ( contact , now ) ) <TAB> else : <TAB> <TAB> self . _data_store [ key ] = [ ( contact , now ) ]",if current :,if len ( current ) > 0 :,False,96.92,72.3,,,
"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB> <TAB> if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) )","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :",True,100.0,74.67,,,
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self.plugin_args.end: <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils.xrange(start, end, 0x1000): <TAB> <TAB> <TAB> if self.plugin_args.start <= vaddr <= self.plugin_args.end: <TAB> <TAB> <TAB> <TAB> yield vaddr, self._CreateMetadata(address_space.describe_vtop(vaddr))",if start == self . plugin_args . start :,if end < self . plugin_args . start :,False,98.07,72.9,,,
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> if name . startswith ( expr ) : <TAB> <TAB> <TAB> <TAB> if name not in found_names : <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) )",if not scoperef :,if not scoperef :,True,100.0,74.61,,,
"def get_xenapi_host ( self ) : <TAB> """""" Return the xenapi host on which nova-compute runs on. """""" <TAB> with self . _get_session ( ) as session : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return session . xenapi . host . get_by_uuid ( self . host_uuid ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return session . xenapi . session . get_this_host ( session . handle )",if self . host_uuid :,if self . host_uuid :,True,100.0,74.13,,,
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> elif "" status "" in line : <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> elif "" error "" in line : <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError","if ""stream"" in line :","if ""stream"" in line and line [ ""stream"" ] . strip ( ) :",False,91.72,65.83,,,
"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr(bonobo, name) <TAB> <TAB> if inspect.ismodule(attr): <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo.__all__","if name . startswith ( ""_"" ) :","if name . startswith ( ""_"" ) :",True,100.0,74.14,,,
"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """""" Coerce the values in a variable to bools. """""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB> <TAB> v = b . data <TAB> <TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB> <TAB> <TAB> const = v . pyval is true_val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> elif not compare . compatible_with ( v , False ) : <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else : <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var","elif isinstance ( v , mixin . Constant ) :","elif not compare . compatible_with ( v , True ) :",False,95.9,93.77,,,
"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB> <TAB> id_ = required_key ( item , "" id "" ) <TAB> <TAB> controls_ids = required_key ( item , "" controls "" ) <TAB> <TAB> if not isinstance ( controls_ids , list ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> id_ = id_ , controls = str ( controls_ids ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError ( msg ) <TAB> <TAB> self . policies [ id_ ] = controls_ids",if controls_ids not in self . policies :,"if controls_ids != ""all"" :",False,96.82,67.32,,,
"def pong ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> payload = payload . decode ( "" utf-8 "" ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Sending a pong data frame  "" <TAB> <TAB> <TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PONG ) <TAB> with self . sock_send_lock : <TAB> <TAB> self . sock . send ( data )","if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",True,100.0,74.46,,,
"def _extract_curve_feature_log ( arg ) : <TAB> """""" extract sampled curve feature for log items """""" <TAB> try : <TAB> <TAB> inp , res = arg <TAB> <TAB> config = inp . config <TAB> <TAB> with inp . target : <TAB> <TAB> <TAB> sch , args = inp . task . instantiate ( config ) <TAB> <TAB> fea = feature . get_buffer_curve_sample_flatten ( sch , args , sample_n = 20 ) <TAB> <TAB> x = np . concatenate ( ( fea , list ( config . get_other_option ( ) . values ( ) ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y = inp . task . flop / np . mean ( res . costs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> y = 0.0 <TAB> <TAB> return x , y <TAB> except Exception : # pylint: disable=broad-except <TAB> <TAB> return None",if res . has_sample :,if res . error_no == 0 :,False,96.98,97.19,,,
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> if ss [ "" branch "" ] : <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> if ss [ "" patch "" ] is not None : <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""revision"" ] :","if ss [ ""revision"" ] :",True,100.0,74.62,,,
"def find_repository ( ) : <TAB> orig_path = path = os . path . realpath ( "" . "" ) <TAB> drive , path = os . path . splitdrive ( path ) <TAB> while path : <TAB> <TAB> current_path = os . path . join ( drive , path ) <TAB> <TAB> current_repo = LocalRepository ( current_path ) <TAB> <TAB> if current_repo . isValid ( ) : <TAB> <TAB> <TAB> return current_repo <TAB> <TAB> path , path_tail = os . path . split ( current_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CannotFindRepository ( "" Cannot find repository for  %s "" % ( orig_path , ) )",if path == orig_path :,if not path_tail :,False,95.95,72.5,,,
"def compute_indices ( text : str , tokens ) : <TAB> indices = [ ] <TAB> for i , token in enumerate ( tokens ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> current_index = indices [ - 1 ] + len ( tokens [ i - 1 ] [ 0 ] ) <TAB> <TAB> <TAB> indices . append ( current_index + text [ current_index : ] . find ( token [ 0 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> indices . append ( text . find ( token [ 0 ] ) ) <TAB> return indices",if i > 0 :,if 1 <= i :,False,96.31,72.32,,,
"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB> <TAB> for item in self.distribution.data_files: <TAB> <TAB> <TAB> if isinstance(item, str): <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path(item) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(item) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname, filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames: <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path(f) <TAB> <TAB> <TAB> <TAB> <TAB> if os.path.isfile(f): <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(f)",if os . path . isfile ( item ) :,if os . path . isfile ( item ) :,True,100.0,74.43,,,
"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB> <TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB> <TAB> elif str ( libcxx ) == "" libstdc++11 "" : <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" ""","if str ( libcxx ) == ""libstdc++10"" :","if str ( libcxx ) == ""libstdc++"" :",False,98.4,72.86,,,
"def _populate_tree ( self , element , d ) : <TAB> """""" Populates an etree with attributes & elements, given a dict. """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v )",elif type ( v ) == str :,"elif isinstance ( v , basestring ) :",False,96.81,72.26,,,
"def test_seek ( self ) : <TAB> <IF-STMT> <TAB> <TAB> print ( "" create large file via seek (may be sparse file) ... "" ) <TAB> with self . open ( TESTFN , "" wb "" ) as f : <TAB> <TAB> f . write ( b "" z "" ) <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> f . seek ( size ) <TAB> <TAB> f . write ( b "" a "" ) <TAB> <TAB> f . flush ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" check file size with os.fstat "" ) <TAB> <TAB> self . assertEqual ( os . fstat ( f . fileno ( ) ) [ stat . ST_SIZE ] , size + 1 )",if DEBUG :,if verbose :,False,97.23,72.59,,,
"def serialize_review_url_field ( self , obj , * * kwargs ) : <TAB> if obj . review_ui : <TAB> <TAB> review_request = obj . get_review_request ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> local_site_name = review_request . local_site . name <TAB> <TAB> else : <TAB> <TAB> <TAB> local_site_name = None <TAB> <TAB> return local_site_reverse ( <TAB> <TAB> <TAB> "" file-attachment "" , <TAB> <TAB> <TAB> local_site_name = local_site_name , <TAB> <TAB> <TAB> kwargs = { <TAB> <TAB> <TAB> <TAB> "" review_request_id "" : review_request . display_id , <TAB> <TAB> <TAB> <TAB> "" file_attachment_id "" : obj . pk , <TAB> <TAB> <TAB> } , <TAB> <TAB> ) <TAB> return "" """,if review_request . local_site :,if review_request . local_site_id :,False,98.57,73.36,,,
"def on_item_down_clicked ( self , button ) : <TAB> model = self . treeview . get_model ( ) <TAB> for s in self . _get_selected ( ) : <TAB> <TAB> <IF-STMT> # XXX need model.swap <TAB> <TAB> <TAB> old = model.get_iter(s[0]) <TAB> <TAB> <TAB> iter = model.insert(s[0] + 2) <TAB> <TAB> <TAB> for i in range(3): <TAB> <TAB> <TAB> <TAB> model.set_value(iter, i, model.get_value(old, i)) <TAB> <TAB> <TAB> model.remove(old) <TAB> <TAB> <TAB> self.treeview.get_selection().select_iter(iter) <TAB> self._update_filter_string()",if s [ 0 ] == 0 :,if s [ 0 ] < len ( model ) - 1 :,False,96.01,69.39,,,
"def writer ( self ) : <TAB> """""" loop forever and copy socket->serial """""" <TAB> while self . alive : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = self . socket . recv ( 1024 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self . serial . write ( b "" "" . join ( self . rfc2217 . filter ( data ) ) ) <TAB> <TAB> except socket . error as msg : <TAB> <TAB> <TAB> self . log . error ( "" {} "" . format ( msg ) ) <TAB> <TAB> <TAB> # probably got disconnected <TAB> <TAB> <TAB> break <TAB> self.stop()",if not data :,if not data :,True,100.0,99.45,,,
"def __getitem__ ( self , key ) : <TAB> if key == 1 : <TAB> <TAB> return self . get_value ( ) <TAB> elif key == 0 : <TAB> <TAB> return self . cell [ 0 ] <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> s = list ( self . cell . __getitem__ ( key ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s [ s . index ( self . cell [ 1 ] ) ] = self . get_value ( ) <TAB> <TAB> return s <TAB> else : <TAB> <TAB> raise IndexError ( key )",if len ( s ) > 1 :,if self . cell [ 1 ] in s :,False,94.38,70.26,,,
"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> "" flush "" , <TAB> <TAB> "" write "" , <TAB> <TAB> "" writelines "" , <TAB> ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB> <TAB> if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) : <TAB> <TAB> <TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB> <TAB> if error_msg : <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ]","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) :","if not hasattr ( wsgi_errors , method ) :",False,95.47,72.49,,,
"def job_rule_modules ( app ) : <TAB> rules_module_list = [ ] <TAB> for rules_module_name in __job_rule_module_names ( app ) : <TAB> <TAB> rules_module = sys . modules . get ( rules_module_name , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB> <TAB> <TAB> # JobWrapper is created <TAB> <TAB> <TAB> rules_module = importlib.import_module(rules_module_name) <TAB> <TAB> rules_module_list.append(rules_module) <TAB> return rules_module_list",if rules_module is None :,if not rules_module :,False,97.07,71.68,,,
"def discover_hdfstore ( f ) : <TAB> d = dict ( ) <TAB> for key in f . keys ( ) : <TAB> <TAB> d2 = d <TAB> <TAB> key2 = key . lstrip ( "" / "" ) <TAB> <TAB> while "" / "" in key2 : <TAB> <TAB> <TAB> group , key2 = key2 . split ( "" / "" , 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> d2 [ group ] = dict ( ) <TAB> <TAB> <TAB> d2 = d2 [ group ] <TAB> <TAB> d2 [ key2 ] = f . get_storer ( key ) <TAB> return discover ( d )",if group not in d2 :,if group not in d2 :,True,100.0,74.45,,,
"def test_update_zone ( self ) : <TAB> zone = self . driver . list_zones ( ) [ 0 ] <TAB> updated_zone = self . driver . update_zone ( zone = zone , domain = "" "" , extra = { "" paused "" : True } ) <TAB> self . assertEqual ( zone . id , updated_zone . id ) <TAB> self . assertEqual ( zone . domain , updated_zone . domain ) <TAB> self . assertEqual ( zone . type , updated_zone . type ) <TAB> self . assertEqual ( zone . ttl , updated_zone . ttl ) <TAB> for key in set ( zone . extra ) | set ( updated_zone . extra ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertNotEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( zone . extra [ key ] , updated_zone . extra [ key ] )","if key == ""paused"" :","if key in ( ""paused"" , ""modified_on"" ) :",False,94.89,67.43,,,
"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dev = devid [ num ] <TAB> <TAB> <TAB> if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =ON "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning On  "" + name ) <TAB> <TAB> <TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =OFF "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning Off  "" + name ) <TAB> <TAB> <TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False )",if num in devid :,if name . lower ( ) in phrase :,False,96.13,71.65,,,
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> if port . port_no == in_port : <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret",if allow_nw_id_external :,elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external :,False,89.97,69.12,,,
"def tail ( filename ) : <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> file = open ( filename , "" r "" ) <TAB> <TAB> st_results = os . stat ( filename ) <TAB> <TAB> st_size = st_results [ 6 ] <TAB> <TAB> file . seek ( st_size ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> where = file . tell ( ) <TAB> <TAB> <TAB> line = file . readline ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> <TAB> <TAB> file . seek ( where ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> <TAB> line , <TAB> <TAB> <TAB> <TAB> ) # already has newline <TAB> else: <TAB> <TAB> print_error(""File not found, cannot tail."")","if line == """" :",if not line :,False,97.56,66.28,,,
"def proc_day_of_week ( d ) : <TAB> if expanded [ 4 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_day_of_week = nearest_diff_method ( d . isoweekday ( ) % 7 , expanded [ 4 ] , 7 ) <TAB> <TAB> if diff_day_of_week is not None and diff_day_of_week != 0 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( days = diff_day_of_week , hour = 23 , minute = 59 , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( days = diff_day_of_week , hour = 0 , minute = 0 , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d","if expanded [ 4 ] [ 0 ] == ""*"" :",if is_prev :,False,93.96,63.74,,,
"def __call__ ( self ) : <TAB> """""" Run all check_* methods. """""" <TAB> if self . on : <TAB> <TAB> oldformatwarning = warnings . formatwarning <TAB> <TAB> warnings . formatwarning = self . formatwarning <TAB> <TAB> try : <TAB> <TAB> <TAB> for name in dir ( self ) : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" check_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr ( self , name ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> warnings . formatwarning = oldformatwarning",if callable ( method ) :,if method and callable ( method ) :,False,98.19,92.07,,,
"def get ( self , request , * args , * * kwargs ) : <TAB> if self . revision : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return send_file ( <TAB> <TAB> <TAB> <TAB> <TAB> request , <TAB> <TAB> <TAB> <TAB> <TAB> self . revision . file . path , <TAB> <TAB> <TAB> <TAB> <TAB> self . revision . created , <TAB> <TAB> <TAB> <TAB> <TAB> self . attachment . original_filename , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> return HttpResponseRedirect ( self . revision . file . url ) <TAB> raise Http404",if self . revision . file :,if settings . USE_LOCAL_PATH :,False,96.24,72.3,,,
"def _close ( self ) : <TAB> super ( Recording , self ) . _close ( ) <TAB> if self . _log_n is not None : <TAB> <TAB> for i in range ( self . n ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _log_n [ i ] . close ( ) <TAB> <TAB> <TAB> <TAB> self . _log_n [ i ] = None",if self . _log_n [ i ] is not None :,if self . _log_n [ i ] is not None :,True,100.0,74.23,,,
"def addTags ( self , rpcObjects = None ) : <TAB> hosts = self . _getOnlyHostObjects ( rpcObjects ) <TAB> if hosts : <TAB> <TAB> title = "" Add Tags "" <TAB> <TAB> body = "" What tags should be added? \n \n Use a comma or space between each "" <TAB> <TAB> ( tags , choice ) = self . getText ( title , body , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tags = str ( tags ) . replace ( "" "" , "" , "" ) . split ( "" , "" ) <TAB> <TAB> <TAB> for host in hosts : <TAB> <TAB> <TAB> <TAB> self . cuebotCall ( <TAB> <TAB> <TAB> <TAB> <TAB> host . addTags , "" Add Tags to  %s  Failed "" % host . data . name , tags <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _update ( )",if choice :,if choice :,True,100.0,74.58,,,
"def available_datasets ( self ) : <TAB> """""" Automatically determine datasets provided by this file """""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB> <TAB> <TAB> <TAB> "" resolution "" : res , <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> if not self . is_geo : <TAB> <TAB> <TAB> <TAB> ds_info [ "" coordinates "" ] = coordinates <TAB> <TAB> <TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info",if val in coordinates :,"if isinstance ( val , netCDF4 . Variable ) :",False,95.83,94.65,,,
"def extract_from_file ( fname : PathIsh ) - > Iterator [ Extraction ] : <TAB> path = Path ( fname ) <TAB> fallback_dt = file_mtime ( path ) <TAB> p = Parser ( path ) <TAB> for r in p . walk ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield r <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Visit ( <TAB> <TAB> <TAB> <TAB> url = r . url , <TAB> <TAB> <TAB> <TAB> dt = fallback_dt , <TAB> <TAB> <TAB> <TAB> locator = Loc . file ( fname ) , # TODO line number <TAB> <TAB> <TAB> <TAB> context=r.context, <TAB> <TAB> <TAB> )",if r . context is None :,"if isinstance ( r , Exception ) :",False,96.25,71.29,,,
"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB> <TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> config . add_section ( module_json [ "" name "" ] ) <TAB> <TAB> <TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <TAB> if config_var not in config [ module_json [ "" name "" ] ] : <TAB> <TAB> <TAB> <TAB> <TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config","if module_json [ ""name"" ] not in config :","if module_json [ ""name"" ] not in config :",True,100.0,74.51,,,
"def _create_entities ( parsed_entities , sidx , eidx ) : <TAB> entities = [ ] <TAB> for k , vs in parsed_entities . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vs = [ vs ] <TAB> <TAB> for value in vs : <TAB> <TAB> <TAB> entities . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" entity "" : k , <TAB> <TAB> <TAB> <TAB> <TAB> "" start "" : sidx , <TAB> <TAB> <TAB> <TAB> <TAB> "" end "" : eidx , # can't be more specific <TAB> <TAB> <TAB> <TAB> <TAB> ""value"": value, <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return entities","if not isinstance ( vs , ( list , tuple ) ) :","if not isinstance ( vs , list ) :",False,97.2,72.77,,,
"def _telegram_upload_stream ( self , stream , * * kwargs ) : <TAB> """""" Perform upload defined in a stream. """""" <TAB> msg = None <TAB> try : <TAB> <TAB> stream . accept ( ) <TAB> <TAB> msg = self . _telegram_special_message ( <TAB> <TAB> <TAB> chat_id = stream . identifier . id , <TAB> <TAB> <TAB> content = stream . raw , <TAB> <TAB> <TAB> msg_type = stream . stream_type , <TAB> <TAB> <TAB> * * kwargs , <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> log . exception ( f "" Upload of  { stream . name }  to  { stream . identifier }  failed. "" ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stream . error ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stream . success ( )",if msg is None :,if msg is None :,True,100.0,99.55,,,
"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB> <TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB> <TAB> line = self.readline() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> out.append(line) <TAB> <TAB> if size > -1: <TAB> <TAB> <TAB> nbr += len(line) <TAB> <TAB> <TAB> if nbr > size: <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if not line :,if not line :,True,100.0,74.43,,,
"def clean_permissions ( <TAB> cls , <TAB> requestor : "" User "" , <TAB> group : auth_models . Group , <TAB> errors : Dict [ Optional [ str ] , List [ ValidationError ] ] , <TAB> cleaned_input : dict , ) : <TAB> field = "" add_permissions "" <TAB> permission_items = cleaned_input . get ( field ) <TAB> if permission_items : <TAB> <TAB> cleaned_input [ field ] = get_permissions ( permission_items ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . ensure_can_manage_permissions ( <TAB> <TAB> <TAB> <TAB> requestor , errors , field , permission_items <TAB> <TAB> <TAB> )",if cleaned_input [ field ] :,if not requestor . is_superuser :,False,95.86,71.5,,,
"def _bwd ( subj = None , obj = None , seen = None ) : <TAB> seen . add ( obj ) <TAB> for s , o in evalPath ( graph , ( None , self . path , obj ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield s , o <TAB> <TAB> if self . more : <TAB> <TAB> <TAB> if s in seen : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for s2 , o2 in _bwd ( None , s , seen ) : <TAB> <TAB> <TAB> <TAB> yield s2 , o",if subj is not None and o is not None :,if not subj or subj == s :,False,93.55,70.44,,,
"def generate_data ( self , request ) : <TAB> """""" Generate data for the widget. """""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB> <TAB> for hosts , stats in cache_stats : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB> <TAB> <TAB> elif stats [ "" uptime "" ] > 3600 : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime }","if stats [ ""uptime"" ] > 24 :","if stats [ ""uptime"" ] > 86400 :",False,99.16,99.04,,,
def refresh ( self ) : <TAB> if self . _handle : <TAB> <TAB> source = self . _db . get_repository_from_handle ( self . _handle ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _title = str ( source . get_type ( ) ) <TAB> <TAB> <TAB> self . _value = source . get_name ( ),if source :,if source :,True,100.0,98.88,,,
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> elif "" . "" in svalue : <TAB> <TAB> <TAB> <TAB> return getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return getint ( svalue ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> return value","if svalue == """" :",if not svalue :,False,96.21,63.9,,,
"def parseGrants ( self , tree ) : <TAB> for grant in tree . findall ( "" .//Grant "" ) : <TAB> <TAB> grantee = Grantee ( ) <TAB> <TAB> g = grant . find ( "" .//Grantee "" ) <TAB> <TAB> grantee . xsi_type = g . attrib [ "" { http://www.w3.org/2001/XMLSchema-instance}type "" ] <TAB> <TAB> grantee . permission = grant . find ( "" Permission "" ) . text <TAB> <TAB> for el in g : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> grantee . display_name = el . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> grantee . tag = el . tag <TAB> <TAB> <TAB> <TAB> grantee . name = el . text <TAB> <TAB> self . grantees . append ( grantee )","if el . tag == ""display"" :","if el . tag == ""DisplayName"" :",False,98.88,73.61,,,
"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB> <TAB> if order == 0 : <TAB> <TAB> <TAB> name = "" std_dev "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = "" sample_std_dev "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order",elif order == 1 :,elif order == 1 :,True,100.0,74.34,,,
"def _shouldRollover ( self ) : <TAB> if self . maxBytes > 0 : # are we rolling over? <TAB> <TAB> try: <TAB> <TAB> <TAB> self.stream.seek(0, 2) # due to non-posix-compliant Windows feature <TAB> <TAB> except IOError: <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> else: <TAB> <TAB> <TAB> self._degrade(False, ""Rotation done or not needed at this time"") <TAB> return False",if self . stream . tell ( ) > self . maxBytes :,if self . stream . tell ( ) >= self . maxBytes :,False,98.28,72.69,,,
"def userfullname ( ) : <TAB> """""" Get the user ' s full name. """""" <TAB> global _userfullname <TAB> if not _userfullname : <TAB> <TAB> uid = os . getuid ( ) <TAB> <TAB> entry = pwd_from_uid ( uid ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB> <TAB> if not _userfullname : <TAB> <TAB> <TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname",if entry :,if entry :,True,100.0,99.31,,,
"def drop ( self ) : <TAB> # mssql <TAB> sql = ""if object_id('%s') is not null drop table %s"" % (self.tname, self.tname) <TAB> try: <TAB> <TAB> self.execute(sql) <TAB> except Exception as e: <TAB> <TAB> self.conn.rollback() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> # sqlite <TAB> <TAB> sql = ""drop table if exists %s"" % self.tname <TAB> <TAB> self.execute(sql)","if e . args [ 0 ] != ""No rows created"" :","if ""syntax error"" not in str ( e ) :",False,90.9,66.65,,,
"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB> <TAB> return 0 <TAB> while True : <TAB> <TAB> b = f . read ( block_size ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return f . tell ( ) <TAB> <TAB> elif delimiter in b : <TAB> <TAB> <TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1",if not b :,if not b :,True,100.0,74.34,,,
"def _convert ( container ) : <TAB> if _value_marker in container : <TAB> <TAB> force_list = False <TAB> <TAB> values = container . pop ( _value_marker ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB> <TAB> if not force_list and len ( values ) == 1 : <TAB> <TAB> <TAB> values = values [ 0 ] <TAB> <TAB> if not container : <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert ( container ) <TAB> el <IF-STMT> <TAB> <TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) )","if isinstance ( container [ 0 ] , list ) :","if container . pop ( _list_marker , False ) :",False,91.58,69.65,,,
"def fitting ( self , value ) : <TAB> self . _fitting = value <TAB> if self . _fitting is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . makedirs ( dirname ( self . checkpoint_path ( ) ) ) <TAB> <TAB> <TAB> except FileExistsError as ex : <TAB> <TAB> <TAB> <TAB> pass # race to create <TAB> <TAB> if not os.path.exists(dirname(self.tensorboard_path())): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> os.makedirs(dirname(self.tensorboard_path())) <TAB> <TAB> <TAB> except FileExistsError as ex: <TAB> <TAB> <TAB> <TAB> pass # race to create",if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :,True,100.0,74.47,,,
"def _make_headers ( self ) : <TAB> libraries = self . _df . columns . to_list ( ) <TAB> columns = [ ] <TAB> for library in libraries : <TAB> <TAB> version = self . _package_versions [ library ] <TAB> <TAB> library_description = self . _libraries_description . get ( library ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> library + = "" {} "" . format ( library_description ) <TAB> <TAB> columns . append ( <TAB> <TAB> <TAB> "" {library} <br><small> {version} </small> "" . format ( <TAB> <TAB> <TAB> <TAB> library = library , version = version <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> return [ "" "" ] + columns",if library_description :,if library_description :,True,100.0,74.43,,,
"def plugin_on_song_ended ( self , song , stopped ) : <TAB> if song is not None : <TAB> <TAB> poll = self . rating_box . poll_vote ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ups = int ( song . get ( "" ~#wins "" ) or 0 ) <TAB> <TAB> <TAB> downs = int ( song . get ( "" ~#losses "" ) or 0 ) <TAB> <TAB> <TAB> ups + = poll [ 0 ] <TAB> <TAB> <TAB> downs + = poll [ 1 ] <TAB> <TAB> <TAB> song [ "" ~#wins "" ] = ups <TAB> <TAB> <TAB> song [ "" ~#losses "" ] = downs <TAB> <TAB> <TAB> song [ "" ~#rating "" ] = ups / max ( ( ups + downs ) , 2 ) <TAB> <TAB> <TAB> # note: ^^^ Look into implementing w/ confidence intervals! <TAB> <TAB> <TAB> song[""~#score""] = ups - downs",if stopped :,if poll [ 0 ] >= 1 or poll [ 1 ] >= 1 :,False,93.57,70.13,,,
"def submit ( self , pig_script , params ) : <TAB> workflow = None <TAB> try : <TAB> <TAB> workflow = self . _create_workflow ( pig_script , params ) <TAB> <TAB> mapping = dict ( <TAB> <TAB> <TAB> [ ( param [ "" name "" ] , param [ "" value "" ] ) for param in workflow . get_parameters ( ) ] <TAB> <TAB> ) <TAB> <TAB> oozie_wf = _submit_workflow ( self . user , self . fs , self . jt , workflow , mapping ) <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> workflow . delete ( skip_trash = True ) <TAB> return oozie_wf",if workflow :,if workflow :,True,100.0,74.43,,,
"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB> <TAB> try : <TAB> <TAB> <TAB> schema . parse ( example . schema_string ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> if not example . valid : <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB> <TAB> correct , <TAB> <TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg )",if example . valid :,if example . valid :,True,100.0,74.6,,,
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" wf "" , "" punc "" ) : <TAB> <TAB> <TAB> itm = self . handle_word ( child ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sent . extend ( itm ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sent . append ( itm ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent )","if isinstance ( itm , list ) :","if self . _unit == ""word"" :",False,94.11,67.13,,,
"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB> <TAB> state = target_widget . cget ( "" state "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> target_widget . configure ( state = tk . NORMAL ) <TAB> <TAB> <TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB> <TAB> <TAB> target_widget . configure ( state = tk . DISABLED ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB> else : <TAB> <TAB> super ( TKText , self ) . _set_property ( target_widget , pname , value )",if state == tk . NORMAL :,if state == tk . DISABLED :,False,98.62,73.37,,,
"def get_vrf_tables ( self , vrf_rf = None ) : <TAB> vrf_tables = { } <TAB> for ( scope_id , table_id ) , table in self . _tables . items ( ) : <TAB> <TAB> if scope_id is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> vrf_tables [ ( scope_id , table_id ) ] = table <TAB> return vrf_tables",if vrf_rf is not None and table . vrf_rf != vrf_rf :,if vrf_rf is not None and table_id != vrf_rf :,False,96.11,71.95,,,
"def new_f ( self , * args , * * kwargs ) : <TAB> for obj in f ( self , * args , * * kwargs ) : <TAB> <TAB> if self . protected == False : <TAB> <TAB> <TAB> if "" user "" in obj and obj [ "" user "" ] [ "" protected "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield obj","if ""user"" in obj and obj [ ""user"" ] [ ""protected"" ] != self . user :","elif ""protected"" in obj and obj [ ""protected"" ] :",False,88.57,64.7,,,
"def draw ( self , context ) : <TAB> col = self . layout . column ( ) <TAB> col . operator ( "" node.sv_show_latest_commits "" ) <TAB> if context . scene . sv_new_version : <TAB> <TAB> col_alert = self . layout . column ( ) <TAB> <TAB> col_alert . alert = True <TAB> <TAB> col_alert . operator ( "" node.sverchok_update_addon "" , text = "" Upgrade Sverchok addon "" ) <TAB> else : <TAB> <TAB> col . operator ( "" node.sverchok_check_for_upgrades_wsha "" , text = "" Check for updates "" ) <TAB> with sv_preferences ( ) as prefs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> col . operator ( "" node.sv_run_pydoc "" )","if prefs . get ( ""run_pydoc"" ) :",if prefs . developer_mode :,False,95.4,68.85,,,
"def generate_tag_1_data ( ids ) : <TAB> if len ( ids ) != SAMPLE_NUM : <TAB> <TAB> raise ValueError ( "" len ids should equal to sample number "" ) <TAB> counter = 0 <TAB> for sample_i in range ( SAMPLE_NUM ) : <TAB> <TAB> one_data = [ ids [ sample_i ] ] <TAB> <TAB> valid_set = [ x for x in range ( TAG_INTERVAL [ 0 ] , TAG_INTERVAL [ 1 ] ) ] <TAB> <TAB> features = np . random . choice ( valid_set , FEATURE_NUM , replace = False ) <TAB> <TAB> one_data + = [ "" : "" . join ( [ x , "" 1.0 "" ] ) for x in features ] <TAB> <TAB> counter + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" generate data  {} "" . format ( counter ) ) <TAB> <TAB> yield one_data",if counter % 10000 == 0 :,if counter % 10000 == 0 :,True,100.0,74.59,,,
"def handle_api_languages ( self , http_context ) : <TAB> mgr = PluginManager . get ( aj . context ) <TAB> languages = set ( ) <TAB> for id in mgr : <TAB> <TAB> locale_dir = mgr . get_content_path ( id , "" locale "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for lang in os . listdir ( locale_dir ) : <TAB> <TAB> <TAB> <TAB> if lang != "" app.pot "" : <TAB> <TAB> <TAB> <TAB> <TAB> languages . add ( lang ) <TAB> return sorted ( list ( languages ) )",if os . path . isdir ( locale_dir ) :,if os . path . isdir ( locale_dir ) :,True,100.0,74.38,,,
"def update ( self , t ) : <TAB> # direction right - up <TAB> for i in range(self.grid.x): <TAB> <TAB> for j in range(self.grid.y): <TAB> <TAB> <TAB> distance = self.test_func(i, j, t) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.turn_off_tile(i, j) <TAB> <TAB> <TAB> elif distance < 1: <TAB> <TAB> <TAB> <TAB> self.transform_tile(i, j, distance) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.turn_on_tile(i, j)",if distance > 0 :,if distance == 0 :,False,98.08,72.36,,,
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB> <TAB> <TAB> if isinstance ( text , CodeViewText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )","elif isinstance ( text , ShellText ) :","elif isinstance ( text , ShellText ) :",True,100.0,74.46,,,
"def test_create_repository ( repo_name , expected_status , client ) : <TAB> with client_with_identity ( "" devtable "" , client ) as cl : <TAB> <TAB> body = { <TAB> <TAB> <TAB> "" namespace "" : "" devtable "" , <TAB> <TAB> <TAB> "" repository "" : repo_name , <TAB> <TAB> <TAB> "" visibility "" : "" public "" , <TAB> <TAB> <TAB> "" description "" : "" foo "" , <TAB> <TAB> } <TAB> <TAB> result = conduct_api_call ( <TAB> <TAB> <TAB> client , RepositoryList , "" post "" , None , body , expected_code = expected_status <TAB> <TAB> ) . json <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert result [ "" name "" ] == repo_name <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> model . repository . get_repository ( "" devtable "" , repo_name ) . name == repo_name <TAB> <TAB> <TAB> )","if result [ ""status"" ] == expected_status :",if expected_status == 201 :,False,96.14,70.17,,,
"def _apply_filter ( filter_item , filter_list ) : <TAB> for filter_method in filter_list : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> raise MessageException ( <TAB> <TAB> <TAB> <TAB> "" Toolbox filter exception from  ' {} ' :  {} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> filter_method . __name__ , unicodify ( e ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return True",if filter_method ( filter_item ) :,"if not filter_method ( context , filter_item ) :",False,96.62,71.13,,,
"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = fp . read ( bufsize ) <TAB> <TAB> <TAB> if not data : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = data . encode ( fp . encoding ) <TAB> <TAB> <TAB> m . update ( data ) <TAB> except IOError as msg : <TAB> <TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB> <TAB> return 1 <TAB> out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0",if fp . encoding :,"if isinstance ( data , str ) :",False,96.45,71.97,,,
"def get_block_loc_keys ( block ) : <TAB> """""" Extract loc_keys used by @block """""" <TAB> symbols = set ( ) <TAB> for instr in block . lines : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( instr . raw , list ) : <TAB> <TAB> <TAB> <TAB> for expr in instr . raw : <TAB> <TAB> <TAB> <TAB> <TAB> symbols . update ( get_expr_locs ( expr ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for arg in instr . args : <TAB> <TAB> <TAB> <TAB> symbols . update ( get_expr_locs ( arg ) ) <TAB> return symbols","if isinstance ( instr , ast . Symbol ) :","if isinstance ( instr , AsmRaw ) :",False,97.51,95.68,,,
"def get_operations ( cls , info , operations : List [ ProductAttributeAssignInput ] ) : <TAB> """""" Resolve all passed global ids into integer PKs of the Attribute type. """""" <TAB> product_attrs_pks = [ ] <TAB> variant_attrs_pks = [ ] <TAB> for operation in operations : <TAB> <TAB> pk = from_global_id_strict_type ( <TAB> <TAB> <TAB> operation . id , only_type = Attribute , field = "" operations "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> product_attrs_pks . append ( pk ) <TAB> <TAB> else : <TAB> <TAB> <TAB> variant_attrs_pks . append ( pk ) <TAB> return product_attrs_pks , variant_attrs_pks",if operation . is_product :,if operation . type == ProductAttributeType . PRODUCT :,False,96.12,94.51,,,
"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB> <TAB> if act [ "" type "" ] == "" SubProcess "" : <TAB> <TAB> <TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> manual_intervention_nodes . add ( act [ "" id "" ] )","elif act [ ""type"" ] == ""PipelinemanualInterventionNode"" :","elif act [ ""component"" ] [ ""code"" ] in MANUAL_INTERVENTION_COMP_CODES :",False,87.09,68.4,,,
"def prompt_authorization ( self , stacks : List [ Stack ] ) : <TAB> auth_required_per_resource = auth_per_resource ( stacks ) <TAB> for resource , authorization_required in auth_required_per_resource : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> auth_confirm = confirm ( <TAB> <TAB> <TAB> <TAB> f "" \t { self . start_bold } { resource }  may not have authorization defined, Is this okay? { self . end_bold } "" , <TAB> <TAB> <TAB> <TAB> default = False , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if not auth_confirm : <TAB> <TAB> <TAB> <TAB> raise GuidedDeployFailedError ( msg = "" Security Constraints Not Satisfied! "" )",if authorization_required :,if not authorization_required :,False,98.67,73.07,,,
"def get_cloud_credential ( self ) : <TAB> """""" Return the credential which is directly tied to the inventory source type. """""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB> <TAB> if self . source in CLOUD_PROVIDERS : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred.credential_type.kind != ""vault"": <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential","if cred . credential_type . kind == ""inventory"" :","if cred . kind == self . source . replace ( ""ec2"" , ""aws"" ) :",False,92.48,82.99,,,
"def validate_party_details ( self ) : <TAB> if self . party : <TAB> <TAB> if not frappe . db . exists ( self . party_type , self . party ) : <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . validate_account_type ( <TAB> <TAB> <TAB> <TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB> <TAB> <TAB> )",if self . party_account :,"if self . party_account and self . party_type in ( ""Customer"" , ""Supplier"" ) :",False,89.56,62.8,,,
"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB> <TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB> <TAB> for i , g in enumerate ( groups ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if i in direct_upstreams : <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [ ] <TAB> <TAB> <TAB> <TAB> <TAB> for _ , vs in g : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1 . extend ( vs ) <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g1 <TAB> <TAB> yield k , tuple ( t )","if isinstance ( g , ( list , tuple ) ) :",if g :,False,96.06,72.62,,,
"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales [ i ] <TAB> <TAB> if not math . isnan ( scale ) : <TAB> <TAB> <TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB> <TAB> <TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData",if i >= len ( scales ) :,"if i >= min ( len ( scales ) , len ( vidxs ) // 2 ) :",False,91.45,69.39,,,
"def _make_ext_obj ( self , obj ) : <TAB> ext = self . _get_ext_class ( obj . objname ) ( ) <TAB> for name , val in obj . body : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Error val should be a list, this is a python-opcua bug "" , <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> type ( val ) , <TAB> <TAB> <TAB> <TAB> val , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for attname , v in val : <TAB> <TAB> <TAB> <TAB> self . _set_attr ( ext , attname , v ) <TAB> return ext","if not isinstance ( val , list ) :","if not isinstance ( val , list ) :",True,100.0,74.49,,,
"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB> <TAB> if row [ 0 ] == linenum : <TAB> <TAB> <TAB> if row [ refnum + 1 ] is None : <TAB> <TAB> <TAB> <TAB> row [ refnum + 1 ] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",if i == 0 :,elif row [ 0 ] > linenum :,False,94.79,69.98,,,
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line","if line . endswith ( "";"" ) :","if "","" in line or "";"" in line :",False,94.46,95.06,,,
"def encodingChanged ( self , idx ) : <TAB> encoding = str ( self . mode_combo . currentText ( ) ) <TAB> validator = None <TAB> if encoding == "" hex "" : <TAB> <TAB> # only clear the box if there are non-hex chars <TAB> <TAB> # before setting the validator. <TAB> <TAB> txt = str(self.data_edit.text()) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.data_edit.setText("""") <TAB> <TAB> regex = QtCore.QRegExp(""^[0-9A-Fa-f]+$"") <TAB> <TAB> validator = QtGui.QRegExpValidator(regex) <TAB> self.data_edit.setValidator(validator) <TAB> self.renderMemory()","if not txt . startswith ( ""#"" ) :",if not all ( c in string . hexdigits for c in txt ) :,False,93.71,89.39,,,
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> if self . callback : <TAB> <TAB> <TAB> <TAB> self . callback ( )",if self . db_interface :,if redo :,False,97.26,73.09,,,
"def _transform_bin ( self , X : DataFrame ) : <TAB> if self . _bin_map : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> X = X . copy ( deep = True ) <TAB> <TAB> with pd . option_context ( "" mode.chained_assignment "" , None ) : <TAB> <TAB> <TAB> # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB> <TAB> <TAB> for column in self._bin_map: <TAB> <TAB> <TAB> <TAB> X[column] = binning.bin_column( <TAB> <TAB> <TAB> <TAB> <TAB> series=X[column], <TAB> <TAB> <TAB> <TAB> <TAB> mapping=self._bin_map[column], <TAB> <TAB> <TAB> <TAB> <TAB> dtype=self._astype_map[column], <TAB> <TAB> <TAB> <TAB> ) <TAB> return X",if self . _astype_map :,if not self . inplace :,False,97.14,71.96,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if '""' in text :","if ""'"" in text :",False,98.71,74.02,,,
"def read ( self ) : <TAB> """""" Reads the robots.txt URL and feeds it to the parser. """""" <TAB> try : <TAB> <TAB> f = urllib . request . urlopen ( self . url ) <TAB> except urllib . error . HTTPError as err : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . disallow_all = True <TAB> <TAB> elif err . code > = 400 and err . code < 500 : <TAB> <TAB> <TAB> self . allow_all = True <TAB> else : <TAB> <TAB> raw = f . read ( ) <TAB> <TAB> self . parse ( raw . decode ( "" utf-8 "" ) . splitlines ( ) )",if err . code == 403 and err . code == 404 :,"if err . code in ( 401 , 403 ) :",False,93.58,94.64,,,
"def post_create ( self , user , billing = None ) : <TAB> from weblate . trans . models import Change <TAB> if billing : <TAB> <TAB> billing . projects . add ( self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . access_control = Project . ACCESS_PRIVATE <TAB> <TAB> else : <TAB> <TAB> <TAB> self . access_control = Project . ACCESS_PUBLIC <TAB> <TAB> self . save ( ) <TAB> if not user . is_superuser : <TAB> <TAB> self . add_user ( user , "" @Administration "" ) <TAB> Change . objects . create ( <TAB> <TAB> action = Change . ACTION_CREATE_PROJECT , project = self , user = user , author = user <TAB> )",if self . is_private :,if billing . plan . change_access_control :,False,94.71,71.95,,,
"def visitConst ( self , node ) : <TAB> if self . documentable : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . documentable . append ( make_docstring ( node . value , node . lineno ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . documentable = None","if isinstance ( node . value , ast . Name ) :","if type ( node . value ) in ( StringType , UnicodeType ) :",False,88.37,65.84,,,
"def requires ( self ) : <TAB> requires = copy . deepcopy ( self . _requires ) <TAB> # Auto add dependencies when parameters reference the Ouptuts of <TAB> # another stack. <TAB> parameters = self.parameters <TAB> for value in parameters.values(): <TAB> <TAB> if isinstance(value, basestring) and ""::"" in value: <TAB> <TAB> <TAB> stack_name, _ = value.split(""::"") <TAB> <TAB> else: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> requires.add(stack_name) <TAB> return requires",if stack_name not in requires :,if stack_name not in requires :,True,100.0,74.24,,,
"def __load_protos ( ) : <TAB> g = globals ( ) <TAB> for k , v in g . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = k [ 4 : ] <TAB> <TAB> <TAB> modname = name . lower ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> mod = __import__ ( modname , g , level = 1 ) <TAB> <TAB> <TAB> <TAB> PPP . set_p ( v , getattr ( mod , name ) ) <TAB> <TAB> <TAB> except ( ImportError , AttributeError ) : <TAB> <TAB> <TAB> <TAB> continue","if k . startswith ( ""protos"" ) :","if k . startswith ( ""PPP_"" ) :",False,97.98,73.21,,,
"def init_weights ( self ) : <TAB> """""" Initialize model weights. """""" <TAB> for m in self . predict_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 )","elif isinstance ( m , nn . Linear ) :","elif isinstance ( m , nn . Linear ) :",True,100.0,74.27,,,
"def get_data ( self ) : <TAB> """""" get all data from sockets """""" <TAB> si = self . inputs <TAB> parameters = [ ] <TAB> for socket in si : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parameters . append ( socket . sv_get ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parameters . append ( socket . sv_get ( default = [ [ ] ] ) ) <TAB> return match_long_repeat ( parameters )",if socket . is_input :,if len ( socket . prop_name ) > 0 :,False,91.83,90.55,,,
"def test_parse_query_params_comparable_field ( self ) : <TAB> query_params = { "" filter[int_field][gt] "" : 42 , "" filter[int_field][lte] "" : 9000 } <TAB> fields = self . view . parse_query_params ( query_params ) <TAB> for key , field_name in fields . items ( ) : <TAB> <TAB> if field_name [ "" int_field "" ] [ "" op "" ] == "" gt "" : <TAB> <TAB> <TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 42 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 9000 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( )","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :","elif field_name [ ""int_field"" ] [ ""op"" ] == ""lte"" :",True,100.0,74.49,,,
"def _create_examples ( self , lines , set_type ) : <TAB> """""" Creates examples for the training and dev sets. """""" <TAB> examples = [ ] <TAB> for ( i , line ) in enumerate ( lines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> guid = "" %s - %s "" % ( set_type , i ) <TAB> <TAB> text = line [ 0 ] <TAB> <TAB> bbox = line [ 1 ] <TAB> <TAB> label = line [ 2 ] <TAB> <TAB> examples . append ( <TAB> <TAB> <TAB> DocExample ( guid = guid , text_a = text , text_b = None , bbox = bbox , label = label ) <TAB> <TAB> ) <TAB> return examples",if i == 0 :,if i == 0 :,True,100.0,99.5,,,
"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB> <TAB> attr_mod , attr_path = ( <TAB> <TAB> <TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB> <TAB> ) <TAB> <TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB> <TAB> op = import_module ( full_mod_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path.split("".""): <TAB> <TAB> <TAB> <TAB> op = getattr(op, part) <TAB> <TAB> return op <TAB> except (ImportError, AttributeError) as ex: <TAB> <TAB> if checked: <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex",if attr_path :,if attr_path :,True,100.0,74.54,,,
"def _load_ui_modules ( self , modules : Any ) - > None : <TAB> if isinstance ( modules , types . ModuleType ) : <TAB> <TAB> self . _load_ui_modules ( dict ( ( n , getattr ( modules , n ) ) for n in dir ( modules ) ) ) <TAB> elif isinstance ( modules , list ) : <TAB> <TAB> for m in modules : <TAB> <TAB> <TAB> self . _load_ui_modules ( m ) <TAB> else : <TAB> <TAB> assert isinstance ( modules , dict ) <TAB> <TAB> for name , cls in modules . items ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . ui_modules [ name ] = cls <TAB> <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> <TAB> pass","if isinstance ( cls , ui . ModuleType ) :","if issubclass ( cls , UIModule ) :",False,96.89,72.48,,,
"def _remove_obsolete_leafs ( input_dict ) : <TAB> if not isinstance ( input_dict , dict ) : <TAB> <TAB> return <TAB> if input_dict [ LEAF_MARKER ] : <TAB> <TAB> bottom_leafs = input_dict [ LEAF_MARKER ] <TAB> <TAB> for leaf in bottom_leafs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> input_dict [ LEAF_MARKER ] . remove ( leaf ) <TAB> for subtree in input_dict . keys ( ) : <TAB> <TAB> _remove_obsolete_leafs ( input_dict [ subtree ] )",if leaf in input_dict [ LEAF_MARKER ] :,if leaf in input_dict :,False,95.84,72.44,,,
"def decode ( self , value , force = False ) : <TAB> "" Return a unicode string from the bytes-like representation "" <TAB> if self . decode_responses or force : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value . tobytes ( ) <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> value = value . decode ( self . encoding , self . encoding_errors ) <TAB> return value","if isinstance ( value , six . text_type ) :","if isinstance ( value , memoryview ) :",False,94.26,72.11,,,
"def audit ( self , directive ) : <TAB> value = _get_value ( directive ) <TAB> if not value : <TAB> <TAB> return <TAB> server_side = directive . name . startswith ( "" proxy_ "" ) <TAB> for var in compile_script ( value ) : <TAB> <TAB> char = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> char = "" \\ n "" <TAB> <TAB> elif not server_side and var . can_contain ( "" \r "" ) : <TAB> <TAB> <TAB> char = "" \\ r "" <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> reason = ' At least variable  "" $ {var} ""  can contain  "" {char} "" ' . format ( <TAB> <TAB> <TAB> var = var . name , char = char <TAB> <TAB> ) <TAB> <TAB> self . add_issue ( directive = [ directive ] + var . providers , reason = reason )","if server_side and var . can_contain ( ""\n"" ) :","if var . can_contain ( ""\n"" ) :",False,97.8,73.81,,,
"def checkFilename ( filename ) : # useful in case of drag and drop <TAB> while True: <TAB> <TAB> if filename[0] == ""'"": <TAB> <TAB> <TAB> filename = filename[1:] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = filename[:-1] <TAB> <TAB> if os.path.exists(filename): <TAB> <TAB> <TAB> return filename <TAB> <TAB> filename = input( <TAB> <TAB> <TAB> ""[!] Cannot find '%s'.\n[*] Enter a valid name of the file containing the paths to test -> "" <TAB> <TAB> <TAB> % filename <TAB> <TAB> )","if filename [ - 1 ] == ""'"" :","if filename [ len ( filename ) - 1 ] == ""'"" :",False,96.99,71.42,,,
"def findfiles ( self , dir , base , rec ) : <TAB> try : <TAB> <TAB> names = os . listdir ( dir or os . curdir ) <TAB> except os . error as msg : <TAB> <TAB> print ( msg ) <TAB> <TAB> return [ ] <TAB> list = [ ] <TAB> subdirs = [ ] <TAB> for name in names : <TAB> <TAB> fn = os . path . join ( dir , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subdirs . append ( fn ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if fnmatch . fnmatch ( name , base ) : <TAB> <TAB> <TAB> <TAB> list . append ( fn ) <TAB> if rec : <TAB> <TAB> for subdir in subdirs : <TAB> <TAB> <TAB> list . extend ( self . findfiles ( subdir , base , rec ) ) <TAB> return list",if os . path . isdir ( fn ) :,if os . path . isdir ( fn ) :,True,100.0,74.61,,,
"def loop ( handler , obj ) : <TAB> handler . response . write ( "" <table> "" ) <TAB> for k , v in obj . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> style = "" color: red "" if not v else "" "" <TAB> <TAB> <TAB> handler . response . write ( <TAB> <TAB> <TAB> <TAB> ' <tr style= "" {} "" ><td> {} :</td><td> {} </td></tr> ' . format ( style , k , v ) <TAB> <TAB> <TAB> ) <TAB> handler . response . write ( "" </table> "" )","if isinstance ( v , dict ) :","if not k in ( ""data"" , ""gae_user"" , ""credentials"" , ""content"" , ""config"" ) :",False,86.1,65.34,,,
"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB> <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> <TAB> executable = winpymap . get ( name , None ) <TAB> <TAB> <TAB> if executable : <TAB> <TAB> <TAB> <TAB> executable = py . path . local ( executable ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable",if os . path . exists ( executable ) :,if executable . check ( ) :,False,95.3,71.57,,,
"def __init__ ( self , socketpath = None ) : <TAB> if socketpath is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> socketpath = "" /var/run/usbmuxd "" <TAB> <TAB> else : <TAB> <TAB> <TAB> socketpath = "" /var/run/usbmuxd "" <TAB> self . socketpath = socketpath <TAB> self . listener = MuxConnection ( socketpath , BinaryProtocol ) <TAB> try : <TAB> <TAB> self . listener . listen ( ) <TAB> <TAB> self . version = 0 <TAB> <TAB> self . protoclass = BinaryProtocol <TAB> except MuxVersionError : <TAB> <TAB> self . listener = MuxConnection ( socketpath , PlistProtocol ) <TAB> <TAB> self . listener . listen ( ) <TAB> <TAB> self . protoclass = PlistProtocol <TAB> <TAB> self . version = 1 <TAB> self . devices = self . listener . devices","if sys . platform == ""darwin"" :","if sys . platform == ""darwin"" :",True,100.0,74.54,,,
"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> elif isinstance ( results [ i ] , list ) : <TAB> <TAB> <TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0","if isinstance ( results [ i ] , dict ) :","if isinstance ( results [ i ] , dict ) :",True,100.0,74.56,,,
"def getRootId ( self , id ) : <TAB> with self . connect ( ) as cu : <TAB> <TAB> while True : <TAB> <TAB> <TAB> stmt = "" select parent_path_id from hierarchy where path_id = ? "" <TAB> <TAB> <TAB> cu . execute ( stmt , ( id , ) ) <TAB> <TAB> <TAB> parent_id = cu . fetchone ( ) [ 0 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return id <TAB> <TAB> <TAB> id = parent_id",if parent_id == id :,if parent_id is None or parent_id == id :,False,95.86,71.15,,,
"def add ( self , path ) : <TAB> with self . get_lock ( path ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . entries [ path ] = { } <TAB> <TAB> <TAB> self . entries [ path ] [ "" lock "" ] = self . new_locks [ path ] <TAB> <TAB> <TAB> del self . new_locks [ path ] <TAB> <TAB> <TAB> self . lru . append ( path )",if path not in self . entries :,if not path in self . entries :,False,97.37,72.33,,,
"def _get_coordinates_for_dataset_key ( self , dsid ) : <TAB> """""" Get the coordinate dataset keys for *dsid*. """""" <TAB> ds_info = self . ids [ dsid ] <TAB> cids = [ ] <TAB> for cinfo in ds_info . get ( "" coordinates "" , [ ] ) : <TAB> <TAB> if not isinstance ( cinfo , dict ) : <TAB> <TAB> <TAB> cinfo = { "" name "" : cinfo } <TAB> <TAB> cinfo [ "" resolution "" ] = ds_info [ "" resolution "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cinfo [ "" polarization "" ] = ds_info [ "" polarization "" ] <TAB> <TAB> cid = DatasetID ( * * cinfo ) <TAB> <TAB> cids . append ( self . get_dataset_key ( cid ) ) <TAB> return cids","if ""polarization"" in ds_info :","if ""polarization"" in ds_info :",True,100.0,99.53,,,
"def build_from_gdobj ( cls , gdobj , steal = False ) : <TAB> # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB> # overloading it __class__ to turn it into an instance of the right class <TAB> ret = BuiltinInitPlaceholder() <TAB> if steal: <TAB> <TAB> assert ffi.typeof(gdobj).kind == ""pointer"" <TAB> <TAB> ret._gd_ptr = gdobj <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret._gd_ptr = cls._copy_gdobj(gdobj) <TAB> <TAB> else: <TAB> <TAB> <TAB> ret._gd_ptr = cls._copy_gdobj(ffi.addressof(gdobj)) <TAB> ret.__class__ = cls <TAB> return ret","if gdobj . kind == ""pointer"" :","if ffi . typeof ( gdobj ) . kind == ""pointer"" :",False,96.52,70.51,,,
"def _listen_output ( self ) : <TAB> "" NB! works in background thread "" <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> chars = self . _proc . read ( 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> as_bytes = chars . encode ( self . encoding ) <TAB> <TAB> <TAB> <TAB> self . _make_output_available ( as_bytes ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _error = "" EOF "" <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as e : <TAB> <TAB> self . _error = str ( e )",if chars :,if len ( chars ) > 0 :,False,96.07,71.08,,,
"def result ( <TAB> metrics : Dict [ metric_types . MetricKey , Any ] ) - > Dict [ metric_types . AttributionsKey , Dict [ Text , Union [ float , np . ndarray ] ] ] : <TAB> """""" Returns mean attributions. """""" <TAB> total_attributions = metrics [ total_attributions_key ] <TAB> weighted_count = metrics [ weighted_example_count_key ] <TAB> attributions = { } <TAB> for k , v in total_attributions . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attributions [ k ] = float ( "" nan "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> attributions [ k ] = v / weighted_count <TAB> return { key : attributions }",if v is None :,"if np . isclose ( weighted_count , 0.0 ) :",False,93.72,92.45,,,
"def write_if_changed ( path , data ) : <TAB> if isinstance ( data , str ) : <TAB> <TAB> data = data . encode ( ) <TAB> changed = False <TAB> with open ( os . open ( path , os . O_CREAT | os . O_RDWR ) , "" wb+ "" ) as f : <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> current = f . read ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> <TAB> f . write ( data ) <TAB> <TAB> <TAB> f . truncate ( ) <TAB> <TAB> os . fsync ( f ) <TAB> return changed",if current != data :,if current != data :,True,100.0,74.48,,,
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> if scan_argv ( self . argv , option ) is not None : <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option",if other_option != option :,if option != other_option :,False,98.17,72.77,,,
"def _infer_return_type ( * args ) : <TAB> """""" Look at the type of all args and divine their implied return type. """""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if arg is None :,if arg is None :,True,100.0,99.61,,,
"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> tasks = self . tasks . tasks # is a group <TAB> <TAB> except AttributeError: <TAB> <TAB> <TAB> tasks = self.tasks <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> app = tasks[0]._app <TAB> <TAB> if app is None and body is not None: <TAB> <TAB> <TAB> app = body._app <TAB> return app if app is not None else current_app",if tasks :,if len ( tasks ) :,False,96.59,71.56,,,
"def add_field ( self , field ) : <TAB> self . remove_field ( field . name ) <TAB> self . fields [ field . name ] = field <TAB> self . columns [ field . db_column ] = field <TAB> self . _sorted_field_list . insert ( field ) <TAB> self . _update_field_lists ( ) <TAB> if field . default is not None : <TAB> <TAB> self . defaults [ field ] = field . default <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _default_callables [ field ] = field . default <TAB> <TAB> <TAB> self . _default_callable_list . append ( ( field . name , field . default ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _default_dict [ field ] = field . default <TAB> <TAB> <TAB> self . _default_by_name [ field . name ] = field . default",if field . callable :,if callable ( field . default ) :,False,97.13,72.39,,,
"def _get_families ( self ) : <TAB> families = [ ] <TAB> for name , ext in self . _get_family_dirs ( ) : <TAB> <TAB> <IF-STMT> # is a directory <TAB> <TAB> <TAB> family = self.get_resource( <TAB> <TAB> <TAB> <TAB> FileSystemPackageFamilyResource.key, location=self.location, name=name <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> family = self.get_resource( <TAB> <TAB> <TAB> <TAB> FileSystemCombinedPackageFamilyResource.key, <TAB> <TAB> <TAB> <TAB> location=self.location, <TAB> <TAB> <TAB> <TAB> name=name, <TAB> <TAB> <TAB> <TAB> ext=ext, <TAB> <TAB> <TAB> ) <TAB> <TAB> families.append(family) <TAB> return families","if name . endswith ( ""/"" ) :",if ext is None :,False,95.75,62.33,,,
"def test ( model , data_loader , device = None ) : <TAB> device = device or torch . device ( "" cpu "" ) <TAB> model . eval ( ) <TAB> correct = 0 <TAB> total = 0 <TAB> with torch . no_grad ( ) : <TAB> <TAB> for batch_idx , ( data , target ) in enumerate ( data_loader ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data , target = data . to ( device ) , target . to ( device ) <TAB> <TAB> <TAB> outputs = model ( data ) <TAB> <TAB> <TAB> _ , predicted = torch . max ( outputs . data , 1 ) <TAB> <TAB> <TAB> total + = target . size ( 0 ) <TAB> <TAB> <TAB> correct + = ( predicted == target ) . sum ( ) . item ( ) <TAB> return correct / total",if batch_idx >= len ( data . data ) :,if batch_idx * len ( data ) > TEST_SIZE :,False,96.47,72.61,,,
"def __animate_progress ( self ) : <TAB> """""" Change the status message, mostly used to animate progress. """""" <TAB> while True : <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> with self . __progress_lock : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> elif self . __show_animation : <TAB> <TAB> <TAB> <TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . __progress_status . show_as_ready ( ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time.sleep(sleep_time)","if self . __current_operation_name == ""progress"" :",if not self . __progress_status :,False,95.55,76.05,,,
"def _parse_subtitles ( self , video_data , url_key ) : <TAB> subtitles = { } <TAB> for translation in video_data . get ( "" translations "" , [ ] ) : <TAB> <TAB> vtt_path = translation . get ( url_key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> lang = translation . get ( "" language_w3c "" ) or ISO639Utils . long2short ( <TAB> <TAB> <TAB> translation [ "" language_medium "" ] <TAB> <TAB> ) <TAB> <TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" ext "" : "" vtt "" , <TAB> <TAB> <TAB> <TAB> "" url "" : vtt_path , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return subtitles",if not vtt_path :,if not vtt_path :,True,100.0,74.51,,,
"def postprocess_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" and msg [ "" value "" ] is not None : <TAB> <TAB> fn , value = msg [ "" fn "" ] , msg [ "" value "" ] <TAB> <TAB> value_batch_ndims = jnp . ndim ( value ) - fn . event_dim <TAB> <TAB> fn_batch_ndim = len ( fn . batch_shape ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> prepend_shapes = ( 1 , ) * ( value_batch_ndims - fn_batch_ndim ) <TAB> <TAB> <TAB> msg [ "" fn "" ] = tree_map ( <TAB> <TAB> <TAB> <TAB> lambda x : jnp . reshape ( x , prepend_shapes + jnp . shape ( x ) ) , fn <TAB> <TAB> <TAB> )",if value_batch_ndims > fn_batch_ndim :,if fn_batch_ndim < value_batch_ndims :,False,97.43,73.05,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_filename ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.14,,,
"def createError ( self , line , pos , description ) : <TAB> global ENABLE_PYIMPORT <TAB> msg = "" Line  "" + unicode ( line ) + "" :  "" + unicode ( description ) <TAB> if ENABLE_JS2PY_ERRORS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> import js2py . base <TAB> <TAB> <TAB> return js2py . base . MakeError ( "" SyntaxError "" , msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ENABLE_JS2PY_ERRORS ( msg ) <TAB> else : <TAB> <TAB> return JsSyntaxError ( msg )",if self . _use_python2py :,"if isinstance ( ENABLE_JS2PY_ERRORS , bool ) :",False,92.36,70.45,,,
"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB> <TAB> extracted = extractor . extract ( <TAB> <TAB> <TAB> page , start_index , end_index , self . template . ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter ( extracted ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if isinstance ( item , ( ItemProcessor , dict ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> item [ u "" _template "" ] = self . template . id <TAB> <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items",if self . template :,if item :,False,97.61,72.99,,,
"def create_volume ( self , volume ) : <TAB> """""" Create a volume. """""" <TAB> try : <TAB> <TAB> cmd = [ "" volume "" , "" create "" , volume [ "" name "" ] , "" %s G "" % ( volume [ "" size "" ] ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cmd . append ( "" pool "" ) <TAB> <TAB> <TAB> cmd . append ( self . configuration . eqlx_pool ) <TAB> <TAB> if self . configuration . san_thin_provision : <TAB> <TAB> <TAB> cmd . append ( "" thin-provision "" ) <TAB> <TAB> out = self . _eql_execute ( * cmd ) <TAB> <TAB> self . add_multihost_access ( volume ) <TAB> <TAB> return self . _get_volume_data ( out ) <TAB> except Exception : <TAB> <TAB> with excutils . save_and_reraise_exception ( ) : <TAB> <TAB> <TAB> LOG . error ( ' Failed to create volume  "" %s "" . ' , volume [ "" name "" ] )",if self . configuration . eqlx_pool :,"if self . configuration . eqlx_pool != ""default"" :",False,97.55,96.23,,,
"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB> <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB> <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB> <TAB> <TAB> code=self.code, site__isnull=True <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> placeholders = placeholders.exclude(pk=self.pk) <TAB> <TAB> if placeholders.exists(): <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""A static placeholder with the same site and code already exists"") <TAB> <TAB> <TAB> )",if self . pk :,if self . pk :,True,100.0,74.32,,,
"def spawnMenu ( self , event ) : <TAB> clickedPos = self . getRowByAbs ( event . Position ) <TAB> self . ensureSelection ( clickedPos ) <TAB> selection = self . getSelectedBoosters ( ) <TAB> mainBooster = None <TAB> if clickedPos != - 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> booster = self . boosters [ clickedPos ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> mainBooster = booster <TAB> itemContext = None if mainBooster is None else _t ( "" Booster "" ) <TAB> menu = ContextMenu . getMenu ( <TAB> <TAB> self , <TAB> <TAB> mainBooster , <TAB> <TAB> selection , <TAB> <TAB> ( "" boosterItem "" , itemContext ) , <TAB> <TAB> ( "" boosterItemMisc "" , itemContext ) , <TAB> ) <TAB> if menu : <TAB> <TAB> self . PopupMenu ( menu )",if booster is not None :,if booster in self . original :,False,97.69,72.79,,,
"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> app.register_error_handler(ex, error_http) <TAB> <TAB> elif ex == 500: <TAB> <TAB> <TAB> app.register_error_handler(ex, internal_error) <TAB> if services.ldap: <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app.errorhandler(services.ldap.LDAPException) <TAB> <TAB> def handle_exception(e): <TAB> <TAB> <TAB> log.debug(""LDAP server not accessible while trying to login to opds feed"") <TAB> <TAB> <TAB> return error_http(FailedDependency())",if ex == 400 :,if ex < 500 :,False,97.7,72.2,,,
"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif "" M "" in fmt : <TAB> <TAB> <TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif "" i "" in fmt : <TAB> <TAB> <TAB> t = int <TAB> <TAB> elif "" f "" in fmt : <TAB> <TAB> <TAB> t = float <TAB> <TAB> else : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self . addColumn ( ColumnItem ( name , i , type = t ) )","if ""D"" in fmt :",if shape :,False,97.03,67.69,,,
"def Proc2 ( IntParIO ) : <TAB> IntLoc = IntParIO + 10 <TAB> while True : <TAB> <TAB> if Char1Glob == "" A "" : <TAB> <TAB> <TAB> IntLoc = IntLoc - 1 <TAB> <TAB> <TAB> IntParIO = IntLoc - IntGlob <TAB> <TAB> <TAB> EnumLoc = Ident1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return IntParIO",if EnumLoc == Ident1 :,if EnumLoc == Ident1 :,True,100.0,74.0,,,
"def opengroup ( self , name = None ) : <TAB> gid = self . groups <TAB> self . groupwidths . append ( None ) <TAB> if self . groups > MAXGROUPS : <TAB> <TAB> raise error ( "" too many groups "" ) <TAB> if name is not None : <TAB> <TAB> ogid = self . groupdict . get ( name , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise error ( <TAB> <TAB> <TAB> <TAB> "" redefinition of group name  %r  as group  %d ;  "" <TAB> <TAB> <TAB> <TAB> "" was group  %d "" % ( name , gid , ogid ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . groupdict [ name ] = gid <TAB> return gid",if ogid is not None :,if ogid is not None :,True,100.0,74.53,,,
"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB> <TAB> if name in self : <TAB> <TAB> <TAB> old_val = self [ name ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Computed attributed  ' {} '  already exists  "" <TAB> <TAB> <TAB> <TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self [ name ] = val <TAB> else : <TAB> <TAB> super ( ) . __setattr__ ( name , val )",if old_val == val :,if old_val == val :,True,100.0,74.49,,,
"def get_all_function_symbols ( self , module = "" kernel "" ) : <TAB> """""" Gets all the function tuples for the given module """""" <TAB> ret = [ ] <TAB> symtable = self . type_map <TAB> if module in symtable : <TAB> <TAB> mod = symtable [ module ] <TAB> <TAB> for ( addr , ( name , _sym_types ) ) in mod . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> addr = addr + self . shift_address <TAB> <TAB> <TAB> ret . append ( [ name , addr ] ) <TAB> else : <TAB> <TAB> debug . info ( "" All symbols requested for non-existent module  %s "" % module ) <TAB> return ret","if name == ""kernel"" :",if self . shift_address and addr :,False,95.49,92.97,,,
"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code . co_name == "" trace_types "" <TAB> <TAB> or self . should_trace <TAB> <TAB> and not self . should_trace ( code ) <TAB> ) : <TAB> <TAB> return self <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . handle_call ( frame ) <TAB> <TAB> elif event == EVENT_RETURN : <TAB> <TAB> <TAB> self . handle_return ( frame , arg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self",if event == EVENT_CALL :,if event == EVENT_CALL :,True,100.0,74.58,,,
"def test_update_topic ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> topic = "" update topic "" <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> await self . chat_thread_client . update_topic ( topic = topic ) <TAB> <TAB> # delete chat threads <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self.chat_client.delete_chat_thread(self.thread_id)",if self . thread_id :,if not self . is_playback ( ) :,False,94.01,69.32,,,
"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid <TAB> :  "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB> <TAB> if j != - 1 : <TAB> <TAB> <TAB> x_str + = "" "" * len ( label ) <TAB> <TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB> <TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str",if i != j :,if i == x [ 0 ] and j == x [ 1 ] :,False,94.19,70.53,,,
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" QA-ZRE "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data.remove_dir(dpath) <TAB> <TAB> build_data.make_dir(dpath) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES: <TAB> <TAB> <TAB> downloadable_file.download_file(dpath) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data.mark_done(dpath, version_string=version)",if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,True,100.0,74.46,,,
"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB> <TAB> repo = _get_repo ( ) <TAB> <TAB> _confirm_dangerous ( ) <TAB> <TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo . remotes . get ( origin ) <TAB> <TAB> if url : <TAB> <TAB> <TAB> repo . pull ( origin_uri = url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB> <TAB> print ( command_help [ "" git pull "" ] )",if not origin :,if url in repo . remotes :,False,96.74,71.93,,,
"def FindAndDelete ( script , sig ) : <TAB> """""" Consensus critical, see FindAndDelete() in Satoshi codebase """""" <TAB> r = b "" "" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r + = script [ last_sop_idx : sop_idx ] <TAB> <TAB> last_sop_idx = sop_idx <TAB> <TAB> if script [ sop_idx : sop_idx + len ( sig ) ] == sig : <TAB> <TAB> <TAB> skip = True <TAB> <TAB> else : <TAB> <TAB> <TAB> skip = False <TAB> <IF-STMT> <TAB> <TAB> r + = script [ last_sop_idx : ] <TAB> return CScript ( r )",if not skip :,if not skip :,True,100.0,99.52,,,
"def get_ip_info ( ipaddress ) : <TAB> """""" Returns device information by IP address """""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if ip . venture is not None : <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> if ip . device is not None : <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . venture is not None :,if ip . device . venture is not None :,False,98.66,90.82,,,
"def restore ( self , state ) : <TAB> """""" Restore the state of a mesh previously saved using save() """""" <TAB> import pickle <TAB> state = pickle . loads ( state ) <TAB> for k in state : <TAB> <TAB> if isinstance ( state [ k ] , list ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> state [ k ] = [ [ v . x ( ) , v . y ( ) , v . z ( ) ] for v in state [ k ] ] <TAB> <TAB> <TAB> state [ k ] = np . array ( state [ k ] ) <TAB> <TAB> setattr ( self , k , state [ k ] )","if k not in [ ""x"" , ""y"" , ""z"" ] :","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) :",False,90.84,89.51,,,
"def get_extra_lines ( tup ) : <TAB> ext_name , pyopencl_ver = tup <TAB> if ext_name is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # capital letters -> CL version, not extension <TAB> <TAB> <TAB> yield """" <TAB> <TAB> <TAB> yield "" <TAB> Available with OpenCL %s."" % (ext_name[3:]) <TAB> <TAB> <TAB> yield """" <TAB> <TAB> else: <TAB> <TAB> <TAB> yield """" <TAB> <TAB> <TAB> yield "" <TAB> Available with the ``%s`` extension."" % ext_name <TAB> <TAB> <TAB> yield """" <TAB> if pyopencl_ver is not None: <TAB> <TAB> yield """" <TAB> <TAB> yield "" <TAB> .. versionadded:: %s"" % pyopencl_ver <TAB> <TAB> yield """"","if ext_name . startswith ( ""OpenCL"" ) :","if ext_name . startswith ( ""CL_"" ) :",False,98.53,73.38,,,
"def _gen_remote_uri ( <TAB> fileobj : IO [ bytes ] , <TAB> remote_uri : Optional [ ParseResult ] , <TAB> remote_path_prefix : Optional [ str ] , <TAB> remote_path_suffix : Optional [ str ] , <TAB> sha256sum : Optional [ str ] , ) - > ParseResult : <TAB> if remote_uri is None : <TAB> <TAB> assert remote_path_prefix is not None and remote_path_suffix is not None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sha256sum = _hash_fileobj ( fileobj ) <TAB> <TAB> return urlparse ( <TAB> <TAB> <TAB> os . path . join ( remote_path_prefix , f "" { sha256sum } { remote_path_suffix } "" ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return remote_uri",if sha256sum is None :,if sha256sum is None :,True,100.0,74.5,,,
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( )",if self . path . k8s :,if not cmd . stdout . strip ( ) :,False,96.39,71.98,,,
"def get_range ( self ) : <TAB> present = self . xml . find ( "" { %s }range "" % self . namespace ) <TAB> if present is not None : <TAB> <TAB> attributes = present . attrib <TAB> <TAB> return_value = dict ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return_value [ "" minimum "" ] = attributes [ "" min "" ] <TAB> <TAB> if "" max "" in attributes : <TAB> <TAB> <TAB> return_value [ "" maximum "" ] = attributes [ "" max "" ] <TAB> <TAB> return return_value <TAB> return False","if ""min"" in attributes :","if ""min"" in attributes :",True,100.0,74.39,,,
"def _configuredOn ( self , workerid , builderid = None , masterid = None ) : <TAB> cfg = [ ] <TAB> for cs in itervalues ( self . configured ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> bid , mid = self . db . builders . builder_masters [ cs [ "" buildermasterid "" ] ] <TAB> <TAB> if builderid is not None and bid != builderid : <TAB> <TAB> <TAB> continue <TAB> <TAB> if masterid is not None and mid != masterid : <TAB> <TAB> <TAB> continue <TAB> <TAB> cfg . append ( { "" builderid "" : bid , "" masterid "" : mid } ) <TAB> return cfg","if cs [ ""workerid"" ] != workerid :","if cs [ ""workerid"" ] != workerid :",True,100.0,74.52,,,
"def __exit__ ( self , type , value , traceback ) : <TAB> try : <TAB> <TAB> if type is not None : <TAB> <TAB> <TAB> return self . exception_handler ( type , value , traceback ) <TAB> finally : <TAB> <TAB> final_contexts = _state . contexts <TAB> <TAB> _state . contexts = self . old_contexts <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise StackContextInconsistentError ( <TAB> <TAB> <TAB> <TAB> "" stack_context inconsistency (may be caused by yield  "" <TAB> <TAB> <TAB> <TAB> ' within a  "" with StackContext ""  block) ' <TAB> <TAB> <TAB> ) <TAB> <TAB> # Break up a reference to itself to allow for faster GC on CPython. <TAB> <TAB> self.new_contexts = None",if final_contexts != self . old_contexts :,if final_contexts is not self . new_contexts :,False,97.23,71.93,,,
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self._keys[hash_] == key: <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB> if initial_hash == hash_: <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",if hash_ not in self . _keys :,if self . _keys [ hash_ ] is self . _empty :,False,95.32,70.16,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.14,,,
"def data_generator ( ) : <TAB> i = 0 <TAB> max_batch_index = len ( X_train ) / / batch_size <TAB> tot = 0 <TAB> while 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> np . ones ( [ batch_size , input_dim ] ) * np . nan , <TAB> <TAB> <TAB> <TAB> np . ones ( [ batch_size , num_classes ] ) * np . nan , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> X_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB> <TAB> <TAB> <TAB> y_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> i + = 1 <TAB> <TAB> tot + = 1 <TAB> <TAB> i = i % max_batch_index",if tot < max_batch_index :,if tot > 3 * len ( X_train ) :,False,96.26,71.88,,,
"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> width = self . statwidth ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB> <TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> width = self . colwidth ( ) <TAB> <TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if op . color : <TAB> <TAB> <TAB> <TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" space "" ] <TAB> return ret",if i > 0 :,if i + 1 != len ( self . vars ) :,False,95.67,72.08,,,
"def get_container_from_dport ( dport , docker_client ) : <TAB> for container in docker_client . containers ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> ports = container [ "" Ports "" ] <TAB> <TAB> <TAB> for port in ports : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if port [ "" PublicPort "" ] == int ( dport ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return container <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> print ( ports ) <TAB> <TAB> <TAB> pass","if port [ ""PublicPort"" ] == int ( dport ) :","if ""PublicPort"" in port :",False,93.24,70.52,,,
"def _get_parents_data ( self , data ) : <TAB> parents = 0 <TAB> if data [ COLUMN_PARENT ] : <TAB> <TAB> family = self . db . get_family_from_handle ( data [ COLUMN_PARENT ] [ 0 ] ) <TAB> <TAB> if family . get_father_handle ( ) : <TAB> <TAB> <TAB> parents + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parents + = 1 <TAB> return parents",if family . get_father_handle ( ) :,if family . get_mother_handle ( ) :,False,97.96,72.37,,,
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> if filename in cache : <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> if old_mtime == mtime : <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result # at the end <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",if last :,if len ( cache ) > max_size :,False,95.02,70.78,,,
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> if op . stage == OperandStage . map : <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . combine : <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else : # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . agg :,elif op . stage == OperandStage . agg :,True,100.0,74.46,,,
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> if op . stage == OperandStage . map : <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . combine : <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else : # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . agg :,if script [ sop_idx : sop_idx + len ( sig ) ] == sig :,False,91.36,68.28,,,
"def extractall ( zip : typing . Any , path : str ) - > NoneType : <TAB> for name in zip . namelist ( ) : <TAB> <TAB> member = zip . getinfo ( name ) <TAB> <TAB> extracted_path = zip . _extract_member ( member , path , None ) <TAB> <TAB> attr = member . external_attr >> 16 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . chmod ( extracted_path , attr )",if attr & 0x80 :,if attr != 0 :,False,95.96,71.94,,,
"def find_all_gyptest_files ( directory ) : <TAB> result = [ ] <TAB> for root , dirs , files in os . walk ( directory ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dirs . remove ( "" .svn "" ) <TAB> <TAB> result . extend ( [ os . path . join ( root , f ) for f in files if is_test_name ( f ) ] ) <TAB> result . sort ( ) <TAB> return result","if "".svn"" in root :","if "".svn"" in dirs :",False,97.82,72.7,,,
"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr(storefile, ""read""): <TAB> <TAB> storefile = open(storefile, ""rb"") <TAB> # Adjust store to have translations <TAB> store = cls.convertfile(storefile, template_store) <TAB> for unit in store.units: <TAB> <TAB> if unit.isheader(): <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unit.target = unit.source <TAB> <TAB> <TAB> unit.rich_target = unit.rich_source <TAB> return store",if unit . is_html ( ) :,if cls . needs_target_sync :,False,95.58,71.38,,,
"def postOptions ( self ) : <TAB> _BasicOptions . postOptions ( self ) <TAB> if self [ "" jobs "" ] : <TAB> <TAB> conflicts = [ "" debug "" , "" profile "" , "" debug-stacktraces "" , "" exitfirst "" ] <TAB> <TAB> for option in conflicts : <TAB> <TAB> <TAB> if self [ option ] : <TAB> <TAB> <TAB> <TAB> raise usage . UsageError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" You can ' t specify -- %s  when using --jobs "" % option <TAB> <TAB> <TAB> <TAB> ) <TAB> if self [ "" nopm "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise usage . UsageError ( "" You must specify --debug when using  "" "" --nopm  "" ) <TAB> <TAB> failure . DO_POST_MORTEM = False","if self [ ""debug"" ] :","if not self [ ""debug"" ] :",False,98.77,73.49,,,
"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB> <TAB> if not ( i < len ( extra . tokens ) ) : <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra . tokens [ i ] <TAB> <TAB> token = jsdict ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" type "" : entry . type , <TAB> <TAB> <TAB> <TAB> "" value "" : entry . value , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra . range : <TAB> <TAB> <TAB> token . range = entry . range <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> token . loc = entry . loc <TAB> <TAB> tokens . append ( token ) <TAB> <TAB> i + = 1 <TAB> extra . tokens = tokens",if extra . loc :,if extra . loc :,True,100.0,74.59,,,
"def on_rebalance_end ( self ) - > None : <TAB> """""" Call when rebalancing is done. """""" <TAB> self . rebalancing = False <TAB> if self . _rebalancing_span : <TAB> <TAB> self . _rebalancing_span . finish ( ) <TAB> self . _rebalancing_span = None <TAB> sensor_state = self . _rebalancing_sensor_state <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . warning ( <TAB> <TAB> <TAB> <TAB> "" Missing sensor state for rebalance # %s "" , self . rebalancing_count <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . sensors . on_rebalance_end ( self , sensor_state ) <TAB> finally : <TAB> <TAB> self . _rebalancing_sensor_state = None",if sensor_state is None :,if not sensor_state :,False,97.64,68.71,,,
"def decorator ( request , * args , * * kwargs ) : <TAB> if CALENDAR_VIEW_PERM : <TAB> <TAB> user = request . user <TAB> <TAB> if not user : <TAB> <TAB> <TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB> <TAB> occurrence , event , calendar = get_objects ( request , * * kwargs ) <TAB> <TAB> if calendar : <TAB> <TAB> <TAB> allowed = CHECK_CALENDAR_PERM_FUNC ( calendar , user ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB> <TAB> <TAB> # all checks passed <TAB> <TAB> <TAB> return function(request, *args, **kwargs) <TAB> <TAB> return HttpResponseNotFound(""<h1>Page not found</h1>"") <TAB> return function(request, *args, **kwargs)",if not allowed :,if not allowed :,True,100.0,74.47,,,
"def reduce_arguments ( self , args ) : <TAB> assert isinstance ( args , nodes . Arguments ) <TAB> if args . incorrect_order ( ) : <TAB> <TAB> raise InvalidArguments ( <TAB> <TAB> <TAB> "" All keyword arguments must be after positional arguments. "" <TAB> <TAB> ) <TAB> reduced_pos = [ self . reduce_single ( arg ) for arg in args . arguments ] <TAB> reduced_kw = { } <TAB> for key in args . kwargs . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidArguments ( "" Keyword argument name is not a string. "" ) <TAB> <TAB> a = args . kwargs [ key ] <TAB> <TAB> reduced_kw [ key ] = self . reduce_single ( a ) <TAB> return ( reduced_pos , reduced_kw )","if not isinstance ( key , str ) :","if not isinstance ( key , str ) :",True,100.0,74.55,,,
"def _encode ( n , nbytes , little_endian = False ) : <TAB> retval = [ ] <TAB> n = long ( n ) <TAB> for i in range ( nbytes ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> retval . append ( chr ( n & 0xFF ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval . insert ( 0 , chr ( n & 0xFF ) ) <TAB> <TAB> n >> = 8 <TAB> return "" "" . join ( retval )",if little_endian :,if little_endian :,True,100.0,74.28,,,
"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( ) # create a new group <TAB> new_i.id = self.id # with the same id <TAB> cls.id = old_id # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <TAB> <TAB> if prop is not ""members"": <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> val = getattr(self, prop) <TAB> <TAB> <TAB> <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i","if hasattr ( self , prop ) :",if self . has ( prop ) :,False,97.36,71.94,,,
"def dataspec ( config ) : <TAB> master = yield fakemaster . make_master ( ) <TAB> data = connector . DataConnector ( ) <TAB> data . setServiceParent ( master ) <TAB> if config [ "" out "" ] != "" -- "" : <TAB> <TAB> dirs = os . path . dirname ( config [ "" out "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( dirs ) <TAB> <TAB> f = open ( config [ "" out "" ] , "" w "" ) <TAB> else : <TAB> <TAB> f = sys . stdout <TAB> if config [ "" global "" ] is not None : <TAB> <TAB> f . write ( "" window. "" + config [ "" global "" ] + "" = "" ) <TAB> f . write ( json . dumps ( data . allEndpoints ( ) , indent = 2 ) ) <TAB> f . close ( ) <TAB> defer . returnValue ( 0 )",if not os . path . isdir ( dirs ) :,if dirs and not os . path . exists ( dirs ) :,False,97.31,72.85,,,
"def _parseSCDOCDC ( self , src ) : <TAB> """""" [S|CDO|CDC]* """""" <TAB> while 1 : <TAB> <TAB> src = src . lstrip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> src = src [ 4 : ] <TAB> <TAB> elif src . startswith ( "" --> "" ) : <TAB> <TAB> <TAB> src = src [ 3 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return src","if src . startswith ( ""<S|CDO|CDC>"" ) :","if src . startswith ( ""<!--"" ) :",False,94.53,93.43,,,
"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB> <TAB> visitor = process_file ( filename ) <TAB> <TAB> if visitor . needs_fix ( ) : <TAB> <TAB> <TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> print ( "" Fixing:  %s "" % filename ) <TAB> <TAB> <TAB> <TAB> fix_file ( filename )",if fix :,if fix :,True,100.0,74.25,,,
"def shutdown ( self ) : <TAB> """""" Shutdown host system. """""" <TAB> self . _check_dbus ( MANAGER ) <TAB> use_logind = self . sys_dbus . logind . is_connected <TAB> _LOGGER . info ( "" Initialize host power off  %s "" , "" logind "" if use_logind else "" systemd "" ) <TAB> try : <TAB> <TAB> await self . sys_core . shutdown ( ) <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await self . sys_dbus . logind . power_off ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await self . sys_dbus . systemd . power_off ( )",if use_logind :,if use_logind :,True,100.0,99.4,,,
"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """""" Splits punctuation on a piece of text. """""" <TAB> if never_split is not None and text in never_split : <TAB> <TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB> <TAB> char = chars [ i ] <TAB> <TAB> if _is_punctuation ( char ) : <TAB> <TAB> <TAB> output . append ( [ char ] ) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> output . append ( [ ] ) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output [ - 1 ] . append ( char ) <TAB> <TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ]",if start_new_word :,if start_new_word :,True,100.0,99.62,,,
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> if tp == "" write "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" write_flush "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass","elif tp == ""write_flush"" :","elif tp == ""flush"" :",False,98.55,73.79,,,
"def checkClassDeclation ( file ) : <TAB> localResult = [ ] <TAB> with open ( file , "" rb "" ) as f : <TAB> <TAB> lineNumber = 0 <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> m = re . search ( "" class \ s+[^ \ (]*: "" , line ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> localResult . append ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Old class definition found on  {0} "" . format ( m . group ( ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return localResult",if m :,if m :,True,100.0,74.37,,,
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> if isinstance ( in_arrays , tuple ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> if self . _progress_hook : <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results","elif isinstance ( in_arrays , dict ) :","elif isinstance ( in_arrays , dict ) :",True,100.0,74.5,,,
"def check_billing_view ( user , permission , obj ) : <TAB> if hasattr ( obj , "" all_projects "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> # This is a billing object <TAB> <TAB> return any(check_permission(user, permission, prj) for prj in obj.all_projects) <TAB> return check_permission(user, permission, obj)","if obj . billing_view == ""view"" :",if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) :,False,81.45,51.51,,,
"def ensure_output_spaces_contain_the_same_data ( self , y , y_ensured ) : <TAB> stride = y . shape [ 1 ] <TAB> self . assertEqual ( y . shape [ 0 ] * y . shape [ 1 ] , y_ensured . shape [ 0 ] ) <TAB> self . assertEqual ( len ( y_ensured . shape ) , 1 ) <TAB> for row in range ( y . shape [ 0 ] ) : <TAB> <TAB> for column in range ( y . shape [ 1 ] ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( y [ row , column ] , y_ensured [ row * stride + column ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( y [ row ] [ column ] , y_ensured [ row * stride + column ] )","if y [ row , column ] == y_ensured [ row , column ] :",if sp . issparse ( y ) :,False,92.28,71.19,,,
"def train ( <TAB> self , <TAB> training_data : TrainingData , <TAB> config : Optional [ RasaNLUModelConfig ] = None , <TAB> * * kwargs : Any , ) - > None : <TAB> """""" Tokenize all training data. """""" <TAB> for example in training_data . training_examples : <TAB> <TAB> for attribute in MESSAGE_ATTRIBUTES : <TAB> <TAB> <TAB> if example . get ( attribute ) is not None and not example . get ( attribute ) == "" "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self . _split_name ( example , attribute ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self . tokenize ( example , attribute ) <TAB> <TAB> <TAB> <TAB> example . set ( TOKENS_NAMES [ attribute ] , tokens )",if attribute in TOKENS_NAMES :,"if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] :",False,93.88,80.5,,,
"def refresh_token ( self , strategy , * args , * * kwargs ) : <TAB> token = self . extra_data . get ( "" refresh_token "" ) or self . extra_data . get ( "" access_token "" ) <TAB> backend = self . get_backend ( strategy ) <TAB> if token and backend and hasattr ( backend , "" refresh_token "" ) : <TAB> <TAB> backend = backend ( strategy = strategy ) <TAB> <TAB> response = backend . refresh_token ( token , * args , * * kwargs ) <TAB> <TAB> extra_data = backend . extra_data ( self , self . uid , response , self . extra_data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . save ( )",if self . _update_extra_data ( extra_data ) :,if self . set_extra_data ( extra_data ) :,False,98.09,73.52,,,
"def _verify_environ ( _collected_environ ) : <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> new_environ = dict ( os . environ ) <TAB> <TAB> current_test = new_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB> <TAB> old_environ = dict ( _collected_environ ) <TAB> <TAB> old_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise DirtyTest ( <TAB> <TAB> <TAB> <TAB> "" Left over environment variables "" , <TAB> <TAB> <TAB> <TAB> current_test , <TAB> <TAB> <TAB> <TAB> _compare_eq_dict ( new_environ , old_environ , verbose = 2 ) , <TAB> <TAB> <TAB> )",if current_test != old_test :,if new_environ != old_environ :,False,96.82,72.45,,,
"def clean_len ( self , line ) : <TAB> """""" Calculate wisible length of string """""" <TAB> if isinstance ( line , basestring ) : <TAB> <TAB> return len ( self . screen . markup . clean_markup ( line ) ) <TAB> elif isinstance ( line , tuple ) or isinstance ( line , list ) : <TAB> <TAB> markups = self . screen . markup . get_markup_vars ( ) <TAB> <TAB> length = 0 <TAB> <TAB> for i in line : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> length + = len ( i ) <TAB> <TAB> return length",if markups and i not in markups :,if i not in markups :,False,97.78,96.82,,,
"def _build_merged_dataset_args ( datasets ) : <TAB> merged_dataset_args = [ ] <TAB> for dataset in datasets : <TAB> <TAB> dataset_code_column = _parse_dataset_code ( dataset ) <TAB> <TAB> arg = dataset_code_column [ "" code "" ] <TAB> <TAB> column_index = dataset_code_column [ "" column_index "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> arg = ( dataset_code_column [ "" code "" ] , { "" column_index "" : [ column_index ] } ) <TAB> <TAB> merged_dataset_args . append ( arg ) <TAB> return merged_dataset_args","if isinstance ( arg , ( list , tuple ) ) :",if column_index is not None :,False,93.29,69.03,,,
"def update_watch_data_table_paths ( self ) : <TAB> if hasattr ( self . tool_data_watcher , "" monitored_dirs "" ) : <TAB> <TAB> for tool_data_table_path in self . tool_data_paths : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . tool_data_watcher . watch_directory ( tool_data_table_path )",if os . path . isdir ( tool_data_table_path ) :,if tool_data_table_path not in self . tool_data_watcher . monitored_dirs :,False,86.91,65.04,,,
"def getsource ( obj ) : <TAB> """""" Wrapper around inspect.getsource """""" <TAB> try : <TAB> <TAB> try : <TAB> <TAB> <TAB> src = encoding . to_unicode ( inspect . getsource ( obj ) ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> src = encoding . to_unicode ( inspect . getsource ( obj . __class__ ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # Bindings like VTK or ITK require this case <TAB> <TAB> <TAB> <TAB> src = getdoc(obj) <TAB> <TAB> return src <TAB> except (TypeError, IOError): <TAB> <TAB> return",if inspect . isclass ( obj ) :,"if hasattr ( obj , ""__class__"" ) :",False,93.96,71.55,,,
"def __iter__ ( self ) : <TAB> for model in self . app_config . get_models ( ) : <TAB> <TAB> admin_model = AdminModel ( model , * * self . options ) <TAB> <TAB> for model_re in self . model_res : <TAB> <TAB> <TAB> if model_re . search ( admin_model . name ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield admin_model",if admin_model . is_active :,if self . model_res :,False,94.76,71.61,,,
"def run ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt ( ) : <TAB> <TAB> <TAB> <TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB> <TAB> <TAB> <TAB> if self . _has_stop_signal ( raw_inputs ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self . _flow_type == BATCH : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = False ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> continue",elif self . _flow_type == FLOW :,elif self . _flow_type == REALTIME :,False,99.2,73.82,,,
"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) )","if isinstance ( getattr ( self , field [ 0 ] ) , Field ) :","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) :",False,98.98,74.04,,,
"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> """""" Validating that user has inputted a value set and that configuration has been initialized """""" <TAB> super ( ) . validate_configuration ( configuration ) <TAB> try : <TAB> <TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB> <TAB> ) , "" value_set must be a list or a set "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB> <TAB> <TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key ' <TAB> except AssertionError as e : <TAB> <TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :","if isinstance ( configuration . kwargs [ ""value_set"" ] , dict ) :",True,100.0,74.64,,,
def test_one_dead_branch ( ) : <TAB> with deterministic_PRNG ( ) : <TAB> <TAB> seen = set ( ) <TAB> <TAB> @run_to_buffer <TAB> <TAB> def x ( data ) : <TAB> <TAB> <TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB> <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> <TAB> data . mark_invalid ( ) <TAB> <TAB> <TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB> <TAB> <TAB> if len ( seen ) < 255 : <TAB> <TAB> <TAB> <TAB> seen . add ( i ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data . mark_interesting ( ),if seen :,elif i not in seen :,False,97.25,69.1,,,
"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB> <TAB> module = self . get_event_module ( event ) <TAB> <TAB> self . __module_view . set_selection ( module . module_num ) <TAB> <TAB> if event . EventObject is self . list_ctrl : <TAB> <TAB> <TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . list_ctrl . deactivate_active_item ( ) <TAB> <TAB> <TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( )",if self . list_ctrl . GetItem ( index ) == event :,if self . list_ctrl . IsSelected ( index ) :,False,97.03,72.51,,,
"def prime ( self , callback ) : <TAB> <IF-STMT> <TAB> <TAB> # import pdb <TAB> <TAB> # pdb.set_trace() <TAB> <TAB> self.cbhdl = simulator.register_rwsynch_callback(callback, self) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise_error(self, ""Unable set up %s Trigger"" % (str(self))) <TAB> Trigger.prime(self)",if self . cbhdl is None :,if self . cbhdl is None :,True,100.0,73.87,,,
"def fstab_configuration ( middleware ) : <TAB> for command in ( <TAB> <TAB> [ <TAB> <TAB> <TAB> [ "" systemctl "" , "" daemon-reload "" ] , <TAB> <TAB> <TAB> [ "" systemctl "" , "" restart "" , "" local-fs.target "" ] , <TAB> <TAB> ] <TAB> <TAB> if osc . IS_LINUX <TAB> <TAB> else [ [ "" mount "" , "" -uw "" , "" / "" ] ] <TAB> ) : <TAB> <TAB> ret = subprocess . run ( command , capture_output = True ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> middleware . logger . debug ( <TAB> <TAB> <TAB> <TAB> f ' Failed to execute  "" { "" "" . join ( command ) } "" :  { ret . stderr . decode ( ) } ' <TAB> <TAB> <TAB> )","if ret . stderr . decode ( ) != ""Unable to execute command"" :",if ret . returncode :,False,93.33,69.37,,,
"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB> <TAB> <TAB> simple_colorize ( todesc , "" description "" ) , <TAB> <TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB> if i > 0: <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize(""---"", ""separator""), <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",if line is None :,if line is None :,True,100.0,74.53,,,
"def update_completion ( self ) : <TAB> """""" Update completion model with exist tags """""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB> <TAB> if "" , "" in orig_text : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB> <TAB> <TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB> <TAB> self . completer_model . setStringList ( tags )",if tag in self . completer_model . stringList ( ) :,"if orig_text [ - 1 ] not in ( "","" , "" "" ) :",False,93.24,67.3,,,
"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB> <TAB> return False <TAB> for digit in reversed ( number ) : <TAB> <TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> digit * = 2 <TAB> <TAB> <TAB> if digit > = 10 : <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit / / 10 <TAB> <TAB> digits . append ( digit ) <TAB> <TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False",if even :,if even :,True,100.0,74.48,,,
"def __get_param_string__ ( params ) : <TAB> params_string = [ ] <TAB> for key in sorted ( params . keys ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> value = params [ key ] <TAB> <TAB> params_string . append ( "" "" if value == "" null "" else str ( value ) ) <TAB> return "" | "" . join ( params_string )","if key == ""params"" :","if ""REFUND"" in params [ key ] or ""|"" in params [ key ] :",False,85.63,60.84,,,
"def _map_handlers ( self , session , event_class , mapfn ) : <TAB> for event in DOC_EVENTS : <TAB> <TAB> event_handler_name = event . replace ( "" - "" , "" _ "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> event_handler = getattr ( self , event_handler_name ) <TAB> <TAB> <TAB> format_string = DOC_EVENTS [ event ] <TAB> <TAB> <TAB> num_args = len ( format_string . split ( "" . "" ) ) - 2 <TAB> <TAB> <TAB> format_args = ( event_class , ) + ( "" * "" , ) * num_args <TAB> <TAB> <TAB> event_string = event + format_string % format_args <TAB> <TAB> <TAB> unique_id = event_class + event_handler_name <TAB> <TAB> <TAB> mapfn ( event_string , event_handler , unique_id )",if event_handler_name in session :,"if hasattr ( self , event_handler_name ) :",False,96.58,71.69,,,
"def _create_param_lr ( self , param_and_grad ) : <TAB> # create learning rate variable for every parameter <TAB> param = param_and_grad[0] <TAB> param_lr = param.optimize_attr[""learning_rate""] <TAB> if type(param_lr) == Variable: <TAB> <TAB> return param_lr <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self._global_learning_rate() <TAB> <TAB> else: <TAB> <TAB> <TAB> with default_main_program()._lr_schedule_guard( <TAB> <TAB> <TAB> <TAB> is_with_opt=True <TAB> <TAB> <TAB> ), framework.name_scope(""scale_with_param_lr""): <TAB> <TAB> <TAB> <TAB> return self._global_learning_rate() * param_lr",if param_lr is None :,if param_lr == 1.0 :,False,98.03,71.82,,,
"def __getitem__ ( self , key ) : <TAB> try : <TAB> <TAB> return self . _clsmap [ key ] <TAB> except KeyError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _mutex . acquire ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . _init ( ) <TAB> <TAB> <TAB> <TAB> <TAB> self . initialized = True <TAB> <TAB> <TAB> <TAB> return self . _clsmap [ key ] <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . _mutex . release ( ) <TAB> <TAB> raise e",if self . initialized :,if not self . initialized :,False,97.43,71.89,,,
"def save ( self , force = False ) : <TAB> if not force : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if time . time ( ) - self . last_save_time < 10 : <TAB> <TAB> <TAB> return <TAB> with self . lock : <TAB> <TAB> with open ( self . file_path , "" w "" ) as fd : <TAB> <TAB> <TAB> for ip in self . cache : <TAB> <TAB> <TAB> <TAB> record = self . cache [ ip ] <TAB> <TAB> <TAB> <TAB> rule = record [ "" r "" ] <TAB> <TAB> <TAB> <TAB> connect_time = record [ "" c "" ] <TAB> <TAB> <TAB> <TAB> update_time = record [ "" update "" ] <TAB> <TAB> <TAB> <TAB> fd . write ( "" %s %s %d %d \n "" % ( ip , rule , connect_time , update_time ) ) <TAB> self . last_save_time = time . time ( ) <TAB> self . need_save = False",if self . need_save :,if not self . need_save :,False,99.08,73.78,,,
"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield x <TAB> <TAB> elif not x . is_atom ( ) and not s . is_atom ( ) : <TAB> <TAB> <TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation )",if x . is_atom ( ) and s . is_atom ( ) :,if match ( s ) :,False,86.51,69.58,,,
"def isValidFloat ( config_param_name , value , constraints ) : <TAB> if isinstance ( value , float ) : <TAB> <TAB> constraints . setdefault ( "" min "" , MIN_VALID_FLOAT_VALUE ) <TAB> <TAB> constraints . setdefault ( "" max "" , MAX_VALID_FLOAT_VALUE ) <TAB> <TAB> minv = float ( constraints . get ( "" min "" ) ) <TAB> <TAB> maxv = float ( constraints . get ( "" max "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value < = maxv : <TAB> <TAB> <TAB> <TAB> return value <TAB> raise FloatValueError ( config_param_name , value , constraints )",if value >= minv :,if value >= minv :,True,100.0,74.39,,,
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f","if ""build_sdk"" not in root and ""do_populate_sdk"" not in root :","if ""qemux86copy-"" in root or ""qemux86-"" in root :",False,91.16,71.4,,,
"def __get_photo ( self , person_or_marriage ) : <TAB> """""" returns the first photo in the media list or None """""" <TAB> media_list = person_or_marriage . get_media_list ( ) <TAB> for media_ref in media_list : <TAB> <TAB> media_handle = media_ref . get_reference_handle ( ) <TAB> <TAB> media = self . database . get_media_from_handle ( media_handle ) <TAB> <TAB> mime_type = media . get_mime_type ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return media <TAB> return None","if mime_type == ""photo"" :","if mime_type and mime_type . startswith ( ""image"" ) :",False,92.79,64.38,,,
"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB> <TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB> <TAB> if array . has_property ( unicode ( k ) ) : <TAB> <TAB> <TAB> kValue = array . get ( unicode ( k ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> res . append ( kValue ) <TAB> <TAB> k + = 1 <TAB> return args . space . ConstructArray ( res )",if kValue is not None :,"if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :",False,89.29,68.05,,,
"def optimize ( self , graph : Graph ) : <TAB> for v in graph . inputs : <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> DumpGraph ( ) . optimize ( graph ) <TAB> <TAB> raise NotImplementedError ( <TAB> <TAB> <TAB> f "" Input Variable  { v }  is too large to handle in WebGL backend "" <TAB> <TAB> ) <TAB> return graph , False",if v . size ( ) > self . _max_output_size :,if flags . DEBUG :,False,88.47,70.15,,,
"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <TAB> <TAB> if type(node.image) is not list: <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node.image: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk.extra[""disk_id""] <TAB> <TAB> <TAB> <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False","if disk . extra [ ""volume_id"" ] == volume :",if disk . id == volume . id :,False,95.09,63.2,,,
"def Yield ( value , level = 1 ) : <TAB> g = greenlet . getcurrent ( ) <TAB> while level != 0 : <TAB> <TAB> if not isinstance ( g , genlet ) : <TAB> <TAB> <TAB> raise RuntimeError ( "" yield outside a genlet "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g . parent . set_child ( g ) <TAB> <TAB> g = g . parent <TAB> <TAB> level - = 1 <TAB> g . switch ( value )",if g . parent :,if level > 1 :,False,96.28,71.68,,,
"def get_all_pipeline_nodes ( <TAB> pipeline : pipeline_pb2 . Pipeline , ) - > List [ pipeline_pb2 . PipelineNode ] : <TAB> """""" Returns all pipeline nodes in the given pipeline. """""" <TAB> result = [ ] <TAB> for pipeline_or_node in pipeline . nodes : <TAB> <TAB> which = pipeline_or_node . WhichOneof ( "" node "" ) <TAB> <TAB> # TODO(goutham): Handle sub-pipelines. <TAB> <TAB> # TODO(goutham): Handle system nodes. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result.append(pipeline_or_node.pipeline_node) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Only pipeline nodes supported."") <TAB> return result","if which == ""system"" :","if which == ""pipeline_node"" :",False,97.66,98.0,,,
"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB> <TAB> if not hasattr ( self , name ) : <TAB> <TAB> <TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> self . __class__ . __name__ , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr ( self , name , value )","if not isinstance ( value , ( dict , list ) ) :",if name not in default_settings :,False,94.68,71.2,,,
"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB> <TAB> elif type ( self . choices ) not in ( types . TupleType , types . ListType ) : <TAB> <TAB> <TAB> raise OptionError ( <TAB> <TAB> <TAB> <TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB> <TAB> <TAB> <TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> ) <TAB> elif self . choices is not None : <TAB> <TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self )",if type ( self . choices ) is None :,if self . choices is None :,False,97.31,73.19,,,
"def prepare ( self , size = None ) : <TAB> if _is_seekable ( self . file ) : <TAB> <TAB> start_pos = self . file . tell ( ) <TAB> <TAB> self . file . seek ( 0 , 2 ) <TAB> <TAB> end_pos = self . file . tell ( ) <TAB> <TAB> self . file . seek ( start_pos ) <TAB> <TAB> fsize = end_pos - start_pos <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . remain = fsize <TAB> <TAB> else : <TAB> <TAB> <TAB> self . remain = min ( fsize , size ) <TAB> return self . remain",if size is None :,if size is None :,True,100.0,74.41,,,
"def _setSitemapTargets ( ) : <TAB> if not conf . sitemapUrl : <TAB> <TAB> return <TAB> infoMsg = "" parsing sitemap  ' %s ' "" % conf . sitemapUrl <TAB> logger . info ( infoMsg ) <TAB> found = False <TAB> for item in parseSitemap ( conf . sitemapUrl ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> kb . targets . add ( ( item . strip ( ) , None , None , None , None ) ) <TAB> if not found and not conf . forms and not conf . crawlDepth : <TAB> <TAB> warnMsg = "" no usable links found (with GET parameters) "" <TAB> <TAB> logger . warn ( warnMsg )",if item . strip ( ) :,"if re . match ( r""[^ ]+\?(.+)"" , item , re . I ) :",False,86.96,64.16,,,
"def test_CY_decomposition ( self , tol ) : <TAB> """""" Tests that the decomposition of the CY gate is correct """""" <TAB> op = qml . CY ( wires = [ 0 , 1 ] ) <TAB> res = op . decomposition ( op . wires ) <TAB> mats = [ ] <TAB> for i in reversed ( res ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mats . append ( np . kron ( i . matrix , np . eye ( 2 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mats . append ( i . matrix ) <TAB> decomposed_matrix = np . linalg . multi_dot ( mats ) <TAB> assert np . allclose ( decomposed_matrix , op . matrix , atol = tol , rtol = 0 )",if i . is_kron :,if len ( i . wires ) == 1 :,False,94.84,81.12,,,
"def _line_ranges ( statements , lines ) : <TAB> """""" Produce a list of ranges for `format_lines`. """""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> if not start : <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start : <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs","if isinstance ( stmt , ( list , tuple ) ) :",if stmt == lines [ lidx ] :,False,95.28,94.76,,,
"def init_params ( net ) : <TAB> """""" Init layer parameters. """""" <TAB> for module in net . modules ( ) : <TAB> <TAB> if isinstance ( module , nn . Conv2d ) : <TAB> <TAB> <TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> init . constant ( module . weight , 1 ) <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . Linear ) : <TAB> <TAB> <TAB> init . normal ( module . weight , std = 1e-3 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 )","elif isinstance ( module , nn . Linear ) :",if module . bias :,False,91.9,68.14,,,
"def _get_directory_size_in_bytes ( directory ) : <TAB> total = 0 <TAB> try : <TAB> <TAB> for entry in os . scandir ( directory ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # if it's a file, use stat() function <TAB> <TAB> <TAB> <TAB> total += entry.stat().st_size <TAB> <TAB> <TAB> elif entry.is_dir(): <TAB> <TAB> <TAB> <TAB> # if it's a directory, recursively call this function <TAB> <TAB> <TAB> <TAB> total += _get_directory_size_in_bytes(entry.path) <TAB> except NotADirectoryError: <TAB> <TAB> # if `directory` isn't a directory, get the file size then <TAB> <TAB> return os.path.getsize(directory) <TAB> except PermissionError: <TAB> <TAB> # if for whatever reason we can't open the folder, return 0 <TAB> <TAB> return 0 <TAB> return total",if entry . is_file ( ) :,if entry . is_file ( ) :,True,100.0,74.51,,,
"def run_cmd ( self , util , to , always_push_mark = False ) : <TAB> if to == "" bof "" : <TAB> <TAB> util . push_mark_and_goto_position ( 0 ) <TAB> elif to == "" eof "" : <TAB> <TAB> util . push_mark_and_goto_position ( self . view . size ( ) ) <TAB> elif to in ( "" eow "" , "" bow "" ) : <TAB> <TAB> visible = self . view . visible_region ( ) <TAB> <TAB> pos = visible . a if to == "" bow "" else visible . b <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> util . push_mark_and_goto_position ( pos ) <TAB> <TAB> else : <TAB> <TAB> <TAB> util . set_cursors ( [ sublime . Region ( pos ) ] )",if always_push_mark :,if always_push_mark :,True,100.0,74.51,,,
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> if "" results.train_y_misclass "" in dd : <TAB> <TAB> <TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) )","if key != ""results"" :","if ""hyper_parameters"" in key :",False,96.49,72.65,,,
"def clean_vc_position ( self ) : <TAB> vc_position = self . cleaned_data [ "" vc_position "" ] <TAB> if self . validate_vc_position : <TAB> <TAB> conflicting_members = Device . objects . filter ( <TAB> <TAB> <TAB> virtual_chassis = self . instance . virtual_chassis , vc_position = vc_position <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise forms . ValidationError ( <TAB> <TAB> <TAB> <TAB> "" A virtual chassis member already exists in position  {} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> vc_position <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vc_position",if conflicting_members :,if conflicting_members . exists ( ) :,False,97.18,71.77,,,
"def cal_pads ( auto_pad , pad_shape ) : <TAB> spatial_size = len ( pad_shape ) <TAB> pads = [ 0 ] * spatial_size * 2 <TAB> for i in range ( spatial_size ) : <TAB> <TAB> if auto_pad == "" SAME_LOWER "" : <TAB> <TAB> <TAB> pads [ i + spatial_size ] = pad_shape [ i ] / / 2 <TAB> <TAB> <TAB> pads [ i ] = pad_shape [ i ] - pads [ i + spatial_size ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pads [ i ] = pad_shape [ i ] / / 2 <TAB> <TAB> <TAB> pads [ i + spatial_size ] = pad_shape [ i ] - pads [ i ] <TAB> return pads","elif auto_pad == ""SAME_UPPER"" :","elif auto_pad == ""SAME_UPPER"" :",True,100.0,74.47,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.46,,,
"def test_cwl_rnaseq ( self , install_test_files ) : <TAB> with install_cwl_test_files ( ) as work_dir : <TAB> <TAB> with utils . chdir ( os . path . join ( work_dir , "" rnaseq "" ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( "" cromwell_work "" ) <TAB> <TAB> <TAB> subprocess . check_call ( <TAB> <TAB> <TAB> <TAB> [ "" bcbio_vm.py "" , "" cwlrun "" , "" cromwell "" , "" rnaseq-workflow "" ] <TAB> <TAB> <TAB> )","if os . path . exists ( ""cromwell_work"" ) :","if os . path . exists ( ""cromwell_work"" ) :",True,100.0,74.31,,,
"def files_per_version ( self ) : <TAB> xpath = "" ./files/file "" <TAB> files = self . root . findall ( xpath ) <TAB> versions = { } <TAB> for file in files : <TAB> <TAB> vfile = file . findall ( "" version "" ) <TAB> <TAB> for version in vfile : <TAB> <TAB> <TAB> nb = version . attrib [ "" nb "" ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> versions [ nb ] = [ ] <TAB> <TAB> <TAB> versions [ nb ] . append ( file . attrib [ "" url "" ] ) <TAB> return versions",if nb not in versions :,if not nb in versions :,False,98.09,73.01,,,
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""SQLite backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return six.text_type(value)",if USE_TZ :,if settings . USE_TZ :,False,97.8,71.75,,,
"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB> <TAB> t = threading . current_thread ( ) <TAB> <TAB> t . name = func . __name__ <TAB> <TAB> try : <TAB> <TAB> <TAB> t . status = func ( * args , * * kwargs ) <TAB> <TAB> except EscapeException as e : # user aborted <TAB> <TAB> <TAB> t.status = ""aborted by user"" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> status(""%s aborted"" % t.name, priority=2) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> t.exception = e <TAB> <TAB> <TAB> t.status = ""exception"" <TAB> <TAB> <TAB> vd.exceptionCaught(e) <TAB> <TAB> if t.sheet: <TAB> <TAB> <TAB> t.sheet.currentThreads.remove(t)",if status :,if status :,True,100.0,74.52,,,
"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB> <TAB> if name . lower ( ) in phrase : <TAB> <TAB> <TAB> dev = devid [ num ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ctrl = "" =ON "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning On  "" + name ) <TAB> <TAB> <TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =OFF "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning Off  "" + name ) <TAB> <TAB> <TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False )","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :","if custom_action_keyword [ ""Dict"" ] [ ""On"" ] in phrase :",True,100.0,74.54,,,
"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB> <TAB> parts = [data_type] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts.append(""PRIMARY KEY"") <TAB> <TAB> if not_null: <TAB> <TAB> <TAB> parts.append(""NOT NULL"") <TAB> <TAB> result[name] = "" "".join(parts) <TAB> return result",if primary_key :,if primary_key :,True,100.0,74.28,,,
"def _validate_forward_input ( x , n_in ) : <TAB> if n_in != 1 : <TAB> <TAB> if not isinstance ( x , ( tuple , list ) ) : <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> f "" Expected input to be a tuple or list; instead got  { type ( x ) } . "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" Input tuple length ( { len ( x ) } ) does not equal required  "" <TAB> <TAB> <TAB> <TAB> f "" number of inputs ( { n_in } ). "" <TAB> <TAB> <TAB> )",if len ( x ) != n_in :,if len ( x ) != n_in :,True,100.0,74.47,,,
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> if isinstance ( val , compat . string_types ) : <TAB> <TAB> <TAB> return "" %s "" % val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> elif val < 1024 * * 3 : <TAB> <TAB> <TAB> return "" %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return "" %s "" % val",elif val < 1024 * * 2 :,elif val < 1024 ** 2 :,False,100.0,73.63,,,
"def get_path_name ( self ) : <TAB> if self . is_root ( ) : <TAB> <TAB> return "" @ "" + self . name <TAB> else : <TAB> <TAB> parent_name = self . parent . get_path_name ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" / "" . join ( [ parent_name , "" @ "" + self . name ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" @ "" + self . name",if parent_name :,if parent_name :,True,100.0,74.23,,,
"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB> <TAB> elif k == "" created_at "" : <TAB> <TAB> <TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( lst , k , v ) <TAB> return lst","if k == ""user"" :","if k == ""user"" :",True,100.0,74.4,,,
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> if not py_file . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" c "" ) <TAB> <TAB> if self . optimize > 0 : <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files",if self . optimize > 0 :,if self . compile :,False,96.81,72.12,,,
"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB> <TAB> if isinstance ( self . subheader , RenderedContent ) : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader <TAB> return d","if isinstance ( self . header , RenderedContent ) :","if isinstance ( self . header , RenderedContent ) :",True,100.0,74.57,,,
"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB> <TAB> child = pathobj . child ( key ) <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> pathdict [ key ] = child <TAB> <TAB> <TAB> child . setContent ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> child . createDirectory ( ) <TAB> <TAB> <TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict","elif isinstance ( value , ( list , tuple ) ) :","elif isinstance ( value , dict ) :",False,96.27,72.65,,,
"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if type ( value ) == list : <TAB> <TAB> <TAB> <TAB> value = value [ - 1 ] <TAB> <TAB> picker . SetPath ( value ) <TAB> <TAB> return True <TAB> return False",if self . _isSetting ( ) :,"if issubclass ( picker . __class__ , wx . FileDialog ) :",False,89.34,68.5,,,
"def recv ( self , buffer_size ) : <TAB> try : <TAB> <TAB> return super ( SSLConnection , self ) . recv ( buffer_size ) <TAB> except ssl . SSLError as err : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> if err . args [ 0 ] in ( ssl . SSL_ERROR_EOF , ssl . SSL_ERROR_ZERO_RETURN ) : <TAB> <TAB> <TAB> self . handle_close ( ) <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> raise","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_WRITE , ssl . SSL_ERROR_WANT_WRITE ) :","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) :",False,98.45,73.1,,,
"def IncrementErrorCount ( self , category ) : <TAB> """""" Bumps the module ' s error statistic. """""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> category = category . split ( "" / "" ) [ 0 ] <TAB> <TAB> if category not in self . errors_by_category : <TAB> <TAB> <TAB> self . errors_by_category [ category ] = 0 <TAB> <TAB> self . errors_by_category [ category ] + = 1","if ""/"" in category :","if self . counting != ""detailed"" :",False,93.92,92.73,,,
"def _get_y ( self , data_inst ) : <TAB> if self . stratified : <TAB> <TAB> y = [ v for i , v in data_inst . mapValues ( lambda v : v . label ) . collect ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y = self . transform_regression_label ( data_inst ) <TAB> else : <TAB> <TAB> # make dummy y <TAB> <TAB> y = [0] * (data_inst.count()) <TAB> return y",elif self . regression :,if self . need_transform :,False,94.77,70.94,,,
"def test_all_project_files ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # XXX something with newlines goes wrong on Windows. <TAB> <TAB> return <TAB> for filepath in support.all_project_files(): <TAB> <TAB> with open(filepath, ""rb"") as fp: <TAB> <TAB> <TAB> encoding = tokenize.detect_encoding(fp.readline)[0] <TAB> <TAB> self.assertIsNotNone(encoding, ""can't detect encoding for %s"" % filepath) <TAB> <TAB> with open(filepath, ""r"") as fp: <TAB> <TAB> <TAB> source = fp.read() <TAB> <TAB> <TAB> source = source.decode(encoding) <TAB> <TAB> tree = driver.parse_string(source) <TAB> <TAB> new = unicode(tree) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.fail(""Idempotency failed: %s"" % filepath)",if tree . is_valid and new != encoding :,"if diff ( filepath , new , encoding ) :",False,95.58,70.42,,,
"def test_resource_arn_override_generator ( self ) : <TAB> overrides = set ( ) <TAB> for k , v in manager . resources . items ( ) : <TAB> <TAB> arn_gen = bool ( v . __dict__ . get ( "" get_arns "" ) or v . __dict__ . get ( "" generate_arn "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> overrides . add ( k ) <TAB> overrides = overrides . difference ( <TAB> <TAB> { <TAB> <TAB> <TAB> "" account "" , <TAB> <TAB> <TAB> "" s3 "" , <TAB> <TAB> <TAB> "" hostedzone "" , <TAB> <TAB> <TAB> "" log-group "" , <TAB> <TAB> <TAB> "" rest-api "" , <TAB> <TAB> <TAB> "" redshift-snapshot "" , <TAB> <TAB> <TAB> "" rest-stage "" , <TAB> <TAB> } <TAB> ) <TAB> if overrides : <TAB> <TAB> raise ValueError ( "" unknown arn overrides in  %s "" % ( "" ,  "" . join ( overrides ) ) )",if arn_gen :,if arn_gen :,True,100.0,74.6,,,
"def _check_dsl_runner ( self ) - > None : <TAB> """""" Checks if runner in dsl is Kubeflow V2 runner. """""" <TAB> with open ( self . flags_dict [ labels . PIPELINE_DSL_PATH ] , "" r "" ) as f : <TAB> <TAB> dsl_contents = f . read ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( "" KubeflowV2DagRunner not found in dsl. "" )","if dsl_contents == """" or dsl_contents == """" :","if ""KubeflowV2DagRunner"" not in dsl_contents :",False,87.7,59.76,,,
"def create_warehouse ( warehouse_name , properties = None , company = None ) : <TAB> if not company : <TAB> <TAB> company = "" _Test Company "" <TAB> warehouse_id = erpnext . encode_company_abbr ( warehouse_name , company ) <TAB> if not frappe . db . exists ( "" Warehouse "" , warehouse_id ) : <TAB> <TAB> warehouse = frappe . new_doc ( "" Warehouse "" ) <TAB> <TAB> warehouse . warehouse_name = warehouse_name <TAB> <TAB> warehouse . parent_warehouse = "" All Warehouses - _TCUV "" <TAB> <TAB> warehouse . company = company <TAB> <TAB> warehouse . account = get_warehouse_account ( warehouse_name , company ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warehouse . update ( properties ) <TAB> <TAB> warehouse . save ( ) <TAB> <TAB> return warehouse . name <TAB> else : <TAB> <TAB> return warehouse_id",if properties :,if properties :,True,100.0,74.54,,,
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> if not len ( line . strip ( ) ) : <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB> <TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB> <TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries",if head in hostnames_found :,if not len ( head ) :,False,97.4,72.69,,,
"def _get_omega ( self ) : <TAB> if self . _omega is None : <TAB> <TAB> n = self . get_drift_dim ( ) / / 2 <TAB> <TAB> omg = sympl . calc_omega ( n ) <TAB> <TAB> if self . oper_dtype == Qobj : <TAB> <TAB> <TAB> self . _omega = Qobj ( omg , dims = self . dyn_dims ) <TAB> <TAB> <TAB> self . _omega_qobj = self . _omega <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _omega = sp . csr_matrix ( omg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _omega = omg <TAB> return self . _omega",elif self . oper_dtype == csr_matrix :,elif self . oper_dtype == sp . csr_matrix :,False,98.15,72.91,,,
"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB> <TAB> for k , v in data . items ( ) : <TAB> <TAB> <TAB> if k == key : <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> out = get_in_inputs ( key , v ) <TAB> <TAB> <TAB> <TAB> if out : <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB> <TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB> <TAB> out = [ x for x in out if x ] <TAB> <TAB> if out : <TAB> <TAB> <TAB> return out [ 0 ]","if isinstance ( v , dict ) :","elif isinstance ( v , ( list , tuple , dict ) ) :",False,95.53,71.0,,,
def visit_binary ( binary ) : <TAB> if binary . operator == operators . eq : <TAB> <TAB> cols = util . column_set ( chain ( * [ c . proxy_set for c in columns . difference ( omit ) ] ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for c in reversed ( columns ) : <TAB> <TAB> <TAB> <TAB> if c . shares_lineage ( binary . right ) and ( <TAB> <TAB> <TAB> <TAB> <TAB> not only_synonyms or c . name == binary . left . name <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> omit . add ( c ) <TAB> <TAB> <TAB> <TAB> <TAB> break,if not only_synonyms :,if binary . left in cols and binary . right in cols :,False,93.6,68.26,,,
"def wait_tasks_or_abort ( futures , timeout = 60 , kill_switch_ev = None ) : <TAB> try : <TAB> <TAB> LazySingletonTasksCoordinator . wait_tasks ( <TAB> <TAB> <TAB> futures , return_when = FIRST_EXCEPTION , raise_exceptions = True <TAB> <TAB> ) <TAB> except Exception as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB> <TAB> <TAB> kill_switch_ev.set() <TAB> <TAB> <TAB> LazySingletonTasksCoordinator.wait_tasks( <TAB> <TAB> <TAB> <TAB> futures, <TAB> <TAB> <TAB> <TAB> return_when=ALL_COMPLETED, <TAB> <TAB> <TAB> <TAB> raise_exceptions=False, <TAB> <TAB> <TAB> <TAB> timeout=timeout, <TAB> <TAB> <TAB> ) <TAB> <TAB> raise e",if kill_switch_ev is not None :,if kill_switch_ev is not None :,True,100.0,74.45,,,
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","if isinstance ( s , ( list , tuple ) ) and s . size == 0 :",if s is None :,False,89.53,69.45,,,
"def setVaName ( self , va , parent = None ) : <TAB> if parent is None : <TAB> <TAB> parent = self <TAB> curname = self . vw . getName ( va ) <TAB> if curname is None : <TAB> <TAB> curname = "" "" <TAB> name , ok = QInputDialog . getText ( parent , "" Enter... "" , "" Name "" , text = curname ) <TAB> if ok : <TAB> <TAB> name = str ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" Duplicate Name:  %s "" % name ) <TAB> <TAB> self . vw . makeName ( va , name )",if name in self . vw . names :,if self . vw . vaByName ( name ) :,False,95.72,71.65,,,
"def generic_tag_compiler ( params , defaults , name , node_class , parser , token ) : <TAB> "" Returns a template.Node subclass. "" <TAB> bits = token . split_contents ( ) [ 1 : ] <TAB> bmax = len ( params ) <TAB> def_len = defaults and len ( defaults ) or 0 <TAB> bmin = bmax - def_len <TAB> if len ( bits ) < bmin or len ( bits ) > bmax : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message = "" %s  takes  %s  arguments "" % ( name , bmin ) <TAB> <TAB> else : <TAB> <TAB> <TAB> message = "" %s  takes between  %s  and  %s  arguments "" % ( name , bmin , bmax ) <TAB> <TAB> raise TemplateSyntaxError ( message ) <TAB> return node_class ( bits )",if bits == def_len :,if bmin == bmax :,False,96.61,73.01,,,
"def extract_segmentation_mask ( annotation ) : <TAB> poly_specs = annotation [ DensePoseDataRelative . S_KEY ] <TAB> if isinstance ( poly_specs , torch . Tensor ) : <TAB> <TAB> # data is already given as mask tensors, no need to decode <TAB> <TAB> return poly_specs <TAB> import pycocotools.mask as mask_utils <TAB> segm = torch.zeros((DensePoseDataRelative.MASK_SIZE,) * 2, dtype=torch.float32) <TAB> for i in range(DensePoseDataRelative.N_BODY_PARTS): <TAB> <TAB> poly_i = poly_specs[i] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mask_i = mask_utils.decode(poly_i) <TAB> <TAB> <TAB> segm[mask_i > 0] = i + 1 <TAB> return segm",if pycocotools . is_binary_mask ( poly_i ) :,if poly_i :,False,94.18,71.78,,,
"def module_list ( target , fast ) : <TAB> """""" Find the list of modules to be compiled """""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB> <TAB> module_name , ext = os . path . splitext ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB> <TAB> <TAB> <TAB> if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) : <TAB> <TAB> <TAB> <TAB> <TAB> modules . append ( module_name ) <TAB> return set ( modules )","if ext == "".py"" :","if ext == "".py"" or ext == """" and os . path . isdir ( os . path . join ( basedir , name ) ) :",False,88.07,58.9,,,
"def filelist_from_patterns ( pats , rootdir = None ) : <TAB> if rootdir is None : <TAB> <TAB> rootdir = "" . "" <TAB> # filelist = [] <TAB> fileset = set([]) <TAB> lines = [line.strip() for line in pats] <TAB> for line in lines: <TAB> <TAB> pat = line[2:] <TAB> <TAB> newfiles = glob(osp.join(rootdir, pat)) <TAB> <TAB> if line.startswith(""+""): <TAB> <TAB> <TAB> fileset.update(newfiles) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fileset.difference_update(newfiles) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError(""line must start with + or -"") <TAB> filelist = list(fileset) <TAB> return filelist","elif line . endswith ( ""-"" ) :","elif line . startswith ( ""-"" ) :",False,98.82,73.14,,,
"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ] # type: List[V1EventTrigger] <TAB> for e in events: <TAB> <TAB> entity_ref = contexts_refs.get_entity_ref(e.ref) <TAB> <TAB> if not entity_ref: <TAB> <TAB> <TAB> continue <TAB> <TAB> if entity_ref not in statuses_by_refs: <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e.kinds: <TAB> <TAB> <TAB> status = V1EventKind.events_statuses_mapping.get(kind) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> statuses_by_refs[entity_ref].append(status) <TAB> return statuses_by_refs",if status :,if status :,True,100.0,74.41,,,
"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> info , reference = value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB> <TAB> <TAB> self . _infos . append ( info ) <TAB> <TAB> if reference not in self . _reverse_references : <TAB> <TAB> <TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB> <TAB> <TAB> self . _references . append ( reference ) <TAB> <TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB> <TAB> <TAB> self . _reverse_infos [ info ] , <TAB> <TAB> <TAB> self . _reverse_references [ reference ] , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) )",if info not in self . _reverse_infos :,if info not in self . _reverse_infos :,True,100.0,74.61,,,
"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if combo . GetLabel ( ) == "" TR_VIRTUAL "" : <TAB> <TAB> <TAB> <TAB> style = style | HTL . TR_VIRTUAL <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB> <TAB> self . SetAGWWindowStyleFlag ( style )","if combo . GetLabel ( ) != ""STYLE"" :",if combo . GetValue ( ) == 1 :,False,95.95,66.56,,,
"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB> <TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB> <TAB> <TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB> <TAB> <TAB> <TAB> <TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self . _CSRFtoken != None : <TAB> <TAB> <TAB> <TAB> break","if c . startswith ( ""CSRF"" ) :","if c . strip ( ) . startswith ( ""CSRF-Token-"" ) :",False,96.44,71.71,,,
"def test_page_size_matching_max_returned_rows ( <TAB> app_client_returned_rows_matches_page_size , ) : <TAB> fetched = [ ] <TAB> path = "" /fixtures/no_primary_key.json "" <TAB> while path : <TAB> <TAB> response = app_client_returned_rows_matches_page_size . get ( path ) <TAB> <TAB> fetched . extend ( response . json [ "" rows "" ] ) <TAB> <TAB> assert len ( response . json [ "" rows "" ] ) in ( 1 , 50 ) <TAB> <TAB> path = response . json [ "" next_url "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = path . replace ( "" http://localhost "" , "" "" ) <TAB> assert 201 == len ( fetched )",if path :,if path :,True,100.0,74.41,,,
"def get_mapping_exception_message ( mappings : List [ Tuple [ Text , Text ] ] ) : <TAB> """""" Return a message given a list of duplicates. """""" <TAB> message = "" "" <TAB> for name , action_name in mappings : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> message + = "" \n "" <TAB> <TAB> message + = ( <TAB> <TAB> <TAB> "" Intent  ' {} '  is set to trigger action  ' {} ' , which is  "" <TAB> <TAB> <TAB> "" not defined in the domain. "" . format ( name , action_name ) <TAB> <TAB> ) <TAB> return message","if name in [ ""action"" , ""action_name"" ] :",if message :,False,91.49,96.85,,,
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> if re_han . match ( blk ) : <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words : <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield x,if x not in Force_Split_Words :,if x :,False,96.49,97.32,,,
"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB> <TAB> if - delta < expr . get_float_value ( ) < delta : <TAB> <TAB> <TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB> <TAB> real , imag = expr . real , expr . imag <TAB> <TAB> if - delta < real . get_float_value ( ) < delta : <TAB> <TAB> <TAB> real = Integer ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> imag = Integer ( 0 ) <TAB> <TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB> <TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr",if - delta < imag . get_float_value ( ) < delta :,if - delta < imag . get_float_value ( ) < delta :,True,100.0,74.63,,,
"def make_row ( self ) : <TAB> res = [ ] <TAB> for i in range ( self . num_cols ) : <TAB> <TAB> t = sqlite3_column_type ( self . stmnt , i ) <TAB> <TAB> # print(""type"", t) <TAB> <TAB> if t == SQLITE_INTEGER: <TAB> <TAB> <TAB> res.append(sqlite3_column_int(self.stmnt, i)) <TAB> <TAB> elif t == SQLITE_FLOAT: <TAB> <TAB> <TAB> res.append(sqlite3_column_double(self.stmnt, i)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res.append(sqlite3_column_text(self.stmnt, i)) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError <TAB> return tuple(res)",elif t == SQLITE_TEXT :,elif t == SQLITE_TEXT :,True,100.0,74.26,,,
"def try_convert ( self , string ) : <TAB> string = string . strip ( ) <TAB> try : <TAB> <TAB> return int ( string ) <TAB> except : <TAB> <TAB> try : <TAB> <TAB> <TAB> return float ( string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> if string == "" True "" : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return string","if string == ""False"" :","if string == ""False"" :",True,100.0,74.27,,,
"def configure_create_table_epilogue ( store ) : <TAB> for val in [ "" "" , ""  ENGINE=InnoDB "" ] : <TAB> <TAB> store . config [ "" create_table_epilogue "" ] = val <TAB> <TAB> store . _set_sql_flavour ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> store . log . info ( "" create_table_epilogue= ' %s ' "" , val ) <TAB> <TAB> <TAB> return <TAB> raise Exception ( "" Can not create a transactional table. "" )",if store . _transactional_enable ( ) :,if store . _test_transaction ( ) :,False,96.85,72.71,,,
"def _check_rule ( self , match , target_dict , cred_dict ) : <TAB> """""" Recursively checks credentials based on the brains rules. """""" <TAB> try : <TAB> <TAB> new_match_list = self . rules [ match ] <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_match_list = ( "" rule: %s "" % self . default_rule , ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return self . check ( new_match_list , target_dict , cred_dict )",if self . default_rule :,if self . default_rule and match != self . default_rule :,False,94.18,86.37,,,
"def get_civil_names ( self ) : <TAB> congresspeople_ids = self . get_all_congresspeople_ids ( ) <TAB> for i , congress_id in enumerate ( congresspeople_ids ) : <TAB> <TAB> if not np . math . isnan ( float ( congress_id ) ) : <TAB> <TAB> <TAB> percentage = i / self . total * 100 <TAB> <TAB> <TAB> msg = "" Processed  {}  out of  {}  ( {:.2f} % ) "" <TAB> <TAB> <TAB> print ( msg . format ( i , self . total , percentage ) , end = "" \r "" ) <TAB> <TAB> <TAB> data = self . fetch_data_repository ( congress_id ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield dict ( data )",if data :,if data is not None :,False,97.72,72.2,,,
"def parse_network_whitelist ( self , network_whitelist_location ) : <TAB> networks = [ ] <TAB> with open ( network_whitelist_location , "" r "" ) as text_file : <TAB> <TAB> for line in text_file : <TAB> <TAB> <TAB> line = line . strip ( ) . strip ( "" ' "" ) . strip ( ' "" ' ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> networks . append ( line ) <TAB> return networks","if line . startswith ( ""networkwhitelist"" ) :",if isIPv4 ( line ) or isIPv6 ( line ) :,False,92.98,62.52,,,
"def _pick ( self , cum ) : <TAB> if self . _isleaf ( ) : <TAB> <TAB> return self . bd [ 0 ] , self . s <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . left . _pick ( cum ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . right . _pick ( cum - self . left . s )",if cum < self . left . s :,if cum < self . left . s :,True,100.0,74.2,,,
"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> if len ( value ) not in ( 2 , 3 ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" When setting content_range to a list/tuple, it must  "" <TAB> <TAB> <TAB> <TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> begin , end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else : <TAB> <TAB> <TAB> begin , end , length = value <TAB> <TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB> <TAB> return None <TAB> return value",if len ( value ) == 2 :,if len ( value ) == 2 :,True,100.0,74.58,,,
"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fields [ k ] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> if k == "" full_title "" : <TAB> <TAB> <TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields","if k . startswith ( ""index_"" ) :","if k in ( ""lccn"" , ""oclc"" , ""isbn"" ) :",False,89.68,64.3,,,
"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB> <TAB> trans_len = len ( translation ) <TAB> <TAB> ind = np . random . randint ( trans_len ) <TAB> <TAB> action = np . random . choice ( actions ) <TAB> <TAB> if action == "" deletion "" : <TAB> <TAB> <TAB> del translation [ ind ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ind_rep = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation [ ind ] = translation [ ind_rep ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ind_insert = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation","elif action == ""insert"" :","elif action == ""replacement"" :",False,98.94,73.75,,,
"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB> <TAB> if t == "" tacotron "" : <TAB> <TAB> <TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB> <TAB> elif t == "" jaconv "" : <TAB> <TAB> <TAB> text = jaconv . normalize ( text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if vietnamese_cleaners is None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB> <TAB> <TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text","elif t == ""vietnamese"" :","elif t == ""vietnamese"" :",True,100.0,74.51,,,
"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB> <TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB> <TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB> <TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB> <TAB> if read_len < len ( var ) : <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params [ "" Data "" ] != 0 : <TAB> <TAB> <TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND","if params [ ""Attributes"" ] != 0 :","if params [ ""Attributes"" ] != 0 :",True,100.0,74.57,,,
"def test_setupapp ( self , overrideRootMenu ) : <TAB> "" Call setupApp with each possible graphics type. "" <TAB> root = self . root <TAB> flist = FileList ( root ) <TAB> for tktype in alltypes : <TAB> <TAB> with self . subTest ( tktype = tktype ) : <TAB> <TAB> <TAB> macosx . _tk_type = tktype <TAB> <TAB> <TAB> macosx . setupApp ( root , flist ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( overrideRootMenu . called ) <TAB> <TAB> <TAB> overrideRootMenu . reset_mock ( )",if overrideRootMenu :,"if tktype in ( ""carbon"" , ""cocoa"" ) :",False,91.76,64.21,,,
"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB> <TAB> self . __storage ( None ) , <TAB> <TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB> <TAB> for b in s : <TAB> <TAB> <TAB> if persistent is not None and b . persistent != persistent : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name not in u : <TAB> <TAB> <TAB> <TAB> result . append ( b . name ) <TAB> <TAB> <TAB> <TAB> u . add ( b . name ) <TAB> return result",if b . is_superuser :,"if b . name . startswith ( ""__"" ) :",False,95.15,63.46,,,
"def _check_extra_specs ( key , value = None ) : <TAB> extra_specs = diff . get ( "" extra_specs "" ) <TAB> specific_type = extra_specs . get ( key ) if extra_specs else None <TAB> old_type = None <TAB> new_type = None <TAB> if specific_type : <TAB> <TAB> old_type , new_type = specific_type <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> old_type = True if old_type and old_type . upper ( ) == value else False <TAB> <TAB> <TAB> new_type = True if new_type and new_type . upper ( ) == value else False <TAB> return old_type , new_type",if old_type :,if value :,False,97.44,73.17,,,
"def _write_lock_file ( self , repo , force = True ) : # type: (Repository, bool) -> None <TAB> if force or (self._update and self._write_lock): <TAB> <TAB> updated_lock = self._locker.set_lock_data(self._package, repo.packages) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._io.write_line("""") <TAB> <TAB> <TAB> self._io.write_line(""<info>Writing lock file</>"")",if updated_lock :,if updated_lock :,True,100.0,98.7,,,
"def process_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" : <TAB> <TAB> batch_shape = msg [ "" fn "" ] . batch_shape <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> batch_shape = [ 1 ] * ( - self . dim - len ( batch_shape ) ) + list ( batch_shape ) <TAB> <TAB> <TAB> batch_shape [ self . dim ] = self . size <TAB> <TAB> <TAB> msg [ "" fn "" ] = msg [ "" fn "" ] . expand ( torch . Size ( batch_shape ) )",if self . dim != self . dim :,if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size :,False,86.72,66.86,,,
"def _test_reducibility ( self ) : <TAB> # make a copy of the graph <TAB> graph = networkx.DiGraph(self._graph) <TAB> # preprocess: make it a super graph <TAB> self._make_supergraph(graph) <TAB> while True: <TAB> <TAB> changed = False <TAB> <TAB> # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB> <TAB> changed |= self._remove_self_loop(graph) <TAB> <TAB> # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB> <TAB> # MultiNode) <TAB> <TAB> changed |= self._merge_single_entry_node(graph) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # a fixed-point is reached <TAB> <TAB> <TAB> break",if changed :,if not changed :,False,98.81,73.16,,,
"def __init__ ( self , roberta , num_classes = 2 , dropout = 0.0 , prefix = None , params = None ) : <TAB> super ( RoBERTaClassifier , self ) . __init__ ( prefix = prefix , params = params ) <TAB> self . roberta = roberta <TAB> self . _units = roberta . _units <TAB> with self . name_scope ( ) : <TAB> <TAB> self . classifier = nn . HybridSequential ( prefix = prefix ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB> <TAB> self . classifier . add ( nn . Dense ( units = self . _units , activation = "" tanh "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB> <TAB> self . classifier . add ( nn . Dense ( units = num_classes ) )",if roberta . _units is not None :,if dropout :,False,92.71,71.72,,,
"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB> <TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB> <TAB> if not o . name : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return o <TAB> if check_symlinks : <TAB> <TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB> <TAB> if m : <TAB> <TAB> <TAB> name = m [ 0 ] <TAB> <TAB> return self . get_object_from_name ( name , False )",if a . lower ( ) == name . lower ( ) :,if o . name . lower ( ) == name . lower ( ) :,False,97.83,73.01,,,
"def __call__ ( self ) : <TAB> """""" Run all check_* methods. """""" <TAB> if self . on : <TAB> <TAB> oldformatwarning = warnings . formatwarning <TAB> <TAB> warnings . formatwarning = self . formatwarning <TAB> <TAB> try : <TAB> <TAB> <TAB> for name in dir ( self ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr ( self , name ) <TAB> <TAB> <TAB> <TAB> <TAB> if method and callable ( method ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> warnings . formatwarning = oldformatwarning","if name . startswith ( ""check_"" ) and name . endswith ( ""check_"" ) :","if name . startswith ( ""check_"" ) :",False,95.09,96.61,,,
"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB> <TAB> print_func = str <TAB> else : <TAB> <TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB> <TAB> value = getattr ( self , k ) <TAB> <TAB> if not defaults and value == default_values [ k ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print_func = repr # keep quotes around strings <TAB> <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB> <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB> <TAB> return """"",if not print_func :,"if isinstance ( value , basestring ) :",False,97.05,71.43,,,
"def apply ( self , * * kwargs : Any ) - > None : <TAB> for node in self . document . traverse ( nodes . target ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> "" ismod "" in node <TAB> <TAB> <TAB> and node . parent . __class__ is nodes . section <TAB> <TAB> <TAB> and <TAB> <TAB> <TAB> # index 0 is the section title node <TAB> <TAB> <TAB> node.parent.index(node) == 1 <TAB> <TAB> ): <TAB> <TAB> <TAB> node.parent[""ids""][0:0] = node[""ids""] <TAB> <TAB> <TAB> node.parent.remove(node)",if node . id is None :,"if not node [ ""ids"" ] :",False,95.9,66.24,,,
"def add_special_token_2d ( <TAB> values : List [ List [ int ] ] , special_token : int = 0 , use_first_value : bool = False ) - > List [ List [ int ] ] : <TAB> results = torch . jit . annotate ( List [ List [ int ] ] , [ ] ) <TAB> for value in values : <TAB> <TAB> result = torch . jit . annotate ( List [ int ] , [ ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> special_token = value [ 0 ] <TAB> <TAB> result . append ( special_token ) <TAB> <TAB> result . extend ( value ) <TAB> <TAB> result . append ( special_token ) <TAB> <TAB> results . append ( result ) <TAB> return results",if use_first_value :,if use_first_value and len ( value ) > 0 :,False,95.59,71.28,,,
"def test_import ( self ) : <TAB> TIMEOUT = 5 <TAB> # Test for a deadlock when importing a module that runs the <TAB> # ThreadedResolver at import-time. See resolve_test.py for <TAB> # full explanation. <TAB> command = [sys.executable, ""-c"", ""import tornado.test.resolve_test_helper""] <TAB> start = time.time() <TAB> popen = Popen(command, preexec_fn=lambda: signal.alarm(TIMEOUT)) <TAB> while time.time() - start < TIMEOUT: <TAB> <TAB> return_code = popen.poll() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.assertEqual(0, return_code) <TAB> <TAB> <TAB> return # Success. <TAB> <TAB> time.sleep(0.05) <TAB> self.fail(""import timed out"")",if return_code != 0 :,if return_code is not None :,False,97.84,71.25,,,
"def find_item_for_key ( self , e ) : <TAB> for item in self . _items : <TAB> <TAB> if item . keycode == e . key and item . shift == e . shift and item . alt == e . alt : <TAB> <TAB> <TAB> focus = get_focus ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self . _items . index ( item ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return - 1 <TAB> return - 1",if focus == e . key :,"if self . command_is_enabled ( item , focus ) :",False,91.31,69.59,,,
"def check_app_config_brackets ( self ) : <TAB> for sn , app in cherrypy . tree . apps . items ( ) : <TAB> <TAB> if not isinstance ( app , cherrypy . Application ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for key in app . config . keys ( ) : <TAB> <TAB> <TAB> if key . startswith ( "" [ "" ) or key . endswith ( "" ] "" ) : <TAB> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> <TAB> "" The application mounted at  %r  has config  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" section names with extraneous brackets:  %r .  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Config *files* need brackets; config *dicts*  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" (e.g. passed to tree.mount) do not. "" % ( sn , key ) <TAB> <TAB> <TAB> <TAB> )","if not isinstance ( app , cherrypy . Application ) :",if not app . config :,False,96.69,72.61,,,
"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr(a, ""modules"", []): <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m.strip() <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self.modules: <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_name"", """").strip() == m: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if mod_type == mod . __name__ :,"if getattr ( mod , ""module_type"" , """" ) . strip ( ) == mod_type . strip ( ) :",False,91.48,62.44,,,
"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr(a, ""modules"", []): <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m.strip() <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self.modules: <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_name"", """").strip() == m: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if mod_type == mod . __name__ :,if not key in do_not_write,False,94.84,71.85,,,
"def parsing ( self , parsing ) : # type: (bool) -> None <TAB> self._parsed = parsing <TAB> for k, v in self._body: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v.value.parsing(parsing) <TAB> <TAB> elif isinstance(v, AoT): <TAB> <TAB> <TAB> for t in v.body: <TAB> <TAB> <TAB> <TAB> t.value.parsing(parsing)","if isinstance ( v , AoT ) :","if isinstance ( v , Table ) :",False,97.88,71.57,,,
"def test_crashers_crash ( self ) : <TAB> for fname in glob . glob ( CRASHER_FILES ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Some ""crashers"" only trigger an exception rather than a <TAB> <TAB> # segfault. Consider that an acceptable outcome. <TAB> <TAB> if test.support.verbose: <TAB> <TAB> <TAB> print(""Checking crasher:"", fname) <TAB> <TAB> assert_python_failure(fname)",if not os . path . exists ( fname ) :,if os . path . basename ( fname ) in infinite_loops :,False,92.77,68.37,,,
"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB> <TAB> if k . step is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB> <TAB> elif k . start is None : <TAB> <TAB> <TAB> raise ValueError ( "" Must specify start index "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB> <TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB> <TAB> addr = k <TAB> return self . _deeper ( addr = addr )",elif k . stop is None :,elif k . stop is not None :,False,98.87,73.72,,,
"def get_lowest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> <TAB> if lowest_wall > j [ "" wall_time "" ] : <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall",if lowest_wall is None :,if lowest_wall is None :,True,100.0,74.0,,,
"def extract_wav_headers ( data ) : <TAB> # def search_subchunk(data, subchunk_id): <TAB> pos = 12 # The size of the RIFF chunk descriptor <TAB> subchunks = [] <TAB> while pos + 8 <= len(data) and len(subchunks) < 10: <TAB> <TAB> subchunk_id = data[pos : pos + 4] <TAB> <TAB> subchunk_size = struct.unpack_from(""<I"", data[pos + 4 : pos + 8])[0] <TAB> <TAB> subchunks.append(WavSubChunk(subchunk_id, pos, subchunk_size)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # 'data' is the last subchunk <TAB> <TAB> <TAB> break <TAB> <TAB> pos += subchunk_size + 8 <TAB> return subchunks",if subchunk_id == 0 :,"if subchunk_id == b""data"" :",False,97.29,66.19,,,
"def _any_targets_have_native_sources ( self , targets ) : <TAB> # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB> # platform-specific packages (maybe find the platforms there too?). <TAB> for tgt in targets: <TAB> <TAB> for type_constraint, target_predicate in self._native_target_matchers.items(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if target_predicate ( tgt ) :,if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) :,False,90.6,68.0,,,
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> if v is None : # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value","if k . startswith ( ""Process"" ) :","if not re . match ( PROCTYPE_MATCH , k ) :",False,93.99,62.82,,,
"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB> <TAB> return False <TAB> for digit in reversed ( number ) : <TAB> <TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB> <TAB> if even : <TAB> <TAB> <TAB> digit * = 2 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit / / 10 <TAB> <TAB> digits . append ( digit ) <TAB> <TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False",if digit % 10 == 0 :,if digit >= 10 :,False,96.55,72.67,,,
"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB> <TAB> ctype , line , col , char = cmd <TAB> <TAB> if ctype == "" D "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB> <TAB> <TAB> <TAB> del buf [ line + 1 ] <TAB> <TAB> elif ctype == "" I "" : <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB> <TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf )",if char :,"if char != ""\n"" :",False,97.07,70.14,,,
"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { } # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB> <TAB> if edge.is_dangling(): <TAB> <TAB> <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <TAB> <TAB> if self._is_my_trace(edge): <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node, shared_axis = self._get_partner(edge) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> partners[partner_node] = set() <TAB> <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",if partner_node not in partners :,if partner_node not in partners :,True,100.0,74.25,,,
"def _bind_interactive_rez ( self ) : <TAB> if config . set_prompt and self . settings . prompt : <TAB> <TAB> stored_prompt = os . getenv ( "" REZ_STORED_PROMPT_CMD "" ) <TAB> <TAB> curr_prompt = stored_prompt or os . getenv ( "" PROMPT "" , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . setenv ( "" REZ_STORED_PROMPT_CMD "" , curr_prompt ) <TAB> <TAB> new_prompt = "" %% REZ_ENV_PROMPT %% "" <TAB> <TAB> new_prompt = ( <TAB> <TAB> <TAB> ( new_prompt + "" %s "" ) if config . prefix_prompt else ( "" %s "" + new_prompt ) <TAB> <TAB> ) <TAB> <TAB> new_prompt = new_prompt % curr_prompt <TAB> <TAB> self . _addline ( "" set PROMPT= %s "" % new_prompt )",if curr_prompt :,if not stored_prompt :,False,98.47,72.96,,,
"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB> <TAB> definition = column ( name ) <TAB> <TAB> if not definition : <TAB> <TAB> <TAB> IECore . msg ( <TAB> <TAB> <TAB> <TAB> IECore . Msg . Level . Error , <TAB> <TAB> <TAB> <TAB> "" GafferImageUI.CatalogueUI "" , <TAB> <TAB> <TAB> <TAB> "" No column registered with name  ' %s ' "" % name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB> <TAB> columns . append ( c ) <TAB> return columns",if definition . icon :,"if isinstance ( definition , IconColumn ) :",False,96.96,72.25,,,
"def _check_invalid_keys ( self , section_name , section ) : <TAB> for key in section : <TAB> <TAB> key_name = str ( key ) <TAB> <TAB> valid_key_names = [ s [ 0 ] for s in self . keys ] <TAB> <TAB> is_valid_key = key_name in valid_key_names <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> err_msg = ( <TAB> <TAB> <TAB> <TAB> "" ' {0} '  is not a valid key name for  ' {1} ' . Must  "" "" be one of these:  {2} "" <TAB> <TAB> <TAB> ) . format ( key_name , section_name , "" ,  "" . join ( valid_key_names ) ) <TAB> <TAB> <TAB> raise InvalidConfig ( err_msg )",if is_valid_key :,if not is_valid_key :,False,98.77,73.23,,,
"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB> <TAB> name = path . name <TAB> <TAB> if name == "" __pycache__ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> names . add ( name ) <TAB> if packages : <TAB> <TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB> <TAB> if len ( names & packages ) == len ( packages ) : <TAB> <TAB> <TAB> return packages <TAB> return names",elif name not in names :,"elif path . is_dir ( ) and ""."" not in name :",False,93.72,67.31,,,
"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB> <TAB> name = path . name <TAB> <TAB> if name == "" __pycache__ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> names . add ( name ) <TAB> if packages : <TAB> <TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB> <TAB> if len ( names & packages ) == len ( packages ) : <TAB> <TAB> <TAB> return packages <TAB> return names",elif name not in names :,"if k [ : 1 ] == ""-"" :",False,94.53,67.56,,,
"def iter_symbols ( code ) : <TAB> """""" Yield names and strings used by `code` and its nested code objects """""" <TAB> for name in code . co_names : <TAB> <TAB> yield name <TAB> for const in code . co_consts : <TAB> <TAB> if isinstance ( const , six . string_types ) : <TAB> <TAB> <TAB> yield const <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for name in iter_symbols ( const ) : <TAB> <TAB> <TAB> <TAB> yield name","elif isinstance ( const , ( list , tuple ) ) :","elif isinstance ( const , CodeType ) :",False,95.4,69.26,,,
"def set_study_directions ( <TAB> self , study_id : int , directions : Sequence [ StudyDirection ] ) - > None : <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> current_directions = self . _studies [ study_id ] . directions <TAB> <TAB> <TAB> if directions == current_directions : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif ( <TAB> <TAB> <TAB> <TAB> len ( current_directions ) == 1 <TAB> <TAB> <TAB> <TAB> and current_directions [ 0 ] == StudyDirection . NOT_SET <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> self . _studies [ study_id ] . directions = list ( directions ) <TAB> <TAB> <TAB> <TAB> self . _backend . set_study_directions ( study_id , directions ) <TAB> <TAB> <TAB> <TAB> return <TAB> self . _backend . set_study_directions ( study_id , directions )",if study_id in self . _studies :,if study_id in self . _studies :,True,100.0,74.55,,,
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList : <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid : <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1",if ReplacedLine :,if self . __Token :,False,95.63,71.62,,,
"def _check_blocking ( self , current_time ) : <TAB> if self . _switch_flag is False : <TAB> <TAB> active_greenlet = self . _active_greenlet <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _notify_greenlet_blocked ( active_greenlet , current_time ) <TAB> self . _switch_flag = False",if active_greenlet is not None :,if active_greenlet is not None and active_greenlet != self . _hub :,False,88.31,66.83,,,
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( r "" BlockDos \ .net "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",if retval :,if retval :,True,100.0,74.29,,,
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section : <TAB> <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >>END "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out",if line . startswith ( section_name ) :,"if line . startswith ( "">>%s"" % section_name ) :",False,96.6,68.28,,,
"def shortcut ( self , input , ch_out , stride , is_first , name ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> elif is_first : <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB> <TAB> return input",if is_first :,if is_first or stride == 1 :,False,96.55,72.04,,,
"def get_value_from_string ( self , string_value ) : <TAB> """""" Return internal representation starting from CFN/user-input value. """""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB> <TAB> if string_value is not None : <TAB> <TAB> <TAB> string_value = str ( string_value ) . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB> <TAB> self . pcluster_config . warn ( <TAB> <TAB> <TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB> <TAB> <TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB> <TAB> ) <TAB> return param_value",if param_value is None :,"if string_value != ""NONE"" :",False,96.08,81.52,,,
"def get_running ( workers ) : <TAB> running = [ ] <TAB> for worker in workers : <TAB> <TAB> current_test_name = worker . current_test_name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = time . monotonic ( ) - worker . start_time <TAB> <TAB> if dt > = PROGRESS_MIN_TIME : <TAB> <TAB> <TAB> text = "" %s  ( %s ) "" % ( current_test_name , format_duration ( dt ) ) <TAB> <TAB> <TAB> running . append ( text ) <TAB> return running","if current_test_name == ""test"" :",if not current_test_name :,False,94.9,63.6,,,
"def generate_data ( self , request ) : <TAB> """""" Generate data for the widget. """""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB> <TAB> for hosts , stats in cache_stats : <TAB> <TAB> <TAB> if stats [ "" uptime "" ] > 86400 : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime }","elif stats [ ""uptime"" ] > 24 :","elif stats [ ""uptime"" ] > 3600 :",False,99.16,99.04,,,
"def add_actors ( self ) : <TAB> """""" Adds `self.actors` to the scene. """""" <TAB> if not self . _actors_added : <TAB> <TAB> self . reader . render_window = self . scene . render_window <TAB> <TAB> self . _update_reader ( ) <TAB> <TAB> self . _actors_added = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _visible_changed ( self . visible ) <TAB> <TAB> self . scene . render ( )",if self . visible :,if not self . visible :,False,98.09,81.14,,,
"def _add_uniqu_suffix ( self , titles ) : <TAB> counters = dict ( ) <TAB> titles_with_suffix = [ ] <TAB> for title in titles : <TAB> <TAB> counters [ title ] = counters [ title ] + 1 if title in counters else 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> title = f "" { title }  ( { counters [ title ] } ) "" <TAB> <TAB> titles_with_suffix . append ( title ) <TAB> return titles_with_suffix",if title not in counters :,if counters [ title ] > 1 :,False,94.4,70.13,,,
"def _verify_udf_resources ( self , job , config ) : <TAB> udf_resources = config . get ( "" userDefinedFunctionResources "" , ( ) ) <TAB> self . assertEqual ( len ( job . udf_resources ) , len ( udf_resources ) ) <TAB> for found , expected in zip ( job . udf_resources , udf_resources ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( found . udf_type , "" resourceUri "" ) <TAB> <TAB> <TAB> self . assertEqual ( found . value , expected [ "" resourceUri "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( found . udf_type , "" inlineCode "" ) <TAB> <TAB> <TAB> self . assertEqual ( found . value , expected [ "" inlineCode "" ] )",if found . is_resource_uri :,"if ""resourceUri"" in expected :",False,95.58,68.72,,,
"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """""" Constructor. """""" <TAB> self . layout = layout <TAB> if value is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB> <TAB> self . value = np . array ( value ) <TAB> <TAB> if self . value . shape != ( self . layout . gaDims , ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB> <TAB> <TAB> )",if string is None :,if string is None :,True,100.0,99.61,,,
"def read_file ( filename , print_error = True ) : <TAB> """""" Returns the contents of a file. """""" <TAB> try : <TAB> <TAB> for encoding in [ "" utf-8 "" , "" latin1 "" ] : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> with io . open ( filename , encoding = encoding ) as fp : <TAB> <TAB> <TAB> <TAB> <TAB> return fp . read ( ) <TAB> <TAB> <TAB> except UnicodeDecodeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> except IOError as exception : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( exception , file = sys . stderr ) <TAB> <TAB> return None",if print_error :,if print_error :,True,100.0,99.45,,,
"def get_albums_for_iter ( self , iter_ ) : <TAB> obj = self . get_value ( iter_ ) <TAB> if isinstance ( obj , AlbumNode ) : <TAB> <TAB> return { obj . album } <TAB> albums = set ( ) <TAB> for child_iter , value in self . iterrows ( iter_ ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> albums . add ( value . album ) <TAB> <TAB> else : <TAB> <TAB> <TAB> albums . update ( self . get_albums_for_iter ( child_iter ) ) <TAB> return albums","if isinstance ( value , AlbumNode ) :","if isinstance ( value , AlbumNode ) :",True,100.0,74.34,,,
"def wait_til_ready ( cls , connector = None ) : <TAB> if connector is None : <TAB> <TAB> connector = cls . connector <TAB> while True : <TAB> <TAB> now = time . time ( ) <TAB> <TAB> next_iteration = now / / 1.0 + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> await cls . _clock . run_til ( next_iteration ) <TAB> <TAB> await asyncio . sleep ( 1.0 )",if cls . _clock . is_connected ( connector ) :,if connector . ready :,False,91.38,70.47,,,
"def remove_property ( self , key ) : # type: (str) -> None <TAB> with self.secure() as config: <TAB> <TAB> keys = key.split(""."") <TAB> <TAB> current_config = config <TAB> <TAB> for i, key in enumerate(keys): <TAB> <TAB> <TAB> if key not in current_config: <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del current_config[key] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config[key]",if i == len ( keys ) - 1 :,if i == len ( keys ) - 1 :,True,100.0,74.24,,,
"def get ( self , hash160 , default = None ) : <TAB> v = self . p2s_for_hash ( hash160 ) <TAB> <IF-STMT> <TAB> <TAB> return v <TAB> if hash160 not in self . _secret_exponent_cache : <TAB> <TAB> v = self . path_for_hash160 ( hash160 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fingerprint , path = v <TAB> <TAB> <TAB> for key in self . _secrets . get ( fingerprint , [ ] ) : <TAB> <TAB> <TAB> <TAB> subkey = key . subkey_for_path ( path ) <TAB> <TAB> <TAB> <TAB> self . _add_key_to_cache ( subkey ) <TAB> return self . _secret_exponent_cache . get ( hash160 , default )",if v :,if v :,True,100.0,74.45,,,
"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> targets = tuple( <TAB> <TAB> <TAB> <TAB> targets, <TAB> <TAB> <TAB> ) <TAB> <TAB> elif type(targets) != tuple: <TAB> <TAB> <TAB> targets = tuple(targets) <TAB> for target in targets: <TAB> <TAB> self._fetch_targets(api_client, q, target)",if type ( targets ) == list :,if type ( targets ) != list and type ( targets ) != tuple :,False,92.92,68.37,,,
"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB> <TAB> data = zip ( * data ) <TAB> <TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( dt , dgl . DGLGraph ) : <TAB> <TAB> <TAB> <TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB> <TAB> <TAB> elif isinstance ( dt , nd . NDArray ) : <TAB> <TAB> <TAB> <TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB> <TAB> <TAB> <TAB> data_list = [ dt for dt in data if dt is not None ] <TAB> <TAB> <TAB> <TAB> return pad ( data_list )","if isinstance ( dt , dgl . DGLGraph ) :",if dt is not None :,False,96.05,72.01,,,
"def capture_server ( evt , buf , serv ) : <TAB> try : <TAB> <TAB> serv . listen ( 5 ) <TAB> <TAB> conn , addr = serv . accept ( ) <TAB> except socket . timeout : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> n = 200 <TAB> <TAB> while n > 0 : <TAB> <TAB> <TAB> r , w , e = select . select ( [ conn ] , [ ] , [ ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = conn . recv ( 10 ) <TAB> <TAB> <TAB> <TAB> # keep everything except for the newline terminator <TAB> <TAB> <TAB> <TAB> buf.write(data.replace(""\n"", """")) <TAB> <TAB> <TAB> <TAB> if ""\n"" in data: <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> n -= 1 <TAB> <TAB> <TAB> time.sleep(0.01) <TAB> <TAB> conn.close() <TAB> finally: <TAB> <TAB> serv.close() <TAB> <TAB> evt.set()",if r :,if r :,True,100.0,74.58,,,
"def elem ( ) : <TAB> if ints_only : <TAB> <TAB> return random . randint ( 0 , 10000000000 ) <TAB> else : <TAB> <TAB> t = random . randint ( 0 , 2 ) <TAB> <TAB> if t == 0 : <TAB> <TAB> <TAB> return random . randint ( 0 , 10000000000 ) <TAB> <TAB> elif t == 1 : <TAB> <TAB> <TAB> return float ( random . randint ( 0 , 10000000000 ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return strings [ random . randint ( 0 , len ( strings ) - 1 ) ] <TAB> <TAB> return random_string ( random . randint ( 100 , 1000 ) )",elif t == 2 :,elif strings is not None :,False,96.73,71.77,,,
"def has_changed ( self , initial , data ) : <TAB> if self . disabled : <TAB> <TAB> return False <TAB> if initial is None : <TAB> <TAB> initial = [ "" "" for x in range ( 0 , len ( data ) ) ] <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> initial = self . widget . decompress ( initial ) <TAB> for field , initial , data in zip ( self . fields , initial , data ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> initial = field . to_python ( initial ) <TAB> <TAB> except ValidationError : <TAB> <TAB> <TAB> return True <TAB> <TAB> if field . has_changed ( initial , data ) : <TAB> <TAB> <TAB> return True <TAB> return False",if self . widget :,"if not isinstance ( initial , list ) :",False,95.73,71.47,,,
"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB> <TAB> package = _normalize_module ( package , 3 ) <TAB> <TAB> filename = _module_relative_path ( package , filename ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if hasattr ( package . __loader__ , "" get_data "" ) : <TAB> <TAB> <TAB> <TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename","if hasattr ( package , ""__loader__"" ) :","if hasattr ( package , ""__loader__"" ) :",True,100.0,74.43,,,
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> if self . owner != tid : <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> if self . count == 0 : <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( )",if self . waiters > 0 :,if self . waiters :,False,97.85,73.2,,,
"def stage ( <TAB> self , x , num_modules , num_blocks , channels , multi_scale_output = True , name = None ) : <TAB> out = x <TAB> for i in range ( num_modules ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out = self . high_resolution_module ( <TAB> <TAB> <TAB> <TAB> out , <TAB> <TAB> <TAB> <TAB> num_blocks , <TAB> <TAB> <TAB> <TAB> channels , <TAB> <TAB> <TAB> <TAB> multi_scale_output = False , <TAB> <TAB> <TAB> <TAB> name = name + "" _ "" + str ( i + 1 ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out = self . high_resolution_module ( <TAB> <TAB> <TAB> <TAB> out , num_blocks , channels , name = name + "" _ "" + str ( i + 1 ) <TAB> <TAB> <TAB> ) <TAB> return out",if i < num_modules - 1 :,if i == num_modules - 1 and multi_scale_output == False :,False,94.79,71.71,,,
"def changeFrontAlteration ( intV , alter ) : <TAB> # fati = front alteration transpose interval <TAB> fati = self.frontAlterationTransposeInterval <TAB> if fati: <TAB> <TAB> newFati = interval.add([fati, intV]) <TAB> <TAB> self.frontAlterationTransposeInterval = newFati <TAB> <TAB> self.frontAlterationAccidental.alter = ( <TAB> <TAB> <TAB> self.frontAlterationAccidental.alter + alter <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.frontAlterationTransposeInterval = None <TAB> <TAB> <TAB> self.frontAlterationAccidental = None <TAB> else: <TAB> <TAB> self.frontAlterationTransposeInterval = intV <TAB> <TAB> self.frontAlterationAccidental = pitch.Accidental(alter)",if self . frontAlterationAccidental . alter == 0 :,if self . frontAlterationAccidental . alter == 0 :,True,100.0,74.23,,,
"def set_to_train ( self ) : <TAB> for T in self . trainable_attributes ( ) : <TAB> <TAB> for k , v in T . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> c_f . set_requires_grad ( v , requires_grad = False ) <TAB> <TAB> <TAB> <TAB> v . eval ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> v . train ( ) <TAB> self . maybe_freeze_trunk_batchnorm ( )","if k == ""train"" :",if k in self . freeze_these :,False,94.88,62.42,,,
"def _migrate ( self , sig = None , compact = True ) : <TAB> with self . lock : <TAB> <TAB> sig = sig or self . sig <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if sig in self . WORDS and len ( self . WORDS [ sig ] ) > 0 : <TAB> <TAB> <TAB> PostingList . Append ( <TAB> <TAB> <TAB> <TAB> self . session , sig , self . WORDS [ sig ] , sig = sig , compact = compact <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self . WORDS [ sig ]",if not self . session :,if sig in GPL_NEVER_MIGRATE :,False,94.53,71.95,,,
"def on_prediction_step ( self , args , state , control , eval_dataloader = None , * * kwargs ) : <TAB> if self . prediction_bar is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . prediction_bar = self . training_tracker . add_child ( len ( eval_dataloader ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . prediction_bar = NotebookProgressBar ( len ( eval_dataloader ) ) <TAB> <TAB> self . prediction_bar . update ( 1 ) <TAB> else : <TAB> <TAB> self . prediction_bar . update ( self . prediction_bar . value + 1 )",if self . training_tracker :,if self . training_tracker is not None :,False,97.21,71.74,,,
"def show ( self , indent = 0 ) : <TAB> """""" Pretty print this structure. """""" <TAB> if indent == 0 : <TAB> <TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB> <TAB> if field . offset is None : <TAB> <TAB> <TAB> offset = "" 0x?? "" <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB> <TAB> print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field . type . show ( indent + 1 )","if isinstance ( field . type , struct . StructField ) :","if isinstance ( field . type , Structure ) :",False,97.74,98.3,,,
"def __exit__ ( self , exc , value , tb ) : <TAB> for key in self . overrides . keys ( ) : <TAB> <TAB> old_value = self . old [ key ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> delattr ( self . instance , key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( self . instance , key , old_value ) <TAB> self . instance . save ( )",if old_value is None :,if old_value is NULL :,False,97.78,72.55,,,
"def complete ( self , block ) : <TAB> with self . _condition : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . _complete ( ) : <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> if block : <TAB> <TAB> <TAB> self . _condition . wait_for ( self . _complete ) <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",if self . _state_root_if_not_already_done :,if not self . _final :,False,92.28,71.3,,,
"def parseArguments ( self ) : <TAB> args = [ ] <TAB> self . expect ( "" ( "" ) <TAB> if not self . match ( "" ) "" ) : <TAB> <TAB> while self . startIndex < self . length : <TAB> <TAB> <TAB> args . append ( self . isolateCoverGrammar ( self . parseAssignmentExpression ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self . expectCommaSeparator ( ) <TAB> self . expect ( "" ) "" ) <TAB> return args",if self . startIndex >= self . length :,"if self . match ( "")"" ) :",False,94.45,66.23,,,
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> if value == "" DD-MM-YYYY "" : <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value )",if int ( day ) < 1 or int ( day ) > 7 :,if int ( day ) < 1 or int ( day ) > 31 :,False,98.85,73.69,,,
"def build_tree ( path ) : <TAB> tree = Tree ( ) <TAB> for basename , entry in trees [ path ] . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mode = stat . S_IFDIR <TAB> <TAB> <TAB> sha = build_tree ( pathjoin ( path , basename ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ( mode , sha ) = entry <TAB> <TAB> tree . add ( basename , mode , sha ) <TAB> object_store . add_object ( tree ) <TAB> return tree . id","if entry [ ""mode"" ] == stat . S_IXGRP :","if isinstance ( entry , dict ) :",False,90.52,61.84,,,
"def get_quarantine_count ( self ) : <TAB> """""" get obj/container/account quarantine counts """""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB> <TAB> for qtype in qcounts : <TAB> <TAB> <TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB> <TAB> <TAB> <TAB> if linkcount > 2 : <TAB> <TAB> <TAB> <TAB> <TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts",if os . path . exists ( qtgt ) :,if os . path . exists ( qtgt ) :,True,100.0,99.53,,,
"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB> <TAB> return False <TAB> for dim_value in shape : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if dim_value < 0 : <TAB> <TAB> <TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True",if dim_value is None or dim_value is None or dim_value is None or dim_value is None :,"if not isinstance ( dim_value , int ) :",False,82.47,66.53,,,
"def BraceDetectAll ( words ) : <TAB> # type: (List[compound_word]) -> List[word_t] <TAB> """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB> out = [] # type: List[word_t] <TAB> for w in words: <TAB> <TAB> # The shortest possible brace expansion is {,}. This heuristic prevents <TAB> <TAB> # a lot of garbage from being created, since otherwise nearly every word <TAB> <TAB> # would be checked. We could be even more precise but this is cheap. <TAB> <TAB> if len(w.parts) >= 3: <TAB> <TAB> <TAB> brace_tree = _BraceDetect(w) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> out.append(brace_tree) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> out.append(w) <TAB> return out",if brace_tree :,if brace_tree :,True,100.0,74.45,,,
"def __init__ ( original , self , * args , * * kwargs ) : <TAB> data = args [ 0 ] if len ( args ) > 0 else kwargs . get ( "" data "" ) <TAB> if data is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> <TAB> "" cannot gather example input when dataset is loaded from a file. "" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo ( <TAB> <TAB> <TAB> <TAB> input_example = deepcopy ( data [ : INPUT_EXAMPLE_SAMPLE_ROWS ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo ( error_msg = str ( e ) ) <TAB> <TAB> setattr ( self , "" input_example_info "" , input_example_info ) <TAB> original ( self , * args , * * kwargs )",if not data . endswith ( INPUT_EXAMPLE_SAMPLE_ROWS ) :,"if isinstance ( data , str ) :",False,95.26,72.6,,,
"def setRow ( self , row , vals ) : <TAB> if row > self . rowCount ( ) - 1 : <TAB> <TAB> self . setRowCount ( row + 1 ) <TAB> for col in range ( len ( vals ) ) : <TAB> <TAB> val = vals [ col ] <TAB> <TAB> item = self . itemClass ( val , row ) <TAB> <TAB> item . setEditable ( self . editable ) <TAB> <TAB> sortMode = self . sortModes . get ( col , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> item . setSortMode ( sortMode ) <TAB> <TAB> format = self . _formats . get ( col , self . _formats [ None ] ) <TAB> <TAB> item . setFormat ( format ) <TAB> <TAB> self . items . append ( item ) <TAB> <TAB> self . setItem ( row , col , item ) <TAB> <TAB> item . setValue ( val ) # Required--the text-change callback is invoked",if sortMode :,if sortMode is not None :,False,97.97,72.94,,,
"def wakeUp ( self ) : <TAB> """""" Write one byte to the pipe, and flush it. """""" <TAB> # We don't use fdesc.writeToFD since we need to distinguish <TAB> # between EINTR (try again) and EAGAIN (do nothing). <TAB> if self.o is not None: <TAB> <TAB> try: <TAB> <TAB> <TAB> util.untilConcludes(os.write, self.o, b""x"") <TAB> <TAB> except OSError as e: <TAB> <TAB> <TAB> # XXX There is no unit test for raising the exception <TAB> <TAB> <TAB> # for other errnos. See #4285. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise",if e . errno != errno . EINTR :,if e . errno != errno . EAGAIN :,False,98.62,73.15,,,
"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model references. <TAB> resolved_classes = [] <TAB> for m in self.model_classes: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if m == owner_model.__name__: <TAB> <TAB> <TAB> <TAB> resolved_classes.append(owner_model) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> ""PolyModelType: Unable to resolve model '{}'."".format(m) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> resolved_classes.append(m) <TAB> self.model_classes = tuple(resolved_classes) <TAB> super(PolyModelType, self)._setup(field_name, owner_model)","if isinstance ( owner_model , types . ModelType ) :","if isinstance ( m , string_type ) :",False,96.67,71.38,,,
"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self._late_binding_returnvalues.get(key, KeyError) <TAB> <TAB> if value_ is KeyError: <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self._eval_late_binding(value) <TAB> <TAB> <TAB> schema = self.late_bind_schemas.get(key) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value_ = schema.validate(value_) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self._late_binding_returnvalues[key] = value_ <TAB> <TAB> return value_ <TAB> else: <TAB> <TAB> return value",if schema :,if schema is not None :,False,98.09,71.87,,,
"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB> <TAB> arg = arg [ 1 : ] <TAB> try : <TAB> <TAB> value = int ( arg , base = 16 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB> <TAB> arg = arg . replace ( "" "" , "" _ "" ) <TAB> <TAB> method = getattr ( discord . Colour , arg , None ) <TAB> <TAB> if arg . startswith ( "" from_ "" ) or method is None or not inspect . ismethod ( method ) : <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return method ( )",if value < 0 :,if not ( 0 <= value <= 0xFFFFFF ) :,False,95.18,71.84,,,
"def get_versions ( * , all = False , quiet = None ) : <TAB> import bonobo <TAB> from bonobo . util . pkgs import bonobo_packages <TAB> yield _format_version ( bonobo , quiet = quiet ) <TAB> if all : <TAB> <TAB> for name in sorted ( bonobo_packages ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> mod = __import__ ( name . replace ( "" - "" , "" _ "" ) ) <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield _format_version ( mod , name = name , quiet = quiet ) <TAB> <TAB> <TAB> <TAB> <TAB> except Exception as exc : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield "" {}  ( {} ) "" . format ( name , exc ) <TAB> <TAB> <TAB> <TAB> except ImportError as exc : <TAB> <TAB> <TAB> <TAB> <TAB> yield "" {}  is not importable ( {} ). "" . format ( name , exc )","if name . endswith ( "".py"" ) :","if name != ""bonobo"" :",False,96.96,73.24,,,
"def assertOperationsInjected ( self , plan , * * kwargs ) : <TAB> for migration , _backward in plan : <TAB> <TAB> operations = iter ( migration . operations ) <TAB> <TAB> for operation in operations : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> next_operation = next ( operations ) <TAB> <TAB> <TAB> <TAB> self . assertIsInstance ( <TAB> <TAB> <TAB> <TAB> <TAB> next_operation , contenttypes_management . RenameContentType <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . app_label , migration . app_label ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . old_model , operation . old_name_lower ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . new_model , operation . new_name_lower )","if isinstance ( operation , contenttypes_management . RenameContentType ) :","if isinstance ( operation , migrations . RenameModel ) :",False,97.33,72.88,,,
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> if line == """": <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",if strip_delimiters :,if strip_delimiters :,True,100.0,99.41,,,
"def read_lccn ( line , is_marc8 = False ) : <TAB> found = [ ] <TAB> for k , v in get_raw_subfields ( line , [ "" a "" ] ) : <TAB> <TAB> lccn = v . strip ( ) <TAB> <TAB> if re_question . match ( lccn ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re_lccn . search ( lccn ) <TAB> <TAB> if not m : <TAB> <TAB> <TAB> continue <TAB> <TAB> # remove letters and bad chars <TAB> <TAB> lccn = re_letters_and_bad.sub("""", m.group(1)).strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> found.append(lccn) <TAB> return found",if is_marc8 and lccn :,if lccn :,False,97.17,69.0,,,
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> elif name == "" mean_module.constant "" : <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","elif name == ""mean_module.raw_outputscale"" :","elif name == ""covar_module.base_kernel.raw_lengthscale"" :",False,95.6,73.54,,,
"def _cleanupSocket ( self ) : <TAB> """""" Close the Connection ' s socket. """""" <TAB> try : <TAB> <TAB> self . _sock . shutdown ( socket . SHUT_WR ) <TAB> except : <TAB> <TAB> return <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r , w , e = select . select ( [ self . _sock ] , [ ] , [ ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> except : <TAB> <TAB> pass <TAB> self . _sock . close ( )",if r == w :,if not r or not self . _sock . recv ( 1024 ) :,False,91.18,63.7,,,
"def fadeIn ( self , acts = None , t = None , duration = None ) : <TAB> """""" Gradually switch on the input list of meshes by increasing opacity. """""" <TAB> if self . bookingMode : <TAB> <TAB> acts , t , duration , rng = self . _parse ( acts , t , duration ) <TAB> <TAB> for tt in rng : <TAB> <TAB> <TAB> alpha = linInterpolate ( tt , [ t , t + duration ] , [ 0 , 1 ] ) <TAB> <TAB> <TAB> self . events . append ( ( tt , self . fadeIn , acts , alpha ) ) <TAB> else : <TAB> <TAB> for a in self . _performers : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> a . alpha ( self . _inputvalues ) <TAB> return self",if not a . enabled :,if a . alpha ( ) >= self . _inputvalues :,False,94.48,93.28,,,
"def get_config_updates_recursive ( self ) : <TAB> config_updates = self . config_updates . copy ( ) <TAB> for sr_path , subrunner in self . subrunners . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> update = subrunner . get_config_updates_recursive ( ) <TAB> <TAB> if update : <TAB> <TAB> <TAB> config_updates [ rel_path ( self . path , sr_path ) ] = update <TAB> return config_updates",if not subrunner :,"if not is_prefix ( self . path , sr_path ) :",False,90.01,68.38,,,
"def setArgs ( self , * * kwargs ) : <TAB> """""" See GridSearchCostGamma """""" <TAB> for key , value in list ( kwargs . items ( ) ) : <TAB> <TAB> if key in ( "" folds "" , "" nfolds "" ) : <TAB> <TAB> <TAB> self . _n_folds = int ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _validator_kwargs [ "" max_epochs "" ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> GridSearchDOE . setArgs ( self , * * { key : value } )","if key == ""max_epochs"" :","elif key in ( ""max_epochs"" ) :",False,94.72,93.28,,,
"def _parse_composite_axis ( composite_axis_name : str ) : <TAB> axes_names = [ axis for axis in composite_axis_name . split ( "" "" ) if len ( axis ) > 0 ] <TAB> for axis in axes_names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> assert "" a "" < = axis [ 0 ] < = "" z "" <TAB> <TAB> for letter in axis : <TAB> <TAB> <TAB> assert str . isdigit ( letter ) or "" a "" < = letter < = "" z "" <TAB> return axes_names",if not axis :,"if axis == ""_"" :",False,95.06,68.27,,,
"def visit_For ( self , node , for_branch = "" body "" , * * kwargs ) : <TAB> if for_branch == "" body "" : <TAB> <TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB> <TAB> branch = node . body <TAB> elif for_branch == "" else "" : <TAB> <TAB> branch = node . else_ <TAB> elif for_branch == "" test "" : <TAB> <TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . sym_visitor . visit ( node . test ) <TAB> <TAB> return <TAB> else : <TAB> <TAB> raise RuntimeError ( "" Unknown for branch "" ) <TAB> for item in branch or ( ) : <TAB> <TAB> self . sym_visitor . visit ( item )","elif for_branch == ""test"" :",if node . test is not None :,False,95.45,66.91,,,
def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,"if node . type == ""text"" :",if not any ( [ not is_text ( s ) for s in node . contents ] ) :,False,79.29,35.67,,,
def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,"if node . type == ""text"" :","if path . endswith ( "":"" ) :",False,89.98,67.74,,,
"def validate_employee_id ( self ) : <TAB> if self . employee : <TAB> <TAB> sales_person = frappe . db . get_value ( "" Sales Person "" , { "" employee "" : self . employee } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Another Sales Person  {0}  exists with the same Employee id "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> sales_person <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if sales_person :,if sales_person and sales_person != self . name :,False,93.13,70.03,,,
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/infer "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""init"" not in item . keywords :","if ""init"" not in item . keywords :",True,100.0,74.3,,,
"def poll ( self , timeout ) : <TAB> if timeout < 0 : <TAB> <TAB> timeout = None # kqueue behaviour <TAB> events = self._kqueue.control(None, KqueueLoop.MAX_EVENTS, timeout) <TAB> results = defaultdict(lambda: POLL_NULL) <TAB> for e in events: <TAB> <TAB> fd = e.ident <TAB> <TAB> if e.filter == select.KQ_FILTER_READ: <TAB> <TAB> <TAB> results[fd] |= POLL_IN <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results[fd] |= POLL_OUT <TAB> return results.items()",elif e . filter == select . KQ_FILTER_WRITE :,elif e . filter == select . KQ_FILTER_WRITE :,True,100.0,74.18,,,
"def _read_dimensions ( self , * dimnames , * * kwargs ) : <TAB> path = kwargs . get ( "" path "" , "" / "" ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ self . rootgrp . dimensions [ dname ] for dname in dimnames ] <TAB> <TAB> group = self . path2group [ path ] <TAB> <TAB> return [ group . dimensions [ dname ] for dname in dimnames ] <TAB> except KeyError : <TAB> <TAB> raise self . Error ( <TAB> <TAB> <TAB> "" In file  %s : \n Error while reading dimensions: ` %s ` with kwargs: ` %s ` "" <TAB> <TAB> <TAB> % ( self . path , dimnames , kwargs ) <TAB> <TAB> )",if path == self . rootgrp . path :,"if path == ""/"" :",False,96.51,67.84,,,
"def spam_to_me ( address ) : <TAB> sock = eventlet . connect ( address ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> sock . sendall ( b "" hello world "" ) <TAB> <TAB> <TAB> # Arbitrary delay to not use all available CPU, keeps the test <TAB> <TAB> <TAB> # running quickly and reliably under a second <TAB> <TAB> <TAB> time.sleep(0.001) <TAB> <TAB> except socket.error as e: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise",if e . args [ 0 ] == errno . ECONNRESET :,if get_errno ( e ) == errno . EPIPE :,False,94.05,69.77,,,
"def has_hash_of ( self , destpath , code , package_level ) : <TAB> """""" Determine if a file has the hash of the code. """""" <TAB> if destpath is not None and os . path . isfile ( destpath ) : <TAB> <TAB> with univ_open ( destpath , "" r "" ) as opened : <TAB> <TAB> <TAB> compiled = readfile ( opened ) <TAB> <TAB> hashash = gethash ( compiled ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if hashash == code :,"if hashash is not None and hashash == self . comp . genhash ( code , package_level ) :",False,86.43,60.67,,,
"def insert ( self , index , item ) : <TAB> if len ( self . lists ) == 1 : <TAB> <TAB> self . lists [ 0 ] . insert ( index , item ) <TAB> <TAB> self . _balance_list ( 0 ) <TAB> else : <TAB> <TAB> list_idx , rel_idx = self . _translate_index ( index ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IndexError ( ) <TAB> <TAB> self . lists [ list_idx ] . insert ( rel_idx , item ) <TAB> <TAB> self . _balance_list ( list_idx ) <TAB> return",if list_idx == 0 :,if list_idx is None :,False,97.1,72.18,,,
"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB> <TAB> if isinstance ( sym , ast . FunctionDef ) : <TAB> <TAB> <TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = _parse_class_simplified ( sym ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB> <TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results","elif isinstance ( sym , ast . ClassDef ) :","elif isinstance ( sym , ast . ClassDef ) :",True,100.0,74.6,,,
"def append_vars ( pairs , result ) : <TAB> for name , value in sorted ( pairs . items ( ) ) : <TAB> <TAB> if isinstance ( value , list ) : <TAB> <TAB> <TAB> value = "" [ %s ] "" % "" , "" . join ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( "" %s : %s = %s "" % ( package , name , value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( "" %s = %s "" % ( name , value ) )",if package :,if package :,True,100.0,74.38,,,
"def nextEditable ( self ) : <TAB> """""" Moves focus of the cursor to the next editable window """""" <TAB> if self . currentEditable is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> if ref in self . _editableChildren : <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei > = len ( self . _editableChildren ) : <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable",if len ( self . _editableChildren ) == 1 :,if len ( self . _editableChildren ) :,False,98.0,85.43,,,
"def everythingIsUnicode ( d ) : <TAB> """""" Takes a dictionary, recursively verifies that every value is unicode """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True","elif isinstance ( i , unicode ) :","elif isinstance ( v , _bytes ) :",False,97.71,73.13,,,
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> if s is None : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","elif isinstance ( s , ( list , tuple ) ) and len ( s ) == 0 :","elif isinstance ( s , np . ndarray ) and s . size == 0 :",False,92.95,69.72,,,
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB> <TAB> <TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] [ ""exp"" ] == ""true"" :","if conf [ ""properties"" ] [ ""attributes"" ] [ ""exp"" ] :",False,91.17,68.86,,,
"def encode ( self ) : <TAB> if self . expr in gpregs . expr : <TAB> <TAB> self . value = gpregs . expr . index ( self . expr ) <TAB> <TAB> self . parent . rot2 . value = 0 <TAB> elif isinstance ( self . expr , ExprOp ) and self . expr . op == allshifts [ 3 ] : <TAB> <TAB> reg , value = self . expr . args <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> self . value = gpregs . expr . index ( reg ) <TAB> <TAB> if not isinstance ( value , ExprInt ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> value = int ( value ) <TAB> <TAB> if not value in [ 8 , 16 , 24 ] : <TAB> <TAB> <TAB> return False <TAB> <TAB> self . parent . rot2 . value = value / / 8 <TAB> return True",if reg not in gpregs . expr :,if reg not in gpregs . expr :,True,100.0,74.63,,,
"def validate_transaction_reference ( self ) : <TAB> bank_account = self . paid_to if self . payment_type == "" Receive "" else self . paid_from <TAB> bank_account_type = frappe . db . get_value ( "" Account "" , bank_account , "" account_type "" ) <TAB> if bank_account_type == "" Bank "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Reference No and Reference Date is mandatory for Bank transaction "" ) <TAB> <TAB> <TAB> )",if not self . reference_date :,if not self . reference_no or not self . reference_date :,False,95.41,71.41,,,
"def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB> <TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB> <TAB> if hasattr ( monad , "" cls_bl_idname "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None",if monad . cls_bl_idname == self . cls_bl_idname :,if monad . cls_bl_idname == self . cls_bl_idname :,True,100.0,74.02,,,
"def _create_mask ( self , plen ) : <TAB> mask = [ ] <TAB> for i in range ( 16 ) : <TAB> <TAB> if plen > = 8 : <TAB> <TAB> <TAB> mask . append ( 0xFF ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mask . append ( 0xFF >> ( 8 - plen ) << ( 8 - plen ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask . append ( 0x00 ) <TAB> <TAB> plen - = 8 <TAB> return mask",elif plen < 8 :,elif plen > 0 :,False,97.35,72.34,,,
"def dataset_to_stream ( dataset , input_name ) : <TAB> """""" Takes a tf.Dataset and creates a numpy stream of ready batches. """""" <TAB> # All input-pipeline processing should be on CPU. <TAB> for example in fastmath.dataset_as_numpy(dataset): <TAB> <TAB> features = example[0] <TAB> <TAB> inp, out = features[input_name], example[1] <TAB> <TAB> mask = features[""mask""] if ""mask"" in features else None <TAB> <TAB> # Some accelerators don't handle uint8 well, cast to int. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> inp = inp.astype(np.int32) <TAB> <TAB> if isinstance(out, np.uint8): <TAB> <TAB> <TAB> out = out.astype(np.int32) <TAB> <TAB> yield (inp, out) if mask is None else (inp, out, mask)","if isinstance ( inp , np . uint8 ) :","if isinstance ( inp , np . uint8 ) :",True,100.0,74.47,,,
"def _idle_redraw_cb ( self ) : <TAB> assert self . _idle_redraw_src_id is not None <TAB> queue = self . _idle_redraw_queue <TAB> if len ( queue ) > 0 : <TAB> <TAB> bbox = queue . pop ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> super ( CanvasRenderer , self ) . queue_draw ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> super ( CanvasRenderer , self ) . queue_draw_area ( * bbox ) <TAB> if len ( queue ) == 0 : <TAB> <TAB> self . _idle_redraw_src_id = None <TAB> <TAB> return False <TAB> return True",if bbox is None :,if bbox is None :,True,100.0,74.41,,,
"def mutated ( self , indiv ) : <TAB> """""" mutate some genes of the given individual """""" <TAB> res = indiv . copy ( ) <TAB> # to avoid having a child identical to one of the currentpopulation''' <TAB> for i in range(self.numParameters): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self.xBound is None: <TAB> <TAB> <TAB> <TAB> res[i] = indiv[i] + gauss(0, self.mutationStdDev) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> res[i] = max( <TAB> <TAB> <TAB> <TAB> <TAB> min(indiv[i] + gauss(0, self.mutationStdDev), self.maxs[i]), <TAB> <TAB> <TAB> <TAB> <TAB> self.mins[i], <TAB> <TAB> <TAB> <TAB> ) <TAB> return res",if i % 2 == 0 :,if random ( ) < self . mutationProb :,False,96.31,95.5,,,
"def _justifyDrawParaLine ( tx , offset , extraspace , words , last = 0 ) : <TAB> setXPos ( tx , offset ) <TAB> text = b "" "" . join ( words ) <TAB> if last : <TAB> <TAB> # last one, left align <TAB> <TAB> tx._textOut(text, 1) <TAB> else: <TAB> <TAB> nSpaces = len(words) - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tx.setWordSpace(extraspace / float(nSpaces)) <TAB> <TAB> <TAB> tx._textOut(text, 1) <TAB> <TAB> <TAB> tx.setWordSpace(0) <TAB> <TAB> else: <TAB> <TAB> <TAB> tx._textOut(text, 1) <TAB> setXPos(tx, -offset) <TAB> return offset",if extraspace :,if nSpaces :,False,98.69,72.93,,,
"def _read_0 ( self , stream ) : <TAB> r = b "" "" <TAB> while True : <TAB> <TAB> c = stream . read ( 2 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> if c == b "" \x00 \x00 "" : <TAB> <TAB> <TAB> break <TAB> <TAB> r + = c <TAB> return r . decode ( self . encoding )","if c == b"""" :",if len ( c ) != 2 :,False,93.05,60.41,,,
"def run ( self , app , editor , args ) : <TAB> line_nums = [ ] <TAB> for cursor in editor . cursors : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line_nums . append ( cursor . y ) <TAB> <TAB> <TAB> data = editor . lines [ cursor . y ] . get_data ( ) . upper ( ) <TAB> <TAB> <TAB> editor . lines [ cursor . y ] . set_data ( data )",if cursor . y not in line_nums :,if cursor . y not in line_nums :,True,100.0,74.24,,,
"def create_default_energy_point_rules ( ) : <TAB> for rule in get_default_energy_point_rules ( ) : <TAB> <TAB> # check if any rule for ref. doctype exists <TAB> <TAB> rule_exists = frappe.db.exists( <TAB> <TAB> <TAB> ""Energy Point Rule"", {""reference_doctype"": rule.get(""reference_doctype"")} <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = frappe.get_doc(rule) <TAB> <TAB> doc.insert(ignore_permissions=True)",if rule_exists :,if rule_exists :,True,100.0,73.93,,,
"def __new__ ( cls , * nodes ) : <TAB> if not nodes : <TAB> <TAB> raise TypeError ( "" DisjunctionNode() requires at least one node "" ) <TAB> elif len ( nodes ) == 1 : <TAB> <TAB> return nodes [ 0 ] <TAB> self = super ( DisjunctionNode , cls ) . __new__ ( cls ) <TAB> self . __nodes = [ ] <TAB> # TODO: Remove duplicates? <TAB> for node in nodes: <TAB> <TAB> if not isinstance(node, Node): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""DisjunctionNode() expects Node instances as arguments;"" <TAB> <TAB> <TAB> <TAB> "" received a non-Node instance %r"" % node <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.__nodes.extend(node.__nodes) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.__nodes.append(node) <TAB> return self","if isinstance ( node , list ) :","if isinstance ( node , DisjunctionNode ) :",False,99.04,73.63,,,
def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB> <TAB> if w not in index : <TAB> <TAB> <TAB> yield from dfs ( w ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> while index [ w ] < boundaries [ - 1 ] : <TAB> <TAB> <TAB> <TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB> <TAB> boundaries . pop ( ) <TAB> <TAB> scc = set ( stack [ index [ v ] : ] ) <TAB> <TAB> del stack [ index [ v ] : ] <TAB> <TAB> identified . update ( scc ) <TAB> <TAB> yield scc,if index [ w ] > boundaries [ - 1 ] :,elif w not in identified :,False,94.51,95.28,,,
"def unpack_item_obj ( map_uuid_global_id , misp_obj ) : <TAB> obj_meta = get_object_metadata ( misp_obj ) <TAB> obj_id = None <TAB> io_content = None <TAB> for attribute in misp_obj . attributes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> obj_id = attribute . value # # TODO: sanitize <TAB> <TAB> <TAB> io_content = attribute.data # # TODO: check if type == io <TAB> if obj_id and io_content: <TAB> <TAB> res = Item.create_item(obj_id, obj_meta, io_content) <TAB> <TAB> map_uuid_global_id[misp_obj.uuid] = get_global_id(""item"", obj_id)","if attribute . type == ""id"" :","if attribute . object_relation == ""raw-data"" :",False,96.52,71.75,,,
"def parse ( self , response ) : <TAB> soup = BeautifulSoup ( response . content . decode ( "" utf-8 "" , "" ignore "" ) , "" lxml "" ) <TAB> image_divs = soup . find_all ( "" div "" , class_ = "" imgpt "" ) <TAB> pattern = re . compile ( r "" murl \"" : \"" (.*?) \ .jpg "" ) <TAB> for div in image_divs : <TAB> <TAB> href_str = html_parser . HTMLParser ( ) . unescape ( div . a [ "" m "" ] ) <TAB> <TAB> match = pattern . search ( href_str ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = match . group ( 1 ) if six . PY3 else match . group ( 1 ) . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> img_url = "" {} .jpg "" . format ( name ) <TAB> <TAB> <TAB> yield dict ( file_url = img_url )",if match :,if match :,True,100.0,74.6,,,
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors",if fn :,if fn is not None :,False,97.96,72.57,,,
"def decompileFormat1 ( self , reader , otFont ) : <TAB> self . classDefs = classDefs = [ ] <TAB> startGlyphID = reader . readUShort ( ) <TAB> glyphCount = reader . readUShort ( ) <TAB> for i in range ( glyphCount ) : <TAB> <TAB> glyphName = otFont . getglyphName ( startGlyphID + i ) <TAB> <TAB> classValue = reader . readUShort ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> classDefs . append ( ( glyphName , classValue ) )",if classValue :,if classValue :,True,100.0,74.22,,,
"def compress ( self , data_list ) : <TAB> if len ( data_list ) == 2 : <TAB> <TAB> value , lookup_expr = data_list <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if lookup_expr not in EMPTY_VALUES : <TAB> <TAB> <TAB> <TAB> return Lookup ( value = value , lookup_expr = lookup_expr ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise forms . ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> self . error_messages [ "" lookup_required "" ] , code = "" lookup_required "" <TAB> <TAB> <TAB> <TAB> ) <TAB> return None",if value is not None :,if value not in EMPTY_VALUES :,False,96.49,72.03,,,
"def open_compat ( path , mode = "" r "" ) : <TAB> if mode in [ "" r "" , "" rb "" ] and not os . path . exists ( path ) : <TAB> <TAB> raise FileNotFoundError ( u ' The file  "" %s ""  could not be found ' % path ) <TAB> if sys . version_info > = ( 3 , ) : <TAB> <TAB> encoding = "" utf-8 "" <TAB> <TAB> errors = "" replace "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> encoding = None <TAB> <TAB> <TAB> errors = None <TAB> <TAB> return open ( path , mode , encoding = encoding , errors = errors ) <TAB> else : <TAB> <TAB> return open ( path , mode )","if encoding == ""utf-8"" and errors == ""ignore"" :","if mode in [ ""rb"" , ""wb"" , ""ab"" ] :",False,91.72,67.67,,,
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> if fn is not None : <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors",if lno != _path :,if _path [ - 1 ] != current_path [ - 1 ] :,False,93.11,70.3,,,
"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB> <TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB> <TAB> lookup = "" "" <TAB> <TAB> if "" "" in level_per_module : <TAB> <TAB> <TAB> level = level_per_module [ "" "" ] <TAB> <TAB> for n in name . split ( "" . "" ) : <TAB> <TAB> <TAB> lookup + = n <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> level = level_per_module [ lookup ] <TAB> <TAB> <TAB> lookup + = "" . "" <TAB> if level is False : <TAB> <TAB> return False <TAB> return record [ "" level "" ] . no > = level",if lookup in level_per_module :,if lookup in level_per_module :,True,100.0,74.56,,,
"def CountButtons ( self ) : <TAB> """""" Returns the number of visible buttons in the docked pane. """""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self . HasCloseButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasPinButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> return n",if self . HasCloseLeft ( ) :,if self . HasMaximizeButton ( ) :,False,98.66,98.52,,,
"def search ( a , b , desired ) : <TAB> if a == b : <TAB> <TAB> return a <TAB> if abs ( b - a ) < 0.005 : <TAB> <TAB> ca = count ( a ) <TAB> <TAB> cb = count ( b ) <TAB> <TAB> dista = abs ( desired - ca ) <TAB> <TAB> distb = abs ( desired - cb ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return a <TAB> <TAB> else : <TAB> <TAB> <TAB> return b <TAB> m = ( a + b ) / 2.0 <TAB> cm = count ( m ) <TAB> if desired < cm : <TAB> <TAB> return search ( m , b , desired ) <TAB> else : <TAB> <TAB> return search ( a , m , desired )",if dista < distb :,if dista < distb :,True,100.0,74.54,,,
"def search ( a , b , desired ) : <TAB> if a == b : <TAB> <TAB> return a <TAB> if abs ( b - a ) < 0.005 : <TAB> <TAB> ca = count ( a ) <TAB> <TAB> cb = count ( b ) <TAB> <TAB> dista = abs ( desired - ca ) <TAB> <TAB> distb = abs ( desired - cb ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return a <TAB> <TAB> else : <TAB> <TAB> <TAB> return b <TAB> m = ( a + b ) / 2.0 <TAB> cm = count ( m ) <TAB> if desired < cm : <TAB> <TAB> return search ( m , b , desired ) <TAB> else : <TAB> <TAB> return search ( a , m , desired )",if dista < distb :,"if ""::1"" in line :",False,95.73,64.45,,,
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( data , dict ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> if not isinstance ( inner , dict ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id",if not fpath . exists ( ) :,if not fpath . exists ( ) :,True,100.0,74.63,,,
"def _get_dbutils ( ) : <TAB> try : <TAB> <TAB> import IPython <TAB> <TAB> ip_shell = IPython . get_ipython ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise _NoDbutilsError <TAB> <TAB> return ip_shell . ns_table [ "" user_global "" ] [ "" dbutils "" ] <TAB> except ImportError : <TAB> <TAB> raise _NoDbutilsError <TAB> except KeyError : <TAB> <TAB> raise _NoDbutilsError","if ""user_global"" not in ip_shell . ns_table :",if ip_shell is None :,False,88.9,62.58,,,
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os.path.splitext(os.path.normcase(py_file))[1] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.compile: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""c"") <TAB> <TAB> if self.optimize > 0: <TAB> <TAB> <TAB> bytecode_files.append(py_file + ""o"") <TAB> return bytecode_files","if ext != "".py"" :",if ext != PYTHON_SOURCE_EXTENSION :,False,97.02,66.23,,,
"def compute_distances_mu ( line , pts , result , gates , tolerance ) : <TAB> """""" calculate all distances with mathuutils """""" <TAB> line_origin = V ( line [ 0 ] ) <TAB> line_end = V ( line [ - 1 ] ) <TAB> local_result = [ [ ] , [ ] , [ ] , [ ] , [ ] ] <TAB> for point in pts : <TAB> <TAB> data = compute_distance ( V ( point ) , line_origin , line_end , tolerance ) <TAB> <TAB> for i , res in enumerate ( local_result ) : <TAB> <TAB> <TAB> res . append ( data [ i ] ) <TAB> for i , res in enumerate ( result ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res . append ( local_result [ i ] )",if i != 0 and gates [ i ] > 0 :,if gates [ i ] :,False,95.12,74.5,,,
"def _get_next_segment ( self , segment_path , page_size , segment_cursor = None ) : <TAB> if segment_path : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return Segment ( self . client , segment_path , page_size , segment_cursor ) <TAB> return None",if segment_cursor is None :,if self . end_time and self . _is_later_than_end_time ( segment_path ) :,False,76.02,63.45,,,
"def _check_number_of_sessions ( ) : <TAB> nb_desktop_sessions = sessions . get_number_of_desktop_sessions ( ignore_gdm = True ) <TAB> if nb_desktop_sessions > 1 : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" WARNING : There are  %d  other desktop sessions open. The GPU switch will not become effective until you have manually "" <TAB> <TAB> <TAB> ""  logged out from ALL desktop sessions. \n "" <TAB> <TAB> <TAB> "" Continue ? (y/N) "" % ( nb_desktop_sessions - 1 ) <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sys . exit ( 0 )",if confirmation is None :,if not confirmation :,False,97.69,72.35,,,
"def delete_compute_environment ( self , compute_environment_name ) : <TAB> if compute_environment_name is None : <TAB> <TAB> raise InvalidParameterValueException ( "" Missing computeEnvironment parameter "" ) <TAB> compute_env = self . get_compute_environment ( compute_environment_name ) <TAB> if compute_env is not None : <TAB> <TAB> # Pop ComputeEnvironment <TAB> <TAB> self._compute_environments.pop(compute_env.arn) <TAB> <TAB> # Delete ECS cluster <TAB> <TAB> self.ecs_backend.delete_cluster(compute_env.ecs_name) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Delete compute environment <TAB> <TAB> <TAB> instance_ids = [instance.id for instance in compute_env.instances] <TAB> <TAB> <TAB> self.ec2_backend.terminate_instances(instance_ids)",if compute_env . instances :,"if compute_env . env_type == ""MANAGED"" :",False,95.64,65.0,,,
"def run ( self ) : <TAB> results = { } <TAB> for func_name in [ <TAB> <TAB> # Execute every function starting with check_* <TAB> <TAB> fn <TAB> <TAB> for fn in self.check_functions <TAB> <TAB> # if the user does not specify any name <TAB> <TAB> if not self.args.get(""check"") <TAB> <TAB> # of if specify the current function name <TAB> <TAB> or self.args.get(""check"") == fn <TAB> ]: <TAB> <TAB> function = getattr(self, func_name) <TAB> <TAB> log.warn(function.__doc__) <TAB> <TAB> result = function() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log.info(""\n"".join(result)) <TAB> <TAB> <TAB> results.update({func_name: result}) <TAB> return results",if result :,if result :,True,100.0,74.39,,,
"def run ( self ) : <TAB> results = { } <TAB> for func_name in [ <TAB> <TAB> # Execute every function starting with check_* <TAB> <TAB> fn <TAB> <TAB> for fn in self.check_functions <TAB> <TAB> # if the user does not specify any name <TAB> <TAB> if not self.args.get(""check"") <TAB> <TAB> # of if specify the current function name <TAB> <TAB> or self.args.get(""check"") == fn <TAB> ]: <TAB> <TAB> function = getattr(self, func_name) <TAB> <TAB> log.warn(function.__doc__) <TAB> <TAB> result = function() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log.info(""\n"".join(result)) <TAB> <TAB> <TAB> results.update({func_name: result}) <TAB> return results",if result :,if br . layer is Layer . Blocks or br . layer not in layers,False,93.54,67.12,,,
"def get_library_dirs ( platform , arch = None ) : <TAB> if platform == "" win32 "" : <TAB> <TAB> jre_home = get_jre_home ( platform ) <TAB> <TAB> jdk_home = JAVA_HOME <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> jre_home = jre_home . decode ( "" utf-8 "" ) <TAB> <TAB> return [ join ( jdk_home , "" lib "" ) , join ( jdk_home , "" bin "" , "" server "" ) ] <TAB> elif platform == "" android "" : <TAB> <TAB> return [ "" libs/ {} "" . format ( arch ) ] <TAB> return [ ]","if isinstance ( jre_home , bytes ) :","if isinstance ( jre_home , bytes ) :",True,100.0,74.4,,,
"def save_plugin_options ( self ) : <TAB> for name , option_widgets in self . _plugin_option_widgets . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . config [ "" plugins "" ] [ name ] = { } <TAB> <TAB> plugin_config = self . config [ "" plugins "" ] [ <TAB> <TAB> <TAB> name <TAB> <TAB> ] # use or instead of get incase the value is actually None <TAB> <TAB> for option_name, option_widget in option_widgets.items(): <TAB> <TAB> <TAB> plugin_config[option_name] = option_widget.option.get_widget_value( <TAB> <TAB> <TAB> <TAB> option_widget.widget <TAB> <TAB> <TAB> )","if name not in self . config [ ""plugins"" ] :","if name not in self . config [ ""plugins"" ] :",True,100.0,74.41,,,
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """""" Select first block delimited by start_tag and end_tag """""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> if str_in [ pos ] == start_tag : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif str_in [ pos ] == end_tag : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",if depth == 0 :,if depth == 0 :,True,100.0,99.5,,,
"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """""" Coerce the values in a variable to bools. """""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB> <TAB> v = b . data <TAB> <TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB> <TAB> <TAB> const = v . pyval is true_val <TAB> <TAB> elif not compare . compatible_with ( v , True ) : <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else : <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var","elif compare . compatible_with ( v , False ) :","elif not compare . compatible_with ( v , False ) :",False,98.95,97.68,,,
def multiline_indentation ( self ) : <TAB> if self . _multiline_indentation is None : <TAB> <TAB> offset = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> offset = 2 <TAB> <TAB> indentation = make_indentation ( 3 * self . indent_size + offset ) <TAB> <TAB> self . _multiline_indentation = indentation <TAB> if self . current_rule : <TAB> <TAB> indent_extra = make_indentation ( self . indent_size ) <TAB> <TAB> return self . _multiline_indentation + indent_extra <TAB> return self . _multiline_indentation,if self . current_rule . is_comment ( ) :,if self . show_aligned_keywords :,False,93.43,75.58,,,
"def __call__ ( self , event , data = None ) : <TAB> datatype , delta = event <TAB> self . midi_ctrl . delta + = delta <TAB> if TIMING_CLOCK in datatype and not self . played : <TAB> <TAB> self . midi_ctrl . pulse + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> t_master = 60.0 <TAB> <TAB> <TAB> self . midi_ctrl . bpm = round ( 60.0 / self . midi_ctrl . delta , 0 ) <TAB> <TAB> <TAB> self . midi_ctrl . pulse = 0 <TAB> <TAB> <TAB> self . midi_ctrl . delta = 0.0",if self . midi_ctrl . pulse == 1 :,if self . midi_ctrl . pulse == self . midi_ctrl . ppqn :,False,95.01,71.51,,,
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> itm = self . handle_word ( child ) <TAB> <TAB> <TAB> if self . _unit == "" word "" : <TAB> <TAB> <TAB> <TAB> sent . extend ( itm ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sent . append ( itm ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent )","if child . tag == ""word"" :","if child . tag in ( ""wf"" , ""punc"" ) :",False,93.81,66.69,,,
"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance(testdef.exception, Exception): <TAB> <TAB> <TAB> <TAB> raise testdef.exception <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception(testdef.exception) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Test parse failure"")",if testdef . exception :,if testdef . exception :,True,100.0,73.96,,,
"def _authorized_sid ( self , jid , sid , ifrom , iq ) : <TAB> with self . _preauthed_sids_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _preauthed_sids [ ( jid , sid , ifrom ) ] <TAB> <TAB> <TAB> return True <TAB> <TAB> return False","if ( jid , sid , ifrom ) in self . _preauthed_sids :","if ( jid , sid , ifrom ) in self . _preauthed_sids :",True,100.0,73.99,,,
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> if code == TERMINATE : <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode",if timeout is None :,if timeout is None :,True,100.0,74.5,,,
"def _gen_legal_y_s_t ( self ) : <TAB> while True : <TAB> <TAB> y = self . _gen_random_scalar ( ) <TAB> <TAB> s = self . tec_arithmetic . mul ( <TAB> <TAB> <TAB> scalar = y , a = self . tec_arithmetic . get_generator ( ) <TAB> <TAB> ) # S = yG <TAB> <TAB> t = self._hash_tec_element(s) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Both S and T are legal <TAB> <TAB> <TAB> LOGGER.info(""randomly generated y, S, T"") <TAB> <TAB> <TAB> return y, s, t",if t != 0 :,if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int :,False,88.0,66.28,,,
"def write_out ( ) : <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> data_str = self . instrument_queue . get ( ) <TAB> <TAB> data_str = data_str . splitlines ( ) <TAB> <TAB> tb . write ( "" "" ) # position cursor to end <TAB> <TAB> for line in data_str: <TAB> <TAB> <TAB> tb.write(line) <TAB> <TAB> tb.write(""\n"")",if self . is_running :,if self . instrument_queue . empty ( ) :,False,94.5,70.22,,,
"def _parse_preamble ( self ) : <TAB> """""" Parse metadata about query (PRIVATE). """""" <TAB> meta = { } <TAB> while self . line : <TAB> <TAB> regx = re . search ( _RE_QUERY , self . line ) <TAB> <TAB> if regx : <TAB> <TAB> <TAB> self . query_id = regx . group ( 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . seq_len = int ( self . line . strip ( ) . split ( ) [ 1 ] ) <TAB> <TAB> self . line = self . handle . readline ( ) . strip ( ) <TAB> return meta","if self . query_id == ""seq"" :","if self . line . startswith ( ""Match_columns"" ) :",False,93.6,93.32,,,
"def init_sequence ( self , coll_name , seq_config ) : <TAB> if not isinstance ( seq_config , list ) : <TAB> <TAB> raise Exception ( ' "" sequence ""  config must be a list ' ) <TAB> handlers = [ ] <TAB> for entry in seq_config : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( ' "" sequence ""  entry must be a dict ' ) <TAB> <TAB> name = entry . get ( "" name "" , "" "" ) <TAB> <TAB> handler = self . load_coll ( name , entry ) <TAB> <TAB> handlers . append ( handler ) <TAB> return HandlerSeq ( handlers )","if not isinstance ( entry , dict ) :","if not isinstance ( entry , dict ) :",True,100.0,74.46,,,
"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB> <TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB> <TAB> if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : <TAB> <TAB> <TAB> ind + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB> <TAB> if "" : "" in line and len ( line ) > 0 : <TAB> <TAB> <TAB> lines = line . split ( "" : "" ) <TAB> <TAB> <TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d",if start :,if start < ind :,False,98.71,73.75,,,
"def wait ( self ) : <TAB> while True : <TAB> <TAB> return_code = self . _process . poll ( ) <TAB> <TAB> if return_code is not None : <TAB> <TAB> <TAB> line = self . _process . stdout . readline ( ) . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> log . debug ( line . strip ( "" \n "" ) ) <TAB> return True",if return_code != 0 :,"if line == """" :",False,94.34,59.06,,,
"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if "" name "" in tag . attrs and tag . attrs [ "" name "" ] in ( key , ) : <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError","if tag . tagName != ""a"" :","if tag . name not in ( ""input"" , ) :",False,92.07,69.57,,,
"def compare_hash ( hash_of_gold , path_to_file ) : <TAB> with open ( path_to_file , "" rb "" ) as f : <TAB> <TAB> hash_of_file = hashlib . sha256 ( f . read ( ) ) . hexdigest ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" ########## Hash sum of "" , <TAB> <TAB> <TAB> <TAB> path_to_file , <TAB> <TAB> <TAB> <TAB> "" differs from the target, the topology will be deleted !!! ########## "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> shutil . rmtree ( os . path . dirname ( path_to_file ) )",if hash_of_gold == hash_of_file :,if hash_of_file != hash_of_gold :,False,98.11,72.49,,,
def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> observer . on_next ( False ) <TAB> <TAB> <TAB> observer . on_completed ( ) <TAB> <TAB> elif donel [ 0 ] : <TAB> <TAB> <TAB> observer . on_next ( True ) <TAB> <TAB> <TAB> observer . on_completed ( ),if qr [ 0 ] :,if len ( ql ) > 0 :,False,93.6,65.03,,,
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> if i < len ( data ) and i > - 1 : <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> if is_tuple : <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None",if abs ( item ) > 0 :,if item < 0 :,False,97.6,73.2,,,
"def _open_url ( cls , url ) : <TAB> if config . browser : <TAB> <TAB> cmd = [ config . browser , url ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" running command:  %s "" % "" "" . join ( cmd ) ) <TAB> <TAB> p = Popen ( cmd ) <TAB> <TAB> p . communicate ( ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" opening URL in browser:  %s "" % url ) <TAB> <TAB> webbrowser . open_new ( url )",if debug :,if not config . quiet :,False,92.53,68.62,,,
"def setLabel ( self , s , protect = False ) : <TAB> """""" Set the label of the minibuffer. """""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> if hasattr(g.app.gui, ""set_minibuffer_label""): <TAB> <TAB> <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB> <TAB> w.setAllText(s) <TAB> <TAB> n = len(s) <TAB> <TAB> w.setSelectionRange(n, n, insert=n) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> k.mb_prefix = s",if protect :,if protect :,True,100.0,99.24,,,
"def setLabel ( self , s , protect = False ) : <TAB> """""" Set the label of the minibuffer. """""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> if hasattr(g.app.gui, ""set_minibuffer_label""): <TAB> <TAB> <TAB> g.app.gui.set_minibuffer_label(c, s) <TAB> <TAB> w.setAllText(s) <TAB> <TAB> n = len(s) <TAB> <TAB> w.setSelectionRange(n, n, insert=n) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> k.mb_prefix = s",if protect :,"if path . startswith ( ""cobra://"" ) or path . startswith ( ""cobrassl://"" ) :",False,87.32,91.53,,,
"def init_params ( net ) : <TAB> """""" Init layer parameters. """""" <TAB> for module in net . modules ( ) : <TAB> <TAB> if isinstance ( module , nn . Conv2d ) : <TAB> <TAB> <TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB> <TAB> <TAB> if module . bias : <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> init . constant ( module . weight , 1 ) <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . Linear ) : <TAB> <TAB> <TAB> init . normal ( module . weight , std = 1e-3 ) <TAB> <TAB> <TAB> if module . bias : <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 )","elif isinstance ( module , nn . BatchNorm2d ) :","elif isinstance ( module , nn . BatchNorm2d ) :",True,100.0,74.6,,,
"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> elif old [ key ] != new [ key ] : <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB> <TAB> if key not in old: <TAB> <TAB> <TAB> added.append(key) <TAB> if removed: <TAB> <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB> <TAB> diff[""added""] = sorted(added) <TAB> return diff",if key in new :,if key not in new :,False,98.92,73.38,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> _kwargs = { <TAB> <TAB> "" max_length "" : 20 , <TAB> <TAB> "" widget "" : forms . TextInput ( attrs = { "" autocomplete "" : "" off "" } ) , <TAB> <TAB> "" label "" : _ ( "" Card number "" ) , <TAB> } <TAB> if "" types "" in kwargs : <TAB> <TAB> self . accepted_cards = set ( kwargs . pop ( "" types "" ) ) <TAB> <TAB> difference = self . accepted_cards - VALID_CARDS <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" The following accepted_cards are  "" "" unknown:  %s "" % difference <TAB> <TAB> <TAB> ) <TAB> _kwargs . update ( kwargs ) <TAB> super ( ) . __init__ ( * args , * * _kwargs )",if difference :,if difference :,True,100.0,74.56,,,
"def dumps ( self ) : <TAB> sections = [ ] <TAB> for name , env_info in self . _dependencies_ . items ( ) : <TAB> <TAB> sections . append ( "" [ENV_ %s ] "" % name ) <TAB> <TAB> for var , values in sorted ( env_info . vars . items ( ) ) : <TAB> <TAB> <TAB> tmp = "" %s = "" % var <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp + = "" [ %s ] "" % "" , "" . join ( [ ' "" %s "" ' % val for val in values ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tmp + = "" %s "" % values <TAB> <TAB> <TAB> sections . append ( tmp ) <TAB> return "" \n "" . join ( sections )","if isinstance ( values , ( list , tuple ) ) :","if isinstance ( values , list ) :",False,97.13,73.16,,,
"def air_quality ( self ) : <TAB> aqi_data = self . _get_aqi_data ( ) <TAB> if aqi_data : <TAB> <TAB> if aqi_data . get ( "" status "" ) == "" ok "" : <TAB> <TAB> <TAB> aqi_data = self . _organize ( aqi_data ) <TAB> <TAB> <TAB> aqi_data = self . _manipulate ( aqi_data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . py3 . error ( aqi_data . get ( "" data "" ) ) <TAB> return { <TAB> <TAB> "" cached_until "" : self . py3 . time_in ( self . cache_timeout ) , <TAB> <TAB> "" full_text "" : self . py3 . safe_format ( self . format , aqi_data ) , <TAB> }","if aqi_data . get ( ""status"" ) == ""failed"" :","elif aqi_data . get ( ""status"" ) == ""error"" :",False,97.64,72.34,,,
"def _blend ( x , y ) : # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance(x, (dict, OrderedDict)): <TAB> <TAB> if not isinstance(y, (dict, OrderedDict)): <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge(x, y, recursion_func=_blend) <TAB> if isinstance(x, (list, tuple)): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [_blend(*i) for i in zip(x, y)] <TAB> <TAB> if len(x) > len(y): <TAB> <TAB> <TAB> result += x[len(y) :] <TAB> <TAB> elif len(x) < len(y): <TAB> <TAB> <TAB> result += y[len(x) :] <TAB> <TAB> return result <TAB> return y","if not isinstance ( y , ( list , tuple ) ) :","if not isinstance ( y , ( list , tuple ) ) :",True,100.0,99.46,,,
"def _rate ( cls , sample1 , sample2 ) : <TAB> "" Simple rate "" <TAB> try : <TAB> <TAB> interval = sample2 [ 0 ] - sample1 [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Infinity ( ) <TAB> <TAB> delta = sample2 [ 1 ] - sample1 [ 1 ] <TAB> <TAB> if delta < 0 : <TAB> <TAB> <TAB> raise UnknownValue ( ) <TAB> <TAB> return ( sample2 [ 0 ] , delta / interval , sample2 [ 2 ] , sample2 [ 3 ] ) <TAB> except Infinity : <TAB> <TAB> raise <TAB> except UnknownValue : <TAB> <TAB> raise <TAB> except Exception as e : <TAB> <TAB> raise NaN ( e )",if interval > 0 :,if interval == 0 :,False,98.01,73.48,,,
"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """""" Modifies HTTP headers to include a specified user-agent. """""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if user_agent not in kwargs [ "" headers "" ] [ "" user-agent "" ] : <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f""{user_agent} "" f'{kwargs[""headers""][""user-agent""]}' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> kwargs[""headers""][""user-agent""] = user_agent <TAB> else: <TAB> <TAB> kwargs[""headers""] = {""user-agent"": user_agent} <TAB> return request_method(*args, **kwargs)","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :","if kwargs [ ""headers"" ] . get ( ""user-agent"" ) :",True,100.0,99.5,,,
"def remove_addons ( auth , resource_object_list ) : <TAB> for config in AbstractNode . ADDONS_AVAILABLE : <TAB> <TAB> try : <TAB> <TAB> <TAB> settings_model = config . node_settings <TAB> <TAB> except LookupError : <TAB> <TAB> <TAB> settings_model = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> addon_list = settings_model . objects . filter ( <TAB> <TAB> <TAB> <TAB> owner__in = resource_object_list , is_deleted = False <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for addon in addon_list : <TAB> <TAB> <TAB> <TAB> addon . after_delete ( auth . user )",if settings_model :,if settings_model :,True,100.0,74.32,,,
"def Decorator ( * args , * * kwargs ) : <TAB> delay = 0.2 <TAB> num_attempts = 15 <TAB> cur_attempt = 0 <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return f ( * args , * * kwargs ) <TAB> <TAB> except exceptions . WebDriverException as e : <TAB> <TAB> <TAB> logging . warning ( "" Selenium raised  %s "" , utils . SmartUnicode ( e ) ) <TAB> <TAB> <TAB> cur_attempt + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> time . sleep ( delay )",if cur_attempt >= num_attempts :,if cur_attempt == num_attempts :,False,98.49,73.16,,,
"def _cleanup_parts_dir ( parts_dir , local_plugins_dir , parts ) : <TAB> if os . path . exists ( parts_dir ) : <TAB> <TAB> logger . info ( "" Cleaning up parts directory "" ) <TAB> <TAB> for subdirectory in os . listdir ( parts_dir ) : <TAB> <TAB> <TAB> path = os . path . join ( parts_dir , subdirectory ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( path ) <TAB> <TAB> <TAB> <TAB> except NotADirectoryError : <TAB> <TAB> <TAB> <TAB> <TAB> os . remove ( path ) <TAB> for part in parts : <TAB> <TAB> part . mark_cleaned ( steps . BUILD ) <TAB> <TAB> part . mark_cleaned ( steps . PULL )",if os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) :,if path != local_plugins_dir :,False,88.66,69.27,,,
"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB> <TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB> <TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB> <TAB> # reach leaf <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB> <TAB> <TAB> tree, sample, cur_node_idx <TAB> <TAB> ) <TAB> <TAB> if reach_leaf: <TAB> <TAB> <TAB> node_pos[""reach_leaf_node""][t_idx] = True <TAB> <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",if cur_node_idx == 0 :,if cur_node_idx == - 1 :,False,98.54,72.78,,,
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> if self . do_corr_and_slope : <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> if self . do_costes : <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ]",if self . do_manders :,if self . do_manders :,True,100.0,74.62,,,
"def create_connection ( self , infos , f2 , laddr_infos , protocol ) : <TAB> for family in infos : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for laddr in laddr_infos : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> protocol = "" foo "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> protocol = "" bar "" <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise <TAB> return protocol",if family == f2 :,if f2 :,False,98.05,73.39,,,
"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB> <TAB> if not hasattr ( request , "" app "" ) : <TAB> <TAB> <TAB> request . app = None <TAB> <TAB> <TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB> <TAB> <TAB> if len ( auth ) == 2 : <TAB> <TAB> <TAB> <TAB> auth_prefix , auth_token = auth <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs )",if auth_prefix == prefix :,if auth_prefix . lower ( ) == prefix :,False,97.57,72.67,,,
"def when ( self , matches , context ) : <TAB> ret = [ ] <TAB> for episode in matches . named ( "" episode "" , lambda match : len ( match . initiator ) == 1 ) : <TAB> <TAB> group = matches . markers . at_match ( <TAB> <TAB> <TAB> episode , lambda marker : marker . name == "" group "" , index = 0 <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not matches . range ( <TAB> <TAB> <TAB> <TAB> * group . span , predicate = lambda match : match . name == "" title "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> ret . append ( episode ) <TAB> return ret",if group :,if group :,True,100.0,74.5,,,
def locate_via_pep514 ( spec ) : <TAB> with _PY_LOCK : <TAB> <TAB> if not _PY_AVAILABLE : <TAB> <TAB> <TAB> from . import pep514 <TAB> <TAB> <TAB> _PY_AVAILABLE . extend ( pep514 . discover_pythons ( ) ) <TAB> <TAB> <TAB> _PY_AVAILABLE . append ( CURRENT ) <TAB> for cur_spec in _PY_AVAILABLE : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return cur_spec . path,if cur_spec . spec == spec :,if cur_spec . satisfies ( spec ) :,False,95.93,68.59,,,
"def setCorkImageDefault ( self ) : <TAB> if settings . corkBackground [ "" image "" ] != "" "" : <TAB> <TAB> i = self . cmbCorkImage . findData ( settings . corkBackground [ "" image "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . cmbCorkImage . setCurrentIndex ( i )",if i != - 1 :,if i != - 1 :,True,100.0,73.88,,,
"def _split_key ( key ) : <TAB> if isinstance ( key , util . string_types ) : <TAB> <TAB> # coerce fooload('*') into ""default loader strategy"" <TAB> <TAB> if key == _WILDCARD_TOKEN: <TAB> <TAB> <TAB> return (_DEFAULT_TOKEN,) <TAB> <TAB> # coerce fooload("".*"") into ""wildcard on default entity"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = key[1:] <TAB> <TAB> return key.split(""."") <TAB> else: <TAB> <TAB> return (key,)","if key . startswith ( ""*"" ) :","elif key . startswith ( ""."" + _WILDCARD_TOKEN ) :",False,93.42,69.29,,,
"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self.list_nodes(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node.image: <TAB> <TAB> <TAB> if disk.id == volume.id: <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk.extra[""disk_id""] <TAB> <TAB> <TAB> <TAB> return self._do_detach_volume(node.id, disk_id) <TAB> return False",if node . id == volume . id :,if type ( node . image ) is not list :,False,95.45,69.68,,,
"def create ( self , private = False ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( <TAB> <TAB> <TAB> <TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> if e . error == "" user_is_bot "" : <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e )",if private :,if private :,True,100.0,74.61,,,
"def test_dataset_has_valid_etag ( self , dataset_name ) : <TAB> py_script_path = list ( filter ( lambda x : x , dataset_name . split ( "" / "" ) ) ) [ - 1 ] + "" .py "" <TAB> dataset_url = hf_bucket_url ( dataset_name , filename = py_script_path , dataset = True ) <TAB> etag = None <TAB> try : <TAB> <TAB> response = requests . head ( <TAB> <TAB> <TAB> dataset_url , allow_redirects = True , proxies = None , timeout = 10 <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> etag = response . headers . get ( "" Etag "" ) <TAB> except ( EnvironmentError , requests . exceptions . Timeout ) : <TAB> <TAB> pass <TAB> self . assertIsNotNone ( etag )","if response . status_code == 200 and ""Etag"" in response . headers :",if response . status_code == 200 :,False,95.59,67.13,,,
"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB> <TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB> <TAB> if os . path . islink ( dirpath ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . chmod ( dirpath , mode )","if os . path . isdir ( dirpath ) and os . access ( dirpath , os . W_OK ) :",if not self . dry_run :,False,85.16,67.98,,,
"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for _ in range ( 3 ) : <TAB> <TAB> <TAB> <TAB> self . _process . terminate ( ) <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> <TAB> <TAB> <TAB> if self . _process . poll ( ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _process . kill ( ) <TAB> <TAB> <TAB> <TAB> self . _process . wait ( ) <TAB> <TAB> <TAB> <TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB> <TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" )",if self . _process . returncode == 0 :,if self . _process . poll ( ) is None :,False,97.7,72.65,,,
"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB> <TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [ ] <TAB> <TAB> elif current_word and self . char_begins_new_word ( current_word , char ) : <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [ char ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current_word . append ( char ) <TAB> <IF-STMT> <TAB> <TAB> yield current_word",if current_word :,if current_word :,True,100.0,74.43,,,
"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB> <TAB> for spec in specs [ i ] . __sro__ : <TAB> <TAB> <TAB> comps = components . get ( spec ) <TAB> <TAB> <TAB> if comps : <TAB> <TAB> <TAB> <TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else : <TAB> <TAB> for iface in provided : <TAB> <TAB> <TAB> comps = components . get ( iface ) <TAB> <TAB> <TAB> if comps : <TAB> <TAB> <TAB> <TAB> r = comps . get ( name ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",if r :,if r is not None :,False,96.28,70.97,,,
"def run ( cmd , task = None ) : <TAB> process = subprocess . Popen ( <TAB> <TAB> cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , close_fds = True <TAB> ) <TAB> output_lines = [ ] <TAB> while True : <TAB> <TAB> line = process . stdout . readline ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> line = line . decode ( "" utf-8 "" ) <TAB> <TAB> output_lines + = [ line ] <TAB> <TAB> logger . info ( line . rstrip ( "" \n "" ) ) <TAB> process . stdout . close ( ) <TAB> exit_code = process . wait ( ) <TAB> if exit_code : <TAB> <TAB> output = "" "" . join ( output_lines ) <TAB> <TAB> raise subprocess . CalledProcessError ( exit_code , cmd , output = output )",if not line :,if not line :,True,100.0,74.57,,,
"def process_response ( self , request , response ) : <TAB> if ( <TAB> <TAB> response . status_code == 404 <TAB> <TAB> and request . path_info . endswith ( "" / "" ) <TAB> <TAB> and not is_valid_path ( request . path_info ) <TAB> <TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request.path[:-1] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with safe_query_string(request): <TAB> <TAB> <TAB> <TAB> newurl += ""?"" + request.META[""QUERY_STRING""] <TAB> <TAB> return HttpResponsePermanentRedirect(newurl) <TAB> return response","if request . META . get ( ""QUERY_STRING"" ) :",if request . GET :,False,94.73,66.33,,,
"def dependencies ( self ) : <TAB> deps = [ ] <TAB> midx = None <TAB> if self . ref is not None : <TAB> <TAB> query = TypeQuery ( self . ref ) <TAB> <TAB> super = query . execute ( self . schema ) <TAB> <TAB> if super is None : <TAB> <TAB> <TAB> log . debug ( self . schema ) <TAB> <TAB> <TAB> raise TypeNotFound ( self . ref ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> deps . append ( super ) <TAB> <TAB> <TAB> midx = 0 <TAB> return ( midx , deps )",if super . is_dependency ( ) :,if not super . builtin ( ) :,False,96.24,72.05,,,
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> elif hasattr ( self . object , "" read "" ) : <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs","if sys . platform == ""win32"" :",if isfile ( self . object ) :,False,96.02,66.47,,,
"def _save ( self ) : <TAB> fd , tempname = tempfile . mkstemp ( ) <TAB> fd = os . fdopen ( fd , "" w "" ) <TAB> json . dump ( self . _cache , fd , indent = 2 , separators = ( "" , "" , "" :  "" ) ) <TAB> fd . close ( ) <TAB> # Silently ignore errors <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os.makedirs(os.path.dirname(self.filename)) <TAB> <TAB> shutil.move(tempname, self.filename) <TAB> except (IOError, OSError): <TAB> <TAB> os.remove(tempname)",if not os . path . isdir ( os . path . dirname ( self . filename ) ) :,if not os . path . exists ( os . path . dirname ( self . filename ) ) :,False,98.53,73.2,,,
"def refiner_configs ( self ) : <TAB> rv = { } <TAB> for refiner in refiner_manager : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rv [ refiner . name ] = { k : v for k , v in self . config . items ( refiner . name ) } <TAB> return rv","if isinstance ( refiner , Refiner ) :",if self . config . has_section ( refiner . name ) :,False,85.91,66.52,,,
"def com_slice ( self , primary , node , assigning ) : <TAB> # short_slice: [lower_bound] "":"" [upper_bound] <TAB> lower = upper = None <TAB> if len(node.children) == 2: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> upper = self.com_node(node.children[1]) <TAB> <TAB> else: <TAB> <TAB> <TAB> lower = self.com_node(node.children[0]) <TAB> elif len(node.children) == 3: <TAB> <TAB> lower = self.com_node(node.children[0]) <TAB> <TAB> upper = self.com_node(node.children[2]) <TAB> return Slice(primary, assigning, lower, upper, lineno=extractLineNo(node))","if node . children [ 0 ] == ""upper"" :",if node . children [ 0 ] . type == token . COLON :,False,96.29,61.52,,,
"def close ( self , * args , * * kwargs ) : <TAB> super ( mytqdm , self ) . close ( * args , * * kwargs ) <TAB> # If it was not run in a notebook, sp is not assigned, check for it <TAB> if hasattr(self, ""sp""): <TAB> <TAB> # Try to detect if there was an error or KeyboardInterrupt <TAB> <TAB> # in manual mode: if n < total, things probably got wrong <TAB> <TAB> if self.total and self.n < self.total: <TAB> <TAB> <TAB> self.sp(bar_style=""danger"") <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.sp(bar_style=""success"") <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self.sp(close=True)",if self . n == 0 :,if self . leave :,False,97.51,72.98,,,
"def test_alloc ( self ) : <TAB> b = bytearray ( ) <TAB> alloc = b . __alloc__ ( ) <TAB> self . assertTrue ( alloc > = 0 ) <TAB> seq = [ alloc ] <TAB> for i in range ( 100 ) : <TAB> <TAB> b + = b "" x "" <TAB> <TAB> alloc = b . __alloc__ ( ) <TAB> <TAB> self . assertTrue ( alloc > = len ( b ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seq . append ( alloc )",if len ( seq ) == 0 :,if alloc not in seq :,False,93.98,70.63,,,
"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> <IF-STMT> <TAB> <TAB> f . compress = zlib . compressobj ( <TAB> <TAB> <TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB> <TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB> <TAB> <TAB> if open_files > self . MAX_OPEN_FILES : <TAB> <TAB> <TAB> <TAB> f . fileobj . close ( ) <TAB> <TAB> <TAB> <TAB> f . fileobj = None <TAB> <TAB> else : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> self . files . pop ( key )",if self . compress_file :,if self . compress :,False,97.12,72.96,,,
"def _run ( self ) : <TAB> # Low-level run method to do the actual scheduling loop. <TAB> self.running = True <TAB> while self.running: <TAB> <TAB> try: <TAB> <TAB> <TAB> self.sched.run() <TAB> <TAB> except Exception as x: <TAB> <TAB> <TAB> logging.error( <TAB> <TAB> <TAB> <TAB> ""Error during scheduler execution: %s"" % str(x), exc_info=True <TAB> <TAB> <TAB> ) <TAB> <TAB> # queue is empty; sleep a short while before checking again <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> time.sleep(5)",if self . queue is not None :,if self . running :,False,96.8,71.84,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 18 :,if tt == 16 :,False,98.42,73.07,,,
"def check ( dbdef ) : <TAB> "" drop script must clear the database "" <TAB> for version in dbdef : <TAB> <TAB> connector = MemConnector ( ) . bound ( None ) <TAB> <TAB> create ( dbdef , version , connector ) <TAB> <TAB> drop ( dbdef , version , connector ) <TAB> <TAB> remaining = connector . execute ( <TAB> <TAB> <TAB> "" SELECT * FROM sqlite_master WHERE name NOT LIKE  ' sqlite_ % ' "" <TAB> <TAB> ) . fetchall ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield "" {0} :drop.sql "" . format ( version ) , remaining",if remaining :,if remaining :,True,100.0,74.39,,,
"def test_open_overwrite_offset_size ( self , sftp ) : <TAB> """""" Test writing data at a specific offset """""" <TAB> f = None <TAB> try : <TAB> <TAB> self . _create_file ( "" file "" , "" xxxxyyyy "" ) <TAB> <TAB> f = yield from sftp . open ( "" file "" , "" r+ "" ) <TAB> <TAB> yield from f . write ( "" zz "" , 3 ) <TAB> <TAB> yield from f . close ( ) <TAB> <TAB> with open ( "" file "" ) as localf : <TAB> <TAB> <TAB> self . assertEqual ( localf . read ( ) , "" xxxzzyyy "" ) <TAB> finally : <TAB> <TAB> <IF-STMT> # pragma: no branch <TAB> <TAB> <TAB> yield from f.close() <TAB> <TAB> remove(""file"")",if f :,if f :,True,100.0,99.53,,,
"def pump ( ) : <TAB> import sys as _sys <TAB> while self . countdown_active ( ) : <TAB> <TAB> if not ( self . connected ( "" send "" ) and other . connected ( "" recv "" ) ) : <TAB> <TAB> <TAB> break <TAB> <TAB> try : <TAB> <TAB> <TAB> data = other . recv ( timeout = 0.05 ) <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if not data : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> self . send ( data ) <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> self . shutdown ( "" send "" ) <TAB> other . shutdown ( "" recv "" )",if _sys . exitcode == 0 :,if not _sys :,False,93.56,71.13,,,
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> if "" results.train_y_misclass "" in dd : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> if "" hyper_parameters "" in key : <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) )","if dd [ ""results.train_y_misclass"" ] > optimal_measure :","if dd [ ""results.train_y_misclass"" ] < optimal_measure :",False,98.87,73.49,,,
"def valid ( self ) : <TAB> valid = True <TAB> <IF-STMT> <TAB> <TAB> return valid <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> with io . open ( self . pathfile , "" w "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> <TAB> f . close ( ) # do nothing <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os.remove(self.pathfile) <TAB> <TAB> return valid","if self . pathfile . endswith ( "".py"" ) :",if os . path . exists ( self . pathfile ) :,False,88.56,59.31,,,
"def __getitem__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . cache [ key ] <TAB> except KeyError : <TAB> <TAB> f = BytesIO ( self . dict [ key . encode ( self . keyencoding ) ] ) <TAB> <TAB> value = Unpickler ( f ) . load ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . cache [ key ] = value <TAB> return value",if value :,if self . writeback :,False,95.84,71.32,,,
"def hasMenu ( cls , callingWindow , mainItem , selection , * fullContexts ) : <TAB> for i , fullContext in enumerate ( fullContexts ) : <TAB> <TAB> srcContext = fullContext [ 0 ] <TAB> <TAB> for menuHandler in cls . menus : <TAB> <TAB> <TAB> m = menuHandler ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False","if m . hasSelection ( mainItem , srcContext , selection , i ) :","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) :",False,92.28,69.33,,,
"def lr_read_tables ( module = tab_module , optimize = 0 ) : <TAB> global _lr_action , _lr_goto , _lr_productions , _lr_method <TAB> try : <TAB> <TAB> exec ( "" import  %s  as parsetab "" % module ) <TAB> <TAB> global parsetab # declare the name of the imported module <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _lr_action = parsetab._lr_action <TAB> <TAB> <TAB> _lr_goto = parsetab._lr_goto <TAB> <TAB> <TAB> _lr_productions = parsetab._lr_productions <TAB> <TAB> <TAB> _lr_method = parsetab._lr_method <TAB> <TAB> <TAB> return 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> return 0 <TAB> except (ImportError, AttributeError): <TAB> <TAB> return 0",if optimize :,if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) :,False,91.07,67.17,,,
"def _Determine_Do ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB> <TAB> self . applicable = 1 <TAB> <TAB> for opt , optarg in self . chosenOptions : <TAB> <TAB> <TAB> if opt == "" --moz-tools "" : <TAB> <TAB> <TAB> <TAB> self . value = os . path . abspath ( os . path . normpath ( optarg ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . value = os . environ [ self . name ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . value = None <TAB> else : <TAB> <TAB> self . applicable = 0 <TAB> self . determined = 1",if self . name in os . environ :,if os . environ . has_key ( self . name ) :,False,95.12,71.53,,,
"def _Determine_Do ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB> <TAB> self . applicable = 1 <TAB> <TAB> for opt , optarg in self . chosenOptions : <TAB> <TAB> <TAB> if opt == "" --moz-tools "" : <TAB> <TAB> <TAB> <TAB> self . value = os . path . abspath ( os . path . normpath ( optarg ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . value = os . environ [ self . name ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . value = None <TAB> else : <TAB> <TAB> self . applicable = 0 <TAB> self . determined = 1",if self . name in os . environ :,"if rest [ : 2 ] != b""\r\n"" :",False,92.87,63.81,,,
"def _scroll_down ( self , cli ) : <TAB> "" Scroll window down. "" <TAB> info = self . render_info <TAB> if self . vertical_scroll < info . content_height - info . window_height : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . content . move_cursor_down ( cli ) <TAB> <TAB> self . vertical_scroll + = 1",if self . vertical_scroll > info . content_height - info . window_height :,if info . cursor_position . y <= info . configured_scroll_offsets . top :,False,85.06,66.07,,,
"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self.distribution.has_data_files(): <TAB> <TAB> for item in self.distribution.data_files: <TAB> <TAB> <TAB> if isinstance(item, str): <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path(item) <TAB> <TAB> <TAB> <TAB> if os.path.isfile(item): <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(item) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname, filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames: <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path(f) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self.filelist.append(f)",if os . path . isfile ( f ) :,if os . path . isfile ( f ) :,True,100.0,74.43,,,
"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if i == 2 and self . count < 1 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self . count < 4 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i",if i == start_after and self . count < 0 :,if i <= start_after :,False,93.66,71.15,,,
"def is_open ( self ) : <TAB> if self . signup_code : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . messages . get ( "" invalid_signup_code "" ) : <TAB> <TAB> <TAB> <TAB> messages . add_message ( <TAB> <TAB> <TAB> <TAB> <TAB> self . request , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> * * { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" code "" : self . get_code ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP",if self . get_code ( ) :,if self . signup_code_present :,False,98.0,73.4,,,
"def on_delete_from_disk ( self , widget , data = None ) : <TAB> model , iter = self . get_selection ( ) . get_selected ( ) <TAB> if iter : <TAB> <TAB> path = model . get_value ( iter , COLUMN_PATH ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ErrorDialog ( _ ( "" Can ' t delete system item from disk. "" ) ) . launch ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . remove ( path ) <TAB> self . update_items ( )",if not os . path . exists ( path ) :,if self . is_defaultitem ( path ) :,False,94.9,71.33,,,
"def get_detections_for_batch ( self , images ) : <TAB> images = images [ . . . , : : - 1 ] <TAB> detected_faces = self . face_detector . detect_from_batch ( images . copy ( ) ) <TAB> results = [ ] <TAB> for i , d in enumerate ( detected_faces ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> results . append ( None ) <TAB> <TAB> <TAB> continue <TAB> <TAB> d = d [ 0 ] <TAB> <TAB> d = np . clip ( d , 0 , None ) <TAB> <TAB> x1 , y1 , x2 , y2 = map ( int , d [ : - 1 ] ) <TAB> <TAB> results . append ( ( x1 , y1 , x2 , y2 ) ) <TAB> return results",if i == 0 :,if len ( d ) == 0 :,False,97.18,72.57,,,
def on_update ( self ) : <TAB> # <TAB> # Calculate maximum # of planes per well <TAB> # <TAB> self.max_per_well = 0 <TAB> for pd in list(self.plate_well_site.values()): <TAB> <TAB> for wd in list(pd.values()): <TAB> <TAB> <TAB> nplanes = sum([len(x) for x in list(wd.values())]) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.max_per_well = nplanes <TAB> for registrant in self.registrants: <TAB> <TAB> registrant(),if nplanes > self . max_per_well :,if nplanes > self . max_per_well :,True,100.0,74.13,,,
"def is_writable ( self , path ) : <TAB> result = False <TAB> while not result : <TAB> <TAB> if os . path . exists ( path ) : <TAB> <TAB> <TAB> result = os . access ( path , os . W_OK ) <TAB> <TAB> <TAB> break <TAB> <TAB> parent = os . path . dirname ( path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> path = parent <TAB> return result",if parent == self . root :,if parent == path :,False,96.37,72.05,,,
"def _check_seed ( self , seed ) : <TAB> if seed is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _raise_error ( <TAB> <TAB> <TAB> <TAB> "" The random number generator seed value, seed, should be integer type or None. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if seed < 0 : <TAB> <TAB> <TAB> self . _raise_error ( <TAB> <TAB> <TAB> <TAB> "" The random number generator seed value, seed, should be non-negative integer or None. "" <TAB> <TAB> <TAB> )","if not isinstance ( seed , int ) :",if type ( seed ) != int :,False,95.34,70.67,,,
"def write ( self , x ) : <TAB> # try to use backslash and surrogate escape strategies before failing <TAB> self._errors = ""backslashescape"" if self.encoding != ""mbcs"" else ""surrogateescape"" <TAB> try: <TAB> <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors)) <TAB> except UnicodeDecodeError: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._errors = ""surrogateescape"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self._errors = ""replace"" <TAB> <TAB> return io.TextIOWrapper.write(self, to_text(x, errors=self._errors))","if self . encoding == ""mbcs"" :","if self . _errors != ""surrogateescape"" :",False,96.08,71.03,,,
"def post ( self , request , * args , * * kwargs ) : <TAB> validated_session = [ ] <TAB> for session_id in request . data : <TAB> <TAB> session = get_object_or_none ( Session , id = session_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> validated_session . append ( session_id ) <TAB> <TAB> <TAB> self . model . objects . create ( <TAB> <TAB> <TAB> <TAB> name = "" kill_session "" , <TAB> <TAB> <TAB> <TAB> args = session . id , <TAB> <TAB> <TAB> <TAB> terminal = session . terminal , <TAB> <TAB> <TAB> ) <TAB> return Response ( { "" ok "" : validated_session } )",if session . is_valid ( ) :,if session and not session . is_finished :,False,96.74,71.54,,,
"def _has_list_or_dict_var_value_before ( self , arg_index ) : <TAB> for idx , value in enumerate ( self . args ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> if variablematcher . is_list_variable ( <TAB> <TAB> <TAB> value <TAB> <TAB> ) and not variablematcher . is_list_variable_subitem ( value ) : <TAB> <TAB> <TAB> return True <TAB> <TAB> if robotapi . is_dict_var ( value ) and not variablematcher . is_dict_var_access ( <TAB> <TAB> <TAB> value <TAB> <TAB> ) : <TAB> <TAB> <TAB> return True <TAB> return False",if idx == arg_index :,if idx > arg_index :,False,98.08,73.02,,,
"def test_return_correct_type ( self ) : <TAB> for proto in protocols : <TAB> <TAB> # Protocol 0 supports only ASCII strings. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._check_return_correct_type(""abc"", 0) <TAB> <TAB> else: <TAB> <TAB> <TAB> for obj in [b""abc\n"", ""abc\n"", -1, -1.1 * 0.1, str]: <TAB> <TAB> <TAB> <TAB> self._check_return_correct_type(obj, proto)",if proto == 0 :,if proto == 0 :,True,100.0,73.88,,,
"def backward_impl ( self , inputs , outputs , prop_down , accum ) : <TAB> # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB> # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB> # Args <TAB> axis = self.forward_func.info.args[""axis""] <TAB> # Compute <TAB> ## w.r.t. dy <TAB> if prop_down[-1]: <TAB> <TAB> g_dy = inputs[-1].grad <TAB> <TAB> g_dy_ = F.stack(*[o.grad for o in outputs], axis=axis) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g_dy += g_dy_ <TAB> <TAB> else: <TAB> <TAB> <TAB> g_dy.copy_from(g_dy_)",if accum [ 0 ] :,if accum [ - 1 ] :,False,98.44,72.11,,,
"def remove ( self , url ) : <TAB> try : <TAB> <TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> was_selected = i in self . selectedindices ( ) <TAB> <TAB> self . list . delete ( i ) <TAB> <TAB> del self . items [ i ] <TAB> <TAB> if not self . items : <TAB> <TAB> <TAB> self . mp . hidepanel ( self . name ) <TAB> <TAB> elif was_selected : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> self . list . select_set ( i )",if self . items [ i ] == url :,if i >= len ( self . items ) :,False,95.65,71.58,,,
"def prepend ( self , value ) : <TAB> """""" prepend value to nodes """""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> if not tag . text : <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> if len ( root ) > 0 : <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self",if i == 0 :,if i > 0 :,False,98.4,98.7,,,
"def _get_tracks_compositors_list ( ) : <TAB> tracks_list = [ ] <TAB> tracks = current_sequence ( ) . tracks <TAB> compositors = current_sequence ( ) . compositors <TAB> for track_index in range ( 1 , len ( tracks ) - 1 ) : <TAB> <TAB> track_compositors = [ ] <TAB> <TAB> for j in range ( 0 , len ( compositors ) ) : <TAB> <TAB> <TAB> comp = compositors [ j ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> track_compositors . append ( comp ) <TAB> <TAB> tracks_list . append ( track_compositors ) <TAB> return tracks_list",if comp . is_track ( ) :,if comp . transition . b_track == track_index :,False,93.85,71.35,,,
"def __getattr__ ( self , name ) : <TAB> if name in self . _sections : <TAB> <TAB> return "" \n "" . join ( self . _sections [ name ] ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ConanException ( "" ConfigParser: Unrecognized field  ' %s ' "" % name )","if name == ""default"" :",if self . _allowed_fields and name in self . _allowed_fields :,False,85.84,61.35,,,
"def get_first_param_index ( self , group_id , param_group , partition_id ) : <TAB> for index , param in enumerate ( param_group ) : <TAB> <TAB> param_id = self . get_param_id ( param ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return index <TAB> return None",if param_id == group_id and param_id == partition_id :,if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] :,False,81.29,63.25,,,
"def handle_uv_sockets ( self , context ) : <TAB> u_socket = self . inputs [ "" U "" ] <TAB> v_socket = self . inputs [ "" V "" ] <TAB> if self . cast_mode == "" Sphere "" : <TAB> <TAB> u_socket . hide_safe = True <TAB> <TAB> v_socket . hide_safe = True <TAB> elif self . cast_mode in [ "" Cylinder "" , "" Prism "" ] : <TAB> <TAB> v_socket . hide_safe = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> u_socket . hide_safe = False <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> u_socket . hide_safe = False <TAB> <TAB> if v_socket . hide_safe : <TAB> <TAB> <TAB> v_socket . hide_safe = False","elif self . cast_mode == ""Sphere"" :",if u_socket . hide_safe :,False,89.56,64.96,,,
"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """""" Remove the first line of comment from each file if it contains a timestamp. """""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> source = os . path . join ( root , filename ) <TAB> <TAB> <TAB> with open ( source , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> lines = f . readlines ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open ( source , "" w "" ) as f : <TAB> <TAB> <TAB> <TAB> if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( lines [ 0 ] ) <TAB> <TAB> <TAB> <TAB> for line in lines [ 1 : ] : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( line )",if not lines :,if len ( lines ) < 1 :,False,97.39,70.34,,,
"def inner ( request , * args , * * kwargs ) : <TAB> page = request . current_page <TAB> if page : <TAB> <TAB> if page . login_required and not request . user . is_authenticated : <TAB> <TAB> <TAB> return redirect_to_login ( <TAB> <TAB> <TAB> <TAB> urlquote ( request . get_full_path ( ) ) , settings . LOGIN_URL <TAB> <TAB> <TAB> ) <TAB> <TAB> site = get_current_site ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return _handle_no_page ( request ) <TAB> return func ( request , * args , * * kwargs )",if site . is_superuser and site . is_superuser :,"if not user_can_view_page ( request . user , page , site ) :",False,90.2,68.69,,,
"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB> <TAB> self . _last_updated = time . time ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> if "" _create_temporary "" in traceback . format_exc ( ) : <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . _last_updated = time . time ( )",if self . _create_temporary :,"if kwargs . get ( ""in_place"" , False ) :",False,94.36,64.03,,,
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list(kwargs.keys()): <TAB> <TAB> if key not in valid_keys: <TAB> <TAB> <TAB> kwargs.pop(key) <TAB> # Truncate certain values over 1k <TAB> for key in [""play"", ""role"", ""task"", ""playbook""]: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if len(kwargs[""event_data""][key]) > 1024: <TAB> <TAB> <TAB> <TAB> kwargs[""event_data""][key] = Truncator(kwargs[""event_data""][key]).chars( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> )","if key in kwargs [ ""event_data"" ] :","if isinstance ( kwargs . get ( ""event_data"" , { } ) . get ( key ) , str ) :",False,91.05,64.37,,,
"def parse_auth ( val ) : <TAB> if val is not None : <TAB> <TAB> authtype , params = val . split ( "" "" , 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if authtype == "" Basic "" and ' "" ' not in params : <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> params = parse_auth_params(params) <TAB> <TAB> return authtype, params <TAB> return val",if params :,if authtype in known_auth_schemes :,False,94.63,71.68,,,
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self . ctl : <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args )",if value is not None :,if value :,False,97.98,73.5,,,
"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <TAB> <TAB> if self.md_bg_color == t.primary_color: <TAB> <TAB> <TAB> c = t.primary_dark <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> c = t.accent_dark <TAB> return c",elif self . md_bg_color == t . accent_color :,elif self . md_bg_color == t . accent_color :,True,100.0,74.14,,,
def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >> = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> part_l | = 1 << 31 <TAB> <TAB> <TAB> part_h >> = 1 <TAB> <TAB> <TAB> if rflag : <TAB> <TAB> <TAB> <TAB> part_h ^ = 0xD8000000 <TAB> <TAB> _table_h . append ( part_h ) <TAB> return _table_h,if rflag :,if part_h & 1 :,False,96.83,77.97,,,
"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB> <TAB> if not old_obj . summary : <TAB> <TAB> <TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB> <TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB> <TAB> self . session_new . add ( new_obj )",if key in self . entries_count [ key ] :,if key not in old_obj . __table__ . columns :,False,93.51,71.27,,,
"def get_in_turn_repetition ( pred , is_cn = False ) : <TAB> """""" Get in-turn repetition. """""" <TAB> if len ( pred ) == 0 : <TAB> <TAB> return 1.0 <TAB> if isinstance ( pred [ 0 ] , str ) : <TAB> <TAB> pred = [ tok . lower ( ) for tok in pred ] <TAB> <TAB> if is_cn : <TAB> <TAB> <TAB> pred = "" "" . join ( pred ) <TAB> tri_grams = set ( ) <TAB> for i in range ( len ( pred ) - 2 ) : <TAB> <TAB> tri_gram = tuple ( pred [ i : i + 3 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 1.0 <TAB> <TAB> tri_grams . add ( tri_gram ) <TAB> return 0.0",if tri_gram not in tri_grams :,if tri_gram in tri_grams :,False,98.78,98.77,,,
"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( ) # Discard attribute list from reader. <TAB> attrs = {} <TAB> d = AttributeList.match.groupdict() <TAB> for k, v in d.items(): <TAB> <TAB> if v is not None: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> v = subs_attrs(v) <TAB> <TAB> <TAB> <TAB> if v: <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes(v, attrs) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> AttributeList.attrs[k] = v <TAB> AttributeList.subs(attrs) <TAB> AttributeList.attrs.update(attrs)","if isinstance ( v , ( list , tuple ) ) :","if k == ""attrlist"" :",False,94.37,61.84,,,
"def _parse ( self , engine ) : <TAB> """""" Parse the layer. """""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if not isinstance ( self . axis , ( int , float ) ) :","if not isinstance ( self . axis , int ) :",False,97.19,96.62,,,
"def __getattr__ ( self , attrname ) : <TAB> if attrname in ( "" visamp "" , "" visamperr "" , "" visphi "" , "" visphierr "" ) : <TAB> <TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB> elif attrname in ( "" cflux "" , "" cfluxerr "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> raise AttributeError ( attrname )","if self . flag == ""masked"" :","if self . __dict__ [ ""_"" + attrname ] != None :",False,91.23,70.71,,,
"def draw ( self , context ) : <TAB> layout = self . layout <TAB> presets . draw_presets_ops ( layout , context = context ) <TAB> for category in presets . get_category_names ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> class_name = preset_category_menus [ category ] . __name__ <TAB> <TAB> <TAB> <TAB> layout . menu ( class_name )",if category in preset_category_menus :,if category in preset_category_menus :,True,100.0,74.14,,,
"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> info , reference = value <TAB> <TAB> if info not in self . _reverse_infos : <TAB> <TAB> <TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB> <TAB> <TAB> self . _infos . append ( info ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB> <TAB> <TAB> self . _references . append ( reference ) <TAB> <TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB> <TAB> <TAB> self . _reverse_infos [ info ] , <TAB> <TAB> <TAB> self . _reverse_references [ reference ] , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) )",if reference not in self . _reverse_references :,if reference not in self . _reverse_references :,True,100.0,74.61,,,
"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> info , reference = value <TAB> <TAB> if info not in self . _reverse_infos : <TAB> <TAB> <TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB> <TAB> <TAB> self . _infos . append ( info ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB> <TAB> <TAB> self . _references . append ( reference ) <TAB> <TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB> <TAB> <TAB> self . _reverse_infos [ info ] , <TAB> <TAB> <TAB> self . _reverse_references [ reference ] , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) )",if reference not in self . _reverse_references :,if len ( symbol ) >= delimiter_len and symbol [ - delimiter_len : ] == delimiter :,False,91.73,69.8,,,
"def output_type ( data , request , response ) : <TAB> accept = request . accept <TAB> if accept in ( "" "" , "" * "" , "" / "" ) : <TAB> <TAB> handler = default or handlers and next ( iter ( handlers . values ( ) ) ) <TAB> else : <TAB> <TAB> handler = default <TAB> <TAB> accepted = [ accept_quality ( accept_type ) for accept_type in accept . split ( "" , "" ) ] <TAB> <TAB> accepted . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> for _quality , accepted_content_type in reversed ( accepted ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> handler = handlers [ accepted_content_type ] <TAB> <TAB> <TAB> <TAB> break <TAB> if not handler : <TAB> <TAB> raise falcon . HTTPNotAcceptable ( error ) <TAB> response . content_type = handler . content_type <TAB> return handler ( data , request = request , response = response )",if _quality == accepted_content_type :,if accepted_content_type in handlers :,False,97.17,73.25,,,
"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> flatten_items . append ( b "" "" ) <TAB> <TAB> elif isinstance ( item , bytes ) : <TAB> <TAB> <TAB> flatten_items . append ( item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB> <TAB> elif isinstance ( item , list ) : <TAB> <TAB> <TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items )","elif isinstance ( item , bytes ) :","elif isinstance ( item , int ) :",False,98.64,73.35,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_mime_type ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_quality ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 8 :,False,98.39,73.07,,,
"def delete ( self , waiters ) : <TAB> # Delete flow. <TAB> msgs = self.ofctl.get_all_flow(waiters) <TAB> for msg in msgs: <TAB> <TAB> for stats in msg.body: <TAB> <TAB> <TAB> vlan_id = VlanRouter._cookie_to_id(REST_VLANID, stats.cookie) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.ofctl.delete_flow(stats) <TAB> assert len(self.packet_buffer) == 0",if vlan_id in self . packet_buffer :,if vlan_id == self . vlan_id :,False,94.6,69.45,,,
def missing_push_allowance ( push_allowances : List [ PushAllowance ] ) - > bool : <TAB> for push_allowance in push_allowances : <TAB> <TAB> # a null databaseId indicates this is not a GitHub App. <TAB> <TAB> if push_allowance.actor.databaseId is None: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True,if push_allowance . actor . databaseId == push_allowance . actor . databaseId :,if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) :,False,84.61,90.37,,,
"def _cluster_page ( self , htmlpage ) : <TAB> template_cluster , preferred = _CLUSTER_NA , None <TAB> if self . clustering : <TAB> <TAB> self . clustering . add_page ( htmlpage ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> clt = self . clustering . classify ( htmlpage ) <TAB> <TAB> <TAB> if clt != - 1 : <TAB> <TAB> <TAB> <TAB> template_cluster = preferred = self . template_names [ clt ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> template_cluster = _CLUSTER_OUTLIER <TAB> return template_cluster , preferred",if self . template_names :,if self . clustering . is_fit :,False,96.19,71.97,,,
"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB> <TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [] <TAB> nbr = 0 <TAB> while True: <TAB> <TAB> line = self.readline() <TAB> <TAB> if not line: <TAB> <TAB> <TAB> break <TAB> <TAB> out.append(line) <TAB> <TAB> if size > -1: <TAB> <TAB> <TAB> nbr += len(line) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out",if nbr > self . _size :,if nbr > size :,False,97.69,72.85,,,
"def post_mortem ( t = None ) : <TAB> # handling the default <TAB> <IF-STMT> <TAB> <TAB> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB> <TAB> # being handled, otherwise it returns None <TAB> <TAB> t = sys.exc_info()[2] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""A valid traceback must be passed if no exception is being handled."" <TAB> <TAB> <TAB> ) <TAB> p = BPdb() <TAB> p.reset() <TAB> p.interaction(None, t)",if t is None :,if t is None :,True,100.0,74.31,,,
"def post_mortem ( t = None ) : <TAB> # handling the default <TAB> <IF-STMT> <TAB> <TAB> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB> <TAB> # being handled, otherwise it returns None <TAB> <TAB> t = sys.exc_info()[2] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""A valid traceback must be passed if no exception is being handled."" <TAB> <TAB> <TAB> ) <TAB> p = BPdb() <TAB> p.reset() <TAB> p.interaction(None, t)",if t is None :,"if txt [ : 3 ] == ""&#x"" :",False,85.13,59.69,,,
"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB> <TAB> value = item . group ( "" stringval "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = item . group ( "" value "" ) <TAB> <TAB> value = _pythonize ( value ) <TAB> <TAB> if not item . group ( "" name "" ) : <TAB> <TAB> <TAB> args . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> name = item . group ( "" name "" ) <TAB> <TAB> <TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs","if value == """" :",if value is None :,False,97.47,68.78,,,
"def IT ( cpu ) : <TAB> cc = cpu . instruction . cc <TAB> true_case = cpu . _evaluate_conditional ( cc ) <TAB> # this is incredibly hacky--how else does capstone expose this? <TAB> # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB> for c in cpu.instruction.mnemonic[1:]: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cpu._it_conditional.append(true_case) <TAB> <TAB> elif c == ""e"": <TAB> <TAB> <TAB> cpu._it_conditional.append(not true_case)","if c == ""g"" :","if c == ""t"" :",False,98.38,72.5,,,
"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB> <TAB> data = await self._retrieve_messages(self.retrieve) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.limit = 0 # terminate the infinite loop <TAB> <TAB> if self.reverse: <TAB> <TAB> <TAB> data = reversed(data) <TAB> <TAB> if self._filter: <TAB> <TAB> <TAB> data = filter(self._filter, data) <TAB> <TAB> for element in data: <TAB> <TAB> <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",if self . limit > self . limit :,if len ( data ) < 100 :,False,96.4,70.79,,,
"def _get_beta_accumulators ( self ) : <TAB> with tf . init_scope ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> graph = None <TAB> <TAB> else : <TAB> <TAB> <TAB> graph = tf . get_default_graph ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> self . _get_non_slot_variable ( "" beta1_power "" , graph = graph ) , <TAB> <TAB> <TAB> self . _get_non_slot_variable ( "" beta2_power "" , graph = graph ) , <TAB> <TAB> )",if self . _train_mode :,if tf . executing_eagerly ( ) :,False,94.78,70.45,,,
"def prefixed ( self , prefix : _StrType ) - > typing . Iterator [ "" Env "" ] : <TAB> """""" Context manager for parsing envvars with a common prefix. """""" <TAB> try : <TAB> <TAB> old_prefix = self . _prefix <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _prefix = prefix <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _prefix = f "" { old_prefix } { prefix } "" <TAB> <TAB> yield self <TAB> finally : <TAB> <TAB> # explicitly reset the stored prefix on completion and exceptions <TAB> <TAB> self._prefix = None <TAB> self._prefix = old_prefix","if old_prefix == """" :",if old_prefix is None :,False,96.8,52.44,,,
"def decode_content ( self ) : <TAB> """""" Return the best possible representation of the response body. """""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB> <TAB> ct , options = parse_options_header ( ct ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> if ct in JSON_CONTENT_TYPES : <TAB> <TAB> <TAB> return self . json ( charset ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . text ( charset ) <TAB> <TAB> elif ct == FORM_URL_ENCODED : <TAB> <TAB> <TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content",elif ct in TEXT_CONTENT_TYPES :,"elif ct . startswith ( ""text/"" ) :",False,95.21,67.61,,,
"def test_incrementaldecoder ( self ) : <TAB> UTF8Writer = codecs . getwriter ( "" utf-8 "" ) <TAB> for sizehint in [ None , - 1 ] + list ( range ( 1 , 33 ) ) + [ 64 , 128 , 256 , 512 , 1024 ] : <TAB> <TAB> istream = BytesIO ( self . tstring [ 0 ] ) <TAB> <TAB> ostream = UTF8Writer ( BytesIO ( ) ) <TAB> <TAB> decoder = self . incrementaldecoder ( ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = istream . read ( sizehint ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> u = decoder . decode ( data ) <TAB> <TAB> <TAB> <TAB> ostream . write ( u ) <TAB> <TAB> self . assertEqual ( ostream . getvalue ( ) , self . tstring [ 1 ] )",if not data :,if not data :,True,100.0,74.59,,,
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .png "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .md "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )","if fn . endswith ( "".py"" ) :",if os . path . isdir ( fn ) :,False,95.95,65.94,,,
"def _delete_reason ( self ) : <TAB> for i in range ( _lib . X509_REVOKED_get_ext_count ( self . _revoked ) ) : <TAB> <TAB> ext = _lib . X509_REVOKED_get_ext ( self . _revoked , i ) <TAB> <TAB> obj = _lib . X509_EXTENSION_get_object ( ext ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _lib . X509_EXTENSION_free ( ext ) <TAB> <TAB> <TAB> _lib . X509_REVOKED_delete_ext ( self . _revoked , i ) <TAB> <TAB> <TAB> break",if obj . status == _lib . OBJ_STATUS_SUCCESS :,if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason :,False,91.37,68.7,,,
"def hexcmp ( x , y ) : <TAB> try : <TAB> <TAB> a = int ( x , 16 ) <TAB> <TAB> b = int ( y , 16 ) <TAB> <TAB> if a < b : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> return cmp ( x , y )",if a > b :,if a > b :,True,100.0,74.16,,,
"def get_indentation_count ( view , start ) : <TAB> indent_count = 0 <TAB> i = start - 1 <TAB> while i > 0 : <TAB> <TAB> ch = view . substr ( i ) <TAB> <TAB> scope = view . scope_name ( i ) <TAB> <TAB> # Skip preprocessors, strings, characaters and comments <TAB> <TAB> if ""string.quoted"" in scope or ""comment"" in scope or ""preprocessor"" in scope: <TAB> <TAB> <TAB> extent = view.extract_scope(i) <TAB> <TAB> <TAB> i = extent.a - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> else: <TAB> <TAB> <TAB> i -= 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> indent_count -= 1 <TAB> <TAB> elif ch == ""{"": <TAB> <TAB> <TAB> indent_count += 1 <TAB> return indent_count","if ch == ""{"" :","if ch == ""}"" :",False,98.94,73.48,,,
"def set ( self , name , value , ex = None , px = None , nx = False , xx = False ) : <TAB> if ( <TAB> <TAB> ( not nx and not xx ) <TAB> <TAB> or ( nx and self . _db . get ( name , None ) is None ) <TAB> <TAB> or ( xx and not self . _db . get ( name , None ) is None ) <TAB> ) : <TAB> <TAB> if ex > 0 : <TAB> <TAB> <TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( seconds = ex ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( milliseconds = px ) ) <TAB> <TAB> self . _db [ name ] = str ( value ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return None",if px > 0 :,elif px > 0 :,False,98.86,73.81,,,
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> if start in line : <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line : <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ]",if should_yield :,if should_yield and line :,False,97.35,72.1,,,
"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB> <TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB> <TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB> <TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) : <TAB> <TAB> <TAB> yield handler",if handler is None :,"if not isinstance ( handler , handlers . ResourceWatchingHandler ) :",False,94.5,69.87,,,
"def __enter__ ( self ) : <TAB> if log_timer : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . logger . debug ( "" %s  starting "" % self . name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( ( "" [ %s  starting]... "" % self . name ) ) <TAB> <TAB> self . tstart = time . time ( )",if self . logger :,if self . logger :,True,100.0,74.04,,,
"def _handle_errors ( errors ) : <TAB> """""" Log out and possibly reraise errors during import. """""" <TAB> if not errors : <TAB> <TAB> return <TAB> log_all = True # pylint: disable=unused-variable <TAB> err_msg = ""T2T: skipped importing {num_missing} data_generators modules."" <TAB> print(err_msg.format(num_missing=len(errors))) <TAB> for module, err in errors: <TAB> <TAB> err_str = str(err) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""Did not import module: %s; Cause: %s"" % (module, err_str)) <TAB> <TAB> if not _is_import_err_msg(err_str, module): <TAB> <TAB> <TAB> print(""From module %s"" % module) <TAB> <TAB> <TAB> raise err",if log_all :,if log_all :,True,100.0,99.35,,,
"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB> <TAB> if isinstance ( v , ( list , tuple ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB> <TAB> <TAB> for v in _ungroup ( v , groups ) : <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else : <TAB> <TAB> <TAB> yield v",if groups is None :,if groups is not None :,False,98.11,72.73,,,
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ),if dt < self . timeout :,if dt > self . timeout :,False,98.91,98.72,,,
"def dont_let_stderr_buffer ( ) : <TAB> while True : <TAB> <TAB> line = context . daemon . stderr . readline ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> if DEAD_DEPLOYD_WORKER_MESSAGE . encode ( "" utf-8 "" ) in line : <TAB> <TAB> <TAB> context . num_workers_crashed + = 1 <TAB> <TAB> print ( f "" deployd stderr:  { line } "" )",if not line :,if not line :,True,100.0,74.1,,,
"def mergeHiLo ( self , x_stats ) : <TAB> """""" Merge the highs and lows of another accumulator into myself. """""" <TAB> if x_stats . firsttime is not None : <TAB> <TAB> if self . firsttime is None or x_stats . firsttime < self . firsttime : <TAB> <TAB> <TAB> self . firsttime = x_stats . firsttime <TAB> <TAB> <TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . lasttime = x_stats . lasttime <TAB> <TAB> <TAB> self . last = x_stats . last",if self . lasttime is None or x_stats . lasttime < self . lasttime :,if self . lasttime is None or x_stats . lasttime >= self . lasttime :,False,97.98,98.38,,,
"def test_rlimit_get ( self ) : <TAB> import resource <TAB> p = psutil . Process ( os . getpid ( ) ) <TAB> names = [ x for x in dir ( psutil ) if x . startswith ( "" RLIMIT "" ) ] <TAB> assert names <TAB> for name in names : <TAB> <TAB> value = getattr ( psutil , name ) <TAB> <TAB> self . assertGreaterEqual ( value , 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( value , getattr ( resource , name ) ) <TAB> <TAB> <TAB> self . assertEqual ( p . rlimit ( value ) , resource . getrlimit ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret = p . rlimit ( value ) <TAB> <TAB> <TAB> self . assertEqual ( len ( ret ) , 2 ) <TAB> <TAB> <TAB> self . assertGreaterEqual ( ret [ 0 ] , - 1 ) <TAB> <TAB> <TAB> self . assertGreaterEqual ( ret [ 1 ] , - 1 )","if hasattr ( resource , name ) :",if name in dir ( resource ) :,False,97.73,73.0,,,
"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB> <TAB> if not prop_name in entity . unindexed_properties ( ) : <TAB> <TAB> <TAB> prop_vals = entity [ prop_name ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> num_prop_vals = len ( prop_vals ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes + = 2 * num_prop_vals <TAB> return writes","if isinstance ( prop_vals , list ) :","if isinstance ( prop_vals , ( list ) ) :",False,97.71,72.11,,,
"def check_value_check ( self , x_data , t_data , use_cudnn ) : <TAB> x = chainer . Variable ( x_data ) <TAB> t = chainer . Variable ( t_data ) <TAB> with chainer . using_config ( "" use_cudnn "" , use_cudnn ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Check if it throws nothing <TAB> <TAB> <TAB> functions.softmax_cross_entropy( <TAB> <TAB> <TAB> <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB> <TAB> <TAB> ) <TAB> <TAB> else: <TAB> <TAB> <TAB> with self.assertRaises(ValueError): <TAB> <TAB> <TAB> <TAB> functions.softmax_cross_entropy( <TAB> <TAB> <TAB> <TAB> <TAB> x, t, enable_double_backprop=self.enable_double_backprop <TAB> <TAB> <TAB> <TAB> )",if self . use_cudnn :,if self . valid :,False,98.13,73.1,,,
"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB> <TAB> fn = mo . groups ( ) [ 0 ] <TAB> <TAB> fn = fn . replace ( "" "" , "" _ "" ) <TAB> <TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> if isinstance ( fn , str ) : <TAB> <TAB> <TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn = unicode ( fn ) <TAB> <TAB> if note_markdown ( note ) : <TAB> <TAB> <TAB> fn + = "" .mkdn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> fn + = "" .txt "" <TAB> <TAB> return fn <TAB> else : <TAB> <TAB> return "" ""","if fn . startswith ( ""/"" ) :",if not fn :,False,96.39,70.32,,,
"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB> <TAB> s = s [ 1 : ] <TAB> <TAB> end = s . find ( "" ; "" ) <TAB> <TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB> <TAB> <TAB> end = s . find ( "" ; "" , end + 1 ) <TAB> <TAB> if end < 0 : <TAB> <TAB> <TAB> end = len ( s ) <TAB> <TAB> f = s [ : end ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> i = f . index ( "" = "" ) <TAB> <TAB> <TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB> <TAB> plist . append ( f . strip ( ) ) <TAB> <TAB> s = s [ end : ] <TAB> return plist","if ""="" in f :","if ""="" in f :",True,100.0,74.68,,,
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if not grandchild . getAttribute ( ""Source"" ) :","if grandchild . tagName != ""File"" :",False,95.71,72.12,,,
"def date_to_format ( value , target_format ) : <TAB> """""" Convert date to specified format """""" <TAB> if target_format == str : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . datetime ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . time ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB> <TAB> ret = value <TAB> return ret","if isinstance ( value , datetime . date ) :","if isinstance ( value , datetime . date ) :",True,100.0,99.48,,,
"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB> <TAB> definition = column ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> IECore . msg ( <TAB> <TAB> <TAB> <TAB> IECore . Msg . Level . Error , <TAB> <TAB> <TAB> <TAB> "" GafferImageUI.CatalogueUI "" , <TAB> <TAB> <TAB> <TAB> "" No column registered with name  ' %s ' "" % name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( definition , IconColumn ) : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB> <TAB> columns . append ( c ) <TAB> return columns",if definition is None :,if not definition :,False,98.22,73.23,,,
"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = v . item ( ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . metrics_to_scalars ( v ) <TAB> <TAB> new_metrics [ k ] = v <TAB> return new_metrics","if isinstance ( v , dict ) :","if isinstance ( v , torch . Tensor ) :",False,96.29,71.39,,,
"def start ( self , connection ) : <TAB> try : <TAB> <TAB> if self . client_name : <TAB> <TAB> <TAB> creds = gssapi . Credentials ( name = gssapi . Name ( self . client_name ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> creds = None <TAB> <TAB> hostname = self . get_hostname ( connection ) <TAB> <TAB> name = gssapi . Name ( <TAB> <TAB> <TAB> b "" @ "" . join ( [ self . service , hostname ] ) , gssapi . NameType . hostbased_service <TAB> <TAB> ) <TAB> <TAB> context = gssapi . SecurityContext ( name = name , creds = creds ) <TAB> <TAB> return context . step ( None ) <TAB> except gssapi . raw . misc . GSSError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> else : <TAB> <TAB> <TAB> raise",if self . fail_silently :,if self . fail_soft :,False,98.89,73.73,,,
"def nanmax ( self , axis = None , dtype = None , keepdims = None ) : <TAB> ret = self . _reduction ( <TAB> <TAB> "" nanmax "" , axis = axis , dtype = dtype , keepdims = keepdims , todense = True <TAB> ) <TAB> if not issparse ( ret ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ret <TAB> <TAB> xps = get_sparse_module ( self . spmatrix ) <TAB> <TAB> ret = SparseNDArray ( xps . csr_matrix ( ret ) ) <TAB> <TAB> return ret <TAB> return ret",if self . spmatrix is None :,if get_array_module ( ret ) . isscalar ( ret ) :,False,90.24,69.59,,,
"def utterance_to_sample ( query_data , tagging_scheme , language ) : <TAB> tokens , tags = [ ] , [ ] <TAB> current_length = 0 <TAB> for chunk in query_data : <TAB> <TAB> chunk_tokens = tokenize ( chunk [ TEXT ] , language ) <TAB> <TAB> tokens + = [ <TAB> <TAB> <TAB> Token ( t . value , current_length + t . start , current_length + t . end ) <TAB> <TAB> <TAB> for t in chunk_tokens <TAB> <TAB> ] <TAB> <TAB> current_length + = len ( chunk [ TEXT ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tags + = negative_tagging ( len ( chunk_tokens ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags + = positive_tagging ( <TAB> <TAB> <TAB> <TAB> tagging_scheme , chunk [ SLOT_NAME ] , len ( chunk_tokens ) <TAB> <TAB> <TAB> ) <TAB> return { TOKENS : tokens , TAGS : tags }",if SLOT_NAME in chunk :,if SLOT_NAME not in chunk :,False,99.04,73.66,,,
"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB> <TAB> if isinstance ( t , Index ) : <TAB> <TAB> <TAB> self . _use_indexes . append ( t ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _use_indexes . append ( Index ( t ) )","elif isinstance ( t , str ) :","elif isinstance ( t , str ) :",True,100.0,74.26,,,
"def reconfigServiceWithBuildbotConfig ( self , new_config ) : <TAB> if new_config . manhole != self . manhole : <TAB> <TAB> if self . manhole : <TAB> <TAB> <TAB> yield self . manhole . disownServiceParent ( ) <TAB> <TAB> <TAB> self . manhole = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . manhole = new_config . manhole <TAB> <TAB> <TAB> yield self . manhole . setServiceParent ( self ) <TAB> # chain up <TAB> yield service.ReconfigurableServiceMixin.reconfigServiceWithBuildbotConfig( <TAB> <TAB> self, new_config <TAB> )",if self . manhole :,if new_config . manhole :,False,96.9,72.82,,,
"def cleanup_folder ( target_folder ) : <TAB> for file in os . listdir ( target_folder ) : <TAB> <TAB> file_path = os . path . join ( target_folder , file ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . remove ( file_path ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> logging . error ( e )",if os . path . exists ( file_path ) :,if os . path . isfile ( file_path ) :,False,97.91,72.47,,,
"def to_key ( literal_or_identifier ) : <TAB> """""" returns string representation of this object """""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k )","if isinstance ( k , float ) :","if isinstance ( k , float ) :",True,100.0,99.59,,,
"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB> <TAB> if pos in decompiler . targets : <TAB> <TAB> <TAB> decompiler . process_target ( pos ) <TAB> <TAB> method = getattr ( decompiler , opname , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB> <TAB> decompiler . pos = pos <TAB> <TAB> decompiler . next_pos = next_pos <TAB> <TAB> x = method ( * arg ) <TAB> <TAB> if x is not None : <TAB> <TAB> <TAB> decompiler . stack . append ( x )",if method is None :,if method is None :,True,100.0,74.47,,,
"def shutdown ( self , timeout , callback = None ) : <TAB> logger . debug ( "" background worker got shutdown request "" ) <TAB> with self . _lock : <TAB> <TAB> if self . is_alive : <TAB> <TAB> <TAB> self . _queue . put_nowait ( _TERMINATOR ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _wait_shutdown ( timeout , callback ) <TAB> <TAB> self . _thread = None <TAB> <TAB> self . _thread_for_pid = None <TAB> logger . debug ( "" background worker shut down "" )",if timeout is not None :,if timeout > 0.0 :,False,96.96,72.25,,,
"def getDOMImplementation ( features = None ) : <TAB> if features : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> features = domreg . _parse_feature_string ( features ) <TAB> <TAB> for f , v in features : <TAB> <TAB> <TAB> if not Document . implementation . hasFeature ( f , v ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> return Document . implementation","if isinstance ( features , str ) :","if isinstance ( features , str ) :",True,100.0,74.14,,,
"def validate_subevent ( self , subevent ) : <TAB> if self . context [ "" event "" ] . has_subevents : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError ( "" You need to set a subevent. "" ) <TAB> <TAB> if subevent . event != self . context [ "" event "" ] : <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> "" The specified subevent does not belong to this event. "" <TAB> <TAB> <TAB> ) <TAB> elif subevent : <TAB> <TAB> raise ValidationError ( "" You cannot set a subevent for this event. "" ) <TAB> return subevent",if subevent is None :,if not subevent :,False,97.29,72.5,,,
"def einsum ( job_id , idx , einsum_expr , data_list ) : <TAB> _ , all_parties = session_init ( job_id , idx ) <TAB> with SPDZ ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = FixedPointTensor . from_source ( "" x "" , data_list [ 0 ] ) <TAB> <TAB> <TAB> y = FixedPointTensor . from_source ( "" y "" , all_parties [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> x = FixedPointTensor . from_source ( "" x "" , all_parties [ 0 ] ) <TAB> <TAB> <TAB> y = FixedPointTensor . from_source ( "" y "" , data_list [ 1 ] ) <TAB> <TAB> return x . einsum ( y , einsum_expr ) . get ( )",if idx == 0 :,if idx == 0 :,True,100.0,74.48,,,
"def slowSorted ( qq ) : <TAB> "" Reference sort peformed by insertion using only < "" <TAB> rr = list ( ) <TAB> for q in qq : <TAB> <TAB> i = 0 <TAB> <TAB> for i in range ( len ( rr ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> rr . insert ( i , q ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> rr . append ( q ) <TAB> return rr",if rr [ i ] [ 0 ] < q [ 0 ] :,if q < rr [ i ] :,False,93.17,70.75,,,
"def _format_entry ( entry , src ) : <TAB> if entry : <TAB> <TAB> result = [ ] <TAB> <TAB> for x in entry . split ( "" , "" ) : <TAB> <TAB> <TAB> x = x . strip ( ) <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( src , x ) ) : <TAB> <TAB> <TAB> <TAB> result . append ( relpath ( os . path . join ( src , x ) , src ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result . append ( relpath ( os . path . abspath ( x ) , src ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" No entry script  %s  found "" % x ) <TAB> <TAB> return "" , "" . join ( result )","elif os . path . isdir ( os . path . join ( src , x ) ) :",elif os . path . exists ( x ) :,False,94.44,72.06,,,
"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB> <TAB> if shape : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif "" M "" in fmt : <TAB> <TAB> <TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif "" i "" in fmt : <TAB> <TAB> <TAB> t = int <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> t = float <TAB> <TAB> else : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self . addColumn ( ColumnItem ( name , i , type = t ) )","elif ""F"" in fmt :","elif ""f"" in fmt :",False,98.84,73.76,,,
"def tool_lineages ( self , trans ) : <TAB> rval = [ ] <TAB> for id , tool in self . app . toolbox . tools ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lineage_dict = tool . lineage . to_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lineage_dict = None <TAB> <TAB> entry = dict ( id = id , lineage = lineage_dict ) <TAB> <TAB> rval . append ( entry ) <TAB> return rval","if hasattr ( tool , ""lineage"" ) :","if hasattr ( tool , ""lineage"" ) :",True,100.0,74.27,,,
"def item ( self , tensor ) : <TAB> numel = 0 <TAB> if len ( tensor . shape ) > 0 : <TAB> <TAB> numel = fct . reduce ( op . mul , tensor . shape ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" expected tensor with one element,  "" f "" got  { tensor . shape } "" <TAB> <TAB> <TAB> ) <TAB> if numel == 1 : <TAB> <TAB> return tensor [ 0 ] <TAB> return tensor",if numel != 1 :,if numel != 1 :,True,100.0,74.33,,,
"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB> <TAB> <TAB> ) . json ( ) <TAB> <TAB> <TAB> if "" Version "" in resp : <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta",if match :,if match is not None and len ( match . groups ( ) ) == 1 :,False,93.1,69.01,,,
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> if isinstance ( leaf , Integer ) : <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse : <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector",if leaf == SymbolTrue :,if leaf == SymbolTrue :,True,100.0,74.5,,,
"def _test_set_metadata ( self , metadata , mask = None ) : <TAB> header = ofproto . OXM_OF_METADATA <TAB> match = OFPMatch ( ) <TAB> if mask is None : <TAB> <TAB> match . set_metadata ( metadata ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> header = ofproto . OXM_OF_METADATA_W <TAB> <TAB> match . set_metadata_masked ( metadata , mask ) <TAB> <TAB> metadata & = mask <TAB> self . _test_serialize_and_parser ( match , header , metadata , mask )",if header == ofproto . OXM_OF_METADATA_W :,if ( mask + 1 ) >> 64 != 1 :,False,91.3,68.64,,,
"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB> <TAB> icon = "" class "" <TAB> else : <TAB> <TAB> if tok . visibility == "" private "" : <TAB> <TAB> <TAB> icon = "" method_priv "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> icon = "" method_prot "" <TAB> <TAB> else : <TAB> <TAB> <TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] )","elif tok . visibility == ""prot"" :","elif tok . visibility == ""protected"" :",False,98.45,73.27,,,
"def path_sum2 ( root , s ) : <TAB> if root is None : <TAB> <TAB> return [ ] <TAB> res = [ ] <TAB> stack = [ ( root , [ root . val ] ) ] <TAB> while stack : <TAB> <TAB> node , ls = stack . pop ( ) <TAB> <TAB> if node . left is None and node . right is None and sum ( ls ) == s : <TAB> <TAB> <TAB> res . append ( ls ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stack . append ( ( node . left , ls + [ node . left . val ] ) ) <TAB> <TAB> if node . right is not None : <TAB> <TAB> <TAB> stack . append ( ( node . right , ls + [ node . right . val ] ) ) <TAB> return res",if node . left is not None :,if node . left is not None :,True,100.0,74.61,,,
"def clear_slot ( self , slot_id , trigger_changed ) : <TAB> if self . slots [ slot_id ] is not None : <TAB> <TAB> old_resource_id = self . slots [ slot_id ] . resource_id <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . sell_list [ old_resource_id ] <TAB> <TAB> else : <TAB> <TAB> <TAB> del self . buy_list [ old_resource_id ] <TAB> self . slots [ slot_id ] = None <TAB> if trigger_changed : <TAB> <TAB> self . _changed ( )",if old_resource_id in self . sell_list :,if self . slots [ slot_id ] . selling :,False,93.03,69.55,,,
"def OnRightUp ( self , event ) : <TAB> self . HandleMouseEvent ( event ) <TAB> self . Unbind ( wx . EVT_RIGHT_UP , handler = self . OnRightUp ) <TAB> self . Unbind ( wx . EVT_MOUSE_CAPTURE_LOST , handler = self . OnRightUp ) <TAB> self . _right = False <TAB> if not self . _left : <TAB> <TAB> self . Unbind ( wx . EVT_MOTION , handler = self . OnMotion ) <TAB> <TAB> self . SendChangeEvent ( ) <TAB> <TAB> self . SetToolTip ( wx . ToolTip ( self . _tooltip ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . ReleaseMouse ( )",if self . _left :,if self . HasCapture ( ) :,False,97.16,72.45,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> for arg in args : <TAB> <TAB> for k , v in arg . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> arg [ k ] = AttrDict ( v ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arg [ k ] = v <TAB> super ( AttrDict , self ) . __init__ ( * args , * * kwargs )","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.28,,,
"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB> <TAB> t = threading . current_thread ( ) <TAB> <TAB> t . name = func . __name__ <TAB> <TAB> try : <TAB> <TAB> <TAB> t . status = func ( * args , * * kwargs ) <TAB> <TAB> except EscapeException as e : # user aborted <TAB> <TAB> <TAB> t.status = ""aborted by user"" <TAB> <TAB> <TAB> if status: <TAB> <TAB> <TAB> <TAB> status(""%s aborted"" % t.name, priority=2) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> t.exception = e <TAB> <TAB> <TAB> t.status = ""exception"" <TAB> <TAB> <TAB> vd.exceptionCaught(e) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> t.sheet.currentThreads.remove(t)",if t in t . sheet . currentThreads :,if t . sheet :,False,97.57,72.95,,,
"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB> <TAB> if text == "" "" : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 )","elif text == """" :",elif text != self . labelList . item ( i ) . text ( ) :,False,89.56,62.54,,,
"def __attempt_add_to_linked_match ( <TAB> self , input_name , hdca , collection_type_description , subcollection_type ) : <TAB> structure = get_structure ( <TAB> <TAB> hdca , collection_type_description , leaf_subcollection_type = subcollection_type <TAB> ) <TAB> if not self . linked_structure : <TAB> <TAB> self . linked_structure = structure <TAB> <TAB> self . collections [ input_name ] = hdca <TAB> <TAB> self . subcollection_types [ input_name ] = subcollection_type <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise exceptions . MessageException ( CANNOT_MATCH_ERROR_MESSAGE ) <TAB> <TAB> self . collections [ input_name ] = hdca <TAB> <TAB> self . subcollection_types [ input_name ] = subcollection_type",if subcollection_type in structure . subcollection_types :,if not self . linked_structure . can_match ( structure ) :,False,93.77,69.79,,,
"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB> <TAB> time . sleep ( 2 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if not online and not self . _is_testbot_online ( ) : <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB> <TAB> )",if self . _testbot_is_offline ( ) :,if online and self . _is_testbot_online ( ) :,False,94.93,71.09,,,
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> if self . match_function ( file ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file )",if self . match_function ( path ) :,if self . match_function ( path ) :,True,100.0,74.63,,,
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> if not Placeholder . check_resolved ( v . size ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed",if height > MAX_TEXTURE_SIZE or width > MAX_TEXTURE_SIZE :,if height <= MAX_TEXTURE_SIZE and width <= MAX_TEXTURE_SIZE :,False,95.34,71.61,,,
"def brightness_func ( args ) : <TAB> device = _get_device_from_filter ( args ) <TAB> if args . set is None : <TAB> <TAB> # Get brightness <TAB> <TAB> if args.raw: <TAB> <TAB> <TAB> print(str(device.brightness)) <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""Brightness: {0}%"".format(device.brightness)) <TAB> else: <TAB> <TAB> brightness_value = float(_clamp_u8(args.set)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""Setting brightness to {0}%"".format(brightness_value)) <TAB> <TAB> device.brightness = brightness_value",if brightness_value > 0 :,if not args . raw :,False,96.51,69.93,,,
"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model reference. <TAB> if not self.model_class: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.model_class = owner_model <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> ""ModelType: Unable to resolve model '{}'."".format(self.model_name) <TAB> <TAB> <TAB> ) <TAB> super(ModelType, self)._setup(field_name, owner_model)","if field_name == ""model"" :",if self . model_name == owner_model . __name__ :,False,90.77,59.3,,,
"def build_json_schema_object ( cls , parent_builder = None ) : <TAB> builder = builders . ObjectBuilder ( cls , parent_builder ) <TAB> if builder . count_type ( builder . type ) > 1 : <TAB> <TAB> return builder <TAB> for _ , name , field in cls . iterate_with_name ( ) : <TAB> <TAB> if isinstance ( field , fields . EmbeddedField ) : <TAB> <TAB> <TAB> builder . add_field ( name , field , _parse_embedded ( field , builder ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> builder . add_field ( name , field , _parse_list ( field , builder ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> builder . add_field ( name , field , _create_primitive_field_schema ( field ) ) <TAB> return builder","elif isinstance ( field , fields . ListField ) :","elif isinstance ( field , fields . ListField ) :",True,100.0,74.53,,,
"def filter_module ( mod , type_req = None , subclass_req = None ) : <TAB> for name in dir ( mod ) : <TAB> <TAB> val = getattr ( mod , name ) <TAB> <TAB> if type_req is not None and not isinstance ( val , type_req ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield name , val","if subclass_req is not None and not isinstance ( val , subclass_req ) :","if subclass_req is not None and not issubclass ( val , subclass_req ) :",False,97.93,72.72,,,
"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> if os.path.exists(self.icon): <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return GdkPixbuf.Pixbuf.new_from_file_at_size(self.icon, 24, 24) <TAB> <TAB> <TAB> except GObject.GError as ge: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> (icon_name, extension) = os.path.splitext(os.path.basename(self.icon)) <TAB> <TAB> theme = Gtk.IconTheme() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return theme.load_icon(icon_name, 24, 0)",if theme . has_theme ( ) :,if theme . has_icon ( icon_name ) :,False,97.2,72.01,,,
"def sysctlTestAndSet ( name , limit ) : <TAB> "" Helper function to set sysctl limits "" <TAB> # convert non-directory names into directory names <TAB> if ""/"" not in name: <TAB> <TAB> name = ""/proc/sys/"" + name.replace(""."", ""/"") <TAB> # read limit <TAB> with open(name, ""r"") as readFile: <TAB> <TAB> oldLimit = readFile.readline() <TAB> <TAB> if isinstance(limit, int): <TAB> <TAB> <TAB> # compare integer limits before overriding <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> with open(name, ""w"") as writeFile: <TAB> <TAB> <TAB> <TAB> <TAB> writeFile.write(""%d"" % limit) <TAB> <TAB> else: <TAB> <TAB> <TAB> # overwrite non-integer limits <TAB> <TAB> <TAB> with open(name, ""w"") as writeFile: <TAB> <TAB> <TAB> <TAB> writeFile.write(limit)",if limit < oldLimit :,if int ( oldLimit ) < limit :,False,97.36,71.67,,,
"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB> <TAB> time . sleep ( 2 ) <TAB> <TAB> if online and self . _is_testbot_online ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB> <TAB> )",elif self . _testbot_is_offline ( ) :,if not online and not self . _is_testbot_online ( ) :,False,92.91,69.03,,,
"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB> <TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB> <TAB> if context . rounding == ROUND_CEILING : <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) )",if context . rounding == ROUND_CEILING :,if context . rounding == ROUND_FLOOR :,False,98.72,73.65,,,
"def _get_item_columns_panel ( items , rows ) : <TAB> hbox = Gtk . HBox ( False , 4 ) <TAB> n_item = 0 <TAB> col_items = 0 <TAB> vbox = Gtk . VBox ( ) <TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB> while n_item < len ( items ) : <TAB> <TAB> item = items [ n_item ] <TAB> <TAB> vbox . pack_start ( item , False , False , 0 ) <TAB> <TAB> n_item + = 1 <TAB> <TAB> col_items + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vbox = Gtk . VBox ( ) <TAB> <TAB> <TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB> <TAB> <TAB> col_items = 0 <TAB> return hbox",if col_items == rows :,if col_items > rows :,False,98.35,73.58,,,
"def _changed ( self ) : <TAB> if self . gtk_range . get_sensitive ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . timer . cancel ( ) <TAB> <TAB> self . timer = _Timer ( 0.5 , lambda : GLib . idle_add ( self . _write ) ) <TAB> <TAB> self . timer . start ( )",if self . timer :,if self . timer :,True,100.0,73.98,,,
"def unlock_graph ( result , callback , interval = 1 , propagate = False , max_retries = None ) : <TAB> if result . ready ( ) : <TAB> <TAB> second_level_res = result . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with allow_join_result ( ) : <TAB> <TAB> <TAB> <TAB> signature ( callback ) . delay ( <TAB> <TAB> <TAB> <TAB> <TAB> list ( joinall ( second_level_res , propagate = propagate ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> unlock_graph . retry ( countdown = interval , max_retries = max_retries )",if second_level_res :,if second_level_res . ready ( ) :,False,96.85,71.75,,,
"def update ( self , other = None , / , * * kwargs ) : <TAB> if self . _pending_removals : <TAB> <TAB> self . _commit_removals ( ) <TAB> d = self . data <TAB> if other is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> other = dict ( other ) <TAB> <TAB> for key , o in other . items ( ) : <TAB> <TAB> <TAB> d [ key ] = KeyedRef ( o , self . _remove , key ) <TAB> for key , o in kwargs . items ( ) : <TAB> <TAB> d [ key ] = KeyedRef ( o , self . _remove , key )","if isinstance ( other , dict ) :","if not hasattr ( other , ""items"" ) :",False,95.18,63.59,,,
"def default ( self , o ) : <TAB> try : <TAB> <TAB> if type ( o ) == datetime . datetime : <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr(o, ""profile""): <TAB> <TAB> <TAB> <TAB> del o.profile <TAB> <TAB> <TAB> if hasattr(o, ""credentials""): <TAB> <TAB> <TAB> <TAB> del o.credentials <TAB> <TAB> <TAB> if hasattr(o, ""metadata_path""): <TAB> <TAB> <TAB> <TAB> del o.metadata_path <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del o.services_config <TAB> <TAB> <TAB> return vars(o) <TAB> except Exception as e: <TAB> <TAB> return str(o)","if hasattr ( o , ""services_config"" ) :","if hasattr ( o , ""services_config"" ) :",True,100.0,74.49,,,
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> if ignore_non_errors and is_noerr ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise",if e . errno != errno . EPERM :,if DEBUG_COMM :,False,95.95,72.56,,,
def heal ( self ) : <TAB> if not self . doctors : <TAB> <TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess.objects.get(id=proc_id) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self.doctors: <TAB> <TAB> <TAB> if dr.confirm(proc): <TAB> <TAB> <TAB> <TAB> dr.cure(proc) <TAB> <TAB> <TAB> <TAB> break,if proc is None :,if not proc . is_alive or proc . is_frozen :,False,92.45,93.47,,,
"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret[key] = val <TAB> <TAB> elif key == ""points"": <TAB> <TAB> <TAB> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB> <TAB> else: <TAB> <TAB> <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret","if key == ""name"" :","if key in [ ""attachments"" , ""custom_attributes"" , ""description_diff"" ] :",False,90.91,65.44,,,
"def default_generator ( <TAB> self , dataset , epochs = 1 , mode = "" fit "" , deterministic = True , pad_batches = True ) : <TAB> for epoch in range ( epochs ) : <TAB> <TAB> for ( X_b , y_b , w_b , ids_b ) in dataset . iterbatches ( <TAB> <TAB> <TAB> batch_size = self . batch_size , <TAB> <TAB> <TAB> deterministic = deterministic , <TAB> <TAB> <TAB> pad_batches = pad_batches , <TAB> <TAB> ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dropout = np . array ( 0.0 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dropout = np . array ( 1.0 ) <TAB> <TAB> <TAB> yield ( [ X_b , dropout ] , [ y_b ] , [ w_b ] )","if mode == ""fit"" :","if mode == ""predict"" :",False,98.9,73.62,,,
"def _cygwin_hack_find_addresses ( target ) : <TAB> addresses = [ ] <TAB> for h in [ <TAB> <TAB> target , <TAB> <TAB> "" localhost "" , <TAB> <TAB> "" 127.0.0.1 "" , <TAB> ] : <TAB> <TAB> try : <TAB> <TAB> <TAB> addr = get_local_ip_for ( h ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> addresses . append ( addr ) <TAB> <TAB> except socket . gaierror : <TAB> <TAB> <TAB> pass <TAB> return defer . succeed ( addresses )",if addr :,if addr not in addresses :,False,97.02,71.33,,,
"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB> <TAB> if action_node . notify : <TAB> <TAB> <TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _chain_notify <TAB> return None",if self . _chain_notify :,elif self . _chain_notify :,False,97.86,71.71,,,
"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra . tokens [ i ] <TAB> <TAB> token = jsdict ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" type "" : entry . type , <TAB> <TAB> <TAB> <TAB> "" value "" : entry . value , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra . range : <TAB> <TAB> <TAB> token . range = entry . range <TAB> <TAB> if extra . loc : <TAB> <TAB> <TAB> token . loc = entry . loc <TAB> <TAB> tokens . append ( token ) <TAB> <TAB> i + = 1 <TAB> extra . tokens = tokens",if i is None :,if not ( i < len ( extra . tokens ) ) :,False,94.95,70.53,,,
"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB> <TAB> if not self . in_current_block ( self . cursor ) : <TAB> <TAB> <TAB> self . seek_to_block ( self . cursor ) <TAB> <TAB> part = self . current_stream . read ( size ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if len ( part ) == 0 : <TAB> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> <TAB> size - = len ( part ) <TAB> <TAB> self . cursor + = len ( part ) <TAB> <TAB> buf + = part <TAB> return bytes ( buf )",if size == 0 :,if size > 0 :,False,98.15,73.51,,,
"def get_properties_from_model ( model_class ) : <TAB> """""" Show properties from a model """""" <TAB> properties = [ ] <TAB> attr_names = [ name for ( name , value ) in inspect . getmembers ( model_class , isprop ) ] <TAB> for attr_name in attr_names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attr_names . remove ( attr_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> properties . append ( <TAB> <TAB> <TAB> <TAB> dict ( label = attr_name , name = attr_name . strip ( "" _ "" ) . replace ( "" _ "" , "" "" ) ) <TAB> <TAB> <TAB> ) <TAB> return sorted ( properties , key = lambda k : k [ "" label "" ] )",if attr_name in attr_names :,"if attr_name . endswith ( ""pk"" ) :",False,95.82,70.5,,,
"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB> <TAB> value = mydict [ name ] <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id ( mydict ) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited . add ( myid ) <TAB> <TAB> mydict = mydict . Parent <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return",if mydict is not None :,if mydict is None :,False,98.3,73.36,,,
"def multicolumn ( self , list , format , cols = 4 ) : <TAB> """""" Format a list of items into a multi-column list. """""" <TAB> result = "" "" <TAB> rows = ( len ( list ) + cols - 1 ) / / cols <TAB> for col in range ( cols ) : <TAB> <TAB> result = result + ' <td width= "" %d %% ""  valign=top> ' % ( 100 / / cols ) <TAB> <TAB> for i in range ( rows * col , rows * col + rows ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result = result + format ( list [ i ] ) + "" <br> \n "" <TAB> <TAB> result = result + "" </td> "" <TAB> return ' <table width= "" 100 %% ""  summary= "" list "" ><tr> %s </tr></table> ' % result",if list [ i ] :,if i < len ( list ) :,False,96.85,97.34,,,
"def format_exc ( exc = None ) : <TAB> """""" Return exc (or sys.exc_info if None), formatted. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exc = _exc_info ( ) <TAB> <TAB> if exc == ( None , None , None ) : <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> import traceback <TAB> <TAB> return "" "" . join ( traceback . format_exception ( * exc ) ) <TAB> finally : <TAB> <TAB> del exc",if exc is None :,if exc is None :,True,100.0,99.29,,,
"def assert_counts ( res , lang , files , blank , comment , code ) : <TAB> for line in res : <TAB> <TAB> fields = line . split ( ) <TAB> <TAB> if len ( fields ) > = 5 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( files , int ( fields [ 1 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( blank , int ( fields [ 2 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( comment , int ( fields [ 3 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( code , int ( fields [ 4 ] ) ) <TAB> <TAB> <TAB> <TAB> return <TAB> self . fail ( "" Found no output line for  {} "" . format ( lang ) )",if fields [ 0 ] == lang :,if fields [ 0 ] == lang :,True,100.0,74.56,,,
"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( value , flag_value ) : <TAB> <TAB> <TAB> yield ( name , self . _has_flag ( value . flag ) )","if name . startswith ( ""_"" ) :","if isinstance ( value , alias_flag_value ) :",False,90.31,60.69,,,
"def optimize_models ( args , use_cuda , models ) : <TAB> """""" Optimize ensemble for generation """""" <TAB> for model in models : <TAB> <TAB> model . make_generation_fast_ ( <TAB> <TAB> <TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB> <TAB> <TAB> need_attn = args . print_alignment , <TAB> <TAB> ) <TAB> <TAB> if args . fp16 : <TAB> <TAB> <TAB> model . half ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> model . cuda ( )",if use_cuda :,if use_cuda :,True,100.0,99.27,,,
"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB> <TAB> target_str = mydict [ source_str ] <TAB> <TAB> if target_str == source_str : <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> pounit = self.convertunit(source_str, target_str) <TAB> <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile",elif target_str == source_str :,"elif target_str . startswith ( u""*** "" ) :",False,94.44,71.11,,,
"def __sparse_values_set ( instances , static_col_indexes : list ) : <TAB> tmp_result = { idx : set ( ) for idx in static_col_indexes } <TAB> for _ , instance in instances : <TAB> <TAB> data_generator = instance . features . get_all_data ( ) <TAB> <TAB> for idx , value in data_generator : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> tmp_result [ idx ] . add ( value ) <TAB> result = [ tmp_result [ x ] for x in static_col_indexes ] <TAB> return result",if idx in tmp_result :,if idx not in tmp_result :,False,98.46,72.88,,,
def puts ( self ) : <TAB> <IF-STMT> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . puts_ = PutRequest ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . puts_,if self . puts_ is None :,if self . puts_ is None :,True,100.0,99.11,,,
"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB> <TAB> filters = { } <TAB> <TAB> if args . resource_ref : <TAB> <TAB> <TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filters [ "" policy_type "" ] = args . policy_type <TAB> <TAB> filters . update ( * * kwargs ) <TAB> <TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB> <TAB> return self . manager . get_all ( * * kwargs )",if args . policy_type :,if args . policy_type :,True,100.0,74.41,,,
"def Get_Gene ( self , id ) : <TAB> """""" Retreive the gene name (GN). """""" <TAB> entry = self . Get ( id ) <TAB> if not entry : <TAB> <TAB> return None <TAB> GN = "" "" <TAB> for line in string . split ( entry , "" \n "" ) : <TAB> <TAB> if line [ 0 : 5 ] == "" GN "" : <TAB> <TAB> <TAB> GN = string . strip ( line [ 5 : ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> GN = GN [ 0 : - 1 ] <TAB> <TAB> <TAB> return GN <TAB> <TAB> if line [ 0 : 2 ] == "" // "" : <TAB> <TAB> <TAB> break <TAB> return GN","if GN . endswith ( ""/"" ) :","if GN [ - 1 ] == ""."" :",False,95.22,67.36,,,
"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . processTrack ( field [ "" track "" ] ) <TAB> <TAB> if "" movie_hdr "" in field : <TAB> <TAB> <TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] )","if ""track"" in field :","if ""track"" in field :",True,100.0,73.95,,,
"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB> <TAB> return <TAB> while True : <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self._get_video_packet() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._decode_video_packet(video_packet) <TAB> <TAB> if video_packet.image is not None or not skip_empty_frame: <TAB> <TAB> <TAB> break <TAB> if _debug: <TAB> <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",if video_packet . is_video :,if video_packet . image == 0 :,False,97.24,71.98,,,
"def get_devices ( display = None ) : <TAB> base = "" /dev/input "" <TAB> for filename in os . listdir ( base ) : <TAB> <TAB> if filename . startswith ( "" event "" ) : <TAB> <TAB> <TAB> path = os . path . join ( base , filename ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> _devices [ path ] = EvdevDevice ( display , path ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> return list ( _devices . values ( ) )",if not os . path . exists ( path ) :,if path in _devices :,False,94.15,71.0,,,
"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB> <TAB> if not self . _nchannels : <TAB> <TAB> <TAB> raise Error ( "" # channels not specified "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Error ( "" sample width not specified "" ) <TAB> <TAB> if not self . _framerate : <TAB> <TAB> <TAB> raise Error ( "" sampling rate not specified "" ) <TAB> <TAB> self . _write_header ( datasize )",if not self . _sampwidth :,if not self . _sampwidth :,True,100.0,74.32,,,
"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB> <TAB> record = line . split ( "" / "" ) <TAB> <TAB> if len ( record ) == 6 and record [ 1 ] : <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))","if record [ 0 ] == ""Directory"" :","if record [ 0 ] == ""D"" :",False,98.78,73.26,,,
"def tearDown ( self ) : <TAB> """""" Shutdown the UDP server. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> if self . sock_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sock_hdlr ) <TAB> <TAB> <TAB> self . sock_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self )",if self . server :,if self . server :,True,100.0,74.15,,,
"def get_backend ( find_library = None ) : <TAB> try : <TAB> <TAB> global _lib , _ctx <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _lib = _load_library ( find_library ) <TAB> <TAB> <TAB> _setup_prototypes ( _lib ) <TAB> <TAB> <TAB> _ctx = _Context ( ) <TAB> <TAB> _logger . warning ( <TAB> <TAB> <TAB> "" OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284) "" <TAB> <TAB> ) <TAB> <TAB> return _OpenUSB ( ) <TAB> except usb . libloader . LibraryException : <TAB> <TAB> # exception already logged (if any) <TAB> <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=False) <TAB> <TAB> return None <TAB> except Exception: <TAB> <TAB> _logger.error(""Error loading OpenUSB backend"", exc_info=True) <TAB> <TAB> return None",if _lib is None :,if _lib is None :,True,100.0,74.46,,,
"def __init__ ( self , event , event_info , fields = [ ] ) : <TAB> _wmi_object . __init__ ( self , event , fields = fields ) <TAB> _set ( self , "" event_type "" , None ) <TAB> _set ( self , "" timestamp "" , None ) <TAB> _set ( self , "" previous "" , None ) <TAB> if event_info : <TAB> <TAB> event_type = self . event_type_re . match ( event_info . Path_ . Class ) . group ( 1 ) . lower ( ) <TAB> <TAB> _set ( self , "" event_type "" , event_type ) <TAB> <TAB> if hasattr ( event_info , "" TIME_CREATED "" ) : <TAB> <TAB> <TAB> _set ( self , "" timestamp "" , from_1601 ( event_info . TIME_CREATED ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _set ( self , "" previous "" , event_info . PreviousInstance )",if event_info . PreviousInstance :,"if hasattr ( event_info , ""PreviousInstance"" ) :",False,96.01,69.04,,,
"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) : <TAB> <TAB> <TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB> <TAB> <TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" )",if pkg in Scheduler . listOfPackagesNextToBuild :,if pkg in Scheduler . listOfPackagesCurrentlyBuilding :,False,97.76,72.75,,,
"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB> <TAB> for line in lines : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> <TAB> self . process ( line ) <TAB> <TAB> <TAB> if not is_command ( line ) : <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0",if gap :,if gap :,True,100.0,74.23,,,
"def diff ( old , new , display = True ) : <TAB> """""" Nice colored diff implementation """""" <TAB> if not isinstance ( old , list ) : <TAB> <TAB> old = decolorize ( str ( old ) ) . splitlines ( ) <TAB> if not isinstance ( new , list ) : <TAB> <TAB> new = decolorize ( str ( new ) ) . splitlines ( ) <TAB> line_types = { "" "" : "" % Reset "" , "" - "" : "" % Red "" , "" + "" : "" %G reen "" , "" ? "" : "" % Pink "" } <TAB> if display : <TAB> <TAB> for line in difflib . Differ ( ) . compare ( old , new ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print ( colorize ( line_types [ line [ 0 ] ] , line ) ) <TAB> return old != new",if line [ 0 ] in line_types :,"if line . startswith ( ""?"" ) :",False,96.19,96.09,,,
"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB> <TAB> try : <TAB> <TAB> <TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB> <TAB> <TAB> if limit < 0 : <TAB> <TAB> <TAB> <TAB> raise ValueError ( ) <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB> if settings.MAX_PAGE_SIZE: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return settings.MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except (KeyError, ValueError): <TAB> <TAB> <TAB> pass <TAB> return self.default_limit",if limit > settings . MAX_PAGE_SIZE :,if limit == 0 :,False,96.23,72.48,,,
"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB> <TAB> new_slice_ = [ 0 ] <TAB> <TAB> offset = 0 <TAB> else : <TAB> <TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB> <TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB> <TAB> if self . squeeze_dims [ i ] : <TAB> <TAB> <TAB> new_slice_ . append ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB> <TAB> <TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_",elif self . indexes [ i ] :,elif offset < len ( slice_ ) :,False,96.21,71.99,,,
"def wrapper ( * args , * * kw ) : <TAB> instance = args [ 0 ] <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret_dict = instance . _create_ret_object ( <TAB> <TAB> <TAB> <TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> instance . logger . error ( instance . MUST_JSON ) <TAB> <TAB> <TAB> return jsonify ( ret_dict ) , 400 <TAB> except BadRequest : <TAB> <TAB> ret_dict = instance . _create_ret_object ( <TAB> <TAB> <TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB> <TAB> ) <TAB> <TAB> instance . logger . error ( instance . MUST_JSON ) <TAB> <TAB> return jsonify ( ret_dict ) , 400 <TAB> instance . logger . debug ( "" JSON is valid "" ) <TAB> return f ( * args , * * kw )",if instance . status == 404 :,if request . get_json ( ) is None :,False,95.92,71.79,,,
"def add_css ( self , data ) : <TAB> if data : <TAB> <TAB> for medium , paths in data . items ( ) : <TAB> <TAB> <TAB> for path in paths : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . _css . setdefault ( medium , [ ] ) . append ( path )","if path not in self . _css . get ( medium , [ ] ) :",if not self . _css . get ( medium ) or path not in self . _css [ medium ] :,False,88.96,66.77,,,
"def mangle_template ( template : str , template_vars : Set [ str ] ) - > str : <TAB> if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template : <TAB> <TAB> raise Exception ( "" Cannot parse a template containing reserved strings "" ) <TAB> for var in template_vars : <TAB> <TAB> original = f "" {{ { var } }} "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> f ' Template string is missing a reference to  "" { var } ""  referred to in kwargs ' <TAB> <TAB> <TAB> ) <TAB> <TAB> template = template . replace ( original , mangled_name ( var ) ) <TAB> return template",if not original . startswith ( TEMPLATE_PREFIX ) :,if original not in template :,False,94.42,71.71,,,
"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """""" Return a sorted list of keywords similar to the one given. """""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB> <TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB> <TAB> if key in seenDict : <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict [ key ] = None <TAB> <TAB> if checkContained and keyword in key : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches )",if kwdSndx in key :,"if kwdSndx == soundex ( key . encode ( ""ascii"" , ""ignore"" ) ) :",False,91.69,87.96,,,
"def GetInfo ( self ) : <TAB> for k , v in sorted ( self . memory_parameters . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v : <TAB> <TAB> <TAB> continue <TAB> <TAB> print ( "" %s :  \t %#08x  ( %s ) "" % ( k , v , v ) ) <TAB> print ( "" Memory ranges: "" ) <TAB> print ( "" Start \t \t End \t \t Length "" ) <TAB> for start , length in self . runs : <TAB> <TAB> print ( "" 0x %X \t \t 0x %X \t \t 0x %X "" % ( start , start + length , length ) )","if k . startswith ( ""memory_"" ) :","if k . startswith ( ""Pad"" ) :",False,98.09,73.52,,,
"def Children ( self ) : <TAB> """""" Returns a list of all of this object ' s owned (strong) children. """""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB> <TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB> <TAB> if is_strong and property in self . _properties : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> children . append ( self . _properties [ property ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> children . extend ( self . _properties [ property ] ) <TAB> return children",if is_list :,if not is_list :,False,98.58,80.46,,,
"def normalize_res_identifier ( self , emu , cw , val ) : <TAB> mask = ( 16 * * ( emu . get_ptr_size ( ) / / 2 ) - 1 ) << 16 <TAB> if val & mask : # not an INTRESOURCE <TAB> <TAB> name = emu.read_mem_string(val, cw) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> name = int(name[1:]) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> return 0 <TAB> else: <TAB> <TAB> name = val <TAB> return name","if name . startswith ( ""0x"" ) :","if name [ 0 ] == ""#"" :",False,94.71,70.83,,,
"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB> <TAB> if best_silhouette is None : <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a , best_silhouette , best_k",elif best_silhouette > silhouette :,elif silhouette <= best_silhouette :,False,96.42,71.58,,,
"def find_commit_type ( sha ) : <TAB> try : <TAB> <TAB> o = obj_store [ sha ] <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> else : <TAB> <TAB> if isinstance ( o , Commit ) : <TAB> <TAB> <TAB> commits . add ( sha ) <TAB> <TAB> elif isinstance ( o , Tag ) : <TAB> <TAB> <TAB> tags . add ( sha ) <TAB> <TAB> <TAB> commits . add ( o . object [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise KeyError ( "" Not a commit or a tag:  %s "" % sha )",if o is None :,if not ignore_unknown :,False,96.81,72.45,,,
"def on_search_entry_keypress ( self , widget , event ) : <TAB> key = Gdk . keyval_name ( event . keyval ) <TAB> if key == "" Escape "" : <TAB> <TAB> self . hide_search_box ( ) <TAB> elif key == "" Return "" : <TAB> <TAB> # Combine with Shift? <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.search_prev = False <TAB> <TAB> <TAB> self.do_search(None) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.search_prev = True",if self . search_prev :,if event . state & Gdk . ModifierType . SHIFT_MASK :,False,92.13,68.04,,,
"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB> <TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" = "" in each : <TAB> <TAB> <TAB> <TAB> key , value = each . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> key , value = each , "" "" <TAB> <TAB> <TAB> result [ key ] = value <TAB> namespace . webhook_properties = result","if isinstance ( each , str ) :",if each :,False,95.53,72.06,,,
"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB> <TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . lock . acquire ( ) <TAB> <TAB> self . modules [ path_id ] = module <TAB> <TAB> self . lock . release ( ) <TAB> <TAB> if resolve : <TAB> <TAB> <TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB> <TAB> <TAB> self . _relations [ path_id ] = [ ] <TAB> <TAB> <TAB> for package in resolution : <TAB> <TAB> <TAB> <TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB> <TAB> <TAB> self . queue_send . put ( ( path_id , module , False , resolution ) )",if path_id is None :,if path_id is None :,True,100.0,74.58,,,
"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB> <TAB> "" torrent "" : "" "" , <TAB> <TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB> <TAB> data = self . session . get ( url ) . text <TAB> <TAB> with bs4_parser ( data ) as html : <TAB> <TAB> <TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB> <TAB> <TAB> if downloads : <TAB> <TAB> <TAB> <TAB> for download in downloads . findAll ( "" a "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> link = download [ "" href "" ] <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" magnet "" ] = link <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return links [ download_type ]","if link . startswith ( ""magnet"" ) :","if link . startswith ( ""magnet"" ) :",True,100.0,74.68,,,
"def _parse_fields ( cls , read ) : <TAB> read = unicode_to_str ( read ) <TAB> if type ( read ) is not str : <TAB> <TAB> _wrong_type_for_arg ( read , "" str "" , "" read "" ) <TAB> fields = { } <TAB> while read and read [ 0 ] != "" ; "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> DeserializeError ( read , "" does not separate fields with commas "" ) <TAB> <TAB> read = read [ 1 : ] <TAB> <TAB> key , _type , value , read = cls . _parse_field ( read ) <TAB> <TAB> fields [ key ] = ( _type , value ) <TAB> if read : <TAB> <TAB> # read[0] == ';' <TAB> <TAB> read = read[1:] <TAB> return fields, read","if read [ 0 ] == "","" :","if read and read [ 0 ] != "","" :",False,97.6,72.58,,,
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> elif isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> if isinstance ( k , bytes ) : <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r","if isinstance ( v , bytes ) :","if isinstance ( v , bytes ) :",True,100.0,74.52,,,
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> if filename in cache : <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result # at the end <TAB> <TAB> if len(cache) > max_size: <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",if old_mtime != mtime :,if old_mtime == mtime :,False,98.7,73.09,,,
def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self.count > self.epiLen: <TAB> <TAB> self.res() <TAB> <TAB> return True <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.pertGlasPos(0) <TAB> <TAB> if self.count == self.epiLen / 2 + 1: <TAB> <TAB> <TAB> self.env.reset() <TAB> <TAB> <TAB> self.pertGlasPos(1) <TAB> <TAB> self.count += 1 <TAB> <TAB> return False,if self . count == 0 :,if self . count == 1 :,False,98.4,72.53,,,
"def _check_vulnerabilities ( self , processed_analysis ) : <TAB> matched_vulnerabilities = list ( ) <TAB> for vulnerability in self . _rule_base_vulnerabilities : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vulnerability_data = vulnerability . get_dict ( ) <TAB> <TAB> <TAB> name = vulnerability_data . pop ( "" short_name "" ) <TAB> <TAB> <TAB> matched_vulnerabilities . append ( ( name , vulnerability_data ) ) <TAB> return matched_vulnerabilities",if vulnerability . get_name ( ) in processed_analysis :,"if evaluate ( processed_analysis , vulnerability . rule ) :",False,92.34,68.6,,,
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" %s "" % val <TAB> <TAB> elif val < 1024 * * 2 : <TAB> <TAB> <TAB> return "" %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> elif val < 1024 * * 3 : <TAB> <TAB> <TAB> return "" %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return "" %s "" % val",if val < 1024 * * 1 :,"if isinstance ( val , compat . string_types ) :",False,94.96,71.68,,,
"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB> <TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB> <TAB> if rd : <TAB> <TAB> <TAB> self . handle_request ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if ex :,if self . event is not None and self . event . is_set ( ) :,False,83.72,63.8,,,
"def resize ( self , * e ) : <TAB> bold = ( "" helvetica "" , - self . _size . get ( ) , "" bold "" ) <TAB> helv = ( "" helvetica "" , - self . _size . get ( ) ) <TAB> xspace = self . _size . get ( ) <TAB> yspace = self . _size . get ( ) <TAB> for widget in self . _widgets : <TAB> <TAB> widget [ "" node_font "" ] = bold <TAB> <TAB> widget [ "" leaf_font "" ] = helv <TAB> <TAB> widget [ "" xspace "" ] = xspace <TAB> <TAB> widget [ "" yspace "" ] = yspace <TAB> <TAB> if self . _size . get ( ) < 20 : <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 2 <TAB> <TAB> else : <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 3 <TAB> self . _layout ( )",elif self . _size . get ( ) < 16 :,elif self . _size . get ( ) < 30 :,False,99.03,73.96,,,
"def __assertTilesChangedInRegion ( self , t1 , t2 , region ) : <TAB> for tileOriginTuple in t1 . keys ( ) : <TAB> <TAB> tileOrigin = imath . V2i ( * tileOriginTuple ) <TAB> <TAB> tileRegion = imath . Box2i ( <TAB> <TAB> <TAB> tileOrigin , tileOrigin + imath . V2i ( GafferImage . ImagePlug . tileSize ( ) ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertNotEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] )",if region in tileRegion :,"if GafferImage . BufferAlgo . intersects ( tileRegion , region ) :",False,92.85,69.67,,,
"def grouped_by_prefix ( args , prefixes ) : <TAB> """""" Group behave args by (directory) scope into multiple test-runs. """""" <TAB> group_args = [ ] <TAB> current_scope = None <TAB> for arg in args . strip ( ) . split ( ) : <TAB> <TAB> assert not arg . startswith ( "" - "" ) , "" REQUIRE: arg, not options "" <TAB> <TAB> scope = select_prefix_for ( arg , prefixes ) <TAB> <TAB> if scope != current_scope : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # -- DETECTED GROUP-END: <TAB> <TAB> <TAB> <TAB> yield "" "".join(group_args) <TAB> <TAB> <TAB> <TAB> group_args = [] <TAB> <TAB> <TAB> current_scope = scope <TAB> <TAB> group_args.append(arg) <TAB> <IF-STMT> <TAB> <TAB> yield "" "".join(group_args)",if group_args :,if group_args :,True,100.0,99.5,,,
"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB> <TAB> print_func = str <TAB> else : <TAB> <TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB> <TAB> value = getattr ( self , k ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( value , basestring ) : <TAB> <TAB> <TAB> print_func = repr # keep quotes around strings <TAB> <TAB> pieces.append(""%s=%s"" % (k, print_func(value))) <TAB> if pieces or self.__base__: <TAB> <TAB> return ""%s(%s)"" % (self.__class__.__name__, "", "".join(pieces)) <TAB> else: <TAB> <TAB> return """"",if value in default_values :,if not defaults and value == default_values [ k ] :,False,95.35,70.1,,,
"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB> <TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB> <TAB> self . tag . append ( node ) <TAB> <TAB> name = getattr ( node , "" name "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB> <TAB> if handler : <TAB> <TAB> <TAB> handler ( node )",if name is None :,if name is None :,True,100.0,74.52,,,
"def createFields ( self ) : <TAB> yield Enum ( Bits ( self , "" class "" , 2 ) , self . CLASS_DESC ) <TAB> yield Enum ( Bit ( self , "" form "" ) , self . FORM_DESC ) <TAB> if self [ "" class "" ] . value == 0 : <TAB> <TAB> yield Enum ( Bits ( self , "" type "" , 5 ) , self . TYPE_DESC ) <TAB> else : <TAB> <TAB> yield Bits ( self , "" type "" , 5 ) <TAB> yield ASNInteger ( self , "" size "" , "" Size in bytes "" ) <TAB> size = self [ "" size "" ] . value <TAB> if size : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for field in self . _handler ( self , size ) : <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else : <TAB> <TAB> <TAB> yield RawBytes ( self , "" raw "" , size )",if self . _handler :,if self . _handler :,True,100.0,74.63,,,
"def _process_service_request ( self , pkttype , pktid , packet ) : <TAB> """""" Process a service request """""" <TAB> # pylint: disable=unused-argument <TAB> service = packet.get_string() <TAB> packet.check_end() <TAB> if service == self._next_service: <TAB> <TAB> self.logger.debug2(""Accepting request for service %s"", service) <TAB> <TAB> self._next_service = None <TAB> <TAB> self.send_packet(MSG_SERVICE_ACCEPT, String(service)) <TAB> <TAB> <IF-STMT> # pragma: no branch <TAB> <TAB> <TAB> self._auth_in_progress = True <TAB> <TAB> <TAB> self._send_deferred_packets() <TAB> else: <TAB> <TAB> raise DisconnectError( <TAB> <TAB> <TAB> DISC_SERVICE_NOT_AVAILABLE, ""Unexpected service request received"" <TAB> <TAB> )",if self . _auth_in_progress :,if self . is_server ( ) and service == _USERAUTH_SERVICE :,False,94.32,69.74,,,
"def _read_fixed_body ( <TAB> self , content_length : int , delegate : httputil . HTTPMessageDelegate ) - > None : <TAB> while content_length > 0 : <TAB> <TAB> body = await self . stream . read_bytes ( <TAB> <TAB> <TAB> min ( self . params . chunk_size , content_length ) , partial = True <TAB> <TAB> ) <TAB> <TAB> content_length - = len ( body ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with _ExceptionLoggingContext ( app_log ) : <TAB> <TAB> <TAB> <TAB> ret = delegate . data_received ( body ) <TAB> <TAB> <TAB> <TAB> if ret is not None : <TAB> <TAB> <TAB> <TAB> <TAB> await ret",if self . params . debug :,if not self . _write_finished or self . is_client :,False,93.17,70.58,,,
"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> if e . args [ 0 ] == errno . ECHILD : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out """,if target_pid == pid :,if target_pid == pid :,True,100.0,74.49,,,
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> if op . stage == OperandStage . map : <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . agg : <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else : # pragma: no cover <TAB> <TAB> <TAB> raise ValueError(""Aggregation operand not executable"") <TAB> finally: <TAB> <TAB> pd.reset_option(""mode.use_inf_as_na"")",elif op . stage == OperandStage . combine :,elif op . stage == OperandStage . combine :,True,100.0,74.46,,,
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> if re_han . match ( blk ) : <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> <TAB> yield x,"if word . startswith ( "" "" ) :",if word not in Force_Split_Words :,False,96.39,47.04,,,
"def _iter_tags ( self , type = None ) : <TAB> """""" Yield all raw tags (limit to |type| if specified) """""" <TAB> for n in itertools . count ( ) : <TAB> <TAB> tag = self . _get_tag ( n ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield tag <TAB> <TAB> if tag [ "" d_tag "" ] == "" DT_NULL "" : <TAB> <TAB> <TAB> break","if type and tag [ ""d_tag"" ] == type :","if type is None or tag [ ""d_tag"" ] == type :",False,96.52,67.71,,,
"def _iter_tags ( self , type = None ) : <TAB> """""" Yield all raw tags (limit to |type| if specified) """""" <TAB> for n in itertools . count ( ) : <TAB> <TAB> tag = self . _get_tag ( n ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield tag <TAB> <TAB> if tag [ "" d_tag "" ] == "" DT_NULL "" : <TAB> <TAB> <TAB> break","if type and tag [ ""d_tag"" ] == type :",if line . startswith ( searchfor ),False,87.83,65.15,,,
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone.is_aware(value): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value.astimezone(timezone.utc).replace(tzinfo=None) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> <TAB> ""Oracle backend does not support timezone-aware datetimes when USE_TZ is False."" <TAB> <TAB> <TAB> ) <TAB> return unicode(value)",if USE_TZ :,if settings . USE_TZ :,False,97.75,71.75,,,
"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as fileobj : <TAB> <TAB> <TAB> header = fileobj . read ( 4 ) <TAB> <TAB> <TAB> if header == b "" OXLI "" : <TAB> <TAB> <TAB> <TAB> fileobj . read ( 1 ) # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj.read(1) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError: <TAB> <TAB> return False","if ftype == b""OXL"" :",if binascii . hexlify ( ftype ) == oxlitype :,False,94.41,63.2,,,
"def unget ( self , char ) : <TAB> # Only one character is allowed to be ungotten at once - it must <TAB> # be consumed again before any further call to unget <TAB> if char is not EOF: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # unget is called quite rarely, so it's a good idea to do <TAB> <TAB> <TAB> # more work here if it saves a bit of work in the frequently <TAB> <TAB> <TAB> # called char and charsUntil. <TAB> <TAB> <TAB> # So, just prepend the ungotten character onto the current <TAB> <TAB> <TAB> # chunk: <TAB> <TAB> <TAB> self.chunk = char + self.chunk <TAB> <TAB> <TAB> self.chunkSize += 1 <TAB> <TAB> else: <TAB> <TAB> <TAB> self.chunkOffset -= 1 <TAB> <TAB> <TAB> assert self.chunk[self.chunkOffset] == char",if self . chunkOffset == 0 :,if self . chunkOffset == 0 :,True,100.0,74.54,,,
"def scan ( rule , extensions , paths , ignore_paths = None ) : <TAB> """""" The libsast scan. """""" <TAB> try : <TAB> <TAB> options = { <TAB> <TAB> <TAB> "" match_rules "" : rule , <TAB> <TAB> <TAB> "" match_extensions "" : extensions , <TAB> <TAB> <TAB> "" ignore_paths "" : ignore_paths , <TAB> <TAB> <TAB> "" show_progress "" : False , <TAB> <TAB> } <TAB> <TAB> scanner = Scanner ( options , paths ) <TAB> <TAB> res = scanner . scan ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return format_findings ( res [ "" pattern_matcher "" ] , paths [ 0 ] ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" libsast scan "" ) <TAB> return { }",if res :,if res :,True,100.0,99.5,,,
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template","if pattern . startswith ( ""0"" ) :","if ""%"" not in pattern :",False,96.18,72.47,,,
"def _forward_response ( self , src , dst ) : <TAB> """""" Forward an SCP response between two remote SCP servers """""" <TAB> # pylint: disable=no-self-use <TAB> try: <TAB> <TAB> exc = yield from src.await_response() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dst.send_error(exc) <TAB> <TAB> <TAB> return exc <TAB> <TAB> else: <TAB> <TAB> <TAB> dst.send_ok() <TAB> <TAB> <TAB> return None <TAB> except OSError as exc: <TAB> <TAB> return exc",if exc is not None :,if exc :,False,97.02,72.05,,,
"def _maybe_signal_recovery_end ( ) - > None : <TAB> if self . in_recovery and not self . active_remaining_total ( ) : <TAB> <TAB> # apply anything stuck in the buffers <TAB> <TAB> self.flush_buffers() <TAB> <TAB> self._set_recovery_ended() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._actives_span.set_tag(""Actives-Ready"", True) <TAB> <TAB> self.signal_recovery_end.set()",if self . _actives_span :,if self . _actives_span is not None :,False,96.69,69.04,,,
"def main ( ) : <TAB> tmpdir = None <TAB> try : <TAB> <TAB> # Create a temporary working directory <TAB> <TAB> tmpdir = tempfile.mkdtemp() <TAB> <TAB> # Unpack the zipfile into the temporary directory <TAB> <TAB> pip_zip = os.path.join(tmpdir, ""pip.zip"") <TAB> <TAB> with open(pip_zip, ""wb"") as fp: <TAB> <TAB> <TAB> fp.write(b85decode(DATA.replace(b""\n"", b""""))) <TAB> <TAB> # Add the zipfile to sys.path so that we can import it <TAB> <TAB> sys.path.insert(0, pip_zip) <TAB> <TAB> # Run the bootstrap <TAB> <TAB> bootstrap(tmpdir=tmpdir) <TAB> finally: <TAB> <TAB> # Clean up our temporary working directory <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutil.rmtree(tmpdir, ignore_errors=True)",if tmpdir is not None :,if tmpdir :,False,98.12,97.91,,,
"def __init__ ( self , api_version_str ) : <TAB> try : <TAB> <TAB> self . latest = self . preview = False <TAB> <TAB> self . yyyy = self . mm = self . dd = None <TAB> <TAB> if api_version_str == "" latest "" : <TAB> <TAB> <TAB> self . latest = True <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . preview = True <TAB> <TAB> <TAB> parts = api_version_str . split ( "" - "" ) <TAB> <TAB> <TAB> self . yyyy = int ( parts [ 0 ] ) <TAB> <TAB> <TAB> self . mm = int ( parts [ 1 ] ) <TAB> <TAB> <TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB> <TAB> )","if api_version_str . endswith ( ""-preview"" ) :","if ""preview"" in api_version_str :",False,96.54,72.84,,,
"def _merge ( self , items , map_id , dep_id , use_disk , meminfo , mem_limit ) : <TAB> combined = self . combined <TAB> merge_combiner = self . aggregator . mergeCombiners <TAB> for k , v in items : <TAB> <TAB> o = combined . get ( k ) <TAB> <TAB> combined [ k ] = merge_combiner ( o , v ) if o is not None else v <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mem_limit = self . _rotate ( )",if mem_limit is None :,if use_disk and meminfo . rss > mem_limit :,False,91.68,69.69,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_value ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 8 :,False,97.74,72.42,,,
"def nice ( deltat ) : <TAB> # singular,plural <TAB> times = _( <TAB> <TAB> ""second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years"" <TAB> ).split("":"") <TAB> d = abs(int(deltat)) <TAB> for div, time in zip((60, 60, 24, 7, 4, 12, 100), times): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""%s%i %s"" % (deltat < 0 and ""-"" or """", d, time.split("","")[d != 1]) <TAB> <TAB> d /= div",if d != 0 :,if d < div * 5 :,False,96.88,95.05,,,
"def after_get_object ( self , event , view_kwargs ) : <TAB> if event and event . state == "" draft "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ObjectNotFound ( { "" parameter "" : "" {id} "" } , "" Event: not found "" )",if not self . get_object_for_model ( event ) :,"if not is_logged_in ( ) or not has_access ( ""is_coorganizer"" , event_id = event . id ) :",False,72.06,57.76,,,
def daemonize_if_required ( self ) : <TAB> if self . options . daemon : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Stop the logging queue listener for the current process <TAB> <TAB> <TAB> # We'll restart it once forked <TAB> <TAB> <TAB> log.shutdown_multiprocessing_logging_listener(daemonizing=True) <TAB> <TAB> # Late import so logging works correctly <TAB> <TAB> salt.utils.process.daemonize() <TAB> # Setup the multiprocessing log queue listener if enabled <TAB> self._setup_mp_logging_listener(),if self . options . use_multiprocessing :,if self . _setup_mp_logging_listener_ is True :,False,91.86,92.07,,,
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """""" iterate over all modules """""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> if not clients : <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None : <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module",if client . is_connected ( ) :,if module . is_compatible_with ( client ) :,False,96.67,96.06,,,
"def _incremental_avg_dp ( self , avg , new_el , idx ) : <TAB> for attr in [ "" coarse_segm "" , "" fine_segm "" , "" u "" , "" v "" ] : <TAB> <TAB> setattr ( <TAB> <TAB> <TAB> avg , attr , ( getattr ( avg , attr ) * idx + getattr ( new_el , attr ) ) / ( idx + 1 ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB> <TAB> <TAB> setattr(new_el, attr, None) <TAB> return avg",if idx == 0 :,if idx :,False,97.12,73.13,,,
"def run ( self , paths = [ ] ) : <TAB> collapsed = False <TAB> for item in SideBarSelection ( paths ) . getSelectedDirectories ( ) : <TAB> <TAB> for view in item . views ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> Window ( ) . focus_view ( view ) <TAB> <TAB> <TAB> <TAB> self . collapse_sidebar_folder ( ) <TAB> <TAB> <TAB> <TAB> collapsed = True <TAB> <TAB> <TAB> view . close ( )",if not collapsed :,if not collapsed :,True,100.0,74.25,,,
"def test_reductions ( expr , rdd ) : <TAB> result = compute ( expr , rdd ) <TAB> expected = compute ( expr , data ) <TAB> if not result == expected : <TAB> <TAB> print ( result ) <TAB> <TAB> print ( expected ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert abs ( result - expected ) < 0.001 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert result == expected",if rdd . ndim == 1 :,"if isinstance ( result , float ) :",False,93.43,69.48,,,
"def deltask ( task , d ) : <TAB> if task [ : 3 ] != "" do_ "" : <TAB> <TAB> task = "" do_ "" + task <TAB> bbtasks = d . getVar ( "" __BBTASKS "" , False ) or [ ] <TAB> if task in bbtasks : <TAB> <TAB> bbtasks . remove ( task ) <TAB> <TAB> d . delVarFlag ( task , "" task "" ) <TAB> <TAB> d . setVar ( "" __BBTASKS "" , bbtasks ) <TAB> d . delVarFlag ( task , "" deps "" ) <TAB> for bbtask in d . getVar ( "" __BBTASKS "" , False ) or [ ] : <TAB> <TAB> deps = d . getVarFlag ( bbtask , "" deps "" , False ) or [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> deps . remove ( task ) <TAB> <TAB> <TAB> d . setVarFlag ( bbtask , "" deps "" , deps )",if task in deps :,if task in deps :,True,100.0,74.61,,,
"def _apply_weightnorm ( self , list_layers ) : <TAB> """""" Try apply weightnorm for all layer in list_layers. """""" <TAB> for i in range ( len ( list_layers ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> layer_name = list_layers [ i ] . name . lower ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> list_layers [ i ] = WeightNormalization ( list_layers [ i ] ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass",if layer_name in self . _layers_by_name :,"if ""conv1d"" in layer_name or ""dense"" in layer_name :",False,91.66,65.1,,,
"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB> <TAB> if operator == "" Average "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB> <TAB> elif operator == "" Count "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB> <TAB> elif operator == "" Min "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB> <TAB> elif operator == "" Sum "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _SumAggregator ( ) )","elif operator == ""Max"" :","elif operator == ""Max"" :",True,100.0,74.59,,,
"def _conv_layer ( self , sess , bottom , name , trainable = True , padding = "" SAME "" , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB> <TAB> filt = self . _get_conv_filter ( sess , name , trainable = trainable ) <TAB> <TAB> conv_biases = self . _get_bias ( sess , name , trainable = trainable ) <TAB> <TAB> conv = tf . nn . conv2d ( bottom , filt , [ 1 , 1 , 1 , 1 ] , padding = padding ) <TAB> <TAB> bias = tf . nn . bias_add ( conv , conv_biases ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bias = tf . nn . relu ( bias ) <TAB> <TAB> return bias",if relu :,if relu :,True,100.0,74.51,,,
"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { } # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self.edges: <TAB> <TAB> if edge.is_dangling(): <TAB> <TAB> <TAB> raise ValueError(""Cannot contract copy tensor with dangling edges"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node, shared_axis = self._get_partner(edge) <TAB> <TAB> if partner_node not in partners: <TAB> <TAB> <TAB> partners[partner_node] = set() <TAB> <TAB> partners[partner_node].add(shared_axis) <TAB> return partners",if edge . is_directed ( ) :,if self . _is_my_trace ( edge ) :,False,94.78,70.92,,,
"def close ( self ) : <TAB> with self . _lock : <TAB> <TAB> """""" Close this _MultiFileWatcher object forever. """""" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _folder_handlers = { } <TAB> <TAB> <TAB> LOGGER . debug ( <TAB> <TAB> <TAB> <TAB> "" Stopping observer thread even though there is a non-zero  "" <TAB> <TAB> <TAB> <TAB> "" number of event observers! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> LOGGER . debug ( "" Stopping observer thread "" ) <TAB> <TAB> self . _observer . stop ( ) <TAB> <TAB> self . _observer . join ( timeout = 5 )",if self . _observer is None :,if len ( self . _folder_handlers ) != 0 :,False,93.76,88.61,,,
"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB> <TAB> elif text != self . labelList . item ( i ) . text ( ) : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 )",if text == self . labelList . item ( i ) . text ( ) :,"if text == """" :",False,91.47,48.3,,,
"def _get_messages ( self ) : <TAB> r = [ ] <TAB> try : <TAB> <TAB> self . _connect ( ) <TAB> <TAB> self . _login ( ) <TAB> <TAB> for message in self . _fetch ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> r . append ( message ) <TAB> <TAB> self . _connection . expunge ( ) <TAB> <TAB> self . _connection . close ( ) <TAB> <TAB> self . _connection . logout ( ) <TAB> except MailFetcherError as e : <TAB> <TAB> self . log ( "" error "" , str ( e ) ) <TAB> return r",if message . is_valid ( ) :,if message :,False,95.57,72.8,,,
"def get_current_user ( self ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return config . get ( "" json_authentication_override "" ) <TAB> <TAB> tkn_header = self . request . headers [ "" authorization "" ] <TAB> except KeyError : <TAB> <TAB> raise WebAuthNError ( reason = "" Missing Authorization Header "" ) <TAB> else : <TAB> <TAB> tkn_str = tkn_header . split ( "" "" ) [ - 1 ] <TAB> try : <TAB> <TAB> tkn = self . jwt_validator ( tkn_str ) <TAB> except AuthenticationError as e : <TAB> <TAB> raise WebAuthNError ( reason = e . message ) <TAB> else : <TAB> <TAB> return tkn","if config . get ( ""json_authentication_override"" ) :","if config . get ( ""development"" ) and config . get ( ""json_authentication_override"" ) :",False,95.3,67.68,,,
def _get_data ( self ) : <TAB> formdata = self . _formdata <TAB> if formdata : <TAB> <TAB> data = [ ] <TAB> <TAB> # TODO: Optimize? <TAB> <TAB> for item in formdata: <TAB> <TAB> <TAB> model = self.loader.get_one(item) if item else None <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data.append(model) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._invalid_formdata = True <TAB> <TAB> self._set_data(data) <TAB> return self._data,if model :,if model :,True,100.0,99.15,,,
"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB> <TAB> loc = self.getLocation(offs, range=True) <TAB> <TAB> if loc and loc[L_LTYPE] == LOC_STRING and loc[L_VA] > va: <TAB> <TAB> <TAB> subs.add((loc[L_VA], loc[L_SIZE])) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",elif loc [ L_LTYPE ] == L_LTYPE :,if loc [ L_TINFO ] :,False,94.37,70.17,,,
def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB> <TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if monad . cls_bl_idname == self . cls_bl_idname : <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None,"if monad . type == ""Monad"" :","if hasattr ( monad , ""cls_bl_idname"" ) :",False,87.85,67.88,,,
"def _set_peer_statuses ( self ) : <TAB> """""" Set peer statuses. """""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB> <TAB> if peer . bad : <TAB> <TAB> <TAB> peer . status = PEER_BAD <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> peer . status = PEER_GOOD <TAB> <TAB> elif peer . last_good : <TAB> <TAB> <TAB> peer . status = PEER_STALE <TAB> <TAB> else : <TAB> <TAB> <TAB> peer . status = PEER_NEVER",elif cutoff > time . time ( ) :,elif peer . last_good > cutoff :,False,95.06,91.89,,,
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> if i == index : <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> if composite_file . optional : <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None",if composite_file . description :,if composite_file . description :,True,100.0,74.53,,,
"def testUiViewServerDump_windowIntM1 ( self ) : <TAB> device = None <TAB> try : <TAB> <TAB> device = MockDevice ( version = 15 , startviewserver = True ) <TAB> <TAB> vc = ViewClient ( device , device . serialno , adb = TRUE , autodump = False ) <TAB> <TAB> vc . dump ( window = - 1 ) <TAB> <TAB> vc . findViewByIdOrRaise ( "" id/home "" ) <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> device . shutdownMockViewServer ( )",if device :,if device :,True,100.0,74.25,,,
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , bytes ) : <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> if isinstance ( k , bytes ) : <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r","elif isinstance ( v , dict ) or isinstance ( v , dict ) :","elif isinstance ( v , dict ) :",False,96.31,73.25,,,
"def _testSendmsgTimeout ( self ) : <TAB> try : <TAB> <TAB> self . cli_sock . settimeout ( 0.03 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> self . sendmsgToServer ( [ b "" a "" * 512 ] ) <TAB> <TAB> except socket . timeout : <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> # bpo-33937 the test randomly fails on Travis CI with <TAB> <TAB> <TAB> # ""OSError: [Errno 12] Cannot allocate memory"" <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""socket.timeout not raised"") <TAB> finally: <TAB> <TAB> self.misc_event.set()",if exc . errno != errno . EAGAIN :,if exc . errno != errno . ENOMEM :,False,98.88,73.43,,,
"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB> <TAB> if self . showAll : <TAB> <TAB> <TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . stream . write ( "" s "" ) <TAB> <TAB> <TAB> self . stream . flush ( ) <TAB> <TAB> return <TAB> _org_AddError ( self , test , err )",if self . showDebug :,elif self . dots :,False,96.03,71.22,,,
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> if self . scrolling : <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",if self . scroll_down_rect ( ) . collidepoint ( p ) :,elif self . scroll_down_rect ( ) . collidepoint ( p ) :,False,98.86,73.38,,,
"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] : # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l.lower().find(""copyright"") <TAB> <TAB> if idx < 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l[idx + 9 :].strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise(copyright) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> if not copyright.find(""200"") >= 0 and not copyright.find(""199"") >= 0: <TAB> <TAB> <TAB> continue <TAB> <TAB> ret.add(copyright) <TAB> return ret",if not copyright :,if not copyright :,True,100.0,74.53,,,
"def get_selectable_values ( self , request ) : <TAB> shop = lfs . core . utils . get_default_shop ( request ) <TAB> countries = [ ] <TAB> for country in shop . shipping_countries . all ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selected = True <TAB> <TAB> else : <TAB> <TAB> <TAB> selected = False <TAB> <TAB> countries . append ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" id "" : country . id , <TAB> <TAB> <TAB> <TAB> "" name "" : country . name , <TAB> <TAB> <TAB> <TAB> "" selected "" : selected , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return countries",if country . is_selected :,if country in self . value . all ( ) :,False,95.4,70.55,,,
"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB> <TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol: <TAB> <TAB> for col in range(0, nCol, 2): <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> if not self.layout.itemAt(row, col): <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row += 1 <TAB> self.layout.addItem(sample, row, col) <TAB> self.layout.addItem(label, row, col + 1)",if col == nCol :,if col + 2 == nCol :,False,98.45,73.08,,,
def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB> <TAB> if not any ( [ not is_text ( s ) for s in node . contents ] ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False,if is_text ( node . contents ) and is_whitespace ( node . contents ) :,if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) :,False,81.2,54.6,,,
"def tokenize_generator ( cw ) : <TAB> ret = [ ] <TAB> done = { } <TAB> for op in ops : <TAB> <TAB> ch = op . symbol [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sops = start_symbols [ ch ] <TAB> <TAB> cw . write ( "" case  ' %s ' : "" % ch ) <TAB> <TAB> for t in gen_tests ( sops , 1 ) : <TAB> <TAB> <TAB> cw . write ( t ) <TAB> <TAB> done [ ch ] = True <TAB> return ret",if ch in done :,if ch in done :,True,100.0,74.38,,,
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> if nbChars [ 0 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> if nbChars [ 1 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit )",if nbChars [ 0 ] == 0 :,"if isinstance ( nbChars , int ) :",False,94.91,71.11,,,
"def init ( self , * args , * * kwargs ) : <TAB> if "" _state "" not in kwargs : <TAB> <TAB> state = { } <TAB> <TAB> # Older versions have the _state entries as individual kwargs <TAB> <TAB> for arg in (""children"", ""windowState"", ""detachedPanels""): <TAB> <TAB> <TAB> if arg in kwargs: <TAB> <TAB> <TAB> <TAB> state[arg] = kwargs[arg] <TAB> <TAB> <TAB> <TAB> del kwargs[arg] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs[""_state""] = state <TAB> originalInit(self, *args, **kwargs)",if state :,if state :,True,100.0,74.27,,,
"def spm_decode ( tokens : List [ str ] ) - > List [ str ] : <TAB> words = [ ] <TAB> pieces : List [ str ] = [ ] <TAB> for t in tokens : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if len ( pieces ) > 0 : <TAB> <TAB> <TAB> <TAB> words . append ( "" "" . join ( pieces ) ) <TAB> <TAB> <TAB> pieces = [ t [ 1 : ] ] <TAB> <TAB> else : <TAB> <TAB> <TAB> pieces . append ( t ) <TAB> if len ( pieces ) > 0 : <TAB> <TAB> words . append ( "" "" . join ( pieces ) ) <TAB> return words","if t [ 0 ] == "" "" :",if t [ 0 ] == DecodeMixin . spm_bos_token :,False,95.3,65.95,,,
"def _compare_dirs ( self , dir1 : str , dir2 : str ) - > List [ str ] : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [] # type: List[str] <TAB> for root, dirs, files in os.walk(dir1): <TAB> <TAB> for file_ in files: <TAB> <TAB> <TAB> path = os.path.join(root, file_) <TAB> <TAB> <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> diff.append(file_) <TAB> return diff",if os . path . isfile ( target_path ) :,if not os . path . exists ( target_path ) :,False,97.28,71.36,,,
"def credentials ( self ) : <TAB> """""" The session credentials as a dict """""" <TAB> creds = { } <TAB> if self . _creds : <TAB> <TAB> <IF-STMT> # pragma: no branch <TAB> <TAB> <TAB> creds[""aws_access_key_id""] = self._creds.access_key <TAB> <TAB> if self._creds.secret_key: # pragma: no branch <TAB> <TAB> <TAB> creds[""aws_secret_access_key""] = self._creds.secret_key <TAB> <TAB> if self._creds.token: <TAB> <TAB> <TAB> creds[""aws_session_token""] = self._creds.token <TAB> if self._session.region_name: <TAB> <TAB> creds[""aws_region""] = self._session.region_name <TAB> if self.requester_pays: <TAB> <TAB> creds[""aws_request_payer""] = ""requester"" <TAB> return creds",if self . _creds . access_key :,if self . _creds . access_key :,True,100.0,99.3,,,
"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr(a, ""modules"", []): <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m.strip() <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self.modules: <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> if getattr(mod, ""module_type"", """").strip() == mod_type.strip(): <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if m == mod_type :,"if getattr ( mod , ""module_name"" , """" ) . strip ( ) == m :",False,92.89,63.52,,,
"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB> <TAB> path = os . path . join ( path , self . index_file ) <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB> <TAB> if os . path . isfile ( path ) : <TAB> <TAB> <TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> <TAB> except IsDirectoryError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path )",if os . path . isdir ( path ) :,"if os . path . isfile ( os . path . join ( path , self . index_file ) ) :",False,93.09,70.29,,,
def _use_full_params ( self ) - > None : <TAB> for p in self . params : <TAB> <TAB> if not p . _is_sharded : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> assert p . _fp16_shard . storage ( ) . size ( ) != 0 <TAB> <TAB> <TAB> <TAB> p . data = p . _fp16_shard <TAB> <TAB> else : <TAB> <TAB> <TAB> assert p . _full_param_padded . storage ( ) . size ( ) != 0 <TAB> <TAB> <TAB> p . data = p . _full_param_padded [ : p . _orig_size . numel ( ) ] . view ( p . _orig_size ),if p . _fp16_shard :,if self . mixed_precision :,False,96.26,94.18,,,
"def _attrdata ( self , cont , name , * val ) : <TAB> if not name : <TAB> <TAB> return None , False <TAB> if isinstance ( name , Mapping ) : <TAB> <TAB> if val : <TAB> <TAB> <TAB> raise TypeError ( "" Cannot set a value to  %s "" % name ) <TAB> <TAB> return name , True <TAB> else : <TAB> <TAB> if val : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return { name : val [ 0 ] } , True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Too may arguments "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cont = self . _extra . get ( cont ) <TAB> <TAB> <TAB> return cont . get ( name ) if cont else None , False","if isinstance ( val , ( list , tuple ) ) :",if len ( val ) == 1 :,False,95.29,71.77,,,
"def evaluate ( env , net , device = "" cpu "" ) : <TAB> obs = env . reset ( ) <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True : <TAB> <TAB> obs_v = ptan . agent . default_states_preprocessor ( [ obs ] ) . to ( device ) <TAB> <TAB> action_v = net ( obs_v ) <TAB> <TAB> action = action_v . data . cpu ( ) . numpy ( ) [ 0 ] <TAB> <TAB> obs , r , done , _ = env . step ( action ) <TAB> <TAB> reward + = r <TAB> <TAB> steps + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return reward , steps",if done :,if done :,True,100.0,74.46,,,
"def convert_html_js_files ( app : Sphinx , config : Config ) - > None : <TAB> """""" This converts string styled html_js_files to tuple styled one. """""" <TAB> html_js_files = [ ] # type: List[Tuple[str, Dict]] <TAB> for entry in config.html_js_files: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> html_js_files.append((entry, {})) <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> filename, attrs = entry <TAB> <TAB> <TAB> <TAB> html_js_files.append((filename, attrs)) <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> logger.warning(__(""invalid js_file: %r, ignored""), entry) <TAB> <TAB> <TAB> <TAB> continue <TAB> config.html_js_files = html_js_files # type: ignore","if isinstance ( entry , str ) :","if isinstance ( entry , str ) :",True,100.0,74.38,,,
"def _check_duplications ( self , regs ) : <TAB> """""" n^2 loop which verifies that each reg exists only once. """""" <TAB> for reg in regs : <TAB> <TAB> count = 0 <TAB> <TAB> for r in regs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> if count > 1 : <TAB> <TAB> <TAB> genutil . die ( "" reg  %s  defined more than once "" % reg )",if r [ 0 ] == reg :,if reg == r :,False,94.36,93.62,,,
"def _check_duplications ( self , regs ) : <TAB> """""" n^2 loop which verifies that each reg exists only once. """""" <TAB> for reg in regs : <TAB> <TAB> count = 0 <TAB> <TAB> for r in regs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> if count > 1 : <TAB> <TAB> <TAB> genutil . die ( "" reg  %s  defined more than once "" % reg )",if r [ 0 ] == reg :,"if var . get ( u""forget"" )",False,91.95,65.76,,,
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( v [ i ] , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","elif isinstance ( v , dict ) :","if isinstance ( v , dict ) :",False,98.62,73.24,,,
"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB> <TAB> if data [ t ] == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data [ t ] <TAB> <TAB> for b in range ( 8 ) : <TAB> <TAB> <TAB> if value & 0x80 : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( "" (unknown) "" ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB> <TAB> <TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) )",if b == 0 :,if len ( TRANSCEIVER [ t ] ) < b + 1 :,False,94.28,70.27,,,
"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB> <TAB> if char != self . int_to_char [ self . blank_index ] : <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> elif char == self.labels[self.space_index]: <TAB> <TAB> <TAB> <TAB> string += "" "" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string",if remove_repetitions :,if remove_repetitions and i != 0 and char == sequence [ i - 1 ] :,False,91.87,67.77,,,
"def clean ( self ) : <TAB> username = self . cleaned_data . get ( "" username "" ) <TAB> password = self . cleaned_data . get ( "" password "" ) <TAB> if username and password : <TAB> <TAB> self . user_cache = authenticate ( username = username , password = password ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_login "" ] ) <TAB> <TAB> elif not self . user_cache . is_active : <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" inactive "" ] ) <TAB> self . check_for_test_cookie ( ) <TAB> return self . cleaned_data",if self . user_cache is None :,if self . user_cache is None :,True,100.0,74.47,,,
"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """""" Check if the conversation is in need for a user message. """""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB> <TAB> if e . get ( "" event "" ) == UserUttered . type_name : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False","if i == 0 and e . get ( ""action"" ) == UserUttered . action_name :","elif e . get ( ""event"" ) == ActionExecuted . type_name :",False,92.07,67.53,,,
"def getReferences ( view , name = "" "" ) : <TAB> """""" Find all reference definitions. """""" <TAB> # returns {name -> Region} <TAB> refs = [] <TAB> name = re.escape(name) <TAB> if name == """": <TAB> <TAB> refs.extend(view.find_all(r""(?<=^\[)([^\]]+)(?=\]:)"", 0)) <TAB> else: <TAB> <TAB> refs.extend(view.find_all(r""(?<=^\[)(%s)(?=\]:)"" % name, 0)) <TAB> regions = refs <TAB> ids = {} <TAB> for reg in regions: <TAB> <TAB> name = view.substr(reg).strip() <TAB> <TAB> key = name.lower() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ids[key].regions.append(reg) <TAB> <TAB> else: <TAB> <TAB> <TAB> ids[key] = Obj(regions=[reg], label=name) <TAB> return ids",if key in ids :,if key in ids :,True,100.0,74.34,,,
"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . revs_enabled : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB> <TAB> <TAB> return headers . get ( header_name )",if url :,if header_name in headers :,False,96.52,72.62,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_shuffle_name ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.14,,,
"def make_release_tree ( self , base_dir , files ) : <TAB> """""" Make the release tree. """""" <TAB> self . mkpath ( base_dir ) <TAB> create_tree ( base_dir , files , dry_run = self . dry_run ) <TAB> if not files : <TAB> <TAB> self . log . warning ( "" no files to distribute -- empty manifest? "" ) <TAB> else : <TAB> <TAB> self . log . info ( "" copying files to  %s ... "" , base_dir ) <TAB> for filename in files : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . warning ( "" ' %s '  not a regular file -- skipping "" , filename ) <TAB> <TAB> else : <TAB> <TAB> <TAB> dest = os . path . join ( base_dir , filename ) <TAB> <TAB> <TAB> self . copy_file ( filename , dest ) <TAB> self . distribution . metadata . write_pkg_info ( base_dir )","if not re . match ( r""^[a-zA-Z]:$"" , filename ) :",if not os . path . isfile ( filename ) :,False,94.15,95.54,,,
"def _parse_names_set ( feature_names ) : <TAB> """""" Helping function of `_parse_feature_names` that parses a set of feature names. """""" <TAB> feature_collection = OrderedDict ( ) <TAB> for feature_name in feature_names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> feature_collection [ feature_name ] = . . . <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Failed to parse  {} , expected string "" . format ( feature_name ) ) <TAB> return feature_collection","if isinstance ( feature_name , six . string_types ) :","if isinstance ( feature_name , str ) :",False,95.58,94.2,,,
"def get_connection ( self , url , proxies = None ) : <TAB> with self . pools . lock : <TAB> <TAB> pool = self . pools . get ( url ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return pool <TAB> <TAB> pool = NpipeHTTPConnectionPool ( <TAB> <TAB> <TAB> self . npipe_path , self . timeout , maxsize = self . max_pool_size <TAB> <TAB> ) <TAB> <TAB> self . pools [ url ] = pool <TAB> return pool",if pool :,if pool :,True,100.0,74.21,,,
"def _parse_dimensions ( dimensions ) : <TAB> arrays = [ ] <TAB> names = [ ] <TAB> for key in dimensions : <TAB> <TAB> values = [ v [ "" name "" ] for v in key [ "" values "" ] ] <TAB> <TAB> role = key . get ( "" role "" , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values = [ _fix_quarter_values ( v ) for v in values ] <TAB> <TAB> <TAB> values = pd . DatetimeIndex ( values ) <TAB> <TAB> arrays . append ( values ) <TAB> <TAB> names . append ( key [ "" name "" ] ) <TAB> midx = pd . MultiIndex . from_product ( arrays , names = names ) <TAB> if len ( arrays ) == 1 and isinstance ( midx , pd . MultiIndex ) : <TAB> <TAB> # Fix for pandas >= 0.21 <TAB> <TAB> midx = midx.levels[0] <TAB> return midx","if role == ""quarter"" :","if role in ( ""time"" , ""TIME_PERIOD"" ) :",False,94.5,68.32,,,
"def _add_trials ( self , name , spec ) : <TAB> """""" Add trial by invoking TrialRunner. """""" <TAB> resource = { } <TAB> resource [ "" trials "" ] = [ ] <TAB> trial_generator = BasicVariantGenerator ( ) <TAB> trial_generator . add_configurations ( { name : spec } ) <TAB> while not trial_generator . is_finished ( ) : <TAB> <TAB> trial = trial_generator . next_trial ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> runner . add_trial ( trial ) <TAB> <TAB> resource [ "" trials "" ] . append ( self . _trial_info ( trial ) ) <TAB> return resource",if trial is None :,if not trial :,False,97.48,96.56,,,
"def _retrieve_key ( self ) : <TAB> url = "" http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf "" <TAB> text = "" "" <TAB> try : <TAB> <TAB> r = requests . get ( url , timeout = self . timeout , proxies = self . proxies ) <TAB> <TAB> text = r . text <TAB> except : <TAB> <TAB> self . error = "" ERROR - URL Connection "" <TAB> if text : <TAB> <TAB> expression = r "" ' (....-....-....-....) ' ; "" <TAB> <TAB> pattern = re . compile ( expression ) <TAB> <TAB> match = pattern . search ( text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . key = match . group ( 1 ) <TAB> <TAB> <TAB> return self . key <TAB> <TAB> else : <TAB> <TAB> <TAB> self . error = "" ERROR - No API Key """,if match :,if match :,True,100.0,74.54,,,
"def test_net ( net , env , count = 10 , device = "" cpu "" ) : <TAB> rewards = 0.0 <TAB> steps = 0 <TAB> for _ in range ( count ) : <TAB> <TAB> obs = env . reset ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> obs_v = ptan . agent . float32_preprocessor ( [ obs ] ) . to ( device ) <TAB> <TAB> <TAB> mu_v = net ( obs_v ) [ 0 ] <TAB> <TAB> <TAB> action = mu_v . squeeze ( dim = 0 ) . data . cpu ( ) . numpy ( ) <TAB> <TAB> <TAB> action = np . clip ( action , - 1 , 1 ) <TAB> <TAB> <TAB> obs , reward , done , _ = env . step ( action ) <TAB> <TAB> <TAB> rewards + = reward <TAB> <TAB> <TAB> steps + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> return rewards / count , steps / count",if done :,if done :,True,100.0,74.62,,,
"def compile ( self , filename , obfuscate = False , raw = False , magic = "" \x00 "" * 8 ) : <TAB> body = marshal . dumps ( compile ( self . visit ( self . _source_ast ) , filename , "" exec "" ) ) <TAB> if obfuscate : <TAB> <TAB> body_len = len ( body ) <TAB> <TAB> offset = 0 if raw else 8 <TAB> <TAB> output = bytearray ( body_len + 8 ) <TAB> <TAB> for i , x in enumerate ( body ) : <TAB> <TAB> <TAB> output [ i + offset ] = ord ( x ) ^ ( ( 2 * * ( ( 65535 - i ) % 65535 ) ) % 251 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for i in xrange ( 8 ) : <TAB> <TAB> <TAB> <TAB> output [ i ] = 0 <TAB> <TAB> return output <TAB> el <IF-STMT> <TAB> <TAB> return body <TAB> else : <TAB> <TAB> return magic + body",if raw :,if raw :,True,100.0,74.64,,,
"def _map_saslprep ( s ) : <TAB> """""" Map stringprep table B.1 to nothing and C.1.2 to ASCII space """""" <TAB> r = [ ] <TAB> for c in s : <TAB> <TAB> if stringprep . in_table_c12 ( c ) : <TAB> <TAB> <TAB> r . append ( "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r . append ( c ) <TAB> return "" "" . join ( r )",elif stringprep . in_table_b18 ( c ) :,elif not stringprep . in_table_b1 ( c ) :,False,95.99,83.48,,,
"def ensemble ( self , pairs , other_preds ) : <TAB> """""" Ensemble the dict with statistical model predictions. """""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> if ( w , pos ) in self . composite_dict : <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None : <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas","elif ( w , pos ) in self . word_dict :",elif w in self . word_dict :,False,97.13,96.69,,,
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> if any ( item is None for item in value ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> return value","if isinstance ( value , MultiNode ) :","if value . has_form ( ""List"" , None ) :",False,94.94,63.6,,,
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> if not dest . parent . is_dir ( ) : <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }  Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> if src . exists ( ) : <TAB> <TAB> <TAB> shutil . copy ( src , dest )",if dest . exists ( ) :,if dest . exists ( ) :,True,100.0,74.57,,,
"def assert_readback ( vehicle , values ) : <TAB> i = 10 <TAB> while i > 0 : <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> i - = 0.1 <TAB> <TAB> for k , v in values . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> if i < = 0 : <TAB> <TAB> raise Exception ( "" Did not match in channels readback  %s "" % values )",if k != vehicle . channel_id :,if vehicle . channels [ k ] != v :,False,93.35,69.77,,,
"def _get_linode_client ( self ) : <TAB> api_key = self . credentials . conf ( "" key "" ) <TAB> api_version = self . credentials . conf ( "" version "" ) <TAB> if api_version == "" "" : <TAB> <TAB> api_version = None <TAB> if not api_version : <TAB> <TAB> api_version = 3 <TAB> <TAB> # Match for v4 api key <TAB> <TAB> regex_v4 = re.compile(""^[0-9a-f]{64}$"") <TAB> <TAB> regex_match = regex_v4.match(api_key) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> api_version = 4 <TAB> else: <TAB> <TAB> api_version = int(api_version) <TAB> return _LinodeLexiconClient(api_key, api_version)",if regex_match :,if regex_match :,True,100.0,74.33,,,
"def mergeHiLo ( self , x_stats ) : <TAB> """""" Merge the highs and lows of another accumulator into myself. """""" <TAB> if x_stats . firsttime is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . firsttime = x_stats . firsttime <TAB> <TAB> <TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB> <TAB> if self . lasttime is None or x_stats . lasttime > = self . lasttime : <TAB> <TAB> <TAB> self . lasttime = x_stats . lasttime <TAB> <TAB> <TAB> self . last = x_stats . last",if self . firsttime is None or x_stats . firsttime >= self . firsttime :,if self . firsttime is None or x_stats . firsttime < self . firsttime :,False,97.99,98.39,,,
"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB> <TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB> <TAB> x_len = lengths [ 0 ] <TAB> else : <TAB> <TAB> x_len = len ( X ) <TAB> if y is not None : <TAB> <TAB> if len ( y ) != x_len : <TAB> <TAB> <TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB> <TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y",if len ( lengths ) != len ( X ) :,if len ( set ( lengths ) ) > 1 :,False,96.44,72.51,,,
"def set ( self , obj , * * kwargs ) : <TAB> """""" Check for missing event functions and substitute these with """""" <TAB> """""" the ignore method """""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB> <TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB> <TAB> if k in self . combinations : <TAB> <TAB> <TAB> for k1 in self . combinations [ k ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> setattr ( self , k1 , ignore )","if getattr ( self , k1 ) is None :","if not hasattr ( self , k1 ) :",False,96.31,94.47,,,
"def _parse_list ( self , tokens ) : <TAB> # Process left to right, allow descending in sub lists <TAB> assert tokens[0] in (""["", ""("") <TAB> delim = ""]"" if tokens.pop(0) == ""["" else "")"" <TAB> expr = ExpressionList() <TAB> while tokens and tokens[0] != delim: <TAB> <TAB> item = self._parse(tokens) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if tokens.pop(0) != "","": <TAB> <TAB> <TAB> <TAB> raise ExpressionSyntaxError('Expected: "",""') <TAB> <TAB> expr.append(item) <TAB> if not tokens or tokens[0] != delim: <TAB> <TAB> raise ExpressionSyntaxError('Missing: ""%s""' % delim) <TAB> else: <TAB> <TAB> tokens.pop(0) <TAB> return expr",if item :,if tokens and tokens [ 0 ] != delim :,False,95.42,69.81,,,
"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self: <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> return token.stripped_value <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> if token.token_type == ""bare-quoted-string"": <TAB> <TAB> <TAB> <TAB> <TAB> for token in token: <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if token.token_type == ""value"": <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token.stripped_value <TAB> return """"","if token . token_type == ""bare-quoted-string"" :","if token . token_type == ""quoted-string"" :",False,98.77,72.94,,,
"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB> """""" Is the paragraph fully commented? """""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if is_magic ( line , main_language ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> return i > 0 and _BLANK_LINE . match ( line ) <TAB> return True",if line . startswith ( comment ) :,if line . startswith ( comment ) :,True,100.0,74.41,,,
"def lots_connected_to_existing_roads ( model ) : <TAB> set = [ ] <TAB> for h in model . HarvestCells : <TAB> <TAB> for ( i , j ) in model . ExistingRoads : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if h not in set : <TAB> <TAB> <TAB> <TAB> <TAB> set . append ( h ) <TAB> return set",if i == j and j == i :,if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) :,False,81.68,60.54,,,
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" \ Abarra_counter_session= "" , <TAB> <TAB> <TAB> <TAB> headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , <TAB> <TAB> <TAB> <TAB> re . I , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" ( \ A| \ b)barracuda_ "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",if retval :,if retval :,True,100.0,74.6,,,
"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os.path.join(os.path.dirname(__file__), os.pardir, os.pardir) <TAB> names = [] <TAB> for d in self.test_directories: <TAB> <TAB> test_dir = os.path.join(dist_dir, d) <TAB> <TAB> for n in os.listdir(test_dir): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> names.append(os.path.join(test_dir, n)) <TAB> for filename in names: <TAB> <TAB> if test_support.verbose: <TAB> <TAB> <TAB> print(""Testing %s"" % filename) <TAB> <TAB> source = read_pyfile(filename) <TAB> <TAB> self.check_roundtrip(source)","if n . endswith ( "".py"" ) :","if n . endswith ( "".py"" ) and not n . startswith ( ""bad"" ) :",False,95.6,63.43,,,
"def test_calibrate_target ( create_target ) : <TAB> mod , params = testing . synthetic . get_workload ( ) <TAB> dataset = get_calibration_dataset ( mod , "" data "" ) <TAB> with relay . quantize . qconfig ( calibrate_mode = "" kl_divergence "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with tvm . target . Target ( "" llvm "" ) : <TAB> <TAB> <TAB> <TAB> relay . quantize . quantize ( mod , params , dataset ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # current_target = None <TAB> <TAB> <TAB> relay.quantize.quantize(mod, params, dataset)",if create_target :,if create_target :,True,100.0,74.34,,,
"def _cleanSubmodule ( self , _ = None ) : <TAB> rc = RC_SUCCESS <TAB> if self . submodules : <TAB> <TAB> command = [ <TAB> <TAB> <TAB> "" submodule "" , <TAB> <TAB> <TAB> "" foreach "" , <TAB> <TAB> <TAB> "" --recursive "" , <TAB> <TAB> <TAB> "" git "" , <TAB> <TAB> <TAB> "" clean "" , <TAB> <TAB> <TAB> "" -f "" , <TAB> <TAB> <TAB> "" -f "" , <TAB> <TAB> <TAB> "" -d "" , <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> command . append ( "" -x "" ) <TAB> <TAB> rc = yield self . _dovccmd ( command ) <TAB> defer . returnValue ( rc )",if self . _is_local :,"if self . mode == ""full"" and self . method == ""fresh"" :",False,92.14,67.67,,,
"def screen_length_to_bytes_count ( string , screen_length_limit , encoding ) : <TAB> bytes_count = 0 <TAB> screen_length = 0 <TAB> for unicode_char in string : <TAB> <TAB> screen_length + = screen_len ( unicode_char ) <TAB> <TAB> char_bytes_count = len ( unicode_char . encode ( encoding ) ) <TAB> <TAB> bytes_count + = char_bytes_count <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bytes_count - = char_bytes_count <TAB> <TAB> <TAB> break <TAB> return bytes_count",if screen_length + char_bytes_count > screen_length_limit :,if screen_length > screen_length_limit :,False,95.41,72.44,,,
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> if char == "" > "" : <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" "" : <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval","elif char == ""<"" :","elif char == ""<"" :",True,100.0,74.65,,,
"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB> <TAB> try : <TAB> <TAB> <TAB> schema . parse ( example . schema_string ) <TAB> <TAB> <TAB> if example . valid : <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB> <TAB> correct , <TAB> <TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg )",if example . valid :,if not example . valid :,False,99.05,73.7,,,
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed","if isinstance ( value , str ) :","if isinstance ( value , bool ) :",False,98.86,73.57,,,
"def normalize ( d : Dict [ Any , Any ] ) - > Dict [ str , Any ] : <TAB> first_exception = None <TAB> for normalizer in normalizers : <TAB> <TAB> try : <TAB> <TAB> <TAB> normalized = normalizer ( d ) <TAB> <TAB> except KeyError as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> first_exception = e <TAB> <TAB> else : <TAB> <TAB> <TAB> return normalized <TAB> assert first_exception is not None <TAB> raise first_exception",if first_exception is None :,if not first_exception :,False,96.36,71.89,,,
"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB> <TAB> backref = callback . backref <TAB> <TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB> <TAB> if root_objs : <TAB> <TAB> <TAB> if not isinstance ( root_objs , Iterable ) : <TAB> <TAB> <TAB> <TAB> root_objs = [ root_objs ] <TAB> <TAB> <TAB> with session . no_autoflush : <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self . get_callback_args ( root_obj , callback ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args","if isinstance ( root_obj , sa . orm . object ) :",if root_obj :,False,95.42,72.13,,,
"def test_opdm_to_oqdm ( self ) : <TAB> for file in filter ( lambda x : x . endswith ( "" .hdf5 "" ) , os . listdir ( DATA_DIRECTORY ) ) : <TAB> <TAB> molecule = MolecularData ( filename = os . path . join ( DATA_DIRECTORY , file ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> test_oqdm = map_one_pdm_to_one_hole_dm ( molecule . fci_one_rdm ) <TAB> <TAB> <TAB> true_oqdm = numpy . eye ( molecule . n_qubits ) - molecule . fci_one_rdm <TAB> <TAB> <TAB> assert numpy . allclose ( test_oqdm , true_oqdm )",if molecule . fci_one_rdm is not None :,if molecule . fci_one_rdm is not None :,True,100.0,74.38,,,
"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB> <TAB> if self . checkForStop ( ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . emitHostname ( subDomain , event )",if subDomain :,if subDomain :,True,100.0,74.16,,,
"def download_cve ( <TAB> download_path : str , years : Optional [ List [ int ] ] = None , update : bool = False ) : <TAB> if update : <TAB> <TAB> process_url ( CVE_URL . format ( "" modified "" ) , download_path ) <TAB> else : <TAB> <TAB> all_cve_urls = get_cve_links ( CVE_URL , years ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CveLookupException ( "" Error: No CVE links found "" ) <TAB> <TAB> for url in all_cve_urls : <TAB> <TAB> <TAB> process_url ( url , download_path )",if not all_cve_urls :,if not all_cve_urls :,True,100.0,74.35,,,
"def is_special ( s , i , directive ) : <TAB> """""" Return True if the body text contains the @ directive. """""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <TAB> <TAB> if match_word(s, i, directive): <TAB> <TAB> <TAB> return True, i <TAB> <TAB> else: <TAB> <TAB> <TAB> i = skip_line(s, i) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> i = skip_ws(s, i) <TAB> return False, -1",if skip_flag :,if skip_flag :,True,100.0,74.39,,,
"def run_async ( self , nuke_cursors ) : <TAB> # type: (bool) -> None <TAB> interface_type = self.view.settings().get(""git_savvy.interface"") <TAB> for cls in subclasses: <TAB> <TAB> if cls.interface_type == interface_type: <TAB> <TAB> <TAB> vid = self.view.id() <TAB> <TAB> <TAB> interface = interfaces.get(vid, None) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> interface = interfaces[vid] = cls(view=self.view) <TAB> <TAB> <TAB> interface.render(nuke_cursors=nuke_cursors) # type: ignore[union-attr] <TAB> <TAB> <TAB> break",if interface is None :,if not interface :,False,97.75,71.14,,,
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if str ( conf [ "" properties "" ] [ "" sslEnforcement "" ] ) . lower ( ) == "" enabled "" : <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""sslEnforcement"" in conf [ ""properties"" ] :","if ""sslEnforcement"" in conf [ ""properties"" ] :",True,100.0,74.08,,,
"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB> <TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB> <TAB> if short_has_arg ( opt , shortopts ) : <TAB> <TAB> <TAB> if optstring == "" "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB> <TAB> <TAB> <TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB> <TAB> <TAB> optarg , optstring = optstring , "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> optarg = "" "" <TAB> <TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args","if args [ 0 ] == """" :",if not args :,False,96.46,69.16,,,
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> if self . count == 0 : <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> if self . waiters : <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( )",if tid in self . locks :,if self . owner != tid :,False,95.96,71.74,,,
"def _summarize_kraken ( fn ) : <TAB> """""" get the value at species level """""" <TAB> kraken = { } <TAB> list_sp , list_value = [ ] , [ ] <TAB> with open ( fn ) as handle : <TAB> <TAB> for line in handle : <TAB> <TAB> <TAB> cols = line . strip ( ) . split ( "" \t "" ) <TAB> <TAB> <TAB> sp = cols [ 5 ] . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> list_sp . append ( sp ) <TAB> <TAB> <TAB> <TAB> list_value . append ( cols [ 0 ] ) <TAB> kraken = { "" kraken_sp "" : list_sp , "" kraken_value "" : list_value } <TAB> return kraken",if sp :,"if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( ""cellular"" ) :",False,88.9,63.75,,,
"def _sync_remote_run ( remote_run ) : <TAB> assert remote_run . remote <TAB> remote_name = remote_run . remote . name <TAB> pull_args = click_util . Args ( remote = remote_name , delete = False ) <TAB> try : <TAB> <TAB> remote_impl_support . pull_runs ( [ remote_run ] , pull_args ) <TAB> except Exception as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . exception ( "" pull  %s  from  %s "" , remote_run . id , remote_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . error ( "" error pulling  %s  from  %s :  %s "" , remote_run . id , remote_name , e )",if log . getEffectiveLevel ( ) <= logging . DEBUG :,if log . getEffectiveLevel ( ) <= logging . DEBUG :,True,100.0,74.47,,,
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if ki != 0 : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if sign * ki < - slop : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq",if sign is None :,if sign is None :,True,100.0,74.56,,,
"def import_til ( self ) : <TAB> log ( "" Importing type libraries... "" ) <TAB> cur = self . db_cursor ( ) <TAB> sql = "" select name from diff.program_data where type =  ' til ' "" <TAB> cur . execute ( sql ) <TAB> for row in cur . fetchall ( ) : <TAB> <TAB> til = row [ "" name "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> til = til . decode ( "" utf-8 "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> add_default_til ( til ) <TAB> <TAB> except : <TAB> <TAB> <TAB> log ( "" Error loading til  %s :  %s "" % ( row [ "" name "" ] , str ( sys . exc_info ( ) [ 1 ] ) ) ) <TAB> cur . close ( ) <TAB> auto_wait ( )","if isinstance ( til , bytes ) :",if type ( til ) is bytes :,False,97.09,72.31,,,
"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> git_branch_line = git_branch_line [ 1 : ] <TAB> <TAB> git_branch_line = git_branch_line . strip ( ) <TAB> <TAB> if BRANCH_ALIAS_MARKER in git_branch_line : <TAB> <TAB> <TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB> <TAB> <TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned","if git_branch_line . startswith ( ""branch"" ) :","if git_branch_line . startswith ( ""*"" ) :",False,98.81,73.38,,,
"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> a = a.includedirs <TAB> <TAB> if not isinstance(a, IncludeDirs): <TAB> <TAB> <TAB> raise InvalidArguments( <TAB> <TAB> <TAB> <TAB> ""Include directory to be added is not an include directory object."" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids.append(a) <TAB> self.include_dirs += ids","if isinstance ( a , File ) :","if hasattr ( a , ""includedirs"" ) :",False,95.54,64.39,,,
"def _serialize_feature ( self , feature ) : <TAB> name = feature . unique_name ( ) <TAB> <IF-STMT> <TAB> <TAB> self . _features_dict [ feature . unique_name ( ) ] = feature . to_dictionary ( ) <TAB> <TAB> for dependency in feature . get_dependencies ( deep = True ) : <TAB> <TAB> <TAB> name = dependency . unique_name ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _features_dict [ name ] = dependency . to_dictionary ( )",if name not in self . _features_dict :,if name not in self . _features_dict :,True,100.0,74.35,,,
"def generate_io ( chart_type , race_configs , environment ) : <TAB> # output JSON structures <TAB> structures = [] <TAB> for race_config in race_configs: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> title = chart_type.format_title( <TAB> <TAB> <TAB> <TAB> environment, <TAB> <TAB> <TAB> <TAB> race_config.track, <TAB> <TAB> <TAB> <TAB> es_license=race_config.es_license, <TAB> <TAB> <TAB> <TAB> suffix=""%s-io"" % race_config.label, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> structures.append(chart_type.io(title, environment, race_config)) <TAB> return structures",if race_config . label :,"if ""io"" in race_config . charts :",False,95.99,63.21,,,
"def format_partition ( partition , partition_schema ) : <TAB> tokens = [ ] <TAB> if isinstance ( partition , dict ) : <TAB> <TAB> for name in partition_schema : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tok = _format_partition_kv ( <TAB> <TAB> <TAB> <TAB> <TAB> name , partition [ name ] , partition_schema [ name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # dynamic partitioning <TAB> <TAB> <TAB> <TAB> tok = name <TAB> <TAB> <TAB> tokens.append(tok) <TAB> else: <TAB> <TAB> for name, value in zip(partition_schema, partition): <TAB> <TAB> <TAB> tok = _format_partition_kv(name, value, partition_schema[name]) <TAB> <TAB> <TAB> tokens.append(tok) <TAB> return ""PARTITION ({})"".format("", "".join(tokens))",if name in partition :,if name in partition :,True,100.0,74.46,,,
"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self # don't copy unless we need to <TAB> if condition is not Undefined: <TAB> <TAB> if isinstance(condition, core.SchemaBase): <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB> <TAB> <TAB> copy = self.copy(deep=[""condition""]) <TAB> <TAB> <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB> <TAB> validate=validate, ignore=ignore, context=context <TAB> )","elif isinstance ( condition , dict ) :","elif ""field"" in condition and ""type"" not in condition :",False,93.97,65.64,,,
"def _checkForCommand ( self ) : <TAB> prompt = b "" cftp>  "" <TAB> if self . _expectingCommand and self . _lineBuffer == prompt : <TAB> <TAB> buf = b "" \n "" . join ( self . _linesReceived ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> buf = buf [ len ( prompt ) : ] <TAB> <TAB> self . clearBuffer ( ) <TAB> <TAB> d , self . _expectingCommand = self . _expectingCommand , None <TAB> <TAB> d . callback ( buf )",if self . _expectingCommand and buf . startswith ( prompt ) :,if buf . startswith ( prompt ) :,False,95.12,72.43,,,
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> if delete : <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id )",if key in LoggerFactory . schedule_logger_dict . keys ( ) :,if key in LoggerFactory . schedule_logger_dict :,False,98.07,73.39,,,
"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB> <TAB> <TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB> <TAB> <TAB> <TAB> if "" %s %s "" % ( wrong , nr ) in nzb_name . lower ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - 30 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0",if wrong_found == 1 :,if wrong_found == 1 :,True,100.0,74.63,,,
"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB> <TAB> value = item . group ( "" stringval "" ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> value = item . group ( "" value "" ) <TAB> <TAB> value = _pythonize ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> name = item . group ( "" name "" ) <TAB> <TAB> <TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs","if item . group ( ""name"" ) == ""args"" :","if not item . group ( ""name"" ) :",False,96.34,68.55,,,
"def leaves ( self , unique = True ) : <TAB> """""" Get the leaves of the tree starting at this root. """""" <TAB> if not self . children : <TAB> <TAB> return [ self ] <TAB> else : <TAB> <TAB> res = list ( ) <TAB> <TAB> for child in self . children : <TAB> <TAB> <TAB> for sub_child in child . leaves ( unique = unique ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( sub_child ) <TAB> <TAB> return res",if sub_child is not None :,if not unique or sub_child not in res :,False,94.27,91.52,,,
"def to_tree ( self , tagname = None , idx = None , namespace = None ) : <TAB> axIds = set ( ( ax . axId for ax in self . _axes ) ) <TAB> for chart in self . _charts : <TAB> <TAB> for id , axis in chart . _axes . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> setattr ( self , axis . tagname , axis ) <TAB> <TAB> <TAB> <TAB> axIds . add ( id ) <TAB> return super ( PlotArea , self ) . to_tree ( tagname )",if id not in axIds :,if id not in axIds :,True,100.0,74.42,,,
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . ENABLED : <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . CONNECT_MODE :,if k == neighbors . CONNECT_MODE :,True,100.0,74.37,,,
"def close_all_connections ( ) : <TAB> global _managers , _lock , _in_use , _timer <TAB> _lock . acquire ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _timer . cancel ( ) <TAB> <TAB> <TAB> _timer = None <TAB> <TAB> for domain , managers in _managers . items ( ) : <TAB> <TAB> <TAB> for manager in managers : <TAB> <TAB> <TAB> <TAB> manager . close ( ) <TAB> <TAB> _managers = { } <TAB> finally : <TAB> <TAB> _lock . release ( )",if _timer :,if _timer :,True,100.0,74.3,,,
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> elif isinstance(value, list): <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model","if isinstance ( item , tf . keras . layers . BatchNorm ) :","if isinstance ( item , tf . keras . layers . Layer ) :",False,98.86,73.2,,,
"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB> <TAB> if fnmatch . fnmatch ( tgt , host ) : <TAB> <TAB> <TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB> <TAB> <TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret","if __opts__ [ ""ssh_user"" ] :","if __opts__ . get ( ""ssh_user"" ) :",False,95.81,71.63,,,
"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB> <TAB> if self . _write_line : <TAB> <TAB> <TAB> sys . stderr . write ( fn + "" :  "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sys . stderr . write ( data ) <TAB> <TAB> if ( data [ - 1 ] ) == "" \n "" : <TAB> <TAB> <TAB> self . _write_line = True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data )","elif isinstance ( data , bytes ) :",if bytes :,False,95.79,72.02,,,
"def task_thread ( ) : <TAB> while not task_queue . empty ( ) : <TAB> <TAB> host , port , username , password = task_queue . get ( ) <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" try burst  {} : {}  use username: {}  password: {} "" . format ( <TAB> <TAB> <TAB> <TAB> host , port , username , password <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with task_queue . mutex : <TAB> <TAB> <TAB> <TAB> task_queue . queue . clear ( ) <TAB> <TAB> <TAB> result_queue . put ( ( username , password ) )",if task_queue . queue :,"if telnet_login ( host , port , username , password ) :",False,93.11,69.58,,,
"def _format_results ( name , ppl , scores , metrics ) : <TAB> """""" Format results. """""" <TAB> result_str = "" "" <TAB> if ppl : <TAB> <TAB> result_str = "" %s  ppl  %.2f "" % ( name , ppl ) <TAB> if scores : <TAB> <TAB> for metric in metrics : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result_str + = "" ,  %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result_str = "" %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB> return result_str",if metric in scores :,if result_str :,False,97.59,97.89,,,
"def info_query ( self , query ) : <TAB> """""" Send a query which only returns 1 row """""" <TAB> self . _cmysql . query ( query ) <TAB> first_row = ( ) <TAB> if self . _cmysql . have_result_set : <TAB> <TAB> first_row = self . _cmysql . fetch_row ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _cmysql . free_result ( ) <TAB> <TAB> <TAB> raise errors . InterfaceError ( "" Query should not return more than 1 row "" ) <TAB> self . _cmysql . free_result ( ) <TAB> return first_row",if first_row > 1 :,if self . _cmysql . fetch_row ( ) :,False,93.39,90.94,,,
"def reset_class ( self ) : <TAB> for f in self . fields_order : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f . value = int ( f . strbits , 2 ) <TAB> <TAB> elif "" default_val "" in f . kargs : <TAB> <TAB> <TAB> f . value = int ( f . kargs [ "" default_val "" ] , 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . value = None <TAB> <TAB> if f . fname : <TAB> <TAB> <TAB> setattr ( self , f . fname , f )",if f . strbits :,if f . strbits and isbin ( f . strbits ) :,False,94.43,70.3,,,
"def _walk_map_list ( self , access_func ) : <TAB> seen = [ ] <TAB> cur = self <TAB> while cur : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield cur <TAB> <TAB> seen . append ( cur . obj_offset ) <TAB> <TAB> # check for signs of infinite looping <TAB> <TAB> if len(seen) > 1024: <TAB> <TAB> <TAB> break <TAB> <TAB> cur = access_func(cur)",if cur . obj_offset in seen :,if cur . obj_offset in seen :,True,100.0,74.16,,,
def bgdel ( ) : <TAB> q = bgdelq <TAB> while True : <TAB> <TAB> name = q . get ( ) <TAB> <TAB> while os . path . exists ( name ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> os . remove ( name ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( name ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if os . path . exists ( name ) : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 ),if os . path . isdir ( name ) :,if os . path . isfile ( name ) :,False,98.71,98.36,,,
"def _find_all_variables ( transfer_variable ) : <TAB> d = { } <TAB> for _k , _v in transfer_variable . __dict__ . items ( ) : <TAB> <TAB> if isinstance ( _v , Variable ) : <TAB> <TAB> <TAB> d [ _v . _name ] = _v <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d . update ( _find_all_variables ( _v ) ) <TAB> return d","elif isinstance ( _v , list ) :","elif isinstance ( _v , BaseTransferVariables ) :",False,97.93,72.35,,,
"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB> <TAB> row = model [ idx ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if idx == len ( os_widget . get_model ( ) ) - 1 : <TAB> <TAB> <TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB> <TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB> <TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB> <TAB> return None",if row [ 0 ] == 0 :,if value and row [ 0 ] == value :,False,96.72,71.76,,,
"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB> <TAB> if methods == ALL : <TAB> <TAB> <TAB> methods = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB> <TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( )",elif methods :,"elif isinstance ( methods , ( list , tuple ) ) :",False,94.79,71.21,,,
"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os.path.join(path, name) <TAB> <TAB> st = os.lstat(pathname) <TAB> <TAB> mode = st.st_mode <TAB> <TAB> if stat.S_ISDIR(mode): <TAB> <TAB> <TAB> files.extend(findfiles(pathname)) <TAB> <TAB> elif stat.S_ISREG(mode): <TAB> <TAB> <TAB> files.append((pathname, name, st)) <TAB> return files","if name . startswith ( ""_"" ) :","if name . startswith ( ""."" ) or name == ""lastsnap.jpg"" :",False,93.43,63.2,,,
"def __getitem__ ( self , key ) : <TAB> if isinstance ( key , str_types ) : <TAB> <TAB> keys = self . get_keys ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise KeyError ( ' "" {0} ""  is an invalid key ' . format ( key ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self [ keys . index ( key ) ] <TAB> else : <TAB> <TAB> return list . __getitem__ ( self , key )",if key not in keys :,if key not in keys :,True,100.0,74.3,,,
"def test_assert_set_equal ( estimate : tp . Iterable [ int ] , message : str ) - > None : <TAB> reference = { 1 , 2 , 3 } <TAB> try : <TAB> <TAB> testing . assert_set_equal ( estimate , reference ) <TAB> except AssertionError as error : <TAB> <TAB> if not message : <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" An error has been raised while it should not. "" <TAB> <TAB> <TAB> ) from error <TAB> <TAB> np . testing . assert_equal ( error . args [ 0 ] . split ( "" \n "" ) [ 1 : ] , message ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AssertionError ( "" An error should have been raised. "" )","if error . args [ 0 ] == ""Error"" :",if message :,False,93.94,66.61,,,
"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subp = os . path . join ( pth , p ) <TAB> <TAB> <TAB> p = os . path . join ( prefix , p ) <TAB> <TAB> <TAB> if recursive and os . path . isdir ( subp ) : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , None ] ) <TAB> return res",if os . path . isdir ( p ) :,"if p [ 0 ] != ""."" :",False,94.93,63.17,,,
"def check ( self , runner , script , info ) : <TAB> if isinstance ( info , ast . FunctionDef ) : <TAB> <TAB> for arg in info . args . args : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if arg . id in script . modelVars : <TAB> <TAB> <TAB> <TAB> <TAB> self . problem ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Function  {0}  may shadow model variable  {1} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info . name , arg . id <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> lineno = info . lineno , <TAB> <TAB> <TAB> <TAB> <TAB> )","if isinstance ( arg , ast . Name ) :","if isinstance ( arg , ast . Name ) :",True,100.0,74.49,,,
"def db_lookup ( field , key , publish_year = None ) : <TAB> sql = "" select sum(ebook_count) as num from subjects where field=$field and key=$key "" <TAB> if publish_year : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sql + = ""  and publish_year between $y1 and $y2 "" <TAB> <TAB> <TAB> ( y1 , y2 ) = publish_year <TAB> <TAB> else : <TAB> <TAB> <TAB> sql + = ""  and publish_year=$publish_year "" <TAB> return list ( ebook_count_db . query ( sql , vars = locals ( ) ) ) [ 0 ] . num","if field == ""y1"" and key == ""y2"" :","if isinstance ( publish_year , ( tuple , list ) ) :",False,91.59,63.33,,,
"def put ( self , session ) : <TAB> with sess_lock : <TAB> <TAB> self . parent . put ( session ) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self.skip_paths: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if session.sid in self._cache: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> del self._cache[session.sid] <TAB> <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self._cache[session.sid] = session <TAB> self._normalize()",if session . sid in sp :,if request . path . startswith ( sp ) :,False,95.26,69.44,,,
"def summarize ( self ) : <TAB> if self . bad_commit and self . good_commit : <TAB> <TAB> for subresult in self . subresults . values ( ) : <TAB> <TAB> <TAB> sub = subresult . summarize ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return sub <TAB> <TAB> return "" Detected bad commit in  {}  repository: \n {} {} "" . format ( <TAB> <TAB> <TAB> self . repo_name , self . bad_commit , get_message ( self . suite , self . bad_commit ) <TAB> <TAB> ) <TAB> return "" """,if sub :,if sub :,True,100.0,74.36,,,
def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB> <TAB> for p in self . grammar . Productions [ 1 : ] : <TAB> <TAB> <TAB> if p . len == 0 : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p . prod : <TAB> <TAB> <TAB> <TAB> if not t in nullable : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len ( nullable ) <TAB> return nullable,if num_nullable == len ( nullable ) :,if len ( nullable ) == num_nullable :,False,97.42,83.65,,,
"def _cast_float64_to_float32 ( self , feeds ) : <TAB> for input_name , input_type in self . inputs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> feed = feeds . get ( input_name ) <TAB> <TAB> <TAB> if feed is not None and feed . dtype == np . float64 : <TAB> <TAB> <TAB> <TAB> feeds [ input_name ] = feed . astype ( np . float32 ) <TAB> return feeds","if input_type == ""float64"" :","if input_type == ""tensor(float)"" :",False,95.53,72.47,,,
"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if is_prev : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d",if diff_min is not None :,if diff_min is not None and diff_min != 0 :,False,94.96,71.74,,,
"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB> <TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB> <TAB> if not isinstance ( key , str ) : <TAB> <TAB> <TAB> key = str ( key ) <TAB> <TAB> detyper = self . get_detyper ( key ) <TAB> <TAB> if detyper is None : <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper(val) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx[key] = deval <TAB> self._detyped = ctx <TAB> return ctx",if deval is None :,if deval is None :,True,100.0,74.52,,,
"def get_or_create_user ( request , user_data ) : <TAB> try : <TAB> <TAB> user = User . objects . get ( sso_id = user_data [ "" id "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> update_user ( user , user_data ) <TAB> <TAB> return user <TAB> except User . DoesNotExist : <TAB> <TAB> user = User . objects . create_user ( <TAB> <TAB> <TAB> user_data [ "" username "" ] , <TAB> <TAB> <TAB> user_data [ "" email "" ] , <TAB> <TAB> <TAB> is_active = user_data . get ( "" is_active "" , True ) , <TAB> <TAB> <TAB> sso_id = user_data [ "" id "" ] , <TAB> <TAB> ) <TAB> <TAB> user . update_acl_key ( ) <TAB> <TAB> setup_new_user ( request . settings , user ) <TAB> <TAB> return user",if user . is_active ( ) :,"if user_needs_updating ( user , user_data ) :",False,95.61,72.42,,,
"def _populate_tree ( self , element , d ) : <TAB> """""" Populates an etree with attributes & elements, given a dict. """""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v )","elif isinstance ( v , bool ) :","elif isinstance ( v , bool ) :",True,100.0,74.6,,,
"def load ( cls ) : <TAB> if not cls . _loaded : <TAB> <TAB> cls . log . debug ( "" Loading action_sets... "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls . _find_action_sets ( PATHS . ACTION_SETS_DIRECTORY ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cls . action_sets = JsonDecoder . load ( PATHS . ACTION_SETS_JSON_FILE ) <TAB> <TAB> cls . log . debug ( "" Done! "" ) <TAB> <TAB> cls . _loaded = True",if os . path . isdir ( PATHS . ACTION_SETS_DIRECTORY ) :,if not horizons . globals . fife . use_atlases :,False,90.33,68.54,,,
"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB> <TAB> for setting , edge in self . Conflicts : <TAB> <TAB> <TAB> answer = self . AskUser ( self . Setting , setting ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = setting . Value . split ( "" | "" ) <TAB> <TAB> <TAB> <TAB> value . remove ( edge ) <TAB> <TAB> <TAB> <TAB> setting . Value = "" | "" . join ( value ) <TAB> <TAB> <TAB> <TAB> if updater : <TAB> <TAB> <TAB> <TAB> <TAB> updater . UpdateSetting ( setting ) <TAB> <TAB> <TAB> if answer == Gtk . ResponseType . NO : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True",if answer == Gtk . ResponseType . NO :,if answer == Gtk . ResponseType . YES :,False,98.83,73.64,,,
"def read_tsv ( input_file , quotechar = None ) : <TAB> """""" Reads a tab separated value file. """""" <TAB> with open ( input_file , "" r "" , encoding = "" utf-8-sig "" ) as f : <TAB> <TAB> reader = csv . reader ( f , delimiter = "" \t "" , quotechar = quotechar ) <TAB> <TAB> lines = [ ] <TAB> <TAB> for line in reader : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> line = list ( str ( cell , "" utf-8 "" ) for cell in line ) # noqa: F821 <TAB> <TAB> <TAB> lines.append(line) <TAB> <TAB> return lines","if isinstance ( line , list ) :",if sys . version_info [ 0 ] == 2 :,False,92.94,88.06,,,
"def devd_devfs_hook ( middleware , data ) : <TAB> if data . get ( "" subsystem "" ) != "" CDEV "" : <TAB> <TAB> return <TAB> if data [ "" type "" ] == "" CREATE "" : <TAB> <TAB> disks = await middleware . run_in_thread ( <TAB> <TAB> <TAB> lambda : sysctl . filter ( "" kern.disks "" ) [ 0 ] . value . split ( ) <TAB> <TAB> ) <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> if data[""cdev""] not in disks: <TAB> <TAB> <TAB> return <TAB> <TAB> await added_disk(middleware, data[""cdev""]) <TAB> elif data[""type""] == ""DESTROY"": <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> await remove_disk(middleware, data[""cdev""])","if data [ ""cdev"" ] not in disks :","if not RE_ISDISK . match ( data [ ""cdev"" ] ) :",False,95.66,71.43,,,
"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . watchdirs [ watchdir_id ] [ "" enabled "" ] : <TAB> <TAB> <TAB> <TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id )",if watchdir_id in self . watchdirs :,"if col and col . get_title ( ) == _ ( ""Active"" ) :",False,91.91,62.82,,,
"def _execute ( self , options , args ) : <TAB> if len ( args ) < 1 : <TAB> <TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> paths = args <TAB> songs = [ self . load_song ( p ) for p in paths ] <TAB> for song in songs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> <TAB> _ ( "" Image editing not supported for  %(file_name)s "" "" ( %(file_format)s ) "" ) <TAB> <TAB> <TAB> <TAB> % { "" file_name "" : song ( "" ~filename "" ) , "" file_format "" : song ( "" ~format "" ) } <TAB> <TAB> <TAB> ) <TAB> for song in songs : <TAB> <TAB> try : <TAB> <TAB> <TAB> song . clear_images ( ) <TAB> <TAB> except AudioFileError as e : <TAB> <TAB> <TAB> raise CommandError ( e )",if not song . has_image ( ) :,if not song . can_change_images :,False,97.48,73.51,,,
"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB> <TAB> for pricing_rule in pricing_rules : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules","if doc . get ( ""condition"" ) :",if pricing_rule . condition :,False,96.37,63.65,,,
"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB> <TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB> <TAB> if text == ' "" use strict "" ' or text == "" ' use strict ' "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _scopeStrictModes . pop ( ) <TAB> <TAB> <TAB> self . _useStrictCurrent = True <TAB> <TAB> <TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent )",if self . _useStrictCurrent :,if len ( self . _scopeStrictModes ) > 0 :,False,93.85,70.14,,,
"def _find_remote_inputs ( metadata ) : <TAB> out = [ ] <TAB> for fr_key in metadata . keys ( ) : <TAB> <TAB> if isinstance ( fr_key , ( list , tuple ) ) : <TAB> <TAB> <TAB> frs = fr_key <TAB> <TAB> else : <TAB> <TAB> <TAB> frs = [ fr_key ] <TAB> <TAB> for fr in frs : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> out . append ( fr ) <TAB> return out","if fr . remote_input_type == ""remote"" :",if objectstore . is_remote ( fr ) :,False,91.38,61.81,,,
"def sub_paragraph ( self , li ) : <TAB> """""" Search for checkbox in sub-paragraph. """""" <TAB> found = False <TAB> if len ( li ) : <TAB> <TAB> first = list ( li ) [ 0 ] <TAB> <TAB> if first . tag == "" p "" and first . text is not None : <TAB> <TAB> <TAB> m = RE_CHECKBOX . match ( first . text ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> first . text = self . markdown . htmlStash . store ( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB> <TAB> <TAB> <TAB> ) + m . group ( "" line "" ) <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found",if m :,if m is not None :,False,97.86,95.36,,,
"def list_files ( basedir ) : <TAB> """""" List files in the directory rooted at |basedir|. """""" <TAB> if not os . path . isdir ( basedir ) : <TAB> <TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB> <TAB> d = directories . pop ( ) <TAB> <TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB> <TAB> <TAB> filename = os . path . join ( d , basename ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> directories . append ( filename ) <TAB> <TAB> <TAB> elif os . path . exists ( os . path . join ( basedir , filename ) ) : <TAB> <TAB> <TAB> <TAB> yield filename","if os . path . isdir ( os . path . join ( basedir , filename , "".py"" ) ) :","if os . path . isdir ( os . path . join ( basedir , filename ) ) :",False,97.02,87.22,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.14,,,
"def _dump ( self , fd ) : <TAB> with self . no_unpicklable_properties ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d = pickle . dumps ( self ) <TAB> <TAB> <TAB> module_name = os . path . basename ( sys . argv [ 0 ] ) . rsplit ( "" . "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> d = d . replace ( b "" c__main__ "" , b "" c "" + module_name . encode ( "" ascii "" ) ) <TAB> <TAB> <TAB> fd . write ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pickle . dump ( self , fd )",if self . pickle :,"if self . __module__ == ""__main__"" :",False,91.26,68.13,,,
"def assert_session_stack ( classes ) : <TAB> assert len ( _SklearnTrainingSession . _session_stack ) == len ( classes ) <TAB> for idx , ( sess , ( parent_clazz , clazz ) ) in enumerate ( <TAB> <TAB> zip ( _SklearnTrainingSession . _session_stack , classes ) <TAB> ) : <TAB> <TAB> assert sess . clazz == clazz <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert sess . _parent is None <TAB> <TAB> else : <TAB> <TAB> <TAB> assert sess . _parent . clazz == parent_clazz",if idx == 0 :,if idx == 0 :,True,100.0,74.3,,,
"def native_color ( c ) : <TAB> try : <TAB> <TAB> color = CACHE [ c ] <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> c = NAMED_COLOR [ c ] <TAB> <TAB> color = Color . FromArgb ( <TAB> <TAB> <TAB> int ( c . rgba . a * 255 ) , int ( c . rgba . r ) , int ( c . rgba . g ) , int ( c . rgba . b ) <TAB> <TAB> ) <TAB> <TAB> CACHE [ c ] = color <TAB> return color",if c in NAMED_COLOR :,"if isinstance ( c , str ) :",False,94.9,70.84,,,
"def callback ( name ) : <TAB> # XXX: move into Action <TAB> for neighbor_name in reactor.configuration.neighbors.keys(): <TAB> <TAB> neighbor = reactor.configuration.neighbors.get(neighbor_name, None) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> neighbor.rib.outgoing.announce_watchdog(name) <TAB> <TAB> yield False <TAB> reactor.processes.answer_done(service)",if neighbor is None :,if not neighbor :,False,96.23,68.83,,,
"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield DataToken ( read_data ( token , source ) ) <TAB> <TAB> elif is_small_integer ( token ) : <TAB> <TAB> <TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Token ( token ) <TAB> <TAB> token = source . read_uint8 ( )",if is_data ( token ) :,if is_push_data_token ( token ) :,False,95.7,72.75,,,
"def setattr ( self , req , ino , attr , to_set , fi ) : <TAB> print ( "" setattr: "" , ino , to_set ) <TAB> a = self . attr [ ino ] <TAB> for key in to_set : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Keep the old file type bit fields <TAB> <TAB> <TAB> a[""st_mode""] = S_IFMT(a[""st_mode""]) | S_IMODE(attr[""st_mode""]) <TAB> <TAB> else: <TAB> <TAB> <TAB> a[key] = attr[key] <TAB> self.attr[ino] = a <TAB> self.reply_attr(req, a, 1.0)",if fi :,"if key == ""st_mode"" :",False,94.78,67.19,,,
"def check_enum_exports ( module , eq_callback , only = None ) : <TAB> """""" Make sure module exports all mnemonics from enums """""" <TAB> for attr in enumerate_module ( module , enum . Enum ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" SKIP "" , attr ) <TAB> <TAB> <TAB> continue <TAB> <TAB> for flag , value in attr . __members__ . items ( ) : <TAB> <TAB> <TAB> print ( module , flag , value ) <TAB> <TAB> <TAB> eq_callback ( getattr ( module , flag ) , value )","if attr . __name__ == ""__module__"" :",if only is not None and attr not in only :,False,89.44,63.96,,,
"def remove_edit_vars_to ( self , n ) : <TAB> try : <TAB> <TAB> removals = [ ] <TAB> <TAB> for v , cei in self . edit_var_map . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> removals . append ( v ) <TAB> <TAB> for v in removals : <TAB> <TAB> <TAB> self . remove_edit_var ( v ) <TAB> <TAB> assert len ( self . edit_var_map ) == n <TAB> except ConstraintNotFound : <TAB> <TAB> raise InternalError ( "" Constraint not found during internal removal "" )","if cei . get_name ( ) == ""edit"" :",if cei . index >= n :,False,93.19,63.28,,,
"def fix_repeating_arguments ( self ) : <TAB> """""" Fix elements that should accumulate/increment values. """""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self",if type ( e . value ) is list :,if e . value is None :,False,96.96,96.9,,,
"def add_I_prefix ( current_line : List [ str ] , ner : int , tag : str ) : <TAB> for i in range ( 0 , len ( current_line ) ) : <TAB> <TAB> if i == 0 : <TAB> <TAB> <TAB> f . write ( line_list [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f . write ( ""  I- "" + tag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . write ( "" "" + current_line [ i ] ) <TAB> f . write ( "" \n "" )",elif i < ner :,elif i == ner :,False,97.62,73.11,,,
def select_word_at_cursor ( self ) : <TAB> word_region = None <TAB> selection = self . view . sel ( ) <TAB> for region in selection : <TAB> <TAB> word_region = self . view . word ( region ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> selection . clear ( ) <TAB> <TAB> <TAB> selection . add ( word_region ) <TAB> <TAB> <TAB> return word_region <TAB> return word_region,if word_region :,if not word_region . empty ( ) :,False,93.46,67.47,,,
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res","elif self . op == ""-"" :","elif self . op == ""-"" :",True,100.0,74.66,,,
"def strip_pod ( lines ) : <TAB> in_pod = False <TAB> stripped_lines = [ ] <TAB> for line in lines : <TAB> <TAB> if re . match ( r "" ^=(?:end|cut) "" , line ) : <TAB> <TAB> <TAB> in_pod = False <TAB> <TAB> elif re . match ( r "" ^= \ w+ "" , line ) : <TAB> <TAB> <TAB> in_pod = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stripped_lines . append ( line ) <TAB> return stripped_lines",if in_pod :,elif not in_pod :,False,97.59,71.8,,,
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> if isinstance ( filename_data , list ) : <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename . startswith ( os . sep ) : <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories",if data :,if data :,True,100.0,74.52,,,
"def loadPerfsFromModule ( self , module ) : <TAB> """""" Return a suite of all perfs cases contained in the given module """""" <TAB> perfs = [ ] <TAB> for name in dir ( module ) : <TAB> <TAB> obj = getattr ( module , name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> perfs . append ( self . loadPerfsFromPerfCase ( obj ) ) <TAB> return self . suiteClass ( perfs )","if isinstance ( obj , PerfsCase ) :","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) :",False,86.48,62.17,,,
"def download_subtitle ( self , subtitle ) : <TAB> if isinstance ( subtitle , XSubsSubtitle ) : <TAB> <TAB> # download the subtitle <TAB> <TAB> logger.info(""Downloading subtitle %r"", subtitle) <TAB> <TAB> r = self.session.get( <TAB> <TAB> <TAB> subtitle.download_link, headers={""Referer"": subtitle.page_link}, timeout=10 <TAB> <TAB> ) <TAB> <TAB> r.raise_for_status() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger.debug(""Unable to download subtitle. No data returned from provider"") <TAB> <TAB> <TAB> return <TAB> <TAB> subtitle.content = fix_line_ending(r.content)",if r . status_code == 404 :,if not r . content :,False,95.35,70.49,,,
"def get_inlaws ( self , person ) : <TAB> inlaws = [ ] <TAB> family_handles = person . get_family_handle_list ( ) <TAB> for handle in family_handles : <TAB> <TAB> fam = self . database . get_family_from_handle ( handle ) <TAB> <TAB> if fam . father_handle and not fam . father_handle == person . handle : <TAB> <TAB> <TAB> inlaws . append ( self . database . get_person_from_handle ( fam . father_handle ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> inlaws . append ( self . database . get_person_from_handle ( fam . mother_handle ) ) <TAB> return inlaws",elif fam . mother_handle and not fam . mother_handle == person . handle :,elif fam . mother_handle and not fam . mother_handle == person . handle :,True,100.0,74.43,,,
"def _check_xorg_conf ( ) : <TAB> if is_there_a_default_xorg_conf_file ( ) : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not "" <TAB> <TAB> <TAB> ""  create it yourself, it was likely generated by your distribution or by an Nvidia utility. \n "" <TAB> <TAB> <TAB> "" This file may contain hard-coded GPU configuration that could interfere with optimus-manager, "" <TAB> <TAB> <TAB> ""  so it is recommended that you delete it before proceeding. \n "" <TAB> <TAB> <TAB> "" Ignore this warning and proceed with GPU switching ? (y/N) "" <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sys . exit ( 0 )",if confirmation is None :,if not confirmation :,False,98.04,72.89,,,
"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> methods = "" "" <TAB> <TAB> elif isinstance ( methods , ( list , tuple ) ) : <TAB> <TAB> <TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB> <TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( )","if methods == """" :",if methods == ALL :,False,98.4,70.28,,,
"def num_of_mapped_volumes ( self , initiator ) : <TAB> cnt = 0 <TAB> for lm_link in self . req ( "" lun-maps "" ) [ "" lun-maps "" ] : <TAB> <TAB> idx = lm_link [ "" href "" ] . split ( "" / "" ) [ - 1 ] <TAB> <TAB> # NOTE(geguileo): There can be races so mapped elements retrieved <TAB> <TAB> # in the listing may no longer exist. <TAB> <TAB> try: <TAB> <TAB> <TAB> lm = self.req(""lun-maps"", idx=int(idx))[""content""] <TAB> <TAB> except exception.NotFound: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cnt += 1 <TAB> return cnt","if lm [ ""initiator"" ] == initiator :","if lm [ ""ig-name"" ] == initiator :",False,98.73,73.29,,,
"def _setAbsoluteY ( self , value ) : <TAB> if value is None : <TAB> <TAB> self . _absoluteY = None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = 10 <TAB> <TAB> elif value == "" below "" : <TAB> <TAB> <TAB> value = - 70 <TAB> <TAB> try : <TAB> <TAB> <TAB> value = common . numToIntOrFloat ( value ) <TAB> <TAB> except ValueError as ve : <TAB> <TAB> <TAB> raise TextFormatException ( <TAB> <TAB> <TAB> <TAB> f "" Not a supported absoluteY position:  { value !r} "" <TAB> <TAB> <TAB> ) from ve <TAB> <TAB> self . _absoluteY = value","if value == ""below"" :","if value == ""above"" :",False,98.63,73.3,,,
"def render_markdown ( text ) : <TAB> users = { u . username . lower ( ) : u for u in get_mention_users ( text ) } <TAB> parts = MENTION_RE . split ( text ) <TAB> for pos , part in enumerate ( parts ) : <TAB> <TAB> if not part . startswith ( "" @ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> username = part [ 1 : ] . lower ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> user = users [ username ] <TAB> <TAB> <TAB> parts [ pos ] = ' **[ {} ]( {} "" {} "" )** ' . format ( <TAB> <TAB> <TAB> <TAB> part , user . get_absolute_url ( ) , user . get_visible_name ( ) <TAB> <TAB> <TAB> ) <TAB> text = "" "" . join ( parts ) <TAB> return mark_safe ( MARKDOWN ( text ) )",if username in users :,if username in users :,True,100.0,74.59,,,
def start_process ( self ) : <TAB> with self . thread_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . allow_process_request = False <TAB> <TAB> <TAB> t = threading . Thread ( target = self . __start ) <TAB> <TAB> <TAB> t . daemon = True <TAB> <TAB> <TAB> t . start ( ),if self . allow_process_request :,if self . allow_process_request :,True,100.0,98.92,,,
"def close ( self ) : <TAB> if self . _fh . closed : <TAB> <TAB> return <TAB> self . _fh . close ( ) <TAB> if os . path . isfile ( self . _filename ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> salt . utils . win_dacl . copy_security ( <TAB> <TAB> <TAB> <TAB> source = self . _filename , target = self . _tmp_filename <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shutil . copymode ( self . _filename , self . _tmp_filename ) <TAB> <TAB> <TAB> st = os . stat ( self . _filename ) <TAB> <TAB> <TAB> os . chown ( self . _tmp_filename , st . st_uid , st . st_gid ) <TAB> atomic_rename ( self . _tmp_filename , self . _filename )",if salt . utils . win_dacl :,if salt . utils . win_dacl . HAS_WIN32 :,False,97.61,73.3,,,
"def _splitSchemaNameDotFieldName ( sn_fn , fnRequired = True ) : <TAB> if sn_fn . find ( "" . "" ) != - 1 : <TAB> <TAB> schemaName , fieldName = sn_fn . split ( "" . "" , 1 ) <TAB> <TAB> schemaName = schemaName . strip ( ) <TAB> <TAB> fieldName = fieldName . strip ( ) <TAB> <TAB> if schemaName and fieldName : <TAB> <TAB> <TAB> return ( schemaName , fieldName ) <TAB> elif not fnRequired : <TAB> <TAB> schemaName = sn_fn . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( schemaName , None ) <TAB> controlflow . system_error_exit ( <TAB> <TAB> 2 , f "" { sn_fn }  is not a valid custom schema.field name. "" <TAB> )",if schemaName and fieldName :,if schemaName :,False,98.19,73.52,,,
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> if dictionary . path in paths : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list","if not isinstance ( op_list , ( list , tuple ) ) :","if not isinstance ( op_list , list ) :",False,96.91,72.67,,,
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_place_handle ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_date_object ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if family :,if family :,True,100.0,74.47,,,
"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> <TAB> value = value == "" true "" <TAB> <TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json )","if key == ""is_enabled"" :","if key in ( ""disabled"" , ""is_up"" ) :",False,94.26,65.81,,,
"def get_billable_and_total_duration ( activity , start_time , end_time ) : <TAB> precision = frappe . get_precision ( "" Timesheet Detail "" , "" hours "" ) <TAB> activity_duration = time_diff_in_hours ( end_time , start_time ) <TAB> billing_duration = 0.0 <TAB> if activity . billable : <TAB> <TAB> billing_duration = activity . billing_hours <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> billing_duration = ( <TAB> <TAB> <TAB> <TAB> activity_duration * activity . billing_hours / activity . hours <TAB> <TAB> <TAB> ) <TAB> return flt ( activity_duration , precision ) , flt ( billing_duration , precision )",if activity . billing_hours :,if activity_duration != activity . billing_hours :,False,96.83,72.58,,,
"def cpus ( self ) : <TAB> try : <TAB> <TAB> cpus = ( <TAB> <TAB> <TAB> self . inspect [ "" Spec "" ] [ "" Resources "" ] [ "" Reservations "" ] [ "" NanoCPUs "" ] / 1000000000.0 <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cpus = int ( cpus ) <TAB> <TAB> return cpus <TAB> except TypeError : <TAB> <TAB> return None <TAB> except KeyError : <TAB> <TAB> return 0",if cpus > cpus :,if cpus == int ( cpus ) :,False,94.19,70.6,,,
"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list(prop_value.keys())[0] <TAB> <TAB> <TAB> if func_name.startswith(""_""): <TAB> <TAB> <TAB> <TAB> func = getattr(self, func_name) <TAB> <TAB> <TAB> <TAB> props[prop_name] = func(prop_value[func_name]) <TAB> if SYMBOL_TYPE in obj_body and obj_body[SYMBOL_TYPE] in self.fake_func_mapping: <TAB> <TAB> return self.fake_func_mapping[obj_body[SYMBOL_TYPE]](**props) <TAB> else: <TAB> <TAB> return props","if isinstance ( prop_value , dict ) :","if isinstance ( prop_value , dict ) and prop_value :",False,97.8,72.42,,,
"def _yield_unescaped ( self , string ) : <TAB> while "" \\ "" in string : <TAB> <TAB> finder = EscapeFinder ( string ) <TAB> <TAB> yield finder . before + finder . backslashes <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield self . _unescape ( finder . text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield finder . text <TAB> <TAB> string = finder . after <TAB> yield string",if self . _is_escaped ( finder . text ) :,if finder . escaped and finder . text :,False,91.3,69.41,,,
"def _check_matches ( rule , matches ) : <TAB> errors = 0 <TAB> for match in matches : <TAB> <TAB> filematch = _match_to_test_file ( match ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> utils . error ( <TAB> <TAB> <TAB> <TAB> "" The match  ' {} '  for rule  ' {} '  points to a non existing test module path:  {} "" , <TAB> <TAB> <TAB> <TAB> match , <TAB> <TAB> <TAB> <TAB> rule , <TAB> <TAB> <TAB> <TAB> filematch , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> errors + = 1 <TAB> return errors",if not filematch :,if not filematch . exists ( ) :,False,96.89,71.68,,,
"def focused_windows ( ) : <TAB> tree = i3 . get_tree ( ) <TAB> workspaces = tree . workspaces ( ) <TAB> for workspace in workspaces : <TAB> <TAB> container = workspace <TAB> <TAB> while container : <TAB> <TAB> <TAB> if not hasattr ( container , "" focus "" ) or not container . focus : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> container_id = container . focus [ 0 ] <TAB> <TAB> <TAB> container = container . find_by_id ( container_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> coname = container . name <TAB> <TAB> <TAB> wsname = workspace . name <TAB> <TAB> <TAB> print ( "" WS "" , wsname + "" : "" , coname )",if container :,if container :,True,100.0,74.48,,,
"def normals ( self , value ) : <TAB> if value is not None : <TAB> <TAB> value = np . asanyarray ( value , dtype = np . float32 ) <TAB> <TAB> value = np . ascontiguousarray ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Incorrect normals shape "" ) <TAB> self . _normals = value",if len ( value ) != self . shape :,if value . shape != self . positions . shape :,False,92.54,69.3,,,
"def test_hexdigest ( self ) : <TAB> for cons in self . hash_constructors : <TAB> <TAB> h = cons ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIsInstance ( h . digest ( 16 ) , bytes ) <TAB> <TAB> <TAB> self . assertEqual ( hexstr ( h . digest ( 16 ) ) , h . hexdigest ( 16 ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertIsInstance ( h . digest ( ) , bytes ) <TAB> <TAB> <TAB> self . assertEqual ( hexstr ( h . digest ( ) ) , h . hexdigest ( ) )",if h . is_hex :,if h . name in self . shakes :,False,95.76,71.4,,,
"def _get_cluster_status ( self ) : <TAB> try : <TAB> <TAB> return ( <TAB> <TAB> <TAB> self . dataproc_client . projects ( ) <TAB> <TAB> <TAB> . regions ( ) <TAB> <TAB> <TAB> . clusters ( ) <TAB> <TAB> <TAB> . get ( <TAB> <TAB> <TAB> <TAB> projectId = self . gcloud_project_id , <TAB> <TAB> <TAB> <TAB> region = self . dataproc_region , <TAB> <TAB> <TAB> <TAB> clusterName = self . dataproc_cluster_name , <TAB> <TAB> <TAB> <TAB> fields = "" status "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> . execute ( ) <TAB> <TAB> ) <TAB> except HttpError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None # We got a 404 so the cluster doesn't exist <TAB> <TAB> else: <TAB> <TAB> <TAB> raise e",if e . response . status == 404 :,if e . resp . status == 404 :,False,99.01,73.62,,,
"def _items_from ( self , context ) : <TAB> self . _context = context <TAB> if self . _is_local_variable ( self . _keyword_name , context ) : <TAB> <TAB> for item in self . _items_from_controller ( context ) : <TAB> <TAB> <TAB> yield item <TAB> else : <TAB> <TAB> for df in context . datafiles : <TAB> <TAB> <TAB> self . _yield_for_other_threads ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for item in self . _items_from_datafile ( df ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield item","if self . _is_local_variable ( self . _keyword_name , df ) :",if self . _items_from_datafile_should_be_checked ( df ) :,False,92.83,71.72,,,
"def Command ( argv , funcs , path_val ) : <TAB> arg , i = COMMAND_SPEC . Parse ( argv ) <TAB> status = 0 <TAB> if arg . v : <TAB> <TAB> for kind , arg in _ResolveNames ( argv [ i : ] , funcs , path_val ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> status = 1 # nothing printed, but we fail <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # This is for -v, -V is more detailed. <TAB> <TAB> <TAB> <TAB> print(arg) <TAB> else: <TAB> <TAB> util.warn(""*** command without -v not not implemented ***"") <TAB> <TAB> status = 1 <TAB> return status","if kind == ""-v"" :",if kind is None :,False,96.74,64.31,,,
"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB> <TAB> if isinstance ( node , Preprint ) : <TAB> <TAB> <TAB> category = "" preprint "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> category = "" registration "" <TAB> <TAB> else : <TAB> <TAB> <TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB> <TAB> index = index , <TAB> <TAB> doc_type = category , <TAB> <TAB> id = elastic_document_id , <TAB> <TAB> refresh = True , <TAB> <TAB> ignore = [ 404 ] , <TAB> )","elif isinstance ( node , Registration ) :",elif node . is_registration :,False,96.15,71.96,,,
"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree(child) <TAB> <TAB> else: <TAB> <TAB> <TAB> content = child.text <TAB> <TAB> if ret_dict.has_key(child.tag): <TAB> <TAB> <TAB> if not type(ret_dict[child.tag]) == list: <TAB> <TAB> <TAB> <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB> <TAB> <TAB> ret_dict[child.tag].append(content or """") <TAB> <TAB> else: <TAB> <TAB> <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict","if isinstance ( child , Tree ) :",if child . getchildren ( ) :,False,97.39,71.33,,,
"def get ( self , block = True , timeout = None , ack = False ) : <TAB> if not block : <TAB> <TAB> return self . get_nowait ( ) <TAB> start_time = time . time ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_nowait ( ack ) <TAB> <TAB> except BaseQueue . Empty : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> lasted = time . time ( ) - start_time <TAB> <TAB> <TAB> <TAB> if timeout > lasted : <TAB> <TAB> <TAB> <TAB> <TAB> time . sleep ( min ( self . max_timeout , timeout - lasted ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( self . max_timeout )",if timeout :,if timeout :,True,100.0,74.57,,,
"def rewrite ( self , string ) : <TAB> string = super ( JSReplaceFuzzy , self ) . rewrite ( string ) <TAB> cdx = self . url_rewriter . rewrite_opts [ "" cdx "" ] <TAB> if cdx . get ( "" is_fuzzy "" ) : <TAB> <TAB> expected = unquote ( cdx [ "" url "" ] ) <TAB> <TAB> actual = unquote ( self . url_rewriter . wburl . url ) <TAB> <TAB> exp_m = self . rx_obj . search ( expected ) <TAB> <TAB> act_m = self . rx_obj . search ( actual ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = string . replace ( exp_m . group ( 1 ) , act_m . group ( 1 ) ) <TAB> <TAB> <TAB> if result != string : <TAB> <TAB> <TAB> <TAB> string = result <TAB> return string",if exp_m :,if exp_m and act_m :,False,98.03,73.2,,,
"def locate_exe_dir ( d , check = True ) : <TAB> exe_dir = os . path . join ( d , "" Scripts "" ) if ON_WINDOWS else os . path . join ( d , "" bin "" ) <TAB> if not os . path . isdir ( exe_dir ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bin_dir = os . path . join ( d , "" bin "" ) <TAB> <TAB> <TAB> if os . path . isdir ( bin_dir ) : <TAB> <TAB> <TAB> <TAB> return bin_dir <TAB> <TAB> if check : <TAB> <TAB> <TAB> raise InvalidVirtualEnv ( "" Unable to locate executables directory. "" ) <TAB> return exe_dir",if ON_WINDOWS :,if ON_WINDOWS :,True,100.0,74.46,,,
"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB> <TAB> s = str ( path ) <TAB> <TAB> if ensuremode == "" append "" : <TAB> <TAB> <TAB> if s not in sys . path : <TAB> <TAB> <TAB> <TAB> sys . path . append ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sys . path . insert ( 0 , s )",if s not in sys . path :,if s != sys . path [ 0 ] :,False,93.74,70.18,,,
"def create_season_banners ( self , show_obj ) : <TAB> if self . season_banners and show_obj : <TAB> <TAB> result = [ ] <TAB> <TAB> for season , episodes in show_obj . episodes . iteritems ( ) : # @UnusedVariable <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> logger.log( <TAB> <TAB> <TAB> <TAB> <TAB> u""Metadata provider "" <TAB> <TAB> <TAB> <TAB> <TAB> + self.name <TAB> <TAB> <TAB> <TAB> <TAB> + "" creating season banners for "" <TAB> <TAB> <TAB> <TAB> <TAB> + show_obj.name, <TAB> <TAB> <TAB> <TAB> <TAB> logger.DEBUG, <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> result = result + [self.save_season_banners(show_obj, season)] <TAB> <TAB> return all(result) <TAB> return False","if episodes and episodes [ ""name"" ] == self . name :","if not self . _has_season_banner ( show_obj , season ) :",False,93.71,63.32,,,
"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB> <TAB> if "" nbgrader "" not in cell . metadata : <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB> <TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB> <TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB> <TAB> if grade_id in ids : <TAB> <TAB> <TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB> <TAB> ids . add ( grade_id )",if locked and grade != locked :,if not grade and not solution and not locked :,False,96.65,71.89,,,
"def read_version ( ) : <TAB> regexp = re . compile ( r "" ^__version__ \ W*= \ W* ' ([ \ d.abrc]+) ' "" ) <TAB> init_py = os . path . join ( os . path . dirname ( __file__ ) , "" aiopg "" , "" __init__.py "" ) <TAB> with open ( init_py ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> match = regexp . match ( line ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return match . group ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( "" Cannot find version in aiopg/__init__.py "" )",if match :,if match is not None :,False,97.67,72.14,,,
"def _column_keys ( self ) : <TAB> """""" Get a dictionary of all columns and their case mapping. """""" <TAB> if not self . exists : <TAB> <TAB> return { } <TAB> with self . db . lock : <TAB> <TAB> if self . _columns is None : <TAB> <TAB> <TAB> # Initialise the table if it doesn't exist <TAB> <TAB> <TAB> table = self.table <TAB> <TAB> <TAB> self._columns = {} <TAB> <TAB> <TAB> for column in table.columns: <TAB> <TAB> <TAB> <TAB> name = normalize_column_name(column.name) <TAB> <TAB> <TAB> <TAB> key = normalize_column_key(name) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> log.warning(""Duplicate column: %s"", name) <TAB> <TAB> <TAB> <TAB> self._columns[key] = name <TAB> <TAB> return self._columns",if key in self . _columns :,if key in self . _columns :,True,100.0,99.51,,,
"def find_controller_by_names ( self , names , testname ) : <TAB> namestring = "" . "" . join ( names ) <TAB> if not namestring . startswith ( self . name ) : <TAB> <TAB> return None <TAB> if namestring == self . name : <TAB> <TAB> return self <TAB> for suite in self . suites : <TAB> <TAB> res = suite . find_controller_by_names ( <TAB> <TAB> <TAB> namestring [ len ( self . name ) + 1 : ] . split ( "" . "" ) , testname <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return res",if res :,if res :,True,100.0,74.4,,,
"def _volume_x_metadata_get_item ( <TAB> context , volume_id , key , model , notfound_exec , session = None ) : <TAB> result = ( <TAB> <TAB> _volume_x_metadata_get_query ( context , volume_id , model , session = session ) <TAB> <TAB> . filter_by ( key = key ) <TAB> <TAB> . first ( ) <TAB> ) <TAB> if not result : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise notfound_exec ( id = volume_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise notfound_exec ( metadata_key = key , volume_id = volume_id ) <TAB> return result","if context . config . get ( ""volume_id_metadata_key_cache"" , False ) :",if model is models . VolumeGlanceMetadata :,False,88.95,61.64,,,
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> if "" hyper_parameters "" in key : <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) )","if ""results.train_y_misclass"" in dd :","if ""results.train_y_misclass"" in dd :",True,100.0,74.5,,,
"def _stop_by_max_time_mins ( self ) : <TAB> """""" Stop optimization process once maximum minutes have elapsed. """""" <TAB> if self . max_time_mins : <TAB> <TAB> total_mins_elapsed = ( <TAB> <TAB> <TAB> datetime . now ( ) - self . _start_datetime <TAB> <TAB> ) . total_seconds ( ) / 60.0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise KeyboardInterrupt ( <TAB> <TAB> <TAB> <TAB> "" {:.2f}  minutes have elapsed. TPOT will close down. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> total_mins_elapsed <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if total_mins_elapsed > self . max_time_mins :,if total_mins_elapsed >= self . max_time_mins :,False,98.75,98.01,,,
"def __new__ ( meta , cls_name , bases , cls_dict ) : <TAB> func = cls_dict . get ( "" func "" ) <TAB> monad_cls = super ( FuncMonadMeta , meta ) . __new__ ( meta , cls_name , bases , cls_dict ) <TAB> if func : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> functions = func <TAB> <TAB> else : <TAB> <TAB> <TAB> functions = ( func , ) <TAB> <TAB> for func in functions : <TAB> <TAB> <TAB> registered_functions [ func ] = monad_cls <TAB> return monad_cls","if isinstance ( func , ( list , tuple ) ) :",if type ( func ) is tuple :,False,93.63,69.91,,,
"def get_tokens_unprocessed ( self , text ) : <TAB> buffered = "" "" <TAB> insertions = [ ] <TAB> lng_buffer = [ ] <TAB> for i , t , v in self . language_lexer . get_tokens_unprocessed ( text ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if lng_buffer : <TAB> <TAB> <TAB> <TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB> <TAB> <TAB> <TAB> lng_buffer = [ ] <TAB> <TAB> <TAB> buffered + = v <TAB> <TAB> else : <TAB> <TAB> <TAB> lng_buffer . append ( ( i , t , v ) ) <TAB> if lng_buffer : <TAB> <TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB> return do_insertions ( insertions , self . root_lexer . get_tokens_unprocessed ( buffered ) )","if t == ""end"" :",if t is self . needle :,False,97.16,64.13,,,
"def get_conditions ( filters ) : <TAB> conditions = { "" docstatus "" : ( "" = "" , 1 ) } <TAB> if filters . get ( "" from_date "" ) and filters . get ( "" to_date "" ) : <TAB> <TAB> conditions [ "" result_date "" ] = ( <TAB> <TAB> <TAB> "" between "" , <TAB> <TAB> <TAB> ( filters . get ( "" from_date "" ) , filters . get ( "" to_date "" ) ) , <TAB> <TAB> ) <TAB> <TAB> filters . pop ( "" from_date "" ) <TAB> <TAB> filters . pop ( "" to_date "" ) <TAB> for key , value in filters . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conditions [ key ] = value <TAB> return conditions","if key != ""result_date"" :",if filters . get ( key ) :,False,95.4,69.17,,,
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if (datetime.now() - limit) > value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> if (datetime.now() + limit) < value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value",if value > limit :,"if config [ key ] [ ""inverse"" ] is True :",False,94.72,64.29,,,
"def GetCurrentKeySet ( self ) : <TAB> "" Return CurrentKeys with  ' darwin '  modifications. "" <TAB> result = self . GetKeySet ( self . CurrentKeys ( ) ) <TAB> if sys . platform == "" darwin "" : <TAB> <TAB> # macOS (OS X) Tk variants do not support the ""Alt"" <TAB> <TAB> # keyboard modifier. Replace it with ""Option"". <TAB> <TAB> # TODO (Ned?): the ""Option"" modifier does not work properly <TAB> <TAB> # <TAB> for Cocoa Tk and XQuartz Tk so we should not use it <TAB> <TAB> # <TAB> in the default 'OSX' keyset. <TAB> <TAB> for k, v in result.items(): <TAB> <TAB> <TAB> v2 = [x.replace(""<Alt-"", ""<Option-"") for x in v] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result[k] = v2 <TAB> return result","if k != ""Alt"" and k != ""XQuartz"" :",if v != v2 :,False,94.23,68.71,,,
"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB> <TAB> package = _normalize_module ( package , 3 ) <TAB> <TAB> filename = _module_relative_path ( package , filename ) <TAB> <TAB> if hasattr ( package , "" __loader__ "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents.replace(os.linesep, ""\n""), filename <TAB> return open(filename).read(), filename","if hasattr ( package . __loader__ , ""get_data"" ) :","if hasattr ( package . __loader__ , ""get_data"" ) :",True,100.0,74.43,,,
"def iter_from_X_lengths ( X , lengths ) : <TAB> if lengths is None : <TAB> <TAB> yield 0 , len ( X ) <TAB> else : <TAB> <TAB> n_samples = X . shape [ 0 ] <TAB> <TAB> end = np . cumsum ( lengths ) . astype ( np . int32 ) <TAB> <TAB> start = end - lengths <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" more than  {:d}  samples in lengths array  {!s} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> n_samples , lengths <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> for i in range ( len ( lengths ) ) : <TAB> <TAB> <TAB> yield start [ i ] , end [ i ]",if len ( start ) > n_samples :,if end [ - 1 ] > n_samples :,False,97.12,72.22,,,
"def change_sel ( self ) : <TAB> """""" Change the view ' s selections. """""" <TAB> if self . alter_select and len ( self . sels ) > 0 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . view . show ( self . sels [ 0 ] ) <TAB> <TAB> self . view . sel ( ) . clear ( ) <TAB> <TAB> self . view . sel ( ) . add_all ( self . sels )",if self . view . sel ( ) . show ( ) :,if self . multi_select is False :,False,91.34,67.29,,,
"def cb_syncthing_device_data_changed ( <TAB> self , daemon , nid , address , client_version , inbps , outbps , inbytes , outbytes ) : <TAB> if nid in self . devices : # Should be always <TAB> <TAB> device = self.devices[nid] <TAB> <TAB> # Update strings <TAB> <TAB> device[""address""] = address <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> device[""version""] = client_version <TAB> <TAB> # Update rates <TAB> <TAB> device[""inbps""] = ""%s/s (%s)"" % (sizeof_fmt(inbps), sizeof_fmt(inbytes)) <TAB> <TAB> device[""outbps""] = ""%s/s (%s)"" % (sizeof_fmt(outbps), sizeof_fmt(outbytes))",if client_version :,"if client_version not in ( ""?"" , None ) :",False,94.95,65.48,,,
"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB> <TAB> ret = [ ] <TAB> <TAB> when_response = list ( when_response ) <TAB> <TAB> for match in when_response : <TAB> <TAB> <TAB> if match not in matches : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> match . name = self . match_name <TAB> <TAB> <TAB> <TAB> matches . append ( match ) <TAB> <TAB> <TAB> <TAB> ret . append ( match ) <TAB> <TAB> return ret <TAB> <IF-STMT> <TAB> <TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB> <TAB> matches . append ( when_response ) <TAB> <TAB> return when_response",if when_response is not None :,if self . match_name :,False,93.69,70.71,,,
"def __update_parents ( self , fileobj , path , delta ) : <TAB> """""" Update all parent atoms with the new size. """""" <TAB> if delta == 0 : <TAB> <TAB> return <TAB> for atom in path : <TAB> <TAB> fileobj . seek ( atom . offset ) <TAB> <TAB> size = cdata . uint_be ( fileobj . read ( 4 ) ) <TAB> <TAB> <IF-STMT> # 64bit <TAB> <TAB> <TAB> # skip name (4B) and read size (8B) <TAB> <TAB> <TAB> size = cdata.ulonglong_be(fileobj.read(12)[4:]) <TAB> <TAB> <TAB> fileobj.seek(atom.offset + 8) <TAB> <TAB> <TAB> fileobj.write(cdata.to_ulonglong_be(size + delta)) <TAB> <TAB> else: # 32bit <TAB> <TAB> <TAB> fileobj.seek(atom.offset) <TAB> <TAB> <TAB> fileobj.write(cdata.to_uint_be(size + delta))",if size == 0 :,if size == 1 :,False,99.01,98.38,,,
"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB> <TAB> if field . primary_key : <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any ( <TAB> <TAB> <TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fields . append ( field ) <TAB> return fields",if requires_index :,if requires_index :,True,100.0,74.19,,,
"def __init__ ( self , value ) : <TAB> """""" Initialize the integer to the given value. """""" <TAB> self . _mpz_p = new_mpz ( ) <TAB> self . _initialized = False <TAB> if isinstance ( value , float ) : <TAB> <TAB> raise ValueError ( "" A floating point type is not a natural number "" ) <TAB> self . _initialized = True <TAB> if isinstance ( value , ( int , long ) ) : <TAB> <TAB> _gmp . mpz_init ( self . _mpz_p ) <TAB> <TAB> result = _gmp . gmp_sscanf ( tobytes ( str ( value ) ) , b ( "" % Zd "" ) , self . _mpz_p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Error converting  ' %d ' "" % value ) <TAB> else : <TAB> <TAB> _gmp . mpz_init_set ( self . _mpz_p , value . _mpz_p )",if result != 0 :,if result != 1 :,False,98.93,98.79,,,
"def decode ( cls , data ) : <TAB> while data : <TAB> <TAB> length , format_type , control_flags , sequence , pid = unpack ( <TAB> <TAB> <TAB> cls . Header . PACK , data [ : cls . Header . LEN ] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise NetLinkError ( "" Buffer underrun "" ) <TAB> <TAB> yield cls . format ( <TAB> <TAB> <TAB> format_type , control_flags , sequence , pid , data [ cls . Header . LEN : length ] <TAB> <TAB> ) <TAB> <TAB> data = data [ length : ]",if length == 0 :,if len ( data ) < length :,False,95.42,71.07,,,
"def __post_init__ ( self ) : <TAB> if self . _node_id is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" invalid node_id:  {} "" . format ( hexlify ( self . _node_id ) . decode ( ) ) <TAB> <TAB> <TAB> ) <TAB> if self . udp_port is not None and not 1 < = self . udp_port < = 65535 : <TAB> <TAB> raise ValueError ( "" invalid udp port "" ) <TAB> if self . tcp_port is not None and not 1 < = self . tcp_port < = 65535 : <TAB> <TAB> raise ValueError ( "" invalid tcp port "" ) <TAB> if not is_valid_public_ipv4 ( self . address , self . allow_localhost ) : <TAB> <TAB> raise ValueError ( f "" invalid ip address:  ' { self . address } ' "" )",if not is_valid_node_id ( self . _node_id ) :,if not len ( self . _node_id ) == constants . HASH_LENGTH :,False,95.5,72.15,,,
"def orderUp ( self , items ) : <TAB> sel = [ ] # new selection <TAB> undoinfo = [] <TAB> for bid, lid in items: <TAB> <TAB> if isinstance(lid, int): <TAB> <TAB> <TAB> undoinfo.append(self.orderUpLineUndo(bid, lid)) <TAB> <TAB> <TAB> sel.append((bid, lid - 1)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> undoinfo.append(self.orderUpBlockUndo(bid)) <TAB> <TAB> <TAB> if bid == 0: <TAB> <TAB> <TAB> <TAB> return items <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> sel.append((bid - 1, None)) <TAB> self.addUndo(undoinfo, ""Move Up"") <TAB> return sel","elif isinstance ( lid , int ) :",elif lid is None :,False,96.5,70.64,,,
"def filter_data ( self , min_len , max_len ) : <TAB> logging . info ( f "" filtering data, min len:  { min_len } , max len:  { max_len } "" ) <TAB> initial_len = len ( self . src ) <TAB> filtered_src = [ ] <TAB> filtered_tgt = [ ] <TAB> for src , tgt in zip ( self . src , self . tgt ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filtered_src . append ( src ) <TAB> <TAB> <TAB> filtered_tgt . append ( tgt ) <TAB> self . src = filtered_src <TAB> self . tgt = filtered_tgt <TAB> filtered_len = len ( self . src ) <TAB> logging . info ( f "" pairs before:  { initial_len } , after:  { filtered_len } "" )",if src < min_len and tgt < max_len :,if min_len <= len ( src ) <= max_len and min_len <= len ( tgt ) <= max_len :,False,89.01,68.94,,,
"def layer_pretrained ( self , net , args , options ) : <TAB> model = getattr ( torchvision . models , args [ 0 ] ) ( pretrained = True ) <TAB> model . train ( True ) <TAB> if options . layer : <TAB> <TAB> layers = list ( model . children ( ) ) [ : options . layer ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> layers [ - 1 ] = nn . Sequential ( * layers [ - 1 ] [ : options . sublayer ] ) <TAB> else : <TAB> <TAB> layers = [ model ] <TAB> <TAB> print ( "" List of pretrained layers: "" , layers ) <TAB> <TAB> raise ValidationException ( <TAB> <TAB> <TAB> "" layer=-1 required for pretrained, sublayer=-1 optional. Layers outputted above. "" <TAB> <TAB> ) <TAB> return nn . Sequential ( * layers )",if options . sublayer :,if options . sublayer :,True,100.0,74.57,,,
"def deleteCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] ) <TAB> for user in users : <TAB> <TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> gapi . call ( cal . calendarList ( ) , "" delete "" , soft_errors = True , calendarId = calendarId )",if not cal :,if not cal :,True,100.0,74.09,,,
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """""" iterate over all modules """""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None : <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> if module . is_compatible_with ( client ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module",if clients is None :,if not clients :,False,98.35,77.68,,,
"def update_me ( self ) : <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> line = self . queue . get_nowait ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . delete ( 1.0 , tk . END ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . insert ( tk . END , str ( line ) ) <TAB> <TAB> <TAB> self . see ( tk . END ) <TAB> <TAB> <TAB> self . update_idletasks ( ) <TAB> except queue . Empty : <TAB> <TAB> pass <TAB> self . after ( 100 , self . update_me )","if line == """" :",if line is None :,False,96.9,64.15,,,
"def request_power_state ( self , state , force = False ) : <TAB> if self . current_state != state or force : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . request_in_progress = True <TAB> <TAB> <TAB> logging . info ( "" Requesting  %s "" % state ) <TAB> <TAB> <TAB> cb = PowerManager . Callback ( self , state ) <TAB> <TAB> <TAB> rets = self . parent . Plugins . run ( <TAB> <TAB> <TAB> <TAB> "" on_power_state_change_requested "" , self , state , cb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cb . num_cb = len ( rets ) <TAB> <TAB> <TAB> cb . check ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . info ( "" Another request in progress "" )",if self . parent . Plugins . is_enabled ( self ) :,if not self . request_in_progress :,False,94.47,71.53,,,
"def __getitem__ ( self , idx ) : <TAB> super ( BatchDataset , self ) . __getitem__ ( idx ) <TAB> maxidx = len ( self . dataset ) <TAB> samples = [ ] <TAB> for i in range ( 0 , self . batchsize ) : <TAB> <TAB> j = idx * self . batchsize + i <TAB> <TAB> if j > = maxidx : <TAB> <TAB> <TAB> break <TAB> <TAB> j = self . perm ( j , maxidx ) <TAB> <TAB> sample = self . dataset [ j ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> samples . append ( sample ) <TAB> samples = self . makebatch ( samples ) <TAB> return samples",if sample is not None :,if self . filter ( sample ) :,False,95.82,71.56,,,
"def __call__ ( self , request , * args , * * kwargs ) : <TAB> template_vars = { } <TAB> for form_name , form_class in self . forms . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> template_vars [ form_name ] = form_class ( request ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template_vars [ form_name ] = None <TAB> if request . method == "" POST "" : <TAB> <TAB> action = self . find_post_handler_action ( request ) <TAB> <TAB> form = self . handlers [ action ] ( request , data = request . POST , files = request . FILES ) <TAB> <TAB> template_vars . update ( form . dispatch ( action , request , * args , * * kwargs ) ) <TAB> return self . GET ( template_vars , request , * args , * * kwargs )",if form_class . is_valid ( request ) :,"if form_class . must_display ( request , * args , ** kwargs ) :",False,94.61,71.55,,,
"def on_show_all ( self , widget , another ) : <TAB> if widget . get_active ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . treeview . update_items ( all = True , comment = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . treeview . update_items ( all = True ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . treeview . update_items ( comment = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . treeview . update_items ( )",if widget . get_comment ( ) :,if another . get_active ( ) :,False,93.71,70.15,,,
"def close ( self ) : <TAB> if self . _closed : <TAB> <TAB> return <TAB> self . _closed = True <TAB> for proto in self . _pipes . values ( ) : <TAB> <TAB> if proto is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> proto . pipe . close ( ) <TAB> if ( <TAB> <TAB> self . _proc is not None <TAB> <TAB> and <TAB> <TAB> # has the child process finished? <TAB> <TAB> self._returncode is None <TAB> <TAB> and <TAB> <TAB> # the child process has finished, but the <TAB> <TAB> # transport hasn't been notified yet? <TAB> <TAB> self._proc.poll() is None <TAB> ): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger.warning(""Close running child process: kill %r"", self) <TAB> <TAB> try: <TAB> <TAB> <TAB> self._proc.kill() <TAB> <TAB> except ProcessLookupError: <TAB> <TAB> <TAB> pass",if self . _log_finished :,if self . _loop . get_debug ( ) :,False,96.97,72.4,,,
"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB> <TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB> <TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB> <TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB> <TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB> <TAB> if fish is bomb : <TAB> <TAB> <TAB> bomb_count + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> fish . click ( ) <TAB> <TAB> time . sleep ( 2.5 )",if bomb_count == 5 :,if bomb_count > 3 :,False,98.09,73.43,,,
"def load_managers ( * , loop , only ) : <TAB> managers = { } <TAB> for key in DB_CLASSES : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> params = DB_DEFAULTS . get ( key ) or { } <TAB> <TAB> params . update ( DB_OVERRIDES . get ( key ) or { } ) <TAB> <TAB> database = DB_CLASSES [ key ] ( * * params ) <TAB> <TAB> managers [ key ] = peewee_async . Manager ( database , loop = loop ) <TAB> return managers",if only :,if only and key not in only :,False,95.85,70.94,,,
"def links_extracted ( self , request , links ) : <TAB> for link in links : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r = self . _create_request ( link . url ) <TAB> <TAB> <TAB> r . meta [ b "" depth "" ] = request . meta [ b "" depth "" ] + 1 <TAB> <TAB> <TAB> self . schedule ( r , self . _get_score ( r . meta [ b "" depth "" ] ) ) <TAB> <TAB> <TAB> link . meta [ b "" state "" ] = States . QUEUED",if link . state == States . SUCCESS :,"if link . meta [ b""state"" ] == States . NOT_CRAWLED :",False,91.35,66.24,,,
"def find_worktree_git_dir ( dotgit ) : <TAB> """""" Search for a gitdir for this worktree. """""" <TAB> try : <TAB> <TAB> statbuf = os . stat ( dotgit ) <TAB> except OSError : <TAB> <TAB> return None <TAB> if not stat . S_ISREG ( statbuf . st_mode ) : <TAB> <TAB> return None <TAB> try : <TAB> <TAB> lines = open ( dotgit , "" r "" ) . readlines ( ) <TAB> <TAB> for key , value in [ line . strip ( ) . split ( "" :  "" ) for line in lines ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return value <TAB> except ValueError : <TAB> <TAB> pass <TAB> return None","if key == ""gitdir"" :","if key == ""gitdir"" :",True,100.0,99.52,,,
"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB> <TAB> return False <TAB> for dim_value in shape : <TAB> <TAB> if not isinstance ( dim_value , int ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True",if dim_value < 0 or dim_value > 0 :,if dim_value < 0 :,False,94.53,72.46,,,
"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB> <TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB> <TAB> if handler_id not in used_handlers : <TAB> <TAB> <TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = handler [ "" filename "" ] <TAB> <TAB> <TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB> <TAB> <TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config )","if ""filename"" in handler :","elif ""filename"" in handler . keys ( ) :",False,96.89,72.3,,,
"def __call__ ( self ) : <TAB> dmin , dmax = self . viewlim_to_dt ( ) <TAB> ymin = self . base . le ( dmin . year ) <TAB> ymax = self . base . ge ( dmax . year ) <TAB> ticks = [ dmin . replace ( year = ymin , * * self . replaced ) ] <TAB> while 1 : <TAB> <TAB> dt = ticks [ - 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return date2num ( ticks ) <TAB> <TAB> year = dt . year + self . base . get_base ( ) <TAB> <TAB> ticks . append ( dt . replace ( year = year , * * self . replaced ) )",if dt . year < ymin and dt . year < ymax :,if dt . year >= ymax :,False,95.09,72.39,,,
"def __call__ ( self ) : <TAB> dmin , dmax = self . viewlim_to_dt ( ) <TAB> ymin = self . base . le ( dmin . year ) <TAB> ymax = self . base . ge ( dmax . year ) <TAB> ticks = [ dmin . replace ( year = ymin , * * self . replaced ) ] <TAB> while 1 : <TAB> <TAB> dt = ticks [ - 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return date2num ( ticks ) <TAB> <TAB> year = dt . year + self . base . get_base ( ) <TAB> <TAB> ticks . append ( dt . replace ( year = year , * * self . replaced ) )",if dt . year < ymin and dt . year < ymax :,if status,False,92.21,71.42,,,
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat.S_ISDIR(int(response.st_mode)): <TAB> <TAB> <TAB> homedir = response.pathspec.path <TAB> <TAB> <TAB> username = os.path.basename(homedir) <TAB> <TAB> <TAB> if username not in self._ignore_users: <TAB> <TAB> <TAB> <TAB> yield rdf_client.User(username=username, homedir=homedir)","if not isinstance ( response , rdfvalue . RDFValue ) :","if not isinstance ( response , rdf_client_fs . StatEntry ) :",False,96.44,72.65,,,
"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB> <TAB> path . responses . append ( response ) <TAB> <TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB> <TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB> <TAB> if not src : <TAB> <TAB> <TAB> break <TAB> <TAB> n + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB> <TAB> response = requests . get ( src , stream = True )",if n > max_next :,if n > max_next :,True,100.0,74.6,,,
"def __enter__ ( self ) : <TAB> """""" Open a file and read it. """""" <TAB> if self . code is None : <TAB> <TAB> LOGGER . info ( "" File is reading:  %s "" , self . path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _file = open ( self . path , encoding = "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _file = open ( self . path , "" rU "" ) <TAB> <TAB> self . code = self . _file . read ( ) <TAB> return self","if sys . version_info < ( 3 , 5 , 6 ) :","if sys . version_info >= ( 3 , ) :",False,95.59,94.25,,,
"def facts_for_oauthclients ( self , namespace ) : <TAB> """""" Gathers facts for oauthclients used with logging """""" <TAB> self . default_keys_for ( "" oauthclients "" ) <TAB> a_list = self . oc_command ( <TAB> <TAB> "" get "" , "" oauthclients "" , namespace = namespace , add_options = [ "" -l "" , LOGGING_SELECTOR ] <TAB> ) <TAB> if len ( a_list [ "" items "" ] ) == 0 : <TAB> <TAB> return <TAB> for item in a_list [ "" items "" ] : <TAB> <TAB> name = item [ "" metadata "" ] [ "" name "" ] <TAB> <TAB> comp = self . comp ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = dict ( redirectURIs = item [ "" redirectURIs "" ] ) <TAB> <TAB> <TAB> self . add_facts_for ( comp , "" oauthclients "" , name , result )","if isinstance ( item , dict ) :",if comp is not None :,False,96.68,97.12,,,
"def get ( self , k ) : <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _data1 [ k ] = self . _data2 [ k ] <TAB> <TAB> <TAB> del self . _data2 [ k ] <TAB> return self . _data1 . get ( k )",if k in self . _data1 :,if k not in self . _data1 and k in self . _data2 :,False,88.51,66.43,,,
"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB> <TAB> s = s [ 1 : ] <TAB> <TAB> end = s . find ( "" ; "" ) <TAB> <TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB> <TAB> <TAB> end = s . find ( "" ; "" , end + 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> end = len ( s ) <TAB> <TAB> f = s [ : end ] <TAB> <TAB> if "" = "" in f : <TAB> <TAB> <TAB> i = f . index ( "" = "" ) <TAB> <TAB> <TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB> <TAB> plist . append ( f . strip ( ) ) <TAB> <TAB> s = s [ end : ] <TAB> return plist",if end < 0 :,if end < 0 :,True,100.0,74.68,,,
"def __init__ ( self , * * params ) : <TAB> if "" length "" in params : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" Supply either length or start and end to Player not both "" ) <TAB> <TAB> params [ "" start "" ] = 0 <TAB> <TAB> params [ "" end "" ] = params . pop ( "" length "" ) - 1 <TAB> elif params . get ( "" start "" , 0 ) > 0 and not "" value "" in params : <TAB> <TAB> params [ "" value "" ] = params [ "" start "" ] <TAB> super ( Player , self ) . __init__ ( * * params )","if params . get ( ""start"" , 0 ) > 0 and params [ ""end"" ] > 0 :","if ""start"" in params or ""end"" in params :",False,89.25,69.56,,,
"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB> <TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB> <TAB> if str ( libcxx ) == "" libstdc++ "" : <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" ""","elif str ( libcxx ) == ""libstdc++"" :","elif str ( libcxx ) == ""libstdc++11"" :",False,98.4,72.86,,,
"def _get_sort_map ( tags ) : <TAB> """""" See TAG_TO_SORT """""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> if tag . has_sort : <TAB> <TAB> <TAB> if tag . user : <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts","elif tag . user != ""user"" :",if tag . internal :,False,93.55,80.92,,,
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> if value . has_form ( "" List "" , None ) : <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> if any ( item is None for item in value ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return value",if value is None :,if value is None or isinf ( value ) or isnan ( value ) :,False,95.01,70.69,,,
"def on_action_chosen ( self , id , action , mark_changed = True ) : <TAB> before = self . set_action ( self . current , id , action ) <TAB> if mark_changed : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # TODO: Maybe better comparison <TAB> <TAB> <TAB> self.undo.append(UndoRedo(id, before, action)) <TAB> <TAB> <TAB> self.builder.get_object(""btUndo"").set_sensitive(True) <TAB> <TAB> self.on_profile_modified() <TAB> else: <TAB> <TAB> self.on_profile_modified(update_ui=False) <TAB> return before","if self . builder . get_object ( ""btUndo"" ) . get_sensitive ( ) :",if before . to_string ( ) != action . to_string ( ) :,False,91.25,59.38,,,
"def setUp ( self ) : <TAB> super ( OperaterTest , self ) . setUp ( ) <TAB> if is_cli : <TAB> <TAB> import clr <TAB> <TAB> self . load_iron_python_test ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> clr . AddReference ( "" System.Drawing.Primitives "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> clr . AddReference ( "" System.Drawing "" )",if self . _primitives :,if is_netcoreapp :,False,95.23,71.27,,,
"def field_to_field_type ( field ) : <TAB> field_type = field [ "" type "" ] <TAB> if isinstance ( field_type , dict ) : <TAB> <TAB> field_type = field_type [ "" type "" ] <TAB> if isinstance ( field_type , list ) : <TAB> <TAB> field_type_length = len ( field_type ) <TAB> <TAB> if field_type_length == 0 : <TAB> <TAB> <TAB> raise Exception ( "" Zero-length type list encountered, invalid CWL? "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field_type = field_type [ 0 ] <TAB> return field_type",if field_type_length == 1 :,elif len ( field_type ) == 1 :,False,95.81,70.77,,,
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> if type ( ah ) is not ActionHandle : # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(ah)) <TAB> <TAB> <TAB> <TAB> <TAB> ahs.add(ah) <TAB> <TAB> <TAB> else: # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError(""Bad argument type %s"" % str(item)) <TAB> return ahs",if type ( item ) is ActionHandle :,if type ( item ) is ActionHandle :,True,100.0,74.54,,,
"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> configTokens = black . configure . items [ "" configTokens "" ] . Get ( ) <TAB> buildFlavour = black . configure . items [ "" buildFlavour "" ] . Get ( ) <TAB> if buildFlavour == "" full "" : <TAB> <TAB> self . value = False <TAB> else : <TAB> <TAB> self . value = True <TAB> for opt , optarg in self . chosenOptions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not self . value : <TAB> <TAB> <TAB> <TAB> configTokens . append ( "" tests "" ) <TAB> <TAB> <TAB> self . value = True <TAB> <TAB> elif opt == "" --without-tests "" : <TAB> <TAB> <TAB> if self . value : <TAB> <TAB> <TAB> <TAB> configTokens . append ( "" notests "" ) <TAB> <TAB> <TAB> self . value = False <TAB> self . determined = 1","if opt == ""--tests"" :","if opt == ""--with-tests"" :",False,98.94,73.83,,,
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file . description : <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> if composite_file . optional : <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None",if i == index :,if i == index :,True,100.0,74.53,,,
"def func ( x , y ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> z = x + 2 * math . sin ( y ) <TAB> <TAB> <TAB> return z * * 2 <TAB> <TAB> elif x == y : <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else : <TAB> <TAB> <TAB> return 2 * * 3 <TAB> except ValueError : <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> foo + = i <TAB> <TAB> return foo <TAB> except TypeError : <TAB> <TAB> return 42 <TAB> else : <TAB> <TAB> return 33 <TAB> finally : <TAB> <TAB> print ( "" finished "" )",if math . isinf ( x ) :,if x > y :,False,96.36,72.19,,,
"def test_suite ( ) : <TAB> suite = unittest . TestSuite ( ) <TAB> for fn in os . listdir ( here ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> modname = "" distutils.tests. "" + fn [ : - 3 ] <TAB> <TAB> <TAB> __import__ ( modname ) <TAB> <TAB> <TAB> module = sys . modules [ modname ] <TAB> <TAB> <TAB> suite . addTest ( module . test_suite ( ) ) <TAB> return suite","if fn . endswith ( "".py"" ) :","if fn . startswith ( ""test"" ) and fn . endswith ( "".py"" ) :",False,93.18,64.33,,,
"def check_stack_names ( self , frame , expected ) : <TAB> names = [ ] <TAB> while frame : <TAB> <TAB> name = frame . f_code . co_name <TAB> <TAB> # Stop checking frames when we get to our test helper. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> names.append(name) <TAB> <TAB> frame = frame.f_back <TAB> self.assertEqual(names, expected)",if name in expected :,"if name . startswith ( ""check_"" ) or name . startswith ( ""call_"" ) :",False,84.8,57.82,,,
"def leave ( self , reason = None ) : <TAB> try : <TAB> <TAB> if self . id . startswith ( "" C "" ) : <TAB> <TAB> <TAB> log . info ( "" Leaving channel  %s  ( %s ) "" , self , self . id ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Leaving group  %s  ( %s ) "" , self , self . id ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to leave channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e ) <TAB> self . _id = None",if e . response . status_code == 404 :,"if e . error == ""user_is_bot"" :",False,95.96,70.15,,,
"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> # <TAB>  not exposing attrs for now if orig_prefix is set. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> wrapped = self.wrapped <TAB> <TAB> <TAB> ident = getattr(wrapped, ""ident"", None) <TAB> <TAB> <TAB> if ident is not None: <TAB> <TAB> <TAB> <TAB> value = self._wrap_hash(ident) <TAB> <TAB> self._ident = value <TAB> return value",if self . _prefix is not None :,if not self . orig_prefix :,False,96.13,71.4,,,
"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> if f . read ( 1 ) == "" 1 "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError : <TAB> <TAB> <TAB> continue <TAB> return False","if f . read ( 1 ) != ""0"" :","if f . read ( ) . strip ( ) != ""Mains"" :",False,96.26,71.34,,,
"def _get_pending_by_app_token ( self , app_token ) : <TAB> result = [ ] <TAB> with self . _pending_lock : <TAB> <TAB> self . _remove_stale_pending ( ) <TAB> <TAB> for data in self . _pending_decisions : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result . append ( data ) <TAB> return result","if data [ ""app_token"" ] == app_token :",if data . app_token == app_token :,False,93.85,62.2,,,
"def do_create ( specific_tables = None , base = Base ) : <TAB> engine = get_engine ( ) <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> <TAB> "" Initializing only a subset of tables as requested:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> specific_tables <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> base . metadata . create_all ( engine , tables = specific_tables ) <TAB> <TAB> else : <TAB> <TAB> <TAB> base . metadata . create_all ( engine ) <TAB> except Exception as err : <TAB> <TAB> raise Exception ( "" could not create/re-create DB tables - exception:  "" + str ( err ) )",if specific_tables :,if specific_tables :,True,100.0,74.49,,,
"def __setitem__ ( self , ndx , val ) : <TAB> # <TAB> # Get the expression data object <TAB> # <TAB> exprdata = None <TAB> if ndx in self._data: <TAB> <TAB> exprdata = self._data[ndx] <TAB> else: <TAB> <TAB> _ndx = normalize_index(ndx) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> exprdata = self._data[_ndx] <TAB> if exprdata is None: <TAB> <TAB> raise KeyError( <TAB> <TAB> <TAB> ""Cannot set the value of Expression '%s' with "" <TAB> <TAB> <TAB> ""invalid index '%s'"" % (self.cname(True), str(ndx)) <TAB> <TAB> ) <TAB> # <TAB> # Set the value <TAB> # <TAB> exprdata.set_value(val)",if _ndx in self . _data :,if _ndx in self . _data :,True,100.0,74.39,,,
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> if self . bitnum == 8 : <TAB> <TAB> <TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1",if self . bytenum == 0 :,if not self . bytestream :,False,97.33,72.9,,,
"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> if proc . poll ( ) is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB> <TAB> proc . terminate ( ) <TAB> <TAB> timeout_time = time . time ( ) + timeout <TAB> <TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB> <TAB> <TAB> time . sleep ( 0.02 ) <TAB> <TAB> if proc . poll ( ) is None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB> <TAB> <TAB> proc . kill ( ) <TAB> return proc . returncode",if log :,if log :,True,100.0,74.56,,,
"def mkpanel ( color , rows , cols , tly , tlx ) : <TAB> win = curses . newwin ( rows , cols , tly , tlx ) <TAB> pan = panel . new_panel ( win ) <TAB> if curses . has_colors ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fg = curses . COLOR_WHITE <TAB> <TAB> else : <TAB> <TAB> <TAB> fg = curses . COLOR_BLACK <TAB> <TAB> bg = color <TAB> <TAB> curses . init_pair ( color , fg , bg ) <TAB> <TAB> win . bkgdset ( ord ( "" "" ) , curses . color_pair ( color ) ) <TAB> else : <TAB> <TAB> win . bkgdset ( ord ( "" "" ) , curses . A_BOLD ) <TAB> return pan",if color == curses . COLOR_WHITE :,if color == curses . COLOR_BLUE :,False,98.71,73.57,,,
"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB> <TAB> if start_char == True : <TAB> <TAB> <TAB> word = "" "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c.lower() <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> word += c.lower() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word",if c . isalnum ( ) :,if c . isalnum ( ) :,True,100.0,74.51,,,
"def get_tf_weights_as_numpy ( path = "" ./ckpt/aeslc/model.ckpt-32000 "" ) - > Dict : <TAB> init_vars = tf . train . list_variables ( path ) <TAB> tf_weights = { } <TAB> ignore_name = [ "" Adafactor "" , "" global_step "" ] <TAB> for name , shape in tqdm ( init_vars , desc = "" converting tf checkpoint to dict "" ) : <TAB> <TAB> skip_key = any ( [ pat in name for pat in ignore_name ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> array = tf . train . load_variable ( path , name ) <TAB> <TAB> tf_weights [ name ] = array <TAB> return tf_weights",if skip_key :,if skip_key :,True,100.0,74.44,,,
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB> <TAB> <TAB> break","elif message [ ""type"" ] == ""websocket.disconnect"" :","elif message [ ""type"" ] == ""websocket.receive"" :",False,98.12,72.78,,,
"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB> <TAB> if sys . platform == "" darwin "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else : <TAB> <TAB> <TAB> theme = self . guess_system_theme ( ) <TAB> <TAB> <TAB> if theme == Dark : <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else : # user settings have highest priority <TAB> <TAB> theme = self._app.config.THEME <TAB> self.load_theme(theme)",if LIGHT == Dark :,if get_osx_theme ( ) == 1 :,False,94.5,71.46,,,
"def example_reading_spec ( self ) : <TAB> data_fields = { "" targets "" : tf . VarLenFeature ( tf . int64 ) } <TAB> <IF-STMT> <TAB> <TAB> data_fields [ "" inputs "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> if self . packed_length : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data_fields [ "" inputs_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> <TAB> data_fields [ "" inputs_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> data_fields [ "" targets_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> data_fields [ "" targets_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> data_items_to_decoders = None <TAB> return ( data_fields , data_items_to_decoders )",if self . packed_length :,if self . has_inputs :,False,96.13,72.74,,,
"def _prepare_travel_graph ( self ) : <TAB> for op in self . op_dict . values ( ) : <TAB> <TAB> op . const = False <TAB> <TAB> if op . node . op in [ "" Const "" , "" Placeholder "" ] : <TAB> <TAB> <TAB> op . resolved = True <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> op . const = True <TAB> <TAB> else : <TAB> <TAB> <TAB> op . resolved = False","elif op . node . op in [ ""Var"" , ""Var"" ] :","if op . node . op == ""Const"" :",False,90.21,63.77,,,
"def get_filestream_file_items ( self ) : <TAB> data = { } <TAB> fs_file_updates = self . get_filestream_file_updates ( ) <TAB> for k , v in six . iteritems ( fs_file_updates ) : <TAB> <TAB> l = [ ] <TAB> <TAB> for d in v : <TAB> <TAB> <TAB> offset = d . get ( "" offset "" ) <TAB> <TAB> <TAB> content = d . get ( "" content "" ) <TAB> <TAB> <TAB> assert offset is not None <TAB> <TAB> <TAB> assert content is not None <TAB> <TAB> <TAB> assert offset == 0 or offset == len ( l ) , ( k , v , l , d ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> l = [ ] <TAB> <TAB> <TAB> l . extend ( map ( json . loads , content ) ) <TAB> <TAB> data [ k ] = l <TAB> return data",if len ( l ) == 0 :,if not offset :,False,96.58,72.75,,,
"def _rewrite_exprs ( self , table , what ) : <TAB> from ibis . expr . analysis import substitute_parents <TAB> what = util . promote_list ( what ) <TAB> all_exprs = [ ] <TAB> for expr in what : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> all_exprs . extend ( expr . exprs ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> bound_expr = ir . bind_expr ( table , expr ) <TAB> <TAB> <TAB> all_exprs . append ( bound_expr ) <TAB> return [ substitute_parents ( x , past_projection = False ) for x in all_exprs ]","if isinstance ( expr , ibis . expr . UnaryExpr ) :","if isinstance ( expr , ir . ExprList ) :",False,96.26,71.99,,,
"def _group_by_commit_and_time ( self , hits ) : <TAB> result = { } <TAB> for hit in hits : <TAB> <TAB> source_hit = hit [ "" _source "" ] <TAB> <TAB> key = "" %s _ %s "" % ( source_hit [ "" commit_info "" ] [ "" id "" ] , source_hit [ "" datetime "" ] ) <TAB> <TAB> benchmark = self . _benchmark_from_es_record ( source_hit ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ key ] [ "" benchmarks "" ] . append ( benchmark ) <TAB> <TAB> else : <TAB> <TAB> <TAB> run_info = self . _run_info_from_es_record ( source_hit ) <TAB> <TAB> <TAB> run_info [ "" benchmarks "" ] = [ benchmark ] <TAB> <TAB> <TAB> result [ key ] = run_info <TAB> return result",if benchmark in result [ key ] :,if key in result :,False,97.17,72.65,,,
"def _group_by_commit_and_time ( self , hits ) : <TAB> result = { } <TAB> for hit in hits : <TAB> <TAB> source_hit = hit [ "" _source "" ] <TAB> <TAB> key = "" %s _ %s "" % ( source_hit [ "" commit_info "" ] [ "" id "" ] , source_hit [ "" datetime "" ] ) <TAB> <TAB> benchmark = self . _benchmark_from_es_record ( source_hit ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ key ] [ "" benchmarks "" ] . append ( benchmark ) <TAB> <TAB> else : <TAB> <TAB> <TAB> run_info = self . _run_info_from_es_record ( source_hit ) <TAB> <TAB> <TAB> run_info [ "" benchmarks "" ] = [ benchmark ] <TAB> <TAB> <TAB> result [ key ] = run_info <TAB> return result",if benchmark in result [ key ] :,if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] :,False,91.29,68.99,,,
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB> <TAB> <TAB> <TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED","if ""attributes"" in conf [ ""properties"" ] :","if ""attributes"" in conf [ ""properties"" ] :",True,100.0,74.26,,,
"def _PatchArtifact ( self , artifact : rdf_artifacts . Artifact ) - > rdf_artifacts . Artifact : <TAB> """""" Patches artifact to not contain byte-string source attributes. """""" <TAB> patched = False <TAB> for source in artifact . sources : <TAB> <TAB> attributes = source . attributes . ToDict ( ) <TAB> <TAB> unicode_attributes = compatibility . UnicodeJson ( attributes ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source . attributes = unicode_attributes <TAB> <TAB> <TAB> patched = True <TAB> if patched : <TAB> <TAB> self . DeleteArtifact ( str ( artifact . name ) ) <TAB> <TAB> self . WriteArtifact ( artifact ) <TAB> return artifact","if unicode_attributes . get ( ""type"" ) == ""unicode"" :",if attributes != unicode_attributes :,False,91.62,94.56,,,
"def edit_file ( self , filename ) : <TAB> import subprocess <TAB> editor = self . get_editor ( ) <TAB> if self . env : <TAB> <TAB> environ = os . environ . copy ( ) <TAB> <TAB> environ . update ( self . env ) <TAB> else : <TAB> <TAB> environ = None <TAB> try : <TAB> <TAB> c = subprocess . Popen ( ' %s "" %s "" ' % ( editor , filename ) , env = environ , shell = True ) <TAB> <TAB> exit_code = c . wait ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ClickException ( "" %s : Editing failed! "" % editor ) <TAB> except OSError as e : <TAB> <TAB> raise ClickException ( "" %s : Editing failed:  %s "" % ( editor , e ) )",if exit_code != 0 :,if exit_code != 0 :,True,100.0,74.56,,,
"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB> <TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB> <TAB> for j , s in enumerate ( c ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if glyph . contours [ i ] . segments [ j ] . type == "" line "" : <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices [ index ] = 1 <TAB> <TAB> <TAB> index + = s [ 1 ] <TAB> return controlPointIndices",if s [ 0 ] == segmentCount :,if j < segmentCount :,False,95.7,72.53,,,
"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated ( request . version , self . min_version ) <TAB> <TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB> <TAB> social = value . copy ( ) <TAB> <TAB> for key in old_social_string_fields : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> social [ key ] = value [ key ] [ 0 ] <TAB> <TAB> <TAB> elif social . get ( key ) == [ ] : <TAB> <TAB> <TAB> <TAB> social [ key ] = "" "" <TAB> <TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value )","if value . get ( key ) == [ ""twitter"" , ""github"" ] :",if social . get ( key ) :,False,94.28,68.5,,,
"def iter_raw_frames ( path , packet_sizes , ctx ) : <TAB> with open ( path , "" rb "" ) as f : <TAB> <TAB> for i , size in enumerate ( packet_sizes ) : <TAB> <TAB> <TAB> packet = Packet ( size ) <TAB> <TAB> <TAB> read_size = f . readinto ( packet ) <TAB> <TAB> <TAB> assert size <TAB> <TAB> <TAB> assert read_size == size <TAB> <TAB> <TAB> if not read_size : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in ctx . decode ( packet ) : <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> while True : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> frames = ctx . decode ( None ) <TAB> <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in frames : <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break",if i == len ( packet_sizes ) - 1 :,if not frames :,False,95.8,72.54,,,
"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB> <TAB> already_test = [ ] <TAB> <TAB> for fname in lib_zip . namelist ( ) : <TAB> <TAB> <TAB> pname , fname = os . path . split ( fname ) <TAB> <TAB> <TAB> if fname or ( pname and fname ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and "" / "" not in pname : <TAB> <TAB> <TAB> <TAB> already_test . append ( pname ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs",if pname not in shadow_pkgs :,if is_shadowing ( pname ) :,False,96.71,72.46,,,
"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB> <TAB> if isinstance ( v , torch . Tensor ) : <TAB> <TAB> <TAB> v = v . item ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = self . metrics_to_scalars ( v ) <TAB> <TAB> new_metrics [ k ] = v <TAB> return new_metrics","elif isinstance ( v , dict ) :","if isinstance ( v , dict ) :",False,97.93,72.37,,,
"def insert_resets ( f ) : <TAB> newsync = dict ( ) <TAB> for k , v in f . sync . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newsync [ k ] = insert_reset ( ResetSignal ( k ) , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newsync [ k ] = v <TAB> f . sync = newsync","if isinstance ( v , ResetSignal ) :",if f . clock_domains [ k ] . rst is not None :,False,86.38,65.58,,,
"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB> <TAB> if node is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings . external_account == external_account : <TAB> <TAB> <TAB> yield node",if node_settings is None :,if node_settings is None :,True,100.0,74.15,,,
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> if isinstance ( test , ast . Const ) : <TAB> <TAB> <TAB> if type ( test . value ) in self . _const_types : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope )",if test . value in self . _const_types :,if not test . value :,False,93.5,71.53,,,
"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [] <TAB> channel = await self.messageable._get_channel() <TAB> self.channel = channel <TAB> while self._get_retrieve(): <TAB> <TAB> data = await self._retrieve_messages(self.retrieve) <TAB> <TAB> if len(data) < 100: <TAB> <TAB> <TAB> self.limit = 0 # terminate the infinite loop <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = reversed(data) <TAB> <TAB> if self._filter: <TAB> <TAB> <TAB> data = filter(self._filter, data) <TAB> <TAB> for element in data: <TAB> <TAB> <TAB> result.append(self.state.create_message(channel=channel, data=element)) <TAB> return result",if self . reverse :,if self . reverse :,True,100.0,74.42,,,
"def compute ( self , x , y = None , targets = None ) : <TAB> if targets is None : <TAB> <TAB> targets = self . out_params <TAB> in_params = list ( self . in_x ) <TAB> if len ( in_params ) == 1 : <TAB> <TAB> args = [ x ] <TAB> else : <TAB> <TAB> args = list ( zip ( * x ) ) <TAB> if y is None : <TAB> <TAB> pipe = self . pipe <TAB> else : <TAB> <TAB> pipe = self . train_pipe <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . append ( y ) <TAB> <TAB> else : <TAB> <TAB> <TAB> args + = list ( zip ( * y ) ) <TAB> <TAB> in_params + = self . in_y <TAB> return self . _compute ( * args , pipe = pipe , param_names = in_params , targets = targets )",if len ( y ) == 1 :,if len ( self . in_y ) == 1 :,False,97.7,73.23,,,
"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module = self.fs_imp.import_from_dir(item, name) <TAB> <TAB> else: <TAB> <TAB> <TAB> module = item.import_top(name) <TAB> <TAB> if module: <TAB> <TAB> <TAB> return module <TAB> return None",if os . path . isdir ( item ) :,"if isinstance ( item , _StringType ) :",False,94.83,69.94,,,
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> if isinstance ( key , ( int , long ) ) : <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)",if k . lower ( ) == ikey :,if k . lower ( ) == ikey :,True,100.0,74.58,,,
"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB> <TAB> if key == "" hooks "" : <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name , _val in val . items ( ) : <TAB> <TAB> <TAB> <TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> new_action = watcher . set_opt ( key , val ) <TAB> <TAB> if new_action == 1 : <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)","elif key == ""actions"" :",if action == 1 :,False,97.0,67.81,,,
"def OnBodyClick ( self , event = None ) : <TAB> try : <TAB> <TAB> c = self . c <TAB> <TAB> p = c . currentPosition ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . OnActivateBody ( event = event ) <TAB> <TAB> g . doHook ( "" bodyclick2 "" , c = c , p = p , v = p , event = event ) <TAB> except : <TAB> <TAB> g . es_event_exception ( "" bodyclick "" )","if g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :","if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",False,98.22,73.02,,,
"def _class_weights ( spec : config . MetricsSpec ) - > Optional [ Dict [ int , float ] ] : <TAB> """""" Returns class weights associated with AggregationOptions at offset. """""" <TAB> if spec . aggregate . HasField ( "" top_k_list "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" class_weights are not supported when top_k_list used:  "" <TAB> <TAB> <TAB> <TAB> "" spec= {} "" . format ( spec ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None <TAB> return dict ( spec . aggregate . class_weights ) or None","if spec . aggregate . field . top_k_list != [ ""default"" ] :",if spec . aggregate . class_weights :,False,91.63,92.29,,,
"def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB> <TAB> if line [ 0 ] == "" # "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp . search ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> f . close ( ) <TAB> <TAB> return False",if r :,if r :,True,100.0,74.18,,,
"def _get_before_insertion_node ( self ) : <TAB> if self . _nodes_stack . is_empty ( ) : <TAB> <TAB> return None <TAB> line = self . _nodes_stack . parsed_until_line + 1 <TAB> node = self . _new_module . get_last_leaf ( ) <TAB> while True : <TAB> <TAB> parent = node . parent <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert node . end_pos [ 0 ] < = line <TAB> <TAB> <TAB> assert node . end_pos [ 1 ] == 0 or "" \n "" in self . _prefix <TAB> <TAB> <TAB> return node <TAB> <TAB> node = parent",if parent is None :,"if parent . type in ( ""suite"" , ""file_input"" ) :",False,91.53,64.18,,,
"def PyJsHoisted_parseClassRanges_ ( this , arguments , var = var ) : <TAB> var = Scope ( { u "" this "" : this , u "" arguments "" : arguments } , var ) <TAB> var . registers ( [ u "" res "" ] ) <TAB> pass <TAB> if var . get ( u "" current "" ) ( Js ( u "" ] "" ) ) : <TAB> <TAB> return Js ( [ ] ) <TAB> else : <TAB> <TAB> var . put ( u "" res "" , var . get ( u "" parseNonemptyClassRanges "" ) ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> var . get ( u "" bail "" ) ( Js ( u "" nonEmptyClassRanges "" ) ) <TAB> <TAB> return var . get ( u "" res "" )","if var . get ( u""bail"" ) :","if var . get ( u""res"" ) . neg ( ) :",False,96.25,72.44,,,
"def _recurse_children ( self , offset ) : <TAB> """""" Recurses thorugh the available children """""" <TAB> while offset < self . obj_offset + self . Length : <TAB> <TAB> item = obj . Object ( "" VerStruct "" , offset = offset , vm = self . obj_vm , parent = self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise StopIteration ( <TAB> <TAB> <TAB> <TAB> "" Could not recover a key for a child at offset  {0} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> item . obj_offset <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> yield item . get_key ( ) , item . get_children ( ) <TAB> <TAB> offset = self . offset_pad ( offset + item . Length ) <TAB> raise StopIteration ( "" No children "" )",if item . get_key ( ) == 0 :,if item . Length < 1 or item . get_key ( ) == None :,False,96.23,75.07,,,
"def _adapt_types ( self , descr ) : <TAB> names = [ ] <TAB> adapted_types = [ ] <TAB> for col in descr : <TAB> <TAB> names . append ( col [ 0 ] ) <TAB> <TAB> impala_typename = col [ 1 ] <TAB> <TAB> typename = udf . _impala_to_ibis_type [ impala_typename . lower ( ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> precision , scale = col [ 4 : 6 ] <TAB> <TAB> <TAB> adapted_types . append ( dt . Decimal ( precision , scale ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> adapted_types . append ( typename ) <TAB> return names , adapted_types","if col [ 4 ] == ""precision"" :","if typename == ""decimal"" :",False,95.62,71.88,,,
"def sniff ( self , filename ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with tarfile . open ( filename , "" r "" ) as temptar : <TAB> <TAB> <TAB> <TAB> for f in temptar : <TAB> <TAB> <TAB> <TAB> <TAB> if not f . isfile ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <TAB> if f . name . endswith ( "" .fast5 "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> except Exception as e : <TAB> <TAB> log . warning ( "" %s , sniff Exception:  %s "" , self , e ) <TAB> return False",if filename :,if filename and tarfile . is_tarfile ( filename ) :,False,95.47,71.41,,,
"def getValue ( self ) : <TAB> if getattr ( self . object , "" type "" , "" "" ) != "" CURVE "" : <TAB> <TAB> return BezierSpline ( ) <TAB> evaluatedObject = getEvaluatedID ( self . object ) <TAB> bSplines = evaluatedObject . data . splines <TAB> if len ( bSplines ) > 0 : <TAB> <TAB> spline = createSplineFromBlenderSpline ( bSplines [ 0 ] ) <TAB> <TAB> # Is None when the spline type is not supported. <TAB> <TAB> if spline is not None: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> spline.transform(evaluatedObject.matrix_world) <TAB> <TAB> <TAB> return spline <TAB> return BezierSpline()","if spline . type == ""BLENDER"" :",if self . useWorldSpace :,False,94.63,66.31,,,
"def escape ( text , newline = False ) : <TAB> """""" Escape special html characters. """""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text","if "">"" in text :","if "">"" in text :",True,100.0,74.67,,,
"def _get_ilo_version ( self ) : <TAB> try : <TAB> <TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB> <TAB> if hasattr ( e , "" code "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e . code == 501 : <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2",if e . code == 502 :,if e . code == 405 :,False,98.33,72.82,,,
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctx . close_path ( )",elif code == Path . CLOSE :,elif code == Path . CLOSEPOLY :,False,98.91,73.71,,,
"def called_by_shrinker ( ) : <TAB> frame = sys . _getframe ( 0 ) <TAB> while frame : <TAB> <TAB> fname = frame . f_globals . get ( "" __file__ "" , "" "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> frame = frame . f_back <TAB> return False","if fname . endswith ( "".shrinker"" ) and fname . endswith ( "".shrinker"" ) :","if os . path . basename ( fname ) == ""shrinker.py"" :",False,83.02,59.29,,,
"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB> <TAB> s = str ( path ) <TAB> <TAB> if ensuremode == "" append "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sys . path . append ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if s != sys . path [ 0 ] : <TAB> <TAB> <TAB> <TAB> sys . path . insert ( 0 , s )",if s not in sys . path :,if s not in sys . path :,True,100.0,74.27,,,
"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB> <TAB> s = str ( path ) <TAB> <TAB> if ensuremode == "" append "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sys . path . append ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if s != sys . path [ 0 ] : <TAB> <TAB> <TAB> <TAB> sys . path . insert ( 0 , s )",if s not in sys . path :,"if instance [ ""VpcId"" ] == vpc",False,91.95,62.76,,,
def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB> <TAB> if page . relations . disambiguation_links_norm is not None : <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ),if page . relations . disambiguation_links is not None :,if page . relations . disambiguation_links is not None :,True,100.0,99.21,,,
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> cnt = 0 <TAB> for e in self . options_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" options %s  < \n "" % elm ) <TAB> <TAB> res + = e . __str__ ( prefix + "" "" , printElemNumber ) <TAB> <TAB> res + = prefix + "" > \n "" <TAB> <TAB> cnt + = 1 <TAB> return res",if printElemNumber :,if printElemNumber :,True,100.0,74.4,,,
"def pre_save_task ( self , task , credentials , verrors ) : <TAB> if task [ "" attributes "" ] [ "" encryption "" ] not in ( None , "" "" , "" AES256 "" ) : <TAB> <TAB> verrors . add ( "" encryption "" , ' Encryption should be null or  "" AES256 "" ' ) <TAB> if not credentials [ "" attributes "" ] . get ( "" skip_region "" , False ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response = await self . middleware . run_in_thread ( <TAB> <TAB> <TAB> <TAB> self . _get_client ( credentials ) . get_bucket_location , <TAB> <TAB> <TAB> <TAB> Bucket = task [ "" attributes "" ] [ "" bucket "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> task [ "" attributes "" ] [ "" region "" ] = response [ "" LocationConstraint "" ] or "" us-east-1 ""","if task [ ""attributes"" ] [ ""bucket"" ] :","if not credentials [ ""attributes"" ] . get ( ""region"" , """" ) . strip ( ) :",False,92.1,67.21,,,
"def get_best_config_reward ( self ) : <TAB> """""" Returns the best configuration found so far, as well as the reward associated with this best config. """""" <TAB> with self . LOCK : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> config_pkl = max ( self . _results , key = self . _results . get ) <TAB> <TAB> <TAB> return pickle . loads ( config_pkl ) , self . _results [ config_pkl ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return dict ( ) , self . _reward_while_pending ( )",if self . _results :,if self . _results :,True,100.0,99.33,,,
"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self.setup_cfg is not None and self.setup_cfg.exists(): <TAB> <TAB> contents = self.setup_cfg.read_text() <TAB> <TAB> base_dir = self.setup_cfg.absolute().parent.as_posix() <TAB> <TAB> try: <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg(self.setup_cfg.as_posix()) <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> contents = self.setup_cfg.read_bytes() <TAB> <TAB> <TAB> parsed = parse_setup_cfg(contents, base_dir) <TAB> <TAB> if not parsed: <TAB> <TAB> <TAB> return {} <TAB> <TAB> return parsed <TAB> return {}",if self . setup_cfg . exists ( ) :,if six . PY2 :,False,95.85,70.67,,,
"def readall ( read_fn , sz ) : <TAB> buff = b "" "" <TAB> have = 0 <TAB> while have < sz : <TAB> <TAB> chunk = yield from read_fn ( sz - have ) <TAB> <TAB> have + = len ( chunk ) <TAB> <TAB> buff + = chunk <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TTransportException ( <TAB> <TAB> <TAB> <TAB> TTransportException . END_OF_FILE , "" End of file reading from transport "" <TAB> <TAB> <TAB> ) <TAB> return buff",if len ( chunk ) == 0 :,if len ( chunk ) == 0 :,True,100.0,74.31,,,
"def _get_use_previous ( <TAB> f , ) : # TODO Sort and group features for DateOffset with two different temporal values <TAB> if isinstance(f, AggregationFeature) and f.use_previous is not None: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ("""", -1) <TAB> <TAB> else: <TAB> <TAB> <TAB> unit = list(f.use_previous.times.keys())[0] <TAB> <TAB> <TAB> value = f.use_previous.times[unit] <TAB> <TAB> <TAB> return (unit, value) <TAB> else: <TAB> <TAB> return ("""", -1)",if f . use_previous . times is None :,if len ( f . use_previous . times . keys ( ) ) > 1 :,False,93.14,67.08,,,
"def istrue ( self ) : <TAB> try : <TAB> <TAB> return self . _istrue ( ) <TAB> except Exception : <TAB> <TAB> self . exc = sys . exc_info ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = [ <TAB> <TAB> <TAB> <TAB> "" "" * ( self . exc [ 1 ] . offset + 4 ) + "" ^ "" , <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> msg . append ( "" SyntaxError: invalid syntax "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> msg = traceback . format_exception_only ( * self . exc [ : 2 ] ) <TAB> <TAB> pytest . fail ( <TAB> <TAB> <TAB> "" Error evaluating  %r  expression \n "" <TAB> <TAB> <TAB> ""  <TAB>  %s \n "" <TAB> <TAB> <TAB> "" %s "" % ( self . name , self . expr , "" \n "" . join ( msg ) ) , <TAB> <TAB> <TAB> pytrace = False , <TAB> <TAB> )","if self . exc [ 0 ] == ""SyntaxError"" :","if isinstance ( self . exc [ 1 ] , SyntaxError ) :",False,96.53,68.3,,,
"def wait_for_crm_operation ( operation , crm ) : <TAB> """""" Poll for cloud resource manager operation until finished. """""" <TAB> logger . info ( <TAB> <TAB> "" wait_for_crm_operation:  "" <TAB> <TAB> "" Waiting for operation  {}  to finish... "" . format ( operation ) <TAB> ) <TAB> for _ in range ( MAX_POLLS ) : <TAB> <TAB> result = crm . operations ( ) . get ( name = operation [ "" name "" ] ) . execute ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( result [ "" error "" ] ) <TAB> <TAB> if "" done "" in result and result [ "" done "" ] : <TAB> <TAB> <TAB> logger . info ( "" wait_for_crm_operation: Operation done. "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( POLL_INTERVAL ) <TAB> return result","if ""error"" in result and result [ ""error"" ] :","if ""error"" in result :",False,96.42,87.51,,,
"def cb_blob_detail_from_elem_and_buf ( self , elem , buf ) : <TAB> if elem . get ( "" lang "" ) != buf . lang : # multi-lang doc <TAB> <TAB> return ""%s Code in %s"" % (elem.get(""lang""), buf.path) <TAB> else: <TAB> <TAB> dir, base = os.path.split(buf.path) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""%s (%s)"" % (base, dir) <TAB> <TAB> else: <TAB> <TAB> <TAB> return base",if dir :,if dir :,True,100.0,74.09,,,
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self.validatepath(path) <TAB> if _path == ""/"": <TAB> <TAB> raise errors.RemoveRootError() <TAB> with ftp_errors(self, path): <TAB> <TAB> try: <TAB> <TAB> <TAB> self.ftp.rmd(_encode(_path, self.ftp.encoding)) <TAB> <TAB> except error_perm as error: <TAB> <TAB> <TAB> code, _ = _parse_ftp_error(error) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self.isfile(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryExpected(path) <TAB> <TAB> <TAB> <TAB> if not self.isempty(path): <TAB> <TAB> <TAB> <TAB> <TAB> raise errors.DirectoryNotEmpty(path) <TAB> <TAB> <TAB> raise # pragma: no cover",if code == 404 :,"if code == ""550"" :",False,98.24,66.25,,,
"def p_clause ( self , node , position ) : <TAB> if isinstance ( node , Graph ) : <TAB> <TAB> self . subjectDone ( node ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> self . write ( "" { "" ) <TAB> <TAB> self . depth + = 1 <TAB> <TAB> serializer = N3Serializer ( node , parent = self ) <TAB> <TAB> serializer . serialize ( self . stream ) <TAB> <TAB> self . depth - = 1 <TAB> <TAB> self . write ( self . indent ( ) + "" } "" ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return False",if self . depth > 0 :,if position is OBJECT :,False,96.2,72.03,,,
"def get_default_shell_info ( shell_name = None , settings = None ) : <TAB> if not shell_name : <TAB> <TAB> settings = settings or load_settings ( lazy = True ) <TAB> <TAB> shell_name = settings . get ( "" shell "" ) <TAB> <TAB> if shell_name : <TAB> <TAB> <TAB> return shell_name , None <TAB> <TAB> shell_path = os . environ . get ( "" SHELL "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shell_name = basepath ( shell_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shell_name = DEFAULT_SHELL <TAB> <TAB> return shell_name , shell_path <TAB> return shell_name , None",if shell_path :,if shell_path :,True,100.0,74.41,,,
"def GetCategory ( self , pidls ) : <TAB> ret = [ ] <TAB> for pidl in pidls : <TAB> <TAB> # Why don't we just get the size of the PIDL? <TAB> <TAB> val = self.sf.GetDetailsEx(pidl, PKEY_Sample_AreaSize) <TAB> <TAB> val = int(val) # it probably came in a VT_BSTR variant <TAB> <TAB> if val < 255 // 3: <TAB> <TAB> <TAB> cid = IDS_SMALL <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cid = IDS_MEDIUM <TAB> <TAB> else: <TAB> <TAB> <TAB> cid = IDS_LARGE <TAB> <TAB> ret.append(cid) <TAB> return ret",elif val > 255 // 3 :,elif val < 2 * 255 // 3 :,False,97.5,72.06,,,
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> if item[0]: <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",elif item [ 3 ] :,elif item [ 3 ] :,True,100.0,74.42,,,
"def add_package_declarations ( generated_root_path ) : <TAB> file_names = os . listdir ( generated_root_path ) <TAB> for file_name in file_names : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( generated_root_path , file_name ) <TAB> <TAB> add_package ( full_name )","if not file_name . endswith ( "".py"" ) :","if not file_name . endswith ( "".java"" ) :",False,97.74,71.65,,,
"def _call_with_retry ( out , retry , retry_wait , method , * args , * * kwargs ) : <TAB> for counter in range ( retry + 1 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return method ( * args , * * kwargs ) <TAB> <TAB> except ( <TAB> <TAB> <TAB> NotFoundException , <TAB> <TAB> <TAB> ForbiddenException , <TAB> <TAB> <TAB> AuthenticationException , <TAB> <TAB> <TAB> RequestErrorException , <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise <TAB> <TAB> except ConanException as exc : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if out : <TAB> <TAB> <TAB> <TAB> <TAB> out . error ( exc ) <TAB> <TAB> <TAB> <TAB> <TAB> out . info ( "" Waiting  %d  seconds to retry... "" % retry_wait ) <TAB> <TAB> <TAB> <TAB> time . sleep ( retry_wait )",if counter == retry_wait :,if counter == retry :,False,98.74,73.76,,,
"def to_wburl_str ( <TAB> url , type = BaseWbUrl . LATEST_REPLAY , mod = "" "" , timestamp = "" "" , end_timestamp = "" "" ) : <TAB> if WbUrl . is_query_type ( type ) : <TAB> <TAB> tsmod = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tsmod + = mod + "" / "" <TAB> <TAB> tsmod + = timestamp <TAB> <TAB> tsmod + = "" * "" <TAB> <TAB> tsmod + = end_timestamp <TAB> <TAB> tsmod + = "" / "" + url <TAB> <TAB> if type == BaseWbUrl . URL_QUERY : <TAB> <TAB> <TAB> tsmod + = "" * "" <TAB> <TAB> return tsmod <TAB> else : <TAB> <TAB> tsmod = timestamp + mod <TAB> <TAB> if len ( tsmod ) > 0 : <TAB> <TAB> <TAB> return tsmod + "" / "" + url <TAB> <TAB> else : <TAB> <TAB> <TAB> return url",if type == BaseWbUrl . URL_QUERY :,if mod :,False,96.16,73.12,,,
"def _configured_ploidy ( items ) : <TAB> ploidies = collections . defaultdict ( set ) <TAB> for data in items : <TAB> <TAB> ploidy = dd . get_ploidy ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k , v in ploidy . items ( ) : <TAB> <TAB> <TAB> <TAB> ploidies [ k ] . add ( v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ploidies [ "" default "" ] . add ( ploidy ) <TAB> out = { } <TAB> for k , vs in ploidies . items ( ) : <TAB> <TAB> assert len ( vs ) == 1 , "" Multiple ploidies set for group calling:  %s %s "" % ( <TAB> <TAB> <TAB> k , <TAB> <TAB> <TAB> list ( vs ) , <TAB> <TAB> ) <TAB> <TAB> out [ k ] = vs . pop ( ) <TAB> return out","if isinstance ( ploidy , dict ) :","if isinstance ( ploidy , dict ) :",True,100.0,74.6,,,
"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> user = self . _users [ username ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . isRoomSame ( user . room ) : <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> self . _users . pop ( username ) <TAB> <TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB> <TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB> <TAB> self . _client . lastLeftTime = time . time ( ) <TAB> <TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( )",if user . isLeftUser :,if user . room :,False,98.76,73.61,,,
"def _thd_cleanup_instance ( self ) : <TAB> container_name = self . getContainerName ( ) <TAB> instances = self . client . containers ( all = 1 , filters = dict ( name = container_name ) ) <TAB> for instance in instances : <TAB> <TAB> # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try: <TAB> <TAB> <TAB> self.client.remove_container(instance[""Id""], v=True, force=True) <TAB> <TAB> except NotFound: <TAB> <TAB> <TAB> pass # that's a race condition <TAB> <TAB> except docker.errors.APIError as e: <TAB> <TAB> <TAB> if ""Conflict operation on container"" not in str(e): <TAB> <TAB> <TAB> <TAB> raise","if instance [ ""Id"" ] != container_name :","if """" . join ( instance [ ""Names"" ] ) . strip ( ""/"" ) != container_name :",False,91.98,49.14,,,
"def handle_ctcp ( self , conn , evt ) : <TAB> args = evt . arguments ( ) <TAB> source = evt . source ( ) . split ( "" ! "" ) [ 0 ] <TAB> if args : <TAB> <TAB> if args [ 0 ] == "" VERSION "" : <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" VERSION  "" + BOT_VERSION ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" PING "" ) <TAB> <TAB> elif args [ 0 ] == "" CLIENTINFO "" : <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" CLIENTINFO PING VERSION CLIENTINFO "" )","elif args [ 0 ] == ""PING"" :","elif args [ 0 ] == ""PING"" :",True,100.0,74.45,,,
"def new_func ( self , * args , * * kwargs ) : <TAB> obj = self . obj_ref ( ) <TAB> attr = self . attr <TAB> if obj is not None : <TAB> <TAB> args = tuple ( TrackedValue . make ( obj , attr , arg ) for arg in args ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs = { <TAB> <TAB> <TAB> <TAB> key : TrackedValue . make ( obj , attr , value ) <TAB> <TAB> <TAB> <TAB> for key , value in iteritems ( kwargs ) <TAB> <TAB> <TAB> } <TAB> result = func ( self , * args , * * kwargs ) <TAB> self . _changed_ ( ) <TAB> return result",if kwargs :,if kwargs :,True,100.0,74.49,,,
"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target.id <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> doc = find_doc_for(target, body_lines) <TAB> <TAB> <TAB> if doc is not None: <TAB> <TAB> <TAB> <TAB> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target.elts: <TAB> <TAB> <TAB> add_doc(e, variables, body_lines)",if name :,if name not in variables :,False,97.88,72.26,,,
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> if tp == "" write "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> elif tp == "" flush "" : <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass","elif tp == ""write"" :","elif tp == ""write_flush"" :",False,98.54,73.79,,,
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . islink ( p ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . isdir ( p ) : <TAB> <TAB> <TAB> res + = get_dir ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res . append ( p ) <TAB> return res","if pth != "".py"" :",if skip_file ( fname ) :,False,95.53,64.02,,,
"def _list_outputs ( self ) : <TAB> outputs = super ( VolSymm , self ) . _list_outputs ( ) <TAB> # Have to manually check for the grid files. <TAB> if os.path.exists(outputs[""trans_file""]): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> outputs[""output_grid""] = re.sub( <TAB> <TAB> <TAB> <TAB> "".(nlxfm|xfm)$"", ""_grid_0.mnc"", outputs[""trans_file""] <TAB> <TAB> <TAB> ) <TAB> return outputs","if outputs [ ""output_grid"" ] == ""nlxfm"" :","if ""grid"" in open ( outputs [ ""trans_file"" ] , ""r"" ) . read ( ) :",False,87.13,59.73,,,
"def _set_texture ( self , texture ) : <TAB> if texture . id is not self . _texture . id : <TAB> <TAB> self . _group = SpriteGroup ( <TAB> <TAB> <TAB> texture , self . _group . blend_src , self . _group . blend_dest , self . _group . parent <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _vertex_list . delete ( ) <TAB> <TAB> <TAB> self . _texture = texture <TAB> <TAB> <TAB> self . _create_vertex_list ( ) <TAB> else : <TAB> <TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB> self . _texture = texture",if self . _texture . is_linked :,if self . _batch is None :,False,97.21,72.52,,,
"def got_result ( result ) : <TAB> deployment = self . persistence_service . get ( ) <TAB> for node in deployment . nodes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dataset_ids = [ <TAB> <TAB> <TAB> <TAB> ( m . dataset . deleted , m . dataset . dataset_id ) <TAB> <TAB> <TAB> <TAB> for m in node . manifestations . values ( ) <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> self . assertIn ( ( True , expected_dataset_id ) , dataset_ids ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> self . fail ( "" Node not found.  {} "" . format ( node . uuid ) )",if node . uuid == result . uuid :,"if same_node ( node , origin ) :",False,95.06,71.22,,,
"def check_result ( result , func , arguments ) : <TAB> if check_warning ( result ) and ( result . value != ReturnCode . WARN_NODATA ) : <TAB> <TAB> log . warning ( UcanWarning ( result , func , arguments ) ) <TAB> elif check_error ( result ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise UcanCmdError ( result , func , arguments ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UcanError ( result , func , arguments ) <TAB> return result",if result . value == ReturnCode . ERROR_NODATA :,if check_error_cmd ( result ) :,False,91.61,70.58,,,
"def _compress_and_sort_bdg_files ( out_dir , data ) : <TAB> for fn in glob . glob ( os . path . join ( out_dir , "" *bdg "" ) ) : <TAB> <TAB> out_file = fn + "" .gz "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> bedtools = config_utils . get_program ( "" bedtools "" , data ) <TAB> <TAB> with file_transaction ( out_file ) as tx_out_file : <TAB> <TAB> <TAB> cmd = f "" sort -k1,1 -k2,2n  { fn }  | bgzip -c >  { tx_out_file } "" <TAB> <TAB> <TAB> message = f "" Compressing and sorting  { fn } . "" <TAB> <TAB> <TAB> do . run ( cmd , message )",if not os . path . exists ( out_file ) :,if utils . file_exists ( out_file ) :,False,96.91,72.21,,,
"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if ha_tools_debug : <TAB> <TAB> <TAB> <TAB> print ( "" killing  %s "" % member ) <TAB> <TAB> <TAB> proc = hosts [ member ] [ "" proc "" ] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, signal.CTRL_C_EVENT) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> os.kill(proc.pid, sig) <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> if ha_tools_debug: <TAB> <TAB> <TAB> <TAB> print(""%s already dead?"" % member)",if proc . pid == 0 :,"if sys . platform in ( ""win32"" , ""cygwin"" ) :",False,94.12,65.6,,,
"def get_top_level_stats ( self ) : <TAB> for func , ( cc , nc , tt , ct , callers ) in self . stats . items ( ) : <TAB> <TAB> self . total_calls + = nc <TAB> <TAB> self . prim_calls + = cc <TAB> <TAB> self . total_tt + = tt <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . top_level [ func ] = None <TAB> <TAB> if len ( func_std_string ( func ) ) > self . max_name_len : <TAB> <TAB> <TAB> self . max_name_len = len ( func_std_string ( func ) )",if callers :,"if ( ""jprofile"" , 0 , ""profiler"" ) in callers :",False,92.03,63.0,,,
"def __str__ ( self ) : <TAB> """""" Only keeps the True values. """""" <TAB> result = [ "" SlicingSpec( "" ] <TAB> if self . entire_dataset : <TAB> <TAB> result . append ( ""  Entire dataset, "" ) <TAB> if self . by_class : <TAB> <TAB> if isinstance ( self . by_class , Iterable ) : <TAB> <TAB> <TAB> result . append ( ""  Into classes  %s , "" % self . by_class ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( ""  Up to class  %d , "" % self . by_class ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( ""  By classes, "" ) <TAB> if self . by_percentiles : <TAB> <TAB> result . append ( ""  By percentiles, "" ) <TAB> if self . by_classification_correctness : <TAB> <TAB> result . append ( ""  By classification correctness, "" ) <TAB> result . append ( "" ) "" ) <TAB> return "" \n "" . join ( result )","elif isinstance ( self . by_class , int ) :","elif isinstance ( self . by_class , int ) :",True,100.0,74.64,,,
"def save_params ( self ) : <TAB> if self . _save_controller : <TAB> <TAB> if not os . path . exists ( self . _save_controller ) : <TAB> <TAB> <TAB> os . makedirs ( self . _save_controller ) <TAB> <TAB> output_dir = self . _save_controller <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( "" ./.rlnas_controller "" ) <TAB> <TAB> output_dir = "" ./.rlnas_controller "" <TAB> with open ( os . path . join ( output_dir , "" rlnas.params "" ) , "" wb "" ) as f : <TAB> <TAB> pickle . dump ( self . _params_dict , f ) <TAB> _logger . debug ( "" Save params done "" )","if not os . path . exists ( ""."" . join ( output_dir , ""rlnas.params"" ) ) :","if not os . path . exists ( ""./.rlnas_controller"" ) :",False,93.37,68.28,,,
"def unexport ( self , pin ) : <TAB> with self . _lock : <TAB> <TAB> self . _pin_refs [ pin ] - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with io . open ( self . path ( "" unexport "" ) , "" wb "" ) as f : <TAB> <TAB> <TAB> <TAB> f . write ( str ( pin ) . encode ( "" ascii "" ) )",if self . _pin_refs [ pin ] == 0 :,if self . _pin_refs [ pin ] == 0 :,True,100.0,74.21,,,
"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super().emit(type, info) <TAB> if self._has_proxy is True and self._session.status > 0: <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> if type in self.__proxy_properties__: <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._session.send_command(""INVOKE"", self._id, ""_emit_at_proxy"", [ev])",elif type in self . __proxy_properties__ :,elif type in self . __event_types_at_proxy :,False,96.42,72.64,,,
"def __call__ ( self , params ) : <TAB> all_errs = { } <TAB> for handler in self . handlers : <TAB> <TAB> out_headers , res , errs = handler ( params ) <TAB> <TAB> all_errs . update ( errs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return out_headers , res , all_errs <TAB> return None , None , all_errs",if out_headers is not None and res is not None :,if res is not None :,False,92.29,71.19,,,
"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> status = self . master . get_status ( ) <TAB> <TAB> if status . get ( "" status "" ) == "" ENDED "" : <TAB> <TAB> <TAB> return <TAB> <TAB> iterations + = 1 <TAB> <TAB> time . sleep ( 1.0 )",if iterations >= self . test_max_iterations :,if iterations > 100 :,False,93.28,71.71,,,
"def _load ( self , path : str ) : <TAB> ds = DataSet ( ) <TAB> with open ( path , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> parts = line . split ( "" \t "" ) <TAB> <TAB> <TAB> <TAB> raw_words1 = parts [ 1 ] <TAB> <TAB> <TAB> <TAB> raw_words2 = parts [ 2 ] <TAB> <TAB> <TAB> <TAB> target = parts [ 0 ] <TAB> <TAB> <TAB> <TAB> if raw_words1 and raw_words2 and target : <TAB> <TAB> <TAB> <TAB> <TAB> ds . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> Instance ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raw_words1 = raw_words1 , raw_words2 = raw_words2 , target = target <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return ds",if line :,if line :,True,100.0,74.61,,,
"def avatar_delete ( event_id , speaker_id ) : <TAB> if request . method == "" DELETE "" : <TAB> <TAB> speaker = ( <TAB> <TAB> <TAB> DataGetter . get_speakers ( event_id ) <TAB> <TAB> <TAB> . filter_by ( user_id = login . current_user . id , id = speaker_id ) <TAB> <TAB> <TAB> . first ( ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> speaker . photo = "" "" <TAB> <TAB> <TAB> speaker . small = "" "" <TAB> <TAB> <TAB> speaker . thumbnail = "" "" <TAB> <TAB> <TAB> speaker . icon = "" "" <TAB> <TAB> <TAB> save_to_db ( speaker ) <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" ok "" } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> abort ( 403 )",if speaker :,if speaker :,True,100.0,74.51,,,
"def getline ( filename , lineno , * args , * * kwargs ) : <TAB> line = py2exe_getline ( filename , lineno , * args , * * kwargs ) <TAB> if not line : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> for i , line in enumerate ( f ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = line . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> line = "" "" <TAB> <TAB> except ( IOError , OSError ) : <TAB> <TAB> <TAB> line = "" "" <TAB> return line",if i == lineno :,if lineno == i + 1 :,False,97.18,72.46,,,
"def write ( self , data ) : <TAB> if not isinstance ( data , ( bytes , bytearray , memoryview ) ) : <TAB> <TAB> raise TypeError ( "" data argument must be byte-ish ( %r ) "" , type ( data ) ) <TAB> if not data : <TAB> <TAB> return <TAB> if self . _conn_lost : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( "" socket.send() raised exception. "" ) <TAB> <TAB> self . _conn_lost + = 1 <TAB> <TAB> return <TAB> if not self . _buffer : <TAB> <TAB> self . _loop . add_writer ( self . _sock_fd , self . _write_ready ) <TAB> # Add it to the buffer. <TAB> self._buffer.extend(data) <TAB> self._maybe_pause_protocol()",if self . _loop . get_writer ( self . _sock_fd ) . is_closed ( ) :,if self . _conn_lost >= constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES :,False,91.45,70.89,,,
"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> if not self.xmlMap: <TAB> <TAB> return 0 <TAB> x_value = str(xValue) <TAB> for anime in self.xmlMap.findall(""anime""): <TAB> <TAB> try: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return int(anime.get(y, 0)) <TAB> <TAB> except ValueError as e: <TAB> <TAB> <TAB> continue <TAB> return 0","if anime . get ( x , 0 ) == x_value :","if anime . get ( x , False ) == x_value :",False,98.59,72.57,,,
"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None : <TAB> <TAB> <TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB> <TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo",if obj_kernel_version and this_kernel_version :,"if line . startswith ( ""vermagic"" ) :",False,94.88,68.04,,,
"def _score ( self , X , y ) : <TAB> for col in self . cols : <TAB> <TAB> # Score the column <TAB> <TAB> X[col] = X[col].map(self.mapping[col]) <TAB> <TAB> # Randomization is meaningful only for training data -> we do it only if y is present <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> random_state_generator = check_random_state(self.random_state) <TAB> <TAB> <TAB> X[col] = X[col] * random_state_generator.normal( <TAB> <TAB> <TAB> <TAB> 1.0, self.sigma, X[col].shape[0] <TAB> <TAB> <TAB> ) <TAB> return X",if y is not None :,if self . randomized and y is not None :,False,97.1,71.1,,,
"def onMouseWheel ( self , event ) : <TAB> if self . selectedHuman . isVisible ( ) : <TAB> <TAB> zoomOut = event . wheelDelta > 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> zoomOut = not zoomOut <TAB> <TAB> if event . x is not None : <TAB> <TAB> <TAB> self . modelCamera . mousePickHumanCenter ( event . x , event . y ) <TAB> <TAB> if zoomOut : <TAB> <TAB> <TAB> self . zoomOut ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . zoomIn ( )",if zoomOut :,"if self . getSetting ( ""invertMouseWheel"" ) :",False,93.26,62.2,,,
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> if self . arch == "" i386 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True )","elif self . arch == ""amd64"" :","elif self . arch == ""amd64"" :",True,100.0,74.55,,,
"def callback ( actions , form , tablename = None ) : <TAB> if actions : <TAB> <TAB> if tablename and isinstance ( actions , dict ) : <TAB> <TAB> <TAB> actions = actions . get ( tablename , [ ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> actions = [ actions ] <TAB> <TAB> [ action ( form ) for action in actions ]","elif isinstance ( actions , list ) :","if not isinstance ( actions , ( list , tuple ) ) :",False,90.28,67.5,,,
"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4: <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i <= 3: <TAB> <TAB> <TAB> continue <TAB> <TAB> if less_than_7_only and i >= 7: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> result.append(i) <TAB> return result",if even_only and i >= even_only :,if even_only and i % 2 != 0 :,False,96.91,71.67,,,
"def set_trial_values ( self , trial_id : int , values : Sequence [ float ] ) - > None : <TAB> with self . _lock : <TAB> <TAB> cached_trial = self . _get_cached_trial ( trial_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _check_trial_is_updatable ( cached_trial ) <TAB> <TAB> <TAB> updates = self . _get_updates ( trial_id ) <TAB> <TAB> <TAB> cached_trial . values = values <TAB> <TAB> <TAB> updates . values = values <TAB> <TAB> <TAB> return <TAB> self . _backend . _update_trial ( trial_id , values = values )",if cached_trial is not None :,if cached_trial is not None :,True,100.0,74.35,,,
"def _get_label_format ( self , workunit ) : <TAB> for label , label_format in self . LABEL_FORMATTING . items ( ) : <TAB> <TAB> if workunit . has_label ( label ) : <TAB> <TAB> <TAB> return label_format <TAB> # Recursively look for a setting to suppress child label formatting. <TAB> if workunit.parent: <TAB> <TAB> label_format = self._get_label_format(workunit.parent) <TAB> <TAB> if label_format == LabelFormat.CHILD_DOT: <TAB> <TAB> <TAB> return LabelFormat.DOT <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return LabelFormat.SUPPRESS <TAB> return LabelFormat.FULL",elif label_format == LabelFormat .CHILD_SUPPRESS :,if label_format == LabelFormat . CHILD_SUPPRESS :,False,98.57,70.61,,,
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> if stored_session : <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> if not expiration . tzinfo : <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )",if stored_session . expiration > expiration :,if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) :,False,92.62,68.9,,,
"def _manage_torrent_cache ( self ) : <TAB> """""" Carry tracker/peer/file lists over to new torrent list """""" <TAB> for torrent in self . _torrent_cache : <TAB> <TAB> new_torrent = rtorrentlib . common . find_torrent ( torrent . info_hash , self . torrents ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_torrent . files = torrent . files <TAB> <TAB> <TAB> new_torrent . peers = torrent . peers <TAB> <TAB> <TAB> new_torrent . trackers = torrent . trackers <TAB> self . _torrent_cache = self . torrents",if new_torrent :,if new_torrent is not None :,False,97.04,93.15,,,
"def _clean_regions ( items , region ) : <TAB> """""" Intersect region with target file if it exists """""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB> <TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB> <TAB> if target : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> target = _load_regions ( target ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> target = [ target ] <TAB> <TAB> <TAB> return target","if isinstance ( target , list ) :","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) :",False,91.68,86.62,,,
def _get_stdout ( self ) : <TAB> while True : <TAB> <TAB> BUFFER_SIZE = 1000 <TAB> <TAB> stdout_buffer = self . kernel . process . GetSTDOUT ( BUFFER_SIZE ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> yield stdout_buffer,if not stdout_buffer :,if len ( stdout_buffer ) == 0 :,False,89.07,60.72,,,
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret",if qkey == key :,if key == qkey :,False,96.78,72.25,,,
"def test_expect_setecho_off ( self ) : <TAB> """""" This tests that echo may be toggled off. """""" <TAB> p = pexpect . spawn ( "" cat "" , echo = True , timeout = 5 ) <TAB> try : <TAB> <TAB> self . _expect_echo_toggle ( p ) <TAB> except IOError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if hasattr ( unittest , "" SkipTest "" ) : <TAB> <TAB> <TAB> <TAB> raise unittest . SkipTest ( "" Not supported on this platform. "" ) <TAB> <TAB> <TAB> return "" skip "" <TAB> <TAB> raise","if sys . platform == ""darwin"" :","if sys . platform . lower ( ) . startswith ( ""sunos"" ) :",False,92.66,90.41,,,
"def _resolve_relative_config ( dir , config ) : <TAB> # Some code shared between Notebook and NotebookInfo <TAB> # Resolve icon, can be relative <TAB> icon = config.get(""icon"") <TAB> if icon: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> icon = File(icon) <TAB> <TAB> else: <TAB> <TAB> <TAB> icon = dir.resolve_file(icon) <TAB> # Resolve document_root, can also be relative <TAB> document_root = config.get(""document_root"") <TAB> if document_root: <TAB> <TAB> if zim.fs.isabs(document_root) or not dir: <TAB> <TAB> <TAB> document_root = Dir(document_root) <TAB> <TAB> else: <TAB> <TAB> <TAB> document_root = dir.resolve_dir(document_root) <TAB> return icon, document_root",if zim . fs . isabs ( icon ) or not dir :,if zim . fs . isabs ( icon ) or not dir :,True,100.0,74.4,,,
"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB> <TAB> for ent_id , ent_desc in _md . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if ent_id in res : <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> res.append(ent_id) <TAB> return res",if ent_desc . entity_id == descriptor . entity_id :,if descriptor in ent_desc :,False,92.49,70.72,,,
"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> if timeout > = 0 : <TAB> <TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB> <TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB> <TAB> if not os . check_error ( n ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if timeout > = 0 : <TAB> <TAB> <TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB> <TAB> vals = struct . unpack ( epoll_event , s ) <TAB> <TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res",if n == - 1 :,if timeout < 0 :,False,97.43,73.15,,,
"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB> <TAB> return <TAB> if authed ( ) : <TAB> <TAB> user = get_current_user_attrs ( ) <TAB> <TAB> team = get_current_team_attrs ( ) <TAB> <TAB> if user and user . banned : <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , <TAB> <TAB> <TAB> <TAB> <TAB> error = "" Your team has been banned from this CTF "" , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> )",if team and team . banned :,if team and team . banned :,True,100.0,74.6,,,
"def _update_read ( self ) : <TAB> """""" Update state when there is read event """""" <TAB> try : <TAB> <TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB> <TAB> if msg : <TAB> <TAB> <TAB> self . on_message ( msg ) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self.close() <TAB> except socket.error as err: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> self.on_error(err) <TAB> return False",if err . errno == errno . EWOULDBLOCK or err . errno == errno . EAGAIN :,"if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) :",False,92.65,93.28,,,
"def update_topic_attr_as_not ( modeladmin , request , queryset , attr ) : <TAB> for topic in queryset : <TAB> <TAB> if attr == "" sticky "" : <TAB> <TAB> <TAB> topic . sticky = not topic . sticky <TAB> <TAB> elif attr == "" closed "" : <TAB> <TAB> <TAB> topic . closed = not topic . closed <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> topic . hidden = not topic . hidden <TAB> <TAB> topic . save ( )","elif attr == ""hidden"" :","elif attr == ""hidden"" :",True,100.0,74.26,,,
"def Startprobe ( self , q ) : <TAB> while not self . finished : <TAB> <TAB> try : <TAB> <TAB> <TAB> sniff ( iface = self . interface , count = 10 , prn = lambda x : q . put ( x ) ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if self . finished :,if self . finished :,True,100.0,74.06,,,
"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elements = path_elements + [ "" female "" ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> if strict : <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> elif strict : <TAB> <TAB> <TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict )",if self . species_id in path_elements :,if self . has_gender_differences :,False,96.08,73.01,,,
"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB> <TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ind + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if start < ind : <TAB> <TAB> <TAB> <TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB> <TAB> if "" : "" in line and len ( line ) > 0 : <TAB> <TAB> <TAB> lines = line . split ( "" : "" ) <TAB> <TAB> <TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d","if strings [ ind ] == """" :","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) :",False,94.34,65.95,,,
"def _send_with_auth ( self , req_kwargs , desired_auth , rsession ) : <TAB> if desired_auth . oauth : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _oauth_creds . refresh ( httplib2 . Http ( ) ) <TAB> <TAB> req_kwargs [ "" headers "" ] = req_kwargs . get ( "" headers "" , { } ) <TAB> <TAB> req_kwargs [ "" headers "" ] [ "" Authorization "" ] = ( <TAB> <TAB> <TAB> "" Bearer  "" + self . _oauth_creds . access_token <TAB> <TAB> ) <TAB> return rsession . request ( * * req_kwargs )",if self . _oauth_creds is not None :,if self . _oauth_creds . access_token_expired :,False,95.49,72.41,,,
"def parse_search_response ( json_data ) : <TAB> """""" Construct response for any input """""" <TAB> if json_data is None : <TAB> <TAB> return { "" error "" : "" Error parsing empty search engine response "" } <TAB> try : <TAB> <TAB> return json . loads ( json_data ) <TAB> except json . JSONDecodeError : <TAB> <TAB> logger . exception ( "" Error parsing search engine response "" ) <TAB> <TAB> m = re_pre . search ( json_data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return { "" error "" : "" Error parsing search engine response "" } <TAB> <TAB> error = web . htmlunquote ( m . group ( 1 ) ) <TAB> <TAB> solr_error = "" org.apache.lucene.queryParser.ParseException:  "" <TAB> <TAB> if error . startswith ( solr_error ) : <TAB> <TAB> <TAB> error = error [ len ( solr_error ) : ] <TAB> <TAB> return { "" error "" : error }",if not m :,if m is None :,False,98.27,73.97,,,
"def wrapper ( * args , * * kws ) : <TAB> missing = [ ] <TAB> saved = getattr ( warnings , "" __warningregistry__ "" , missing ) . copy ( ) <TAB> try : <TAB> <TAB> return func ( * args , * * kws ) <TAB> finally : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> del warnings . __warningregistry__ <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> warnings . __warningregistry__ = saved",if saved is None :,if saved is missing :,False,98.42,73.03,,,
"def parse_expression ( self ) : <TAB> """""" Return string containing command to run. """""" <TAB> expression_el = self . root . find ( "" expression "" ) <TAB> if expression_el is not None : <TAB> <TAB> expression_type = expression_el . get ( "" type "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Unknown expression type [ %s ] encountered "" % expression_type <TAB> <TAB> <TAB> ) <TAB> <TAB> return expression_el . text <TAB> return None",if expression_type is not None :,"if expression_type != ""ecma5.1"" :",False,95.71,70.31,,,
"def test_geocode ( ) : <TAB> # look for tweets from New York ; the search radius is larger than NYC <TAB> # so hopefully we'll find one from New York in the first 500? <TAB> count = 0 <TAB> found = False <TAB> for tweet in T.search(None, geocode=""40.7484,-73.9857,1mi""): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> break <TAB> <TAB> if count > 500: <TAB> <TAB> <TAB> break <TAB> <TAB> count += 1 <TAB> assert found",if tweet . radius > 1 :,"if ( tweet [ ""place"" ] or { } ) . get ( ""name"" ) == ""Manhattan"" :",False,84.71,60.67,,,
"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = "" std_dev "" <TAB> <TAB> elif order == 1 : <TAB> <TAB> <TAB> name = "" sample_std_dev "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order",if order == 0 :,if order == 0 :,True,100.0,74.34,,,
"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB> <TAB> a = self . _d . getTime ( ) <TAB> <TAB> b = other . _d . getTime ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> elif a == b : <TAB> <TAB> <TAB> return 0 <TAB> else : <TAB> <TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1",if a > b :,if a < b :,False,98.12,72.94,,,
"def run ( self ) : <TAB> tid = self . ident <TAB> try : <TAB> <TAB> with self . _lock : <TAB> <TAB> <TAB> _GUIS [ tid ] = self <TAB> <TAB> <TAB> self . _state ( True ) <TAB> <TAB> self . new_mail_notifications ( summarize = True ) <TAB> <TAB> loop_count = 0 <TAB> <TAB> while self . _sock : <TAB> <TAB> <TAB> loop_count + = 1 <TAB> <TAB> <TAB> self . _select_sleep ( 1 ) # FIXME: Lengthen this when possible <TAB> <TAB> <TAB> self.change_state() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # FIXME: This involves a fair number of set operations, <TAB> <TAB> <TAB> <TAB> # <TAB> <TAB> should only do this after new mail has arrived. <TAB> <TAB> <TAB> <TAB> self.new_mail_notifications() <TAB> finally: <TAB> <TAB> del _GUIS[tid]",if loop_count == self . _loop_count :,if loop_count % 5 == 0 :,False,96.77,72.66,,,
"def __cache_dimension_masks ( self , * args ) : <TAB> # cache masks for each feature map we'll need <TAB> if len(self.masks) == 0: <TAB> <TAB> for m1 in args: <TAB> <TAB> <TAB> batch_size, emb_dim, h, w = m1.size() <TAB> <TAB> <TAB> # make mask <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> mask = self.feat_size_w_mask(h, m1) <TAB> <TAB> <TAB> <TAB> self.masks[h] = mask",if emb_dim == 0 and len ( m1 ) == w :,if h not in self . masks :,False,90.39,67.3,,,
"def __call__ ( self , * flattened_representation ) : <TAB> unflattened_representation = [ ] <TAB> for index , subtree in self . children : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unflattened_representation . append ( flattened_representation [ index ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sub_representation = flattened_representation [ index ] <TAB> <TAB> <TAB> unflattened_representation . append ( subtree ( * sub_representation ) ) <TAB> return self . _cls ( * unflattened_representation , * * self . _kwargs )","if isinstance ( subtree , _Unstructured ) :",if subtree is None :,False,94.2,70.5,,,
"def click_outside ( event ) : <TAB> if event not in d : <TAB> <TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB> <TAB> if y == 0 : <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y + = 3 <TAB> <TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d . dismiss ( "" Goto "" )",if self . blockFaceUnderCursor [ 1 ] == gotoPanel :,if event . num_clicks == 2 :,False,92.33,69.94,,,
"def get_mapped_input_keysequences ( self , mode = "" global "" , prefix = u "" "" ) : <TAB> # get all bindings in this mode <TAB> globalmaps, modemaps = self.get_keybindings(mode) <TAB> candidates = list(globalmaps.keys()) + list(modemaps.keys()) <TAB> if prefix is not None: <TAB> <TAB> prefixes = prefix + "" "" <TAB> <TAB> cand = [c for c in candidates if c.startswith(prefixes)] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> candidates = cand + [prefix] <TAB> <TAB> else: <TAB> <TAB> <TAB> candidates = cand <TAB> return candidates",if len ( candidates ) == 1 :,if prefix in candidates :,False,95.09,71.01,,,
"def _set_length ( self , length ) : <TAB> with self . _cond : <TAB> <TAB> self . _length = length <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _ready = True <TAB> <TAB> <TAB> self . _cond . notify ( ) <TAB> <TAB> <TAB> del self . _cache [ self . _job ]",if self . _length == 0 :,if self . _index == self . _length :,False,93.24,69.56,,,
"def _pct_encoded_replace_unreserved ( mo ) : <TAB> try : <TAB> <TAB> i = int ( mo . group ( 1 ) , 16 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return chr ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return mo . group ( ) . upper ( ) <TAB> except ValueError : <TAB> <TAB> return mo . group ( )",if i < 32 :,if _unreserved [ i ] :,False,94.17,70.35,,,
"def is_open ( self ) : <TAB> if self . signup_code : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> if self . signup_code_present : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> messages . add_message ( <TAB> <TAB> <TAB> <TAB> <TAB> self . request , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> * * { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" code "" : self . get_code ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP","if self . request . method == ""POST"" :","if self . messages . get ( ""invalid_signup_code"" ) :",False,95.57,72.1,,,
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value","if member [ 0 ] == ""field"" :",if member [ 0 ] == key :,False,98.22,67.9,,,
"def move_sender_strings_to_sender_model ( apps , schema_editor ) : <TAB> sender_model = apps . get_model ( "" documents "" , "" Sender "" ) <TAB> document_model = apps . get_model ( "" documents "" , "" Document "" ) <TAB> # Create the sender and log the relationship with the document <TAB> for document in document_model.objects.all(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> DOCUMENT_SENDER_MAP[document.pk], <TAB> <TAB> <TAB> <TAB> created, <TAB> <TAB> <TAB> ) = sender_model.objects.get_or_create( <TAB> <TAB> <TAB> <TAB> name=document.sender, defaults={""slug"": slugify(document.sender)} <TAB> <TAB> <TAB> )",if document . sender in DOCUMENT_SENDER_MAP :,if document . sender :,False,96.58,72.98,,,
"def compute_output_shape ( self , input_shape ) : <TAB> if None not in input_shape [ 1 : ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> total = np . prod ( input_shape [ 2 : 4 ] ) * self . num_anchors <TAB> <TAB> else : <TAB> <TAB> <TAB> total = np . prod ( input_shape [ 1 : 3 ] ) * self . num_anchors <TAB> <TAB> return ( input_shape [ 0 ] , total , 4 ) <TAB> else : <TAB> <TAB> return ( input_shape [ 0 ] , None , 4 )",if self . num_anchors > 1 :,"if keras . backend . image_data_format ( ) == ""channels_first"" :",False,88.28,61.31,,,
"def decompress ( self , value ) : <TAB> if value : <TAB> <TAB> if type ( value ) == PhoneNumber : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> "" + %d "" % value . country_code , <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number ( value ) , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ]",if value . country_code :,if value . country_code and value . national_number :,False,95.37,71.25,,,
"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> <TAB> if self . expr is not None : <TAB> <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> if self . expr is not None : <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self","if isinstance ( other , ( ParseElement , ParseElement ) ) :",if other not in self . ignoreExprs :,False,93.07,70.37,,,
"def mkdir ( self , mode = 0o777 , parents = False , exist_ok = False ) : <TAB> if self . _closed : <TAB> <TAB> self . _raise_closed ( ) <TAB> if not parents : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode ) <TAB> <TAB> except FileExistsError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode ) <TAB> <TAB> except FileExistsError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> except OSError as e : <TAB> <TAB> <TAB> if e . errno != ENOENT : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self . parent . mkdir ( parents = True ) <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode )",if exist_ok :,if not exist_ok or not self . is_dir ( ) :,False,90.53,68.15,,,
"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB> <TAB> if dirs [ m , n ] == "" | "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> <TAB> mask [ m ] = 1 <TAB> <TAB> elif dirs [ m , n ] == "" ^ "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask","elif dirs [ n , m ] == ""~"" :","elif dirs [ m , n ] == ""<"" :",False,96.53,71.87,,,
"def clean ( self , * args , * * kwargs ) : <TAB> data = super ( ) . clean ( * args , * * kwargs ) <TAB> if isinstance ( data , File ) : <TAB> <TAB> filename = data . name <TAB> <TAB> ext = os . path . splitext ( filename ) [ 1 ] <TAB> <TAB> ext = ext . lower ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise forms . ValidationError ( _ ( "" Filetype not allowed! "" ) ) <TAB> return data","if ext not in ( "".py"" , "".py"" ) :",if ext not in self . ext_whitelist :,False,90.88,63.32,,,
"def get_doc_object ( obj , what = None ) : <TAB> if what is None : <TAB> <TAB> if inspect . isclass ( obj ) : <TAB> <TAB> <TAB> what = "" class "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> what = "" module "" <TAB> <TAB> elif callable ( obj ) : <TAB> <TAB> <TAB> what = "" function "" <TAB> <TAB> else : <TAB> <TAB> <TAB> what = "" object "" <TAB> if what == "" class "" : <TAB> <TAB> return SphinxClassDoc ( obj , "" "" , func_doc = SphinxFunctionDoc ) <TAB> elif what in ( "" function "" , "" method "" ) : <TAB> <TAB> return SphinxFunctionDoc ( obj , "" "" ) <TAB> else : <TAB> <TAB> return SphinxDocString ( pydoc . getdoc ( obj ) )",elif inspect . isclass ( obj ) :,elif inspect . ismodule ( obj ) :,False,98.78,73.69,,,
"def apply_pssm ( val ) : <TAB> if val is not None : <TAB> <TAB> val_c = PSSM_VALUES . get ( val , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> <TAB> val , tuple ( PSSM_VALUES . values ( ) ) <TAB> <TAB> <TAB> ) , "" ' store_as '  should be one of:  %r  or an instance of  %r  not  %r "" % ( <TAB> <TAB> <TAB> <TAB> tuple ( PSSM_VALUES . keys ( ) ) , <TAB> <TAB> <TAB> <TAB> tuple ( PSSM_VALUES . values ( ) ) , <TAB> <TAB> <TAB> <TAB> val , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return val <TAB> <TAB> return val_c ( )",if val_c is None :,if val_c is None :,True,100.0,74.5,,,
"def read_postmaster_opts ( self ) : <TAB> """""" returns the list of option names/values from postgres.opts, Empty dict if read failed or no file """""" <TAB> result = { } <TAB> try : <TAB> <TAB> with open ( os . path . join ( self . _postgresql . data_dir , "" postmaster.opts "" ) ) as f : <TAB> <TAB> <TAB> data = f . read ( ) <TAB> <TAB> <TAB> for opt in data . split ( ' "" "" ' ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> name , val = opt . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> result [ name . strip ( "" - "" ) ] = val . rstrip ( ' "" \n ' ) <TAB> except IOError : <TAB> <TAB> logger . exception ( "" Error when reading postmaster.opts "" ) <TAB> return result","if ""="" in opt :","if ""="" in opt and opt . startswith ( ""--"" ) :",False,95.69,96.98,,,
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( r "" F5-TrafficShield "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = ( <TAB> <TAB> <TAB> re . search ( r "" \ AASINFO= "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return retval",if retval :,if retval :,True,100.0,74.52,,,
"def on_task_start ( self , task , config ) : <TAB> for item in config : <TAB> <TAB> for plugin_name , plugin_config in item . items ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> thelist = plugin . get ( plugin_name , self ) . get_list ( plugin_config ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> raise PluginError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Plugin  %s  does not support list interface "" % plugin_name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise plugin . PluginError ( thelist . immutable )",if thelist . immutable :,if thelist . immutable :,True,100.0,74.43,,,
"def nq ( t ) : <TAB> p = t [ 0 ] if ( t and t [ 0 ] in "" -+ "" ) else "" "" <TAB> t = t [ len ( p ) : ] <TAB> if t . startswith ( "" tag: "" ) or t . startswith ( "" in: "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> raw_tag = session . config . get_tag ( t . split ( "" : "" ) [ 1 ] ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> t = "" in: %s "" % raw_tag . slug <TAB> <TAB> except ( IndexError , KeyError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> return p + t",if raw_tag . slug :,if raw_tag and raw_tag . hasattr ( slug ) :,False,95.07,71.56,,,
"def _recur_strip ( s ) : <TAB> if is_str ( s ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" "" . join ( s . strip ( ) . split ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" "" . join ( s . strip ( ) . split ( ) ) . replace ( bos_token + "" "" , "" "" ) <TAB> else : <TAB> <TAB> s_ = [ _recur_strip ( si ) for si in s ] <TAB> <TAB> return _maybe_list_to_array ( s_ , s )","if bos_token == """" :","if bos_token == """" :",True,100.0,99.38,,,
"def __delitem__ ( self , key ) : <TAB> "" Deleting tag[key] deletes all  ' key '  attributes for the tag. "" <TAB> for item in self . attrs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . attrs . remove ( item ) <TAB> <TAB> <TAB> # We don't break because bad HTML can define the same <TAB> <TAB> <TAB> # attribute multiple times. <TAB> <TAB> self._getAttrMap() <TAB> <TAB> if self.attrMap.has_key(key): <TAB> <TAB> <TAB> del self.attrMap[key]","if item . get ( ""key"" ) == key :",if item [ 0 ] == key :,False,94.56,62.74,,,
"def comment_import_help ( init_file , out_file ) : <TAB> f_out = open ( out_file , "" w "" ) <TAB> output = "" "" <TAB> updated = False <TAB> with open ( init_file , "" r "" ) as f_in : <TAB> <TAB> for line in f_in : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> updated = True <TAB> <TAB> <TAB> <TAB> line = "" #  "" + line <TAB> <TAB> <TAB> output + = line <TAB> f_out . write ( output ) <TAB> f_out . close ( ) <TAB> return updated","if line . startswith ( ""#"" ) :","if ""import"" in line and ""_help"" in line and not updated :",False,90.96,64.43,,,
"def prepare_text ( lines ) : <TAB> out = [ ] <TAB> for s in lines . split ( "" | "" ) : <TAB> <TAB> s = s . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # line beginning with '/' is in italics <TAB> <TAB> <TAB> s = r""{\i1}%s{\i0}"" % s[1:].strip() <TAB> <TAB> out.append(s) <TAB> return ""\\N"".join(out)","if s . startswith ( ""/"" ) :","if s . startswith ( ""/"" ) :",True,100.0,74.1,,,
"def sqlctx ( sc ) : <TAB> pytest . importorskip ( "" pyspark "" ) <TAB> from odo . backends . sparksql import HiveContext <TAB> try : <TAB> <TAB> yield HiveContext ( sc ) <TAB> finally : <TAB> <TAB> dbpath = "" metastore_db "" <TAB> <TAB> logpath = "" derby.log "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert os . path . isdir ( dbpath ) <TAB> <TAB> <TAB> shutil . rmtree ( dbpath ) <TAB> <TAB> if os . path . exists ( logpath ) : <TAB> <TAB> <TAB> assert os . path . isfile ( logpath ) <TAB> <TAB> <TAB> os . remove ( logpath )",if os . path . exists ( dbpath ) :,if os . path . exists ( dbpath ) :,True,100.0,74.47,,,
"def _user2dict ( self , uid ) : <TAB> usdict = None <TAB> if uid in self . users : <TAB> <TAB> usdict = self . users [ uid ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> infos = self . users_info [ uid ] <TAB> <TAB> <TAB> for attr in infos : <TAB> <TAB> <TAB> <TAB> usdict [ attr [ "" attr_type "" ] ] = attr [ "" attr_data "" ] <TAB> <TAB> usdict [ "" uid "" ] = uid <TAB> return usdict",if uid in self . users_info :,if uid in self . users_info :,True,100.0,74.32,,,
"def _validate_options ( self ) : <TAB> for option in self . options : <TAB> <TAB> # if value type is bool or int, then we know the options is set <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self.options.required[option] is True and not self.options[option]: <TAB> <TAB> <TAB> <TAB> if option == Constants.PASSWORD_CLEAR: <TAB> <TAB> <TAB> <TAB> <TAB> option = ""password"".upper() <TAB> <TAB> <TAB> <TAB> raise FrameworkException( <TAB> <TAB> <TAB> <TAB> <TAB> ""Value required for the '%s' option."" % (option.upper()) <TAB> <TAB> <TAB> <TAB> ) <TAB> return","if isinstance ( self . options . required [ option ] , bool ) :","if not type ( self . options [ option ] ) in [ bool , int ] :",False,93.73,68.02,,,
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> if dest . exists ( ) : <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }  Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> if src . exists ( ) : <TAB> <TAB> <TAB> shutil . copy ( src , dest )",if dest . is_dir ( ) :,if not dest . parent . is_dir ( ) :,False,97.78,72.79,,,
"def truncate_seq_pair ( tokens_a , tokens_b , max_length ) : <TAB> """""" Truncates a sequence pair in place to the maximum length. """""" <TAB> # This is a simple heuristic which will always truncate the longer sequence <TAB> # one token at a time. This makes more sense than truncating an equal percent <TAB> # of tokens from each, since if one sequence is very short then each token <TAB> # that's truncated likely contains more information than a longer sequence. <TAB> while True: <TAB> <TAB> total_length = len(tokens_a) + len(tokens_b) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> if len(tokens_a) > len(tokens_b): <TAB> <TAB> <TAB> tokens_a.pop() <TAB> <TAB> else: <TAB> <TAB> <TAB> tokens_b.pop()",if total_length > max_length :,if total_length <= max_length :,False,98.43,73.43,,,
"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB> <TAB> channel = add_channel [ "" channel "" ] <TAB> <TAB> defaults = { "" currency "" : channel . currency_code } <TAB> <TAB> if "" discount_value "" in add_channel . keys ( ) : <TAB> <TAB> <TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB> <TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB> <TAB> <TAB> voucher = voucher , <TAB> <TAB> <TAB> channel = channel , <TAB> <TAB> <TAB> defaults = defaults , <TAB> <TAB> )","if ""min_amount_spent"" in add_channel . keys ( ) :","if ""min_amount_spent"" in add_channel . keys ( ) :",True,100.0,74.53,,,
"def services ( self , id = None , name = None ) : <TAB> for service_dict in self . service_ls ( id = id , name = name ) : <TAB> <TAB> service_id = service_dict [ "" ID "" ] <TAB> <TAB> service_name = service_dict [ "" NAME "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> task_list = self . service_ps ( service_id ) <TAB> <TAB> yield DockerService . from_cli ( self , service_dict , task_list )",if service_name != service_id :,if not service_name . startswith ( self . _name_prefix ) :,False,90.54,68.59,,,
"def lll ( dirname ) : <TAB> for name in os . listdir ( dirname ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> full = os . path . join ( dirname , name ) <TAB> <TAB> <TAB> if os . path . islink ( full ) : <TAB> <TAB> <TAB> <TAB> print ( name , "" -> "" , os . readlink ( full ) )","if os . path . isdir ( os . path . join ( dirname , name , ""lll"" ) ) :","if name not in ( os . curdir , os . pardir ) :",False,83.52,57.56,,,
"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB> <TAB> target_str = mydict [ source_str ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> elif target_str.startswith(u""*** ""): <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u"""" <TAB> <TAB> pounit = self.convertunit(source_str, target_str) <TAB> <TAB> self.mypofile.addunit(pounit) <TAB> return self.mypofile","if target_str . startswith ( u""web2py"" ) :",if target_str == source_str :,False,95.48,66.31,,,
"def __init__ ( self , * * kwargs ) : <TAB> for k , v in kwargs . items ( ) : <TAB> <TAB> setattr ( self , k , v ) <TAB> self . attempted_charsets = set ( ) <TAB> request = cherrypy . serving . request <TAB> if request . handler is not None : <TAB> <TAB> # Replace request.handler with self <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cherrypy.log(""Replacing request.handler"", ""TOOLS.ENCODE"") <TAB> <TAB> self.oldhandler = request.handler <TAB> <TAB> request.handler = self",if request . handler != self :,if self . debug :,False,95.33,71.45,,,
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >>END "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out",if in_section :,elif in_section :,False,99.0,73.53,,,
"def bit_length ( n ) : <TAB> try : <TAB> <TAB> return n . bit_length ( ) <TAB> except AttributeError : <TAB> <TAB> norm = deflate_long ( n , False ) <TAB> <TAB> hbyte = byte_ord ( norm [ 0 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> bitlen = len ( norm ) * 8 <TAB> <TAB> while not ( hbyte & 0x80 ) : <TAB> <TAB> <TAB> hbyte << = 1 <TAB> <TAB> <TAB> bitlen - = 1 <TAB> <TAB> return bitlen",if hbyte == 0 :,if hbyte == 0 :,True,100.0,74.33,,,
"def step ( self , action ) : <TAB> """""" Repeat action, sum reward, and max over last observations. """""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> if i == self . _skip - 2 : <TAB> <TAB> <TAB> self . _obs_buffer [ 0 ] = obs <TAB> <TAB> if i == self . _skip - 1 : <TAB> <TAB> <TAB> self . _obs_buffer [ 1 ] = obs <TAB> <TAB> total_reward + = reward <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if done is None :,if done :,False,98.54,97.39,,,
"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB> <TAB> trans_len = len ( translation ) <TAB> <TAB> ind = np . random . randint ( trans_len ) <TAB> <TAB> action = np . random . choice ( actions ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del translation [ ind ] <TAB> <TAB> elif action == "" replacement "" : <TAB> <TAB> <TAB> ind_rep = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation [ ind ] = translation [ ind_rep ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ind_insert = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation","if action == ""delete"" :","if action == ""deletion"" :",False,98.94,73.75,,,
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> if sign is None : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if sign * ki < - slop : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq",elif sign * ki > slop :,if ki != 0 :,False,96.76,72.25,,,
def get_dirlist ( _rootdir ) : <TAB> dirlist = [ ] <TAB> with os . scandir ( _rootdir ) as rit : <TAB> <TAB> for entry in rit : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> dirlist . append ( entry . path ) <TAB> <TAB> <TAB> <TAB> dirlist + = get_dirlist ( entry . path ) <TAB> return dirlist,if entry . is_dir ( ) :,"if not entry . name . startswith ( ""."" ) and entry . is_dir ( ) :",False,88.1,48.47,,,
"def __init__ ( <TAB> self , <TAB> fixed : MQTTFixedHeader = None , <TAB> variable_header : PublishVariableHeader = None , <TAB> payload = None , ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PUBLISH , 0x00 ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException ( <TAB> <TAB> <TAB> <TAB> "" Invalid fixed packet type  %s  for PublishPacket init "" <TAB> <TAB> <TAB> <TAB> % fixed . packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = variable_header <TAB> self . payload = payload",if fixed . packet_type is not PUBLISH :,if fixed . packet_type is not PUBLISH :,True,100.0,74.46,,,
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res","if pth == ""MVC_Python_1_0"" :","if fname == ""output"" :",False,95.26,72.77,,,
"def reward ( self ) : <TAB> """""" Returns a tuple of sum of raw and processed rewards. """""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raw_rewards += ts.raw_reward <TAB> <TAB> if ts.processed_reward is not None: <TAB> <TAB> <TAB> processed_rewards += ts.processed_reward <TAB> return raw_rewards, processed_rewards",if ts . raw_reward is not None :,if ts . raw_reward is not None :,True,100.0,99.28,,,
"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . extend ( self . _split_option ( line ) ) <TAB> <TAB> elif line and not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> args . append ( line ) <TAB> return args",if self . _is_option ( line ) :,"if line . startswith ( ""-"" ) :",False,92.7,63.96,,,
"def __on_change_button_clicked ( self , widget = None ) : <TAB> """""" compute all primary objects and toggle the  ' Change '  attribute """""" <TAB> self . change_status = not self . change_status <TAB> for prim_obj , tmp in self . xobjects : <TAB> <TAB> obj_change = self . top . get_object ( "" %s _change "" % prim_obj ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . change_entries [ prim_obj ] . set_val ( self . change_status ) <TAB> <TAB> obj_change . set_active ( self . change_status )",if not obj_change :,if not obj_change . get_sensitive ( ) :,False,95.54,85.06,,,
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> if not fpath . exists ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> if not isinstance ( inner , dict ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id",if not data :,"if not isinstance ( data , dict ) :",False,97.31,72.46,,,
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) )","if not isinstance ( inst , Cosimulation ) :",if not inst . modctxt :,False,94.43,71.29,,,
"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB> <TAB> has_xml = accepts . find ( b "" xml "" ) <TAB> <TAB> if has_xml > 0 : <TAB> <TAB> <TAB> semicolon = accepts . find ( b "" ; "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if semicolon > 0 and len ( accepts ) > 0 and len ( accepts ) > semicolon :,if semicolon < 0 or has_xml < semicolon :,False,86.6,66.98,,,
"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB> <TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return target <TAB> <TAB> else : <TAB> <TAB> <TAB> mapper = _mapper_or_none ( target ) <TAB> <TAB> <TAB> if mapper is not None : <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB> <TAB> return target","if isinstance ( target , mapperlib . Mapper ) :","if issubclass ( target , mapperlib . Mapper ) :",False,98.51,73.15,,,
"def _get_font_afm ( self , prop ) : <TAB> key = hash ( prop ) <TAB> font = self . afmfontd . get ( key ) <TAB> <IF-STMT> <TAB> <TAB> fname = findfont ( prop , fontext = "" afm "" ) <TAB> <TAB> font = self . afmfontd . get ( fname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> font = AFM ( file ( findfont ( prop , fontext = "" afm "" ) ) ) <TAB> <TAB> <TAB> self . afmfontd [ fname ] = font <TAB> <TAB> self . afmfontd [ key ] = font <TAB> return font",if font is None :,if font is None :,True,100.0,74.42,,,
"def _get_font_afm ( self , prop ) : <TAB> key = hash ( prop ) <TAB> font = self . afmfontd . get ( key ) <TAB> <IF-STMT> <TAB> <TAB> fname = findfont ( prop , fontext = "" afm "" ) <TAB> <TAB> font = self . afmfontd . get ( fname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> font = AFM ( file ( findfont ( prop , fontext = "" afm "" ) ) ) <TAB> <TAB> <TAB> self . afmfontd [ fname ] = font <TAB> <TAB> self . afmfontd [ key ] = font <TAB> return font",if font is None :,if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby,False,77.97,63.71,,,
"def save ( self ) : <TAB> if self . preferences . get ( ENCRYPT_ON_DISK , False ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . storage . write ( <TAB> <TAB> <TAB> <TAB> self . to_dict ( encrypt_password = self . encryption_password ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif not self . is_locked : <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Disk encryption requested but no password available for encryption.  "" <TAB> <TAB> <TAB> <TAB> "" Resetting encryption preferences and saving wallet in an unencrypted state. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . preferences [ ENCRYPT_ON_DISK ] = False <TAB> return self . storage . write ( self . to_dict ( ) )",if self . encryption_password :,if self . encryption_password is not None :,False,97.94,72.47,,,
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> if value == "" DD-MM-YYYY "" : <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value )",if int ( month ) < 1 or int ( month ) > 1 :,if int ( month ) < 1 or int ( month ) > 12 :,False,98.85,73.69,,,
"def _capture ( self , call_name , data = None , * * kwargs ) : <TAB> if data is None : <TAB> <TAB> data = self . get_default_context ( ) <TAB> else : <TAB> <TAB> default_context = self . get_default_context ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> default_context . update ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> default_context [ "" extra "" ] [ "" extra_data "" ] = data <TAB> <TAB> data = default_context <TAB> client = self . get_sentry_client ( ) <TAB> return getattr ( client , call_name ) ( data = data , * * kwargs )","if ""extra"" not in default_context :","if isinstance ( data , dict ) :",False,94.7,64.34,,,
"def check ( input , expected_output = None , expected_ffi_error = False ) : <TAB> import _cffi_backend <TAB> ffi = _cffi_backend . FFI ( ) <TAB> if not expected_ffi_error : <TAB> <TAB> ct = ffi . typeof ( input ) <TAB> <TAB> assert isinstance ( ct , ffi . CType ) <TAB> <TAB> assert ct . cname == ( expected_output or input ) <TAB> else : <TAB> <TAB> e = py . test . raises ( ffi . error , ffi . typeof , input ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert str ( e . value ) == expected_ffi_error",if e :,"if isinstance ( expected_ffi_error , str ) :",False,93.07,71.04,,,
"def run ( self ) : <TAB> """""" Process queries from task queue, stop if processor is None. """""" <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> processor , iprot , oprot , otrans , callback = self . queue . get ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> processor . process ( iprot , oprot ) <TAB> <TAB> <TAB> callback ( True , otrans . getvalue ( ) ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . exception ( "" Exception while processing request "" ) <TAB> <TAB> <TAB> callback ( False , "" "" )",if processor is None :,if processor is None :,True,100.0,99.47,,,
"def search ( self , query ) : <TAB> query = query . strip ( ) . lower ( ) <TAB> results = [ ] <TAB> for provider in SidebarItemProvider . all ( self . context ) : <TAB> <TAB> for item in provider . provide ( ) : <TAB> <TAB> <TAB> if "" url "" in item : <TAB> <TAB> <TAB> <TAB> search_source = "" $ "" . join ( <TAB> <TAB> <TAB> <TAB> <TAB> [ item . get ( "" id "" , "" "" ) , item . get ( "" name "" , "" "" ) ] <TAB> <TAB> <TAB> <TAB> ) . lower ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> results . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" title "" : item [ "" name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" icon "" : item [ "" icon "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" url "" : item [ "" url "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return results",if search_source in query :,if query in search_source :,False,98.69,73.76,,,
"def handle ( self ) - > None : <TAB> """""" Handles a request ignoring dropped connections. """""" <TAB> try : <TAB> <TAB> BaseHTTPRequestHandler . handle ( self ) <TAB> except ( ConnectionError , socket . timeout ) as e : <TAB> <TAB> self . connection_dropped ( e ) <TAB> except Exception as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log_error ( "" SSL error occurred:  %s "" , e ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise <TAB> if self . server . shutdown_signal : <TAB> <TAB> self . initiate_shutdown ( )",if self . server . ssl_error :,if self . server . ssl_context is not None and is_ssl_error ( e ) :,False,91.84,91.07,,,
"def cdn_url_handler ( error , endpoint , kwargs ) : <TAB> if endpoint == "" cdn "" : <TAB> <TAB> path = kwargs . pop ( "" path "" ) <TAB> <TAB> # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB> <TAB> # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB> <TAB> cdn = app.config.get(""cdn"", ""//cdnjscn.b0.upaiyun.com/libs/"") <TAB> <TAB> return urljoin(cdn, path) <TAB> else: <TAB> <TAB> exc_type, exc_value, tb = sys.exc_info() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> reraise(exc_type, exc_value, tb) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise error","if exc_type in ( ""InvalidHostError"" , ""InvalidHostError"" ) :",if exc_value is error :,False,94.69,65.35,,,
"def pairs ( self ) : <TAB> for path in os . listdir ( "" src "" ) : <TAB> <TAB> if path == "" .svn "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep = join ( "" src "" , path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dep , join ( build_dir , path )",if not os . path . isdir ( dep ) :,if isdir ( dep ) :,False,93.76,71.27,,,
"def get_condition ( self ) : <TAB> """""" Return the condition element ' s name. """""" <TAB> for child in self . xml : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cond = child . tag . split ( "" } "" , 1 ) [ - 1 ] <TAB> <TAB> <TAB> if cond in self . conditions : <TAB> <TAB> <TAB> <TAB> return cond <TAB> return "" not-authorized ""","if child . tag . startswith ( ""condition"" ) :","if ""{%s}"" % self . namespace in child . tag :",False,88.83,68.52,,,
"def get_condition ( self ) : <TAB> """""" Return the condition element ' s name. """""" <TAB> for child in self . xml : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cond = child . tag . split ( "" } "" , 1 ) [ - 1 ] <TAB> <TAB> <TAB> if cond in self . conditions : <TAB> <TAB> <TAB> <TAB> return cond <TAB> return "" not-authorized ""","if child . tag . startswith ( ""condition"" ) :","if "":"" not in tag :",False,90.65,69.07,,,
"def checkIfSessionCodeExists ( self , sessionCode ) : <TAB> if self . emrtFile : <TAB> <TAB> sessionsForExperiment = ( <TAB> <TAB> <TAB> self . emrtFile . root . data_collection . session_meta_data . where ( <TAB> <TAB> <TAB> <TAB> "" experiment_id ==  %d "" % ( self . active_experiment_id , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> sessionCodeMatch = [ <TAB> <TAB> <TAB> sess for sess in sessionsForExperiment if sess [ "" code "" ] == sessionCode <TAB> <TAB> ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",if sessionCodeMatch :,if len ( sessionCodeMatch ) > 0 :,False,95.77,70.84,,,
"def save_bytearray ( self , obj ) : <TAB> if self . proto < 5 : <TAB> <TAB> <IF-STMT> # bytearray is empty <TAB> <TAB> <TAB> self.save_reduce(bytearray, (), obj=obj) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.save_reduce(bytearray, (bytes(obj),), obj=obj) <TAB> <TAB> return <TAB> n = len(obj) <TAB> if n >= self.framer._FRAME_SIZE_TARGET: <TAB> <TAB> self._write_large_bytes(BYTEARRAY8 + pack(""<Q"", n), obj) <TAB> else: <TAB> <TAB> self.write(BYTEARRAY8 + pack(""<Q"", n) + obj)",if not obj :,if not obj :,True,100.0,74.12,,,
"def _restore_freeze ( self , new ) : <TAB> size_change = [ ] <TAB> for k , v in six . iteritems ( self . _freeze_backup ) : <TAB> <TAB> newv = new . get ( k , [ ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size_change . append ( ( self . _key_name ( k ) , len ( v ) , len ( newv ) ) ) <TAB> if size_change : <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" These collections were modified but restored in  {} :  {} "" . format ( <TAB> <TAB> <TAB> <TAB> self . _name , <TAB> <TAB> <TAB> <TAB> "" ,  "" . join ( map ( lambda t : "" ( {} :  {} -> {} ) "" . format ( * t ) , size_change ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> restore_collection ( self . _freeze_backup )",if v != newv :,if len ( v ) != len ( newv ) :,False,95.9,71.66,,,
"def check_options ( self , expr , evaluation , options ) : <TAB> for key in options : <TAB> <TAB> if key != "" System`SameTest "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) , expr ) <TAB> return None","if self . _test_options . get ( key , None ) :",if expr is None :,False,89.62,69.98,,,
"def bundle_directory ( self , dirpath ) : <TAB> """""" Bundle all modules/packages in the given directory. """""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> if nm . startswith ( "" . "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> elif nm . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . bundle_module ( itempath )","if nm . endswith ( "".py"" ) :","if os . path . exists ( os . path . join ( itempath , ""__init__.py"" ) ) :",False,89.37,93.66,,,
"def _read_block ( self , size ) : <TAB> if self . _file_end is not None : <TAB> <TAB> max_size = self . _file_end - self . _file . tell ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> size = max_size <TAB> <TAB> size = max ( min ( size , max_size ) , 0 ) <TAB> return self . _file . read ( size )",if size > max_size :,if size == - 1 :,False,94.96,71.0,,,
"def question_mark ( self ) : <TAB> """""" Shows help for this command and it ' s sub-commands. """""" <TAB> ret = [ ] <TAB> if self . param_help_msg or len ( self . subcommands ) == 0 : <TAB> <TAB> ret . append ( self . _quick_help ( ) ) <TAB> if len ( self . subcommands ) > 0 : <TAB> <TAB> for k , _ in sorted ( self . subcommands . items ( ) ) : <TAB> <TAB> <TAB> command_path , param_help , cmd_help = self . _instantiate_subcommand ( <TAB> <TAB> <TAB> <TAB> k <TAB> <TAB> <TAB> ) . _quick_help ( nested = True ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret . append ( ( command_path , param_help , cmd_help ) ) <TAB> return ( CommandsResponse ( STATUS_OK , self . help_formatter ( ret ) ) , self . __class__ )",if command_path :,if command_path or param_help or cmd_help :,False,96.19,83.15,,,
"def list_domains ( self , r53 , * * kwargs ) : <TAB> marker = None <TAB> domains = [ ] <TAB> while True : <TAB> <TAB> if marker : <TAB> <TAB> <TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ( Marker = marker ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ) <TAB> <TAB> for domain in response . get ( "" Domains "" ) : <TAB> <TAB> <TAB> domains . append ( domain ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> marker = response . get ( "" NextPageMarker "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return domains","if response . get ( ""NextPageMarker"" ) :","if response . get ( ""NextPageMarker"" ) :",True,100.0,74.49,,,
"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB> <TAB> stream . write ( sep ) <TAB> <TAB> sep = "" "" <TAB> <TAB> if not isinstance ( item , str ) : <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> if not PY3K : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" )","if isinstance ( item , str ) :","if not isinstance ( item , unicode ) :",False,96.5,71.63,,,
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> view . run_command ( "" toggle_comment "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pt = utils . next_non_white_space_char ( view , s . a , white_space = "" \t "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pt = utils . next_non_white_space_char ( <TAB> <TAB> <TAB> <TAB> view , self . view . line ( s . a ) . a , white_space = "" \t "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return R ( pt , pt ) <TAB> return s",if s . a . isspace ( ) :,"if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) :",False,84.01,64.1,,,
"def _parse_timestamp ( value ) : <TAB> if value : <TAB> <TAB> match = _TIMESTAMP_PATTERN . match ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if match . group ( 2 ) : <TAB> <TAB> <TAB> <TAB> format = "" % Y- % m- %d % H: % M: % S. %f "" <TAB> <TAB> <TAB> <TAB> # use the pattern to truncate the value <TAB> <TAB> <TAB> <TAB> value = match.group() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> format = ""%Y-%m-%d %H:%M:%S"" <TAB> <TAB> <TAB> value = datetime.datetime.strptime(value, format) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception('Cannot convert ""{}"" into a datetime'.format(value)) <TAB> else: <TAB> <TAB> value = None <TAB> return value",if match :,if match :,True,100.0,74.45,,,
"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB> <TAB> if model_site [ "" type "" ] == "" sample "" : <TAB> <TAB> <TAB> log_r_term = model_site [ "" log_prob "" ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB> <TAB> <TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r","if model_site [ ""type"" ] == ""base"" :","if not model_site [ ""is_observed"" ] :",False,95.06,67.17,,,
"def get_translationproject ( self ) : <TAB> """""" returns the translation project belonging to this directory. """""" <TAB> if self . is_language ( ) or self . is_project ( ) : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . translationproject <TAB> <TAB> else : <TAB> <TAB> <TAB> aux_dir = self <TAB> <TAB> <TAB> while not aux_dir . is_translationproject ( ) and aux_dir . parent is not None : <TAB> <TAB> <TAB> <TAB> aux_dir = aux_dir . parent <TAB> <TAB> <TAB> return aux_dir . translationproject",if self . translationproject :,if self . is_translationproject ( ) :,False,96.38,91.69,,,
"def get_hosted_content ( ) : <TAB> try : <TAB> <TAB> scheme , rest = target . split ( "" :// "" , 1 ) <TAB> <TAB> prefix , host_and_port = rest . split ( "" .interactivetool. "" ) <TAB> <TAB> faked_host = rest <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> faked_host = rest . split ( "" / "" , 1 ) [ 0 ] <TAB> <TAB> url = "" %s :// %s "" % ( scheme , host_and_port ) <TAB> <TAB> response = requests . get ( url , timeout = 1 , headers = { "" Host "" : faked_host } ) <TAB> <TAB> return response . text <TAB> except Exception as e : <TAB> <TAB> print ( e ) <TAB> <TAB> return None","if prefix == ""*"" :","if ""/"" in rest :",False,96.53,72.62,,,
"def install ( self ) : <TAB> log . info ( self . openssl_cli ) <TAB> if not self . has_openssl or self . args . force : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _download_src ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . debug ( "" Already has src  {} "" . format ( self . src_file ) ) <TAB> <TAB> self . _unpack_src ( ) <TAB> <TAB> self . _build_src ( ) <TAB> <TAB> self . _make_install ( ) <TAB> else : <TAB> <TAB> log . info ( "" Already has installation  {} "" . format ( self . install_dir ) ) <TAB> # validate installation <TAB> version = self.openssl_version <TAB> if self.version not in version: <TAB> <TAB> raise ValueError(version)",if self . is_download :,if not self . has_src :,False,96.97,72.58,,,
"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB> <TAB> if i % 2 : <TAB> <TAB> <TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces )",elif piece :,elif piece :,True,100.0,74.31,,,
"def get_current_events_users ( calendar ) : <TAB> now = timezone . make_aware ( datetime . now ( ) , timezone . get_current_timezone ( ) ) <TAB> result = [ ] <TAB> day = Day ( calendar . events . all ( ) , now ) <TAB> for o in day . get_occurrences ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> usernames = o . event . title . split ( "" , "" ) <TAB> <TAB> <TAB> for username in usernames : <TAB> <TAB> <TAB> <TAB> result . append ( User . objects . get ( username = username . strip ( ) ) ) <TAB> return result",if o . event . title :,if o . start <= now <= o . end :,False,93.84,71.03,,,
"def from_cfn_params ( self , cfn_params ) : <TAB> """""" Initialize param value by parsing CFN input only if the scheduler is awsbatch. """""" <TAB> cfn_converter = self . definition . get ( "" cfn_param_mapping "" , None ) <TAB> if cfn_converter and cfn_params : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB> <TAB> <TAB> # so the CFN input could be a float <TAB> <TAB> <TAB> self.value = int(float(get_cfn_param(cfn_params, cfn_converter))) <TAB> return self","if get_cfn_param ( cfn_params , ""spot_price"" , None ) :","if get_cfn_param ( cfn_params , ""Scheduler"" ) == ""awsbatch"" :",False,95.03,64.91,,,
"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l . split ( "" : "" ) <TAB> <TAB> if len ( l ) != 2 : <TAB> <TAB> <TAB> continue <TAB> <TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setChapters ( res )",if len ( l ) != 3 :,if not l :,False,93.94,71.53,,,
"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB> <TAB> # most common case: extend a range <TAB> <TAB> if i == _range[0] - 1: <TAB> <TAB> <TAB> _range[0] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _range[1] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",if i == _range [ 1 ] - 1 :,elif i == _range [ 1 ] + 1 :,False,97.33,71.09,,,
"def process_dollar ( token , state , command_line ) : <TAB> if not state . is_range_start_line_parsed : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . start . append ( token ) <TAB> else : <TAB> <TAB> if command_line . line_range . end : <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . end . append ( token ) <TAB> return parse_line_ref , command_line",if command_line . line_range . start :,if command_line . line_range . start :,True,100.0,74.44,,,
"def process_dollar ( token , state , command_line ) : <TAB> if not state . is_range_start_line_parsed : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . start . append ( token ) <TAB> else : <TAB> <TAB> if command_line . line_range . end : <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . end . append ( token ) <TAB> return parse_line_ref , command_line",if command_line . line_range . start :,"if clean . startswith ( ""Severity:"" ) :",False,94.47,65.55,,,
"def apply ( self , chart , grammar ) : <TAB> for prod in grammar . productions ( empty = True ) : <TAB> <TAB> for index in compat . xrange ( chart . num_leaves ( ) + 1 ) : <TAB> <TAB> <TAB> new_edge = TreeEdge . from_production ( prod , index ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield new_edge",if chart . add_edge ( new_edge ) :,"if chart . insert ( new_edge , ( ) ) :",False,93.51,69.65,,,
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res","if self . op == ""+"" :","if self . op == ""+"" :",True,100.0,74.66,,,
"def cascade ( self , event = None ) : <TAB> """""" Cascade all Leo windows. """""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB> <TAB> w = frame and frame . top <TAB> <TAB> if w : <TAB> <TAB> <TAB> r = w . geometry ( ) # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x += 30 <TAB> <TAB> <TAB> y += 30 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta += 10",if x < 10 and y < 40 :,if x > 200 :,False,97.08,97.55,,,
"def redirect ( self ) : <TAB> c = self . c <TAB> if c . config . getBool ( "" eval-redirect "" ) : <TAB> <TAB> self . old_stderr = g . stdErrIsRedirected ( ) <TAB> <TAB> self . old_stdout = g . stdOutIsRedirected ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g . redirectStderr ( ) <TAB> <TAB> if not self . old_stdout : <TAB> <TAB> <TAB> g . redirectStdout ( )",if not self . old_stderr :,if not self . old_stderr :,True,100.0,74.2,,,
"def on_event ( self , c , button , data ) : <TAB> if self . rvGestureGrab . get_reveal_child ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . use ( ) <TAB> <TAB> elif button == "" Y "" and data [ 0 ] == 0 : <TAB> <TAB> <TAB> self . start_over ( )","if button == ""X"" and data [ 0 ] == 0 :","if button == ""A"" and data [ 0 ] == 0 :",False,97.54,72.23,,,
"def __init__ ( self , in_feats , out_feats , norm = "" both "" , bias = True , activation = None ) : <TAB> super ( DenseGraphConv , self ) . __init__ ( ) <TAB> self . _in_feats = in_feats <TAB> self . _out_feats = out_feats <TAB> self . _norm = norm <TAB> with self . name_scope ( ) : <TAB> <TAB> self . weight = self . params . get ( <TAB> <TAB> <TAB> "" weight "" , <TAB> <TAB> <TAB> shape = ( in_feats , out_feats ) , <TAB> <TAB> <TAB> init = mx . init . Xavier ( magnitude = math . sqrt ( 2.0 ) ) , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . bias = self . params . get ( "" bias "" , shape = ( out_feats , ) , init = mx . init . Zero ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . bias = None <TAB> <TAB> self . _activation = activation",if bias :,if bias :,True,100.0,74.62,,,
"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys.path: <TAB> <TAB> if isinstance(item, _StringType): <TAB> <TAB> <TAB> module = self.fs_imp.import_from_dir(item, name) <TAB> <TAB> else: <TAB> <TAB> <TAB> module = item.import_top(name) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return module <TAB> return None",if module is not None :,if module :,False,97.04,72.18,,,
"def resolver ( schemas , f ) : <TAB> if not callable ( f ) : <TAB> <TAB> return <TAB> if not hasattr ( f , "" accepts "" ) : <TAB> <TAB> return <TAB> new_params = [ ] <TAB> for p in f . accepts : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_params . append ( p . resolve ( schemas ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ResolverError ( "" Invalid parameter definition  {0} "" . format ( p ) ) <TAB> # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB> f.accepts.clear() <TAB> f.accepts.extend(new_params)","if isinstance ( p , ParameterDefinition ) :","if isinstance ( p , ( Patch , Ref , Attribute ) ) :",False,95.39,70.94,,,
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> if fname == "" output "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" : # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os.path.isdir(p): <TAB> <TAB> <TAB> get_dir(p) <TAB> <TAB> else: <TAB> <TAB> <TAB> res.append(p) <TAB> return res","if pth . startswith ( ""pycache"" ) :","if fname == ""PureMVC_Python_1_0"" :",False,94.25,72.12,,,
"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB> <TAB> for rightname in kerning [ leftname ] : <TAB> <TAB> <TAB> if rightname [ 0 ] == "" @ "" : <TAB> <TAB> <TAB> <TAB> for rightname2 in groups [ rightname ] : <TAB> <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname2 ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname)",elif includeAll :,if not includeAll :,False,98.41,72.81,,,
"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB> <TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB> <TAB> <TAB> if key not in old_obj . __table__ . columns : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB> <TAB> self . session_new . add ( new_obj )",if old_obj . __table__ . columns . _data . keys ( ) :,if not old_obj . summary :,False,92.42,71.26,,,
"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB> <TAB> envvar = match . groups ( ) [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = os . environ [ envvar ] <TAB> <TAB> <TAB> if six . PY2 : <TAB> <TAB> <TAB> <TAB> value = value . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> <TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB> <TAB> <TAB> <TAB> msg , var , _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> )",if envvar in os . environ :,if envvar in os . environ :,True,100.0,74.63,,,
"def __next__ ( self ) : <TAB> self . _parse_reset ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> line = next ( self . input_iter ) <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> # End of input OR exception <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Error(""newline inside string"") <TAB> <TAB> <TAB> raise <TAB> <TAB> self.line_num += 1 <TAB> <TAB> if ""\0"" in line: <TAB> <TAB> <TAB> raise Error(""line contains NULL byte"") <TAB> <TAB> pos = 0 <TAB> <TAB> while pos < len(line): <TAB> <TAB> <TAB> pos = self._parse_process_char(line, pos) <TAB> <TAB> self._parse_eol() <TAB> <TAB> if self.state == self.START_RECORD: <TAB> <TAB> <TAB> break <TAB> fields = self.fields <TAB> self.fields = [] <TAB> return fields",if self . state == self . START_RECORD :,if len ( self . field ) > 0 :,False,96.24,71.26,,,
"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB> <TAB> pos = self . stream . searchBytes ( <TAB> <TAB> <TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB> <TAB> ) # seek forward by at most 1MB <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> padsize = pos - self.current_size <TAB> <TAB> <TAB> if padsize: <TAB> <TAB> <TAB> <TAB> yield PaddingBytes(self, ""pad[]"", padsize // 8) <TAB> <TAB> chunk = Chunk(self, ""chunk[]"") <TAB> <TAB> try: <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk[""content/data""] <TAB> <TAB> except: <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk",if pos :,if pos is not None :,False,98.13,72.3,,,
"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB> <TAB> if part . type == "" uid "" : <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB> <TAB> <TAB> yield f ( id , msg , write , flush ) <TAB> <TAB> if part is not query [ - 1 ] : <TAB> <TAB> <TAB> space ( ) <TAB> if uid and not seenUID : <TAB> <TAB> space ( ) <TAB> <TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( )",if body :,"if part . type == ""body"" :",False,95.85,66.73,,,
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance(value, datetime) and isinstance(limit, timedelta): <TAB> <TAB> <TAB> if config[key][""inverse""] is True: <TAB> <TAB> <TAB> <TAB> if (datetime.now() - limit) > value: <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() - limit <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime.now() + limit <TAB> <TAB> elif value > limit: <TAB> <TAB> <TAB> value = limit <TAB> return value","if config [ key ] [ ""inverse"" ] is True :",if ( datetime . now ( ) + limit ) < value :,False,94.76,63.8,,,
"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB> <TAB> if mod == "" input "" : <TAB> <TAB> <TAB> iter = op . inputs <TAB> <TAB> else : <TAB> <TAB> <TAB> iter = op . outputs <TAB> <TAB> for i in iter : <TAB> <TAB> <TAB> for name in names : <TAB> <TAB> <TAB> <TAB> if i . raw_name == name and name not in map : <TAB> <TAB> <TAB> <TAB> <TAB> map [ i . raw_name ] = i . full_name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> for name in names : <TAB> <TAB> new_names . append ( map [ name ] ) <TAB> return new_names",if i . raw_name in map :,if len ( map ) == len ( names ) :,False,95.16,71.06,,,
"def traverse ( tree ) : <TAB> """""" Generator dropping comment nodes """""" <TAB> for entry in tree : <TAB> <TAB> # key, values = entry <TAB> <TAB> spaceless = [e for e in entry if not nginxparser.spacey(e)] <TAB> <TAB> if spaceless: <TAB> <TAB> <TAB> key = spaceless[0] <TAB> <TAB> <TAB> values = spaceless[1] if len(spaceless) > 1 else None <TAB> <TAB> else: <TAB> <TAB> <TAB> key = values = """" <TAB> <TAB> if isinstance(key, list): <TAB> <TAB> <TAB> new = copy.deepcopy(entry) <TAB> <TAB> <TAB> new[1] = filter_comments(values) <TAB> <TAB> <TAB> yield new <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield spaceless","if isinstance ( entry , dict ) :","if key != ""#"" and spaceless :",False,95.95,65.05,,,
"def mergeCombiners ( self , x , y ) : <TAB> for item in y : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . heap . push ( x , item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . heap . push_pop ( x , item ) <TAB> return x",if self . heap . is_full ( x ) :,if len ( x ) < self . heap_limit :,False,90.41,67.96,,,
"def test_scatter ( self , harness : primitive_harness . Harness ) : <TAB> f_name = harness . params [ "" f_lax "" ] . __name__ <TAB> dtype = harness . params [ "" dtype "" ] <TAB> if jtu . device_under_test ( ) == "" tpu "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise unittest . SkipTest ( f "" TODO: complex  { f_name }  on TPU fails in JAX "" ) <TAB> self . ConvertAndCompare ( harness . dyn_fun , * harness . dyn_args_maker ( self . rng ( ) ) )",if dtype != np . complex :,"if dtype is np . complex64 and f_name in [ ""scatter_min"" , ""scatter_max"" ] :",False,85.36,64.09,,,
"def TryMerge ( self , decoder ) : <TAB> while decoder . avail ( ) > 0 : <TAB> <TAB> tag = decoder . getVarInt32 ( ) <TAB> <TAB> if tag == TAG_BEGIN_ITEM_GROUP : <TAB> <TAB> <TAB> ( type_id , message ) = Item . Decode ( decoder ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . items [ type_id ] . MergeFrom ( Item ( message ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . items [ type_id ] = Item ( message ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tag == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> decoder . skipData ( tag )",if type_id in self . items :,if type_id in self . items :,True,100.0,74.49,,,
"def process_continuations ( lines ) : <TAB> global continuation_pattern <TAB> olines = [ ] <TAB> while len ( lines ) != 0 : <TAB> <TAB> line = no_comments ( lines [ 0 ] ) <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> lines . pop ( 0 ) <TAB> <TAB> if line == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # combine this line with the next line if the next line exists <TAB> <TAB> <TAB> line = continuation_pattern.sub("""", line) <TAB> <TAB> <TAB> if len(lines) >= 1: <TAB> <TAB> <TAB> <TAB> combined_lines = [line + lines[0]] <TAB> <TAB> <TAB> <TAB> lines.pop(0) <TAB> <TAB> <TAB> <TAB> lines = combined_lines + lines <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> olines.append(line) <TAB> del lines <TAB> return olines","if line . startswith ( ""#"" ) :",if continuation_pattern . search ( line ) :,False,97.14,94.84,,,
"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB> <TAB> if pkg in Scheduler . listOfPackagesCurrentlyBuilding : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB> <TAB> <TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" )",if Scheduler . _isNextToBuild ( pkg ) :,if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) :,False,92.83,69.42,,,
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr(obj, ""use_scope""): <TAB> <TAB> <TAB> if obj.use_scope: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation",elif obj . use_scope :,elif obj . use_scope is None :,False,98.61,72.4,,,
"def find_distribution_modules ( name = __name__ , file = __file__ ) : <TAB> current_dist_depth = len ( name . split ( "" . "" ) ) - 1 <TAB> current_dist = os . path . join ( <TAB> <TAB> os . path . dirname ( file ) , * ( [ os . pardir ] * current_dist_depth ) <TAB> ) <TAB> abs = os . path . abspath ( current_dist ) <TAB> dist_name = os . path . basename ( abs ) <TAB> for dirpath , dirnames , filenames in os . walk ( abs ) : <TAB> <TAB> package = ( dist_name + dirpath [ len ( abs ) : ] ) . replace ( "" / "" , "" . "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield package <TAB> <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> <TAB> if filename . endswith ( "" .py "" ) and filename != "" __init__.py "" : <TAB> <TAB> <TAB> <TAB> <TAB> yield "" . "" . join ( [ package , filename ] ) [ : - 3 ]","if package . endswith ( "".py"" ) :","if ""__init__.py"" in filenames :",False,96.2,72.98,,,
"def transform_value ( i , v , * args ) : <TAB> if i not in converter_functions : <TAB> <TAB> # no converter defined on this field, return value as-is <TAB> <TAB> return v <TAB> else: <TAB> <TAB> try: <TAB> <TAB> <TAB> return converter_functions[i](v, *args) <TAB> <TAB> except Exception as e: <TAB> <TAB> <TAB> if failonerror == ""inline"": <TAB> <TAB> <TAB> <TAB> return e <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> return errorvalue","elif failonerror == ""ignore"" :",elif failonerror :,False,96.39,64.54,,,
"def _get_file ( self ) : <TAB> if self . _file is None : <TAB> <TAB> self . _file = SpooledTemporaryFile ( <TAB> <TAB> <TAB> max_size = self . _storage . max_memory_size , <TAB> <TAB> <TAB> suffix = "" .S3Boto3StorageFile "" , <TAB> <TAB> <TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _is_dirty = False <TAB> <TAB> <TAB> self . obj . download_fileobj ( self . _file ) <TAB> <TAB> <TAB> self . _file . seek ( 0 ) <TAB> <TAB> if self . _storage . gzip and self . obj . content_encoding == "" gzip "" : <TAB> <TAB> <TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file",if self . _is_dirty :,"if ""r"" in self . _mode :",False,96.72,67.5,,,
"def connect ( self , host , port , timeout ) : <TAB> fp = Telnet ( ) <TAB> for i in range ( 50 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> fp . sock = socket . create_connection ( <TAB> <TAB> <TAB> <TAB> ( host , int ( port ) ) , timeout = int ( timeout ) , source_address = ( "" "" , 1023 - i ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> except socket . error as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise e <TAB> self . need_handshake = True <TAB> return TCP_Connection ( fp )",if i == 50 :,"if ( e . errno , e . strerror ) != ( 98 , ""Address already in use"" ) :",False,88.3,60.15,,,
"def filtercomments ( source ) : <TAB> """""" NOT USED: strips trailing comments and put them at the top. """""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB> <TAB> if re . search ( r "" ^ \ s* \ / \ * "" , source ) : <TAB> <TAB> <TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment : <TAB> <TAB> <TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB> <TAB> <TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source","elif re . search ( r""^\s*/"" , source ) :","elif re . search ( r""^\s*\/\/"" , source ) :",False,98.26,73.93,,,
"def yview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB> <TAB> value = float ( value ) <TAB> if mode is None : <TAB> <TAB> return self . vsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB> <TAB> frameHeight = self . innerframe . winfo_reqheight ( ) <TAB> <TAB> self . _startY = value * float ( frameHeight ) <TAB> else : # mode == 'scroll' <TAB> <TAB> clipperHeight = self._clipper.winfo_height() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> jump = int(clipperHeight * self._jfraction) <TAB> <TAB> else: <TAB> <TAB> <TAB> jump = clipperHeight <TAB> <TAB> self._startY = self._startY + value * jump <TAB> self.reposition()",if self . _jfraction :,"if units == ""units"" :",False,96.53,65.98,,,
"def visit ( stmt ) : <TAB> """""" Collect information about VTCM buffers and their alignments. """""" <TAB> if isinstance ( stmt , tvm . tir . AttrStmt ) : <TAB> <TAB> if stmt . attr_key == "" storage_scope "" and stmt . value == "" local.vtcm "" : <TAB> <TAB> <TAB> vtcm_buffers . append ( stmt . node ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not stmt . node in alignments : <TAB> <TAB> <TAB> <TAB> alignments [ stmt . node ] = [ ] <TAB> <TAB> <TAB> alignments [ stmt . node ] . append ( stmt . value )","elif stmt . attr_key == ""alignments"" :","elif stmt . attr_key == ""storage_alignment"" :",False,97.31,98.28,,,
"def cost ( P ) : <TAB> # wda loss <TAB> loss_b = 0 <TAB> loss_w = 0 <TAB> for i, xi in enumerate(xc): <TAB> <TAB> xi = np.dot(xi, P) <TAB> <TAB> for j, xj in enumerate(xc[i:]): <TAB> <TAB> <TAB> xj = np.dot(xj, P) <TAB> <TAB> <TAB> M = dist(xi, xj) <TAB> <TAB> <TAB> G = sinkhorn(wc[i], wc[j + i], M, reg, k) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> loss_w += np.sum(G * M) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> loss_b += np.sum(G * M) <TAB> # loss inversed because minimization <TAB> return loss_w / loss_b",if reg == j + i :,if j == 0 :,False,97.28,72.0,,,
"def __init__ ( self , comm , in_channels , out_channels , ksize , pad = 1 ) : <TAB> super ( Block , self ) . __init__ ( ) <TAB> with self . init_scope ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . conv = ParallelConvolution2D ( <TAB> <TAB> <TAB> <TAB> comm , in_channels , out_channels , ksize , pad = pad , nobias = True <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . conv = chainer . links . Convolution2D ( <TAB> <TAB> <TAB> <TAB> in_channels , out_channels , ksize , pad = pad , nobias = True <TAB> <TAB> <TAB> ) <TAB> <TAB> self . bn = L . BatchNormalization ( out_channels )",if comm . num_channels == 1 :,if comm . size <= in_channels :,False,96.89,72.75,,,
"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB> <TAB> <TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found + = 1 <TAB> <TAB> if wrong_found == 1 : <TAB> <TAB> <TAB> return - 30 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0",if nzb_name == wrong :,"if ""%s%s"" % ( wrong , nr ) in nzb_name . lower ( ) :",False,91.75,68.6,,,
"def should_include ( service ) : <TAB> for f in filt : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> state = filt [ f ] <TAB> <TAB> <TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB> <TAB> <TAB> if not has_container_with_state ( containers , state ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == "" source "" : <TAB> <TAB> <TAB> source = filt [ f ] <TAB> <TAB> <TAB> if source == "" image "" or source == "" build "" : <TAB> <TAB> <TAB> <TAB> if source not in service . options : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True","if f == ""state"" :","if f == ""status"" :",False,99.07,73.87,,,
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB """,if length <= self . LENGTH_LIMIT_BLOB :,if length <= self . LENGTH_LIMIT_BLOB :,True,100.0,74.22,,,
"def click_outside ( event ) : <TAB> if event not in d : <TAB> <TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y + = 3 <TAB> <TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB> <TAB> if event . num_clicks == 2 : <TAB> <TAB> <TAB> d . dismiss ( "" Goto "" )",if x == 0 :,if y == 0 :,False,97.96,72.78,,,
"def check_related_active_jobs ( self , obj ) : <TAB> active_jobs = obj . get_active_jobs ( ) <TAB> if len ( active_jobs ) > 0 : <TAB> <TAB> raise ActiveJobConflict ( active_jobs ) <TAB> time_cutoff = now ( ) - dateutil . relativedelta . relativedelta ( minutes = 1 ) <TAB> recent_jobs = obj . _get_related_jobs ( ) . filter ( finished__gte = time_cutoff ) <TAB> for unified_job in recent_jobs . get_real_instances ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PermissionDenied ( <TAB> <TAB> <TAB> <TAB> _ ( "" Related job  {}  is still processing events. "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> unified_job . log_format <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> )",if unified_job . is_processing_events ( ) :,if not unified_job . event_processing_finished :,False,96.28,72.23,,,
"def run ( self ) : <TAB> self . alive = True <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB> <TAB> _log . debug ( "" started "" ) <TAB> while self . alive : <TAB> <TAB> task = self . queue . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> function , args , kwargs = task <TAB> <TAB> <TAB> assert function <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> function ( * args , * * kwargs ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> _log . exception ( "" calling  %s "" , function ) <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB> <TAB> _log . debug ( "" stopped "" )",if task is not None :,if task :,False,97.73,73.31,,,
"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB> <TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB> <TAB> if v is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> contents [ k ] = v <TAB> <TAB> updated_am + = 1 <TAB> if updated_am : <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str ( contents ) , <TAB> <TAB> ] <TAB> <TAB> if not exists : <TAB> <TAB> <TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB> <TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 )","if allow_empty and v == """" :",if len ( v ) == 0 and not allow_empty :,False,95.86,60.28,,,
"def wrapper ( # type: ignore <TAB> self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path.rstrip(""/"") <TAB> <TAB> <TAB> <IF-STMT> # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB> if self.request.query: <TAB> <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",if uri :,if uri :,True,100.0,74.28,,,
def output_handles_from_execution_plan ( execution_plan ) : <TAB> output_handles_for_current_run = set ( ) <TAB> for step_level in execution_plan . execution_step_levels ( ) : <TAB> <TAB> for step in step_level : <TAB> <TAB> <TAB> for step_input in step . step_inputs : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> output_handles_for_current_run . update ( step_input . source_handles ) <TAB> return output_handles_for_current_run,if step_input . is_output :,if step_input . source_handles :,False,97.2,97.11,,,
"def _read_value ( self , item ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _store [ item ] <TAB> <TAB> <TAB> raise KeyError ( item ) <TAB> <TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> elif item in self . _children : <TAB> <TAB> return PathResult ( item , dir = True ) <TAB> else : <TAB> <TAB> raise KeyError ( item )",if self . _store [ item ] is None :,if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) :,False,85.42,66.31,,,
"def _line_ranges ( statements , lines ) : <TAB> """""" Produce a list of ranges for `format_lines`. """""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines [ lidx ] : <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start : <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs",if start is None and end is None :,if not start :,False,96.56,86.12,,,
"def _update_help_obj_params ( help_obj , data_params , params_equal , attr_key_tups ) : <TAB> loaded_params = [ ] <TAB> for param_obj in help_obj . parameters : <TAB> <TAB> loaded_param = next ( <TAB> <TAB> <TAB> ( n for n in data_params if params_equal ( param_obj , n ) ) , None <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> BaseHelpLoader . _update_obj_from_data_dict ( <TAB> <TAB> <TAB> <TAB> param_obj , loaded_param , attr_key_tups <TAB> <TAB> <TAB> ) <TAB> <TAB> loaded_params . append ( param_obj ) <TAB> help_obj . parameters = loaded_params",if loaded_param :,if loaded_param :,True,100.0,74.32,,,
"def __get_ratio ( self ) : <TAB> """""" Return splitter ratio of the main splitter. """""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB> <TAB> w = free_layout . get_main_splitter ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> aList = w . sizes ( ) <TAB> <TAB> <TAB> if len ( aList ) == 2 : <TAB> <TAB> <TAB> <TAB> n1 , n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float(n1) / float(n1 + n2) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5",if w :,if w :,True,100.0,99.45,,,
"def _check_required_env_variables ( vars ) : <TAB> for var in vars : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . tc . logger . error ( <TAB> <TAB> <TAB> <TAB> "" %s  is not set. Did you forget to source your build environment setup script? "" <TAB> <TAB> <TAB> <TAB> % var <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise OEQAPreRun","if not getattr ( self . tc . config , var , None ) :",if not os . environ . get ( var ) :,False,90.64,67.66,,,
"def clean_indexes ( ) : <TAB> for coll_name in mongo . collection_types . keys ( ) : <TAB> <TAB> coll = mongo . get_collection ( coll_name ) <TAB> <TAB> indexes = coll_indexes [ coll_name ] <TAB> <TAB> try : <TAB> <TAB> <TAB> for index in coll . list_indexes ( ) : <TAB> <TAB> <TAB> <TAB> name = index [ "" name "" ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> coll . drop_index ( name ) <TAB> <TAB> except pymongo . errors . OperationFailure : <TAB> <TAB> <TAB> pass",if name in indexes :,"if name == ""_id"" or name == ""_id_"" or name in indexes :",False,90.75,64.43,,,
"def _compare_dirs ( self , dir1 , dir2 ) : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [] <TAB> for root, dirs, files in os.walk(dir1): <TAB> <TAB> for file_ in files: <TAB> <TAB> <TAB> path = os.path.join(root, file_) <TAB> <TAB> <TAB> target_path = os.path.join(dir2, os.path.split(path)[-1]) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> diff.append(file_) <TAB> return diff",if os . path . isfile ( target_path ) :,if not os . path . exists ( target_path ) :,False,97.0,70.76,,,
"def load_state_dict ( self , state_dict , strict = True ) : <TAB> """""" Customized load. """""" <TAB> self . language_model . load_state_dict ( <TAB> <TAB> state_dict [ self . _language_model_key ] , strict = strict <TAB> ) <TAB> if mpu . is_pipeline_last_stage ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . multichoice_head . load_state_dict ( <TAB> <TAB> <TAB> <TAB> state_dict [ self . _multichoice_head_key ] , strict = strict <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print_rank_last ( <TAB> <TAB> <TAB> <TAB> "" ***WARNING*** could not find  {}  in the checkpoint,  "" <TAB> <TAB> <TAB> <TAB> "" initializing to random "" . format ( self . _multichoice_head_key ) <TAB> <TAB> <TAB> )",if self . _multichoice_head_key :,if self . _multichoice_head_key in state_dict :,False,97.87,95.48,,,
"def _parse_timedelta ( self , value ) : <TAB> try : <TAB> <TAB> sum = datetime . timedelta ( ) <TAB> <TAB> start = 0 <TAB> <TAB> while start < len ( value ) : <TAB> <TAB> <TAB> m = self . _TIMEDELTA_PATTERN . match ( value , start ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception ( ) <TAB> <TAB> <TAB> num = float ( m . group ( 1 ) ) <TAB> <TAB> <TAB> units = m . group ( 2 ) or "" seconds "" <TAB> <TAB> <TAB> units = self . _TIMEDELTA_ABBREV_DICT . get ( units , units ) <TAB> <TAB> <TAB> sum + = datetime . timedelta ( * * { units : num } ) <TAB> <TAB> <TAB> start = m . end ( ) <TAB> <TAB> return sum <TAB> except : <TAB> <TAB> raise",if not m :,if not m :,True,100.0,74.56,,,
"def SetChildMenuBar ( self , pChild ) : <TAB> if not pChild : <TAB> <TAB> # No Child, set Our menu bar back. <TAB> <TAB> if self._pMyMenuBar: <TAB> <TAB> <TAB> self.SetMenuBar(self._pMyMenuBar) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.SetMenuBar(self.GetMenuBar()) <TAB> <TAB> # Make sure we know our menu bar is in use <TAB> <TAB> self._pMyMenuBar = None <TAB> else: <TAB> <TAB> if pChild.GetMenuBar() is None: <TAB> <TAB> <TAB> return <TAB> <TAB> # Do we need to save the current bar? <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._pMyMenuBar = self.GetMenuBar() <TAB> <TAB> self.SetMenuBar(pChild.GetMenuBar())",if self . _pMyMenuBar is None :,if self . _pMyMenuBar is None :,True,100.0,74.38,,,
"def init_weights ( self ) : <TAB> """""" Initialize weights of the head. """""" <TAB> # retinanet_bias_init <TAB> bias_cls = bias_init_with_prob(0.01) <TAB> normal_init(self.conv_reg, std=0.01) <TAB> normal_init(self.conv_centerness, std=0.01) <TAB> normal_init(self.conv_cls, std=0.01, bias=bias_cls) <TAB> for branch in [self.cls_convs, self.reg_convs]: <TAB> <TAB> for module in branch.modules(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> caffe2_xavier_init(module.conv)","if isinstance ( module , caffe2 . AFFE2 ) :","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) :",False,92.93,64.49,,,
"def handle_exception ( self , e , result ) : <TAB> for k in sorted ( result . thrift_spec ) : <TAB> <TAB> if result . thrift_spec [ k ] [ 1 ] == "" success "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> _ , exc_name , exc_cls , _ = result . thrift_spec [ k ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( result , exc_name , e ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise","if isinstance ( exc_cls , Exception ) :","if isinstance ( e , exc_cls ) :",False,96.63,72.04,,,
"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> <TAB> elif subdir : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) )",if script . startswith ( application_root ) :,"if script . startswith ( ""http"" ) :",False,97.86,70.03,,,
"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> <TAB> elif subdir : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) )",if script . startswith ( application_root ) :,if field . auto_created and not field . concrete,False,94.79,70.92,,,
"def setTestOutcome ( self , event ) : <TAB> """""" Update outcome, exc_info and reason based on configured mappings """""" <TAB> if event . exc_info : <TAB> <TAB> ec , ev , tb = event . exc_info <TAB> <TAB> classname = ec . __name__ <TAB> <TAB> if classname in self . treatAsFail : <TAB> <TAB> <TAB> short , long_ = self . labels ( classname ) <TAB> <TAB> <TAB> self . _setOutcome ( event , "" failed "" , short , long_ ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> short , long_ = self . labels ( classname , upper = False ) <TAB> <TAB> <TAB> self . _setOutcome ( event , "" skipped "" , short , "" %s :  ' %s ' "" % ( long_ , ev ) , str ( ev ) )",elif classname in self . treatAsSkip :,elif classname in self . treatAsSkip :,True,100.0,99.55,,,
"def small_count ( v ) : <TAB> if not v : <TAB> <TAB> return 0 <TAB> z = [ <TAB> <TAB> ( 1000000000 , _ ( "" b "" ) ) , <TAB> <TAB> ( 1000000 , _ ( "" m "" ) ) , <TAB> <TAB> ( 1000 , _ ( "" k "" ) ) , <TAB> ] <TAB> v = int ( v ) <TAB> for x , y in z : <TAB> <TAB> o , p = divmod ( v , x ) <TAB> <TAB> if o : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return "" %d %s "" % ( o , y ) <TAB> <TAB> <TAB> return "" %.1f %s "" % ( v / float ( x ) , y ) <TAB> return v",if p :,if len ( str ( o ) ) > 2 or not p :,False,93.87,70.11,,,
"def __read ( self , n ) : <TAB> if self . _read_watcher is None : <TAB> <TAB> raise UnsupportedOperation ( "" read "" ) <TAB> while 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> return _read ( self . _fileno , n ) <TAB> <TAB> except ( IOError , OSError ) as ex : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> wait_on_watcher ( self . _read_watcher , None , None , self . hub )",if ex . errno != errno . EBADF :,if ex . args [ 0 ] not in ignored_errors :,False,92.77,69.53,,,
"def locked ( self ) : <TAB> inputfiles = set ( self . all_inputfiles ( ) ) <TAB> outputfiles = set ( self . all_outputfiles ( ) ) <TAB> if os . path . exists ( self . _lockdir ) : <TAB> <TAB> for lockfile in self . _locks ( "" input "" ) : <TAB> <TAB> <TAB> with open ( lockfile ) as lock : <TAB> <TAB> <TAB> <TAB> for f in lock : <TAB> <TAB> <TAB> <TAB> <TAB> f = f . strip ( ) <TAB> <TAB> <TAB> <TAB> <TAB> if f in outputfiles : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> for lockfile in self . _locks ( "" output "" ) : <TAB> <TAB> <TAB> with open ( lockfile ) as lock : <TAB> <TAB> <TAB> <TAB> for f in lock : <TAB> <TAB> <TAB> <TAB> <TAB> f = f . strip ( ) <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if f in inputfiles :,if f in outputfiles or f in inputfiles :,False,98.53,73.32,,,
"def _flags_to_int ( flags ) : <TAB> # Note, that order does not matter, libev has its own predefined order <TAB> if not flags: <TAB> <TAB> return 0 <TAB> if isinstance(flags, integer_types): <TAB> <TAB> return flags <TAB> result = 0 <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flags = flags.split("","") <TAB> <TAB> for value in flags: <TAB> <TAB> <TAB> value = value.strip().lower() <TAB> <TAB> <TAB> if value: <TAB> <TAB> <TAB> <TAB> result |= _flags_str2int[value] <TAB> except KeyError as ex: <TAB> <TAB> raise ValueError( <TAB> <TAB> <TAB> ""Invalid backend or flag: %s\nPossible values: %s"" <TAB> <TAB> <TAB> % (ex, "", "".join(sorted(_flags_str2int.keys()))) <TAB> <TAB> ) <TAB> return result","if "","" in flags :","if isinstance ( flags , basestring ) :",False,97.28,65.6,,,
"def setFg ( self , colour , override = False ) : <TAB> if not self . ttkFlag : <TAB> <TAB> self . containerStack [ - 1 ] [ "" fg "" ] = colour <TAB> <TAB> gui . SET_WIDGET_FG ( self . _getContainerProperty ( "" container "" ) , colour , override ) <TAB> <TAB> for child in self . _getContainerProperty ( "" container "" ) . winfo_children ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> gui . SET_WIDGET_FG ( child , colour , override ) <TAB> else : <TAB> <TAB> gui . trace ( "" In ttk mode - trying to set FG to  %s "" , colour ) <TAB> <TAB> self . ttkStyle . configure ( "" TLabel "" , foreground = colour ) <TAB> <TAB> self . ttkStyle . configure ( "" TFrame "" , foreground = colour )","if child . get ( ""fg"" ) == colour :",if not self . _isWidgetContainer ( child ) :,False,94.55,67.92,,,
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" SCE_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states )","elif name . startswith ( ""SCIilla_"" ) :","elif name . startswith ( ""SCLEX_"" ) :",False,98.76,73.61,,,
"def extract_error_message ( response : requests . Response ) : <TAB> if response . content : <TAB> <TAB> try : <TAB> <TAB> <TAB> content = json . loads ( response . content ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return content [ "" message "" ] <TAB> <TAB> except : <TAB> <TAB> <TAB> logging . debug ( f "" Failed to parse the response content:  { response . content } "" ) <TAB> return response . reason","if content [ ""status"" ] == ""Error"" :","if ""message"" in content :",False,91.1,64.9,,,
"def canvas_size ( self ) : <TAB> """""" Return the width and height for this sprite canvas """""" <TAB> width = height = 0 <TAB> for image in self . images : <TAB> <TAB> x = image . x + image . absolute_width <TAB> <TAB> y = image . y + image . absolute_height <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> width = x <TAB> <TAB> if height < y : <TAB> <TAB> <TAB> height = y <TAB> return round_up ( width ) , round_up ( height )",if width < x :,if width < x :,True,100.0,99.31,,,
"def _load_widgets ( self ) : <TAB> logger . info ( "" Loading plugins preferences widgets "" ) <TAB> # Collect the preferences widget for each active plugin <TAB> for plugin in self.plugin_manager.get_active_plugins(): <TAB> <TAB> plugin_name = plugin.metadata.get(""name"") <TAB> <TAB> try: <TAB> <TAB> <TAB> preferences_widget = plugin.get_preferences_widget() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self._tabs.addTab(preferences_widget, plugin_name) <TAB> <TAB> except Exception as reason: <TAB> <TAB> <TAB> logger.error( <TAB> <TAB> <TAB> <TAB> ""Unable to add the preferences widget (%s): %s"", plugin_name, reason <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue",if preferences_widget :,if preferences_widget :,True,100.0,74.31,,,
"def clean_objects ( string , common_attributes ) : <TAB> """""" Return object and attribute lists """""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words [ : - 1 ] : <TAB> <TAB> <TAB> if att not in common_attributes : <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ string ] , [ ] <TAB> else : <TAB> <TAB> return [ string ] , [ ]",if prefix_words_are_adj :,if prefix_words_are_adj :,True,100.0,99.5,,,
"def _reader ( ) : <TAB> if shuffle : <TAB> <TAB> random . shuffle ( file_list ) <TAB> while True : <TAB> <TAB> for fn in file_list : <TAB> <TAB> <TAB> for line in open ( fn , "" r "" ) : <TAB> <TAB> <TAB> <TAB> yield self . _process_line ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break",if not self . _has_line ( ) :,if not cycle :,False,91.61,70.73,,,
"def load ( weights , model , K , fsz , dil ) : <TAB> index = 0 <TAB> layers = model . layers <TAB> for layer in layers . _layers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if layer . W . shape == weights [ index ] . shape : <TAB> <TAB> <TAB> <TAB> layer . W [ : ] = weights [ index ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> layer . W [ : ] = dilate ( weights [ index ] , K , fsz , dil ) <TAB> <TAB> <TAB> index + = 1",if layer . shape == weights [ index ] . shape :,"if hasattr ( layer , ""W"" ) :",False,92.31,62.0,,,
"def upgrade ( migrate_engine ) : <TAB> print ( __doc__ ) <TAB> metadata . bind = migrate_engine <TAB> liftoverjobs = dict ( ) <TAB> jobs = context . query ( DeferredJob ) . filter_by ( plugin = "" LiftOverTransferPlugin "" ) . all ( ) <TAB> for job in jobs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] = [ ] <TAB> <TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] . append ( job . id ) <TAB> for parent in liftoverjobs : <TAB> <TAB> lifts = liftoverjobs [ parent ] <TAB> <TAB> deferred = context . query ( DeferredJob ) . filter_by ( id = parent ) . first ( ) <TAB> <TAB> deferred . params [ "" liftover "" ] = lifts <TAB> context . flush ( )","if job . params [ ""parentjob"" ] not in liftoverjobs :","if job . params [ ""parentjob"" ] not in liftoverjobs :",True,100.0,74.58,,,
"def get_refs ( self , recursive = False ) : <TAB> """""" :see: AbstractExpression.get_refs() """""" <TAB> if recursive : <TAB> <TAB> conds_refs = self . refs + sum ( ( c . get_refs ( True ) for c in self . conds ) , [ ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> conds_refs . extend ( self . consequent . get_refs ( True ) ) <TAB> <TAB> return conds_refs <TAB> else : <TAB> <TAB> return self . refs",if self . consequent is not None :,if self . consequent :,False,96.69,69.87,,,
"def _parse ( self , engine ) : <TAB> """""" Parse the layer. """""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' )","if ""axis"" in self . args :","if ""axis"" in self . args :",True,100.0,99.61,,,
"def CountMatches ( pat , predicate ) : <TAB> num_matches = 0 <TAB> for i in xrange ( 256 ) : <TAB> <TAB> b = chr ( i ) <TAB> <TAB> m = pat . match ( b ) <TAB> <TAB> left = bool ( m ) <TAB> <TAB> right = predicate ( i ) <TAB> <TAB> if left != right : <TAB> <TAB> <TAB> self . fail ( "" i =  %d , b =  %r , match:  %s , predicate:  %s "" % ( i , b , left , right ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> num_matches + = 1 <TAB> return num_matches",if m :,if m :,True,100.0,74.41,,,
"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB> <TAB> if len ( kwargs ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> cls . __name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if not args [ 0 ] : <TAB> <TAB> <TAB> return super ( ) . __new__ ( cls ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs )",if kwargs [ 0 ] :,"if isinstance ( args [ 0 ] , cls ) :",False,95.84,71.21,,,
"def concatenateCharacterTokens ( tokens ) : <TAB> pendingCharacters = [ ] <TAB> for token in tokens : <TAB> <TAB> type = token [ "" type "" ] <TAB> <TAB> if type in ( "" Characters "" , "" SpaceCharacters "" ) : <TAB> <TAB> <TAB> pendingCharacters . append ( token [ "" data "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } <TAB> <TAB> <TAB> <TAB> pendingCharacters = [ ] <TAB> <TAB> <TAB> yield token <TAB> <IF-STMT> <TAB> <TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) }",if pendingCharacters :,if pendingCharacters :,True,100.0,74.53,,,
"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB> <TAB> if func . type in support_set : <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> <IF-STMT> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges",if pos < pos_end :,if pos_end >= pos_start :,False,92.5,70.23,,,
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> if fname not in self . _flags : <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if output == input : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if fname in self . _orig :,if self . _flags [ fname ] == 1 :,False,96.45,72.22,,,
"def graph_merge_softmax_with_crossentropy_softmax ( node ) : <TAB> if node . op == softmax_with_bias : <TAB> <TAB> x , b = node . inputs <TAB> <TAB> for x_client in x . clients : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> big_client = x_client [ 0 ] <TAB> <TAB> <TAB> <TAB> if big_client in [ b_client [ 0 ] for b_client in b . clients ] : <TAB> <TAB> <TAB> <TAB> <TAB> xx , bb , ll = big_client . inputs <TAB> <TAB> <TAB> <TAB> <TAB> mergeable_client = big_client . op ( x , b , ll ) <TAB> <TAB> <TAB> <TAB> <TAB> copy_stack_trace ( node . outputs [ 0 ] , mergeable_client [ 1 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> return [ mergeable_client [ 1 ] ]",if x_client in [ x_client [ 0 ] for x_client in b . clients ] :,if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias :,False,93.97,71.36,,,
"def confidence ( self ) : <TAB> if self . bbox : <TAB> <TAB> # Units are measured in Kilometers <TAB> <TAB> distance = Distance(self.northeast, self.southwest, units=""km"") <TAB> <TAB> for score, maximum in [ <TAB> <TAB> <TAB> (10, 0.25), <TAB> <TAB> <TAB> (9, 0.5), <TAB> <TAB> <TAB> (8, 1), <TAB> <TAB> <TAB> (7, 5), <TAB> <TAB> <TAB> (6, 7.5), <TAB> <TAB> <TAB> (5, 10), <TAB> <TAB> <TAB> (4, 15), <TAB> <TAB> <TAB> (3, 20), <TAB> <TAB> <TAB> (2, 25), <TAB> <TAB> ]: <TAB> <TAB> <TAB> if distance < maximum: <TAB> <TAB> <TAB> <TAB> return score <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return 1 <TAB> # Cannot determine score <TAB> return 0",if score > maximum :,if distance >= 25 :,False,98.07,72.57,,,
"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB> <TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB> <TAB> for bp in bplist : <TAB> <TAB> <TAB> if id ( bp ) == item_id : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp . cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self . RespondDebuggerData ( )",if bp . cond == text :,"if text . strip ( ) . lower ( ) == ""none"" :",False,92.68,61.68,,,
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( text , CodeViewText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> elif isinstance ( text , ShellText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( )",if text . autocompleter is None :,"if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) :",False,88.98,67.21,,,
"def visit_Macro ( self , node , frame ) : <TAB> macro_frame , macro_ref = self . macro_body ( node , frame ) <TAB> self . newline ( ) <TAB> if frame . toplevel : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . write ( "" context.exported_vars.add( %r ) "" % node . name ) <TAB> <TAB> ref = frame . symbols . ref ( node . name ) <TAB> <TAB> self . writeline ( "" context.vars[ %r ] =  "" % node . name ) <TAB> self . write ( "" %s  =  "" % frame . symbols . ref ( node . name ) ) <TAB> self . macro_def ( macro_ref , macro_frame )",if not frame . toplevel :,"if not node . name . startswith ( ""_"" ) :",False,93.75,65.82,,,
"def execute ( cls , ctx , op ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return cls . _execute_map ( ctx , op ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return cls . _execute_combine ( ctx , op ) <TAB> finally : <TAB> <TAB> pd . reset_option ( "" mode.use_inf_as_na "" )",if op . map :,if op . stage == OperandStage . map :,False,95.93,71.26,,,
"def ranges ( self , start , end ) : <TAB> try : <TAB> <TAB> iterators = [ i . ranges ( start , end ) for i in self . range_iterators ] <TAB> <TAB> starts , ends , values = zip ( * [ next ( i ) for i in iterators ] ) <TAB> <TAB> starts = list ( starts ) <TAB> <TAB> ends = list ( ends ) <TAB> <TAB> values = list ( values ) <TAB> <TAB> while start < end : <TAB> <TAB> <TAB> min_end = min ( ends ) <TAB> <TAB> <TAB> yield start , min_end , values <TAB> <TAB> <TAB> start = min_end <TAB> <TAB> <TAB> for i , iterator in enumerate ( iterators ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> starts [ i ] , ends [ i ] , values [ i ] = next ( iterator ) <TAB> except StopIteration : <TAB> <TAB> return",if start < start and end < start :,if ends [ i ] == min_end :,False,95.89,72.26,,,
"def get_explanation ( self , spec ) : <TAB> """""" Expand an explanation. """""" <TAB> if spec : <TAB> <TAB> try : <TAB> <TAB> <TAB> a = self . dns_txt ( spec ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB> <TAB> except PermError : <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB> if self.strict > 1: <TAB> <TAB> <TAB> <TAB> raise # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> elif self.strict > 1: <TAB> <TAB> raise PermError(""Empty domain-spec on exp="") <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None",if len ( a ) == 1 :,if len ( a ) == 1 :,True,100.0,99.58,,,
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> if exclude_meta and field . meta : <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> if field_val is _marker : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val",if exclude_unset :,if exclude_unset :,True,100.0,74.54,,,
"def __setattr__ ( self , name , value ) : <TAB> try : <TAB> <TAB> field = self . _meta . get_field ( name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = value [ : field . max_length ] <TAB> except models . fields . FieldDoesNotExist : <TAB> <TAB> pass # This happens with foreign keys. <TAB> super.__setattr__(self, name, value)",if field . max_length and field . max_length < value :,"if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str :",False,82.34,61.28,,,
"def create_child ( self , value = None , _id = None ) : <TAB> with atomic ( savepoint = False ) : <TAB> <TAB> child_key = self . get_next_child_key ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = child_key <TAB> <TAB> child = self . __class__ . objects . create ( id = _id , key = child_key , value = value ) <TAB> <TAB> return child",if value is None :,if value is None :,True,100.0,74.17,,,
"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ "" HasMoreTags "" ] = True <TAB> <TAB> <TAB> break <TAB> <TAB> if exclusive_start_tag_key and key < exclusive_start_tag_key : <TAB> <TAB> <TAB> continue <TAB> <TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result",if key >= limit :,if limit and len ( tags ) >= limit :,False,96.33,71.73,,,
"def emit ( self , record ) : <TAB> try : <TAB> <TAB> app = get_app ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = self . format ( record ) <TAB> <TAB> <TAB> debug_buffer = app . layout . get_buffer_by_name ( "" debug_buffer "" ) <TAB> <TAB> <TAB> current_document = debug_buffer . document . text <TAB> <TAB> <TAB> if current_document : <TAB> <TAB> <TAB> <TAB> msg = "" \n "" . join ( [ current_document , msg ] ) <TAB> <TAB> <TAB> debug_buffer . set_document ( Document ( text = msg ) , bypass_readonly = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> super ( ) . emit ( record ) <TAB> except : <TAB> <TAB> self . handleError ( record )",if self . debug :,"if app . is_running and getattr ( app , ""debug"" , False ) :",False,92.53,63.74,,,
"def worker ( ) : <TAB> global error <TAB> while True : <TAB> <TAB> ( num , q ) = pq . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pq . task_done ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> try : <TAB> <TAB> <TAB> process_one ( q ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> error = e <TAB> <TAB> finally : <TAB> <TAB> <TAB> pq . task_done ( )",if num == 0 :,if q is None or error is not None :,False,93.36,67.9,,,
"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB> <TAB> if data [ t ] == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data [ t ] <TAB> <TAB> for b in range ( 8 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if len ( TRANSCEIVER [ t ] ) < b + 1 : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( "" (unknown) "" ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB> <TAB> <TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) )",if value & 1 :,if value & 0x80 :,False,98.84,73.67,,,
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> if self . opHash . has_key ( tval ) : <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount < = 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break","if ttype == ""close"" :",if ttype == SCE_PL_UNUSED :,False,97.47,66.84,,,
"def GenerateVector ( self , hits , vector , level ) : <TAB> """""" Generate possible hit vectors which match the rules. """""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> if vector : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> if level + 1 == len ( hits ) : <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result",if item not in vector :,if item < vector [ - 1 ] :,False,96.75,95.69,,,
"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value [ 0 ] != "" / "" : <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == "" load_time "" : <TAB> <TAB> if value and not isinstance ( value , int ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Page load time must be specified in integer milliseconds. "" <TAB> <TAB> <TAB> ) <TAB> object . __setattr__ ( self , name , value )",if value :,"if value and value != """" :",False,96.43,51.96,,,
"def awaitTermination ( self , timeout = None ) : <TAB> if self . scheduler is None : <TAB> <TAB> raise RuntimeError ( "" StreamimgContext not started "" ) <TAB> try : <TAB> <TAB> deadline = time . time ( ) + timeout if timeout is not None else None <TAB> <TAB> while True : <TAB> <TAB> <TAB> is_terminated = self . _runOnce ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self . batchCallback : <TAB> <TAB> <TAB> <TAB> self . batchCallback ( ) <TAB> except KeyboardInterrupt : <TAB> <TAB> pass <TAB> finally : <TAB> <TAB> self . sc . stop ( ) <TAB> <TAB> logger . info ( "" StreamingContext stopped successfully "" )",if is_terminated :,if is_terminated or ( deadline is not None and time . time ( ) > deadline ) :,False,91.87,68.31,,,
"def stopbutton ( self ) : <TAB> if GPIOcontrol : <TAB> <TAB> while mediastopbutton : <TAB> <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> print ( "" Stopped "" ) <TAB> <TAB> <TAB> <TAB> stop ( )",if self . debug :,if not GPIO . input ( stoppushbutton ) :,False,90.28,65.79,,,
"def test_create_connection_timeout ( self ) : <TAB> # Issue #9792: create_connection() should not recast timeout errors <TAB> # as generic socket errors. <TAB> with self.mocked_socket_module(): <TAB> <TAB> try: <TAB> <TAB> <TAB> socket.create_connection((HOST, 1234)) <TAB> <TAB> except socket.timeout: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else: <TAB> <TAB> <TAB> self.fail(""socket.timeout not raised"")",if exc . errno != errno . ECONNRESET :,if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT :,False,94.39,68.92,,,
"def handle_exception_and_die ( e ) : <TAB> if hasattr ( e , "" kind "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sys . stderr . write ( "" ABORT:  "" + e . msg + "" \n "" ) <TAB> <TAB> <TAB> sys . exit ( e . value ) <TAB> <TAB> elif e . kind == "" exit "" : <TAB> <TAB> <TAB> sys . stderr . write ( "" EXITING \n "" ) <TAB> <TAB> <TAB> sys . exit ( e . value ) <TAB> else : <TAB> <TAB> print ( str ( e ) ) <TAB> <TAB> sys . exit ( 1 )","if e . kind == ""abort"" :","if e . kind == ""die"" :",False,98.52,73.33,,,
"def gets ( self , key ) : <TAB> with self . client_pool . get_and_release ( destroy_on_fail = True ) as client : <TAB> <TAB> try : <TAB> <TAB> <TAB> return client . gets ( key ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return ( None , None ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise",if self . fail_silently :,if self . ignore_exc :,False,96.57,72.38,,,
"def _execute ( self , options , args ) : <TAB> if len ( args ) < 3 : <TAB> <TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> tag = fsn2text ( args [ 0 ] ) <TAB> value = fsn2text ( args [ 1 ] ) <TAB> paths = args [ 2 : ] <TAB> songs = [ ] <TAB> for path in paths : <TAB> <TAB> song = self . load_song ( path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CommandError ( _ ( "" Can not set  %r "" ) % tag ) <TAB> <TAB> self . log ( "" Add  %r  to  %r "" % ( value , tag ) ) <TAB> <TAB> song . add ( tag , value ) <TAB> <TAB> songs . append ( song ) <TAB> self . save_songs ( songs )",if not song :,if not song . can_change ( tag ) :,False,95.87,72.52,,,
"def get_place_name ( self , place_handle ) : <TAB> """""" Obtain a place name """""" <TAB> text = "" "" <TAB> if place_handle : <TAB> <TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB> <TAB> if place : <TAB> <TAB> <TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if len ( place_title ) > 25 : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title [ : 24 ] + "" ... "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text",if place_title :,"if place_title != """" :",False,97.39,66.65,,,
"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> self . value = os . environ . get ( self . name , None ) <TAB> if self . value is None and black . configure . items . has_key ( "" buildType "" ) : <TAB> <TAB> buildType = black . configure . items [ "" buildType "" ] . Get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . value = "" warn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = None <TAB> self . determined = 1","if buildType == ""warn"" :","if buildType == ""debug"" :",False,98.22,73.18,,,
"def bundle_directory ( self , dirpath ) : <TAB> """""" Bundle all modules/packages in the given directory. """""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> elif nm . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . bundle_module ( itempath )","if not nm . startswith ( ""_"" ) :","if nm . startswith ( ""."" ) :",False,97.69,95.35,,,
"def header_fields ( self , fields ) : <TAB> headers = dict ( self . conn . response . getheaders ( ) ) <TAB> ret = { } <TAB> for field in fields : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" %s  was not found in response header "" % ( field [ 1 ] ) ) <TAB> <TAB> try : <TAB> <TAB> <TAB> ret [ field [ 0 ] ] = int ( headers [ field [ 1 ] ] ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> ret [ field [ 0 ] ] = headers [ field [ 1 ] ] <TAB> return ret",if field [ 0 ] not in headers :,if not headers . has_key ( field [ 1 ] ) :,False,92.61,70.42,,,
"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB> <TAB> n = ord ( char ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB> <TAB> if 96 < n < 123 : <TAB> <TAB> <TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB> <TAB> result = result + chr ( n ) <TAB> return result",if 65 < n < 65 :,if 64 < n < 91 :,False,96.08,71.65,,,
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args: <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr(val, ""__len__""): <TAB> <TAB> <TAB> val = str(val) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver.needsQuoting(val, True): <TAB> <TAB> <TAB> value = value.replace('""', '""""') <TAB> <TAB> <TAB> value = '""' + value + '""' <TAB> <TAB> res = ((res and res + ""."") or """") + value <TAB> return res","if val == """" :",if len ( val ) == 0 :,False,96.89,65.72,,,
"def _parse_timezone ( <TAB> value : Optional [ str ] , error : Type [ Exception ] ) - > Union [ None , int , timezone ] : <TAB> if value == "" Z "" : <TAB> <TAB> return timezone . utc <TAB> elif value is not None : <TAB> <TAB> offset_mins = int ( value [ - 2 : ] ) if len ( value ) > 3 else 0 <TAB> <TAB> offset = 60 * int ( value [ 1 : 3 ] ) + offset_mins <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> offset = - offset <TAB> <TAB> try : <TAB> <TAB> <TAB> return timezone ( timedelta ( minutes = offset ) ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise error ( ) <TAB> else : <TAB> <TAB> return None","if value [ - 2 ] == ""-"" :","if value [ 0 ] == ""-"" :",False,98.3,73.53,,,
"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * "" "" <TAB> if len ( elem ) : <TAB> <TAB> if not elem . text or not elem . text . strip ( ) : <TAB> <TAB> <TAB> elem . text = i + "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elem . tail = i <TAB> <TAB> for elem in elem : <TAB> <TAB> <TAB> indent ( elem , level + 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elem . tail = i <TAB> else : <TAB> <TAB> if level and ( not elem . tail or not elem . tail . strip ( ) ) : <TAB> <TAB> <TAB> elem . tail = i",if not elem . tail or not elem . tail . strip ( ) :,if not elem . tail or not elem . tail . strip ( ) :,True,100.0,74.62,,,
"def _make_slices ( <TAB> shape : tp . Tuple [ int , . . . ] , <TAB> axes : tp . Tuple [ int , . . . ] , <TAB> size : int , <TAB> rng : np . random . RandomState , ) - > tp . List [ slice ] : <TAB> slices = [ ] <TAB> for a , s in enumerate ( shape ) : <TAB> <TAB> if a in axes : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Cannot crossover on axis with size 1 "" ) <TAB> <TAB> <TAB> start = rng . randint ( s - size ) <TAB> <TAB> <TAB> slices . append ( slice ( start , start + size ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> slices . append ( slice ( None ) ) <TAB> return slices",if s == 1 :,if s <= 1 :,False,98.79,73.76,,,
"def _loadTestsFromTestCase ( self , event , testCaseClass ) : <TAB> evt = events . LoadFromTestCaseEvent ( event . loader , testCaseClass ) <TAB> result = self . session . hooks . loadTestsFromTestCase ( evt ) <TAB> if evt . handled : <TAB> <TAB> loaded_suite = result or event . loader . suiteClass ( ) <TAB> else : <TAB> <TAB> names = self . _getTestCaseNames ( event , testCaseClass ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> names = [ "" runTest "" ] <TAB> <TAB> # FIXME return failure test case if name not in testcase class <TAB> <TAB> loaded_suite = event.loader.suiteClass(map(testCaseClass, names)) <TAB> if evt.extraTests: <TAB> <TAB> loaded_suite.addTests(evt.extraTests) <TAB> return loaded_suite",if not names :,"if not names and hasattr ( testCaseClass , ""runTest"" ) :",False,94.55,64.14,,,
"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB> <TAB> if not settings . USE_TZ : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB> <TAB> <TAB> <TAB> "" False. "" % self . alias <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB> <TAB> <TAB> <TAB> "" handles time zones conversions natively. "" % self . alias <TAB> <TAB> <TAB> )","if self . settings_dict [ ""ENGINE"" ] != ""local"" :",elif self . features . supports_timezones :,False,92.04,66.4,,,
"def collect_conflicting_diffs ( path , decisions ) : <TAB> local_conflict_diffs = [ ] <TAB> remote_conflict_diffs = [ ] <TAB> for d in decisions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ld = adjust_patch_level ( path , d . common_path , d . local_diff ) <TAB> <TAB> <TAB> rd = adjust_patch_level ( path , d . common_path , d . remote_diff ) <TAB> <TAB> <TAB> local_conflict_diffs . extend ( ld ) <TAB> <TAB> <TAB> remote_conflict_diffs . extend ( rd ) <TAB> return local_conflict_diffs , remote_conflict_diffs",if d . local_diff != d . remote_diff :,if d . conflict :,False,93.44,71.8,,,
"def short_repr ( obj ) : <TAB> if isinstance ( <TAB> <TAB> obj , <TAB> <TAB> ( type , types . ModuleType , types . BuiltinMethodType , types . BuiltinFunctionType ) , <TAB> ) : <TAB> <TAB> return obj . __name__ <TAB> if isinstance ( obj , types . MethodType ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return obj . im_func . __name__ + ""  (bound) "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return obj . im_func . __name__ <TAB> if isinstance ( obj , ( tuple , list , dict , set ) ) : <TAB> <TAB> return "" %d  items "" % len ( obj ) <TAB> if isinstance ( obj , weakref . ref ) : <TAB> <TAB> return "" all_weakrefs_are_one "" <TAB> return repr ( obj ) [ : 40 ]",if obj . bound :,if obj . im_self is not None :,False,96.63,72.35,,,
"def short_repr ( obj ) : <TAB> if isinstance ( <TAB> <TAB> obj , <TAB> <TAB> ( type , types . ModuleType , types . BuiltinMethodType , types . BuiltinFunctionType ) , <TAB> ) : <TAB> <TAB> return obj . __name__ <TAB> if isinstance ( obj , types . MethodType ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return obj . im_func . __name__ + ""  (bound) "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return obj . im_func . __name__ <TAB> if isinstance ( obj , ( tuple , list , dict , set ) ) : <TAB> <TAB> return "" %d  items "" % len ( obj ) <TAB> if isinstance ( obj , weakref . ref ) : <TAB> <TAB> return "" all_weakrefs_are_one "" <TAB> return repr ( obj ) [ : 40 ]",if obj . bound :,"if uri . startswith ( ""hdfs:///"" ) :",False,94.12,67.1,,,
"def chsub ( self , msg , chatid ) : <TAB> ( cmd , evt , params ) = self . tokenize ( msg , 3 ) <TAB> if cmd == "" /sub "" : <TAB> <TAB> sql = "" replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?) "" <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sql = "" delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1) "" # does not look very elegant, but makes unsub'ing everythign possible <TAB> <TAB> else: <TAB> <TAB> <TAB> sql = ""delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ?"" <TAB> with self.bot.database as conn: <TAB> <TAB> conn.execute(sql, [chatid, evt, params]) <TAB> <TAB> conn.commit() <TAB> return","if evt == ""delete"" :","if evt == ""everything"" :",False,98.9,73.63,,,
"def undefined_symbols ( self ) : <TAB> result = [ ] <TAB> for p in self . Productions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for s in p . prod : <TAB> <TAB> <TAB> if not s in self . Prodnames and not s in self . Terminals and s != "" error "" : <TAB> <TAB> <TAB> <TAB> result . append ( ( s , p ) ) <TAB> return result",if not p . is_symbol :,if not p :,False,95.34,72.7,,,
"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB> <TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB> <TAB> if m is not None : <TAB> <TAB> <TAB> sx , sy = m . groups ( ) <TAB> <TAB> <TAB> x = colname2num ( sx ) <TAB> <TAB> <TAB> y = int ( sy ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> part = cellname ( x + dx , y + dy ) <TAB> <TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment )",if x1 == x2 and y1 == y2 :,if x1 <= x <= x2 and y1 <= y <= y2 :,False,95.37,71.7,,,
"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB> <TAB> gate = column [ i ] <TAB> <TAB> if gate is self : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column[i] = None <TAB> <TAB> <TAB> self._basis_change += gate._basis_change <TAB> <TAB> <TAB> self.qubits += gate.qubits <TAB> <TAB> elif gate is not None: <TAB> <TAB> <TAB> column[i] = gate.controlled_by(self.qubits[0])",if gate is not None :,"elif isinstance ( gate , ParityControlCell ) :",False,96.11,70.82,,,
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . ENABLED : <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . CONNECT_MODE : <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets )",if k == neighbors . MED :,if k == neighbors . MULTI_EXIT_DISC :,False,96.24,73.11,,,
"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB> <TAB> val = self . nodeValue <TAB> <TAB> if not isinstance ( val , str ) : <TAB> <TAB> <TAB> val = str ( self . nodeValue ) <TAB> else : <TAB> <TAB> v = self . nodeValue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = str ( v ) <TAB> <TAB> if strip : <TAB> <TAB> <TAB> v = "" "" . join ( v . split ( ) ) <TAB> <TAB> val = escape ( v ) <TAB> w ( val )","if not isinstance ( v , str ) :","if not isinstance ( v , str ) :",True,100.0,74.58,,,
"def _condition ( ct ) : <TAB> for qobj in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj.children: <TAB> <TAB> <TAB> <TAB> kwargs.update(dict([child])) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <TAB> <TAB> if getattr(ct, attr) != val: <TAB> <TAB> <TAB> return False <TAB> return True","if isinstance ( qobj , QObject ) :","if qobj . connector == ""AND"" and not qobj . negated :",False,91.54,60.78,,,
"def results_iter ( self ) : <TAB> <IF-STMT> <TAB> <TAB> from django . db . models . fields import DateTimeField <TAB> <TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB> <TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB> <TAB> for row in rows : <TAB> <TAB> <TAB> date = row [ offset ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB> <TAB> <TAB> elif needs_string_cast : <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp ( str ( date ) ) <TAB> <TAB> <TAB> yield date",if fields :,if self . connection . ops . oracle :,False,92.45,68.64,,,
"def get_job_type ( self ) : <TAB> if int ( self . job_runtime_conf . get ( "" dsl_version "" , 1 ) ) == 2 : <TAB> <TAB> job_type = ( <TAB> <TAB> <TAB> self . job_runtime_conf [ "" job_parameters "" ] . get ( "" common "" , { } ) . get ( "" job_type "" ) <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> else : <TAB> <TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> return job_type","elif job_type == ""train"" :",if not job_type :,False,95.54,69.39,,,
"def validate_assessment_criteria ( self ) : <TAB> if self . assessment_criteria : <TAB> <TAB> total_weightage = 0 <TAB> <TAB> for criteria in self . assessment_criteria : <TAB> <TAB> <TAB> total_weightage + = criteria . weightage or 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Total Weightage of all Assessment Criteria must be 100 % "" ) )",if total_weightage > 100 :,if total_weightage != 100 :,False,96.7,72.19,,,
"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB> <TAB> for x in notifications_list : <TAB> <TAB> <TAB> split_provider_id = x . split ( "" : "" ) # email:id <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _id = split_provider_id[1] <TAB> <TAB> <TAB> <TAB> cursor = self.get_by_id(_id) <TAB> <TAB> <TAB> <TAB> if cursor: # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result.append(cursor) <TAB> return result","if split_provider_id [ 0 ] == ""email"" :",if len ( split_provider_id ) == 2 :,False,94.84,62.13,,,
"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB> <TAB> for x in notifications_list : <TAB> <TAB> <TAB> split_provider_id = x . split ( "" : "" ) # email:id <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> _id = split_provider_id[1] <TAB> <TAB> <TAB> <TAB> cursor = self.get_by_id(_id) <TAB> <TAB> <TAB> <TAB> if cursor: # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result.append(cursor) <TAB> return result","if split_provider_id [ 0 ] == ""email"" :",if relation_is_present,False,92.47,62.85,,,
"def __init__ ( self , * * kwargs ) : <TAB> # We hard-code the `to` argument for ForeignKey.__init__ <TAB> dfl = get_model_label(self.default_model_class) <TAB> if ""to"" in kwargs.keys(): # pragma: no cover <TAB> <TAB> old_to = get_model_label(kwargs.pop(""to"")) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg = ""%s can only be a ForeignKey to %s; %s passed"" % ( <TAB> <TAB> <TAB> <TAB> self.__class__.__name__, <TAB> <TAB> <TAB> <TAB> dfl, <TAB> <TAB> <TAB> <TAB> old_to, <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> warnings.warn(msg, SyntaxWarning) <TAB> kwargs[""to""] = dfl <TAB> super().__init__(**kwargs)",if old_to != dfl :,if old_to . lower ( ) != dfl . lower ( ) :,False,95.67,68.92,,,
"def reverse ( self ) : <TAB> """""" Reverse *IN PLACE*. """""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB> <TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB> <TAB> li + = 1 <TAB> <TAB> if li > = BLOCKLEN : <TAB> <TAB> <TAB> lb = lb . rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rb = rb . leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1",if ri >= BLOCKLEN :,if ri < 0 :,False,97.73,85.84,,,
"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB> <TAB> API_CACHE_LOCK . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if API_CACHE is None : <TAB> <TAB> <TAB> <TAB> API_CACHE = { } <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api",if not API_CACHE [ url ] :,if API_CACHE . get ( url ) is None :,False,94.86,70.11,,,
"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB> <TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> start , stop = index . start , index . stop <TAB> <TAB> new_start , new_stop = None , None <TAB> <TAB> if start is not None : <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB> <TAB> new_index = [ ] <TAB> <TAB> for ind in index : <TAB> <TAB> <TAB> new_index . append ( length - ind ) <TAB> return new_index",if stop is not None :,if stop is not None :,True,100.0,74.56,,,
"def infer_returned_object ( pyfunction , args ) : <TAB> """""" Infer the `PyObject` this `PyFunction` returns after calling """""" <TAB> object_info = pyfunction . pycore . object_info <TAB> result = object_info . get_exact_returned ( pyfunction , args ) <TAB> if result is not None : <TAB> <TAB> return result <TAB> result = _infer_returned ( pyfunction , args ) <TAB> if result is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> params = args . get_arguments ( pyfunction . get_param_names ( special_args = False ) ) <TAB> <TAB> <TAB> object_info . function_called ( pyfunction , params , result ) <TAB> <TAB> return result <TAB> return object_info . get_returned ( pyfunction , args )",if pyfunction . get_param_names ( ) :,if args and pyfunction . get_module ( ) . get_resource ( ) is not None :,False,92.28,90.39,,,
"def _check_imports ( lib ) : <TAB> # Make sure no conflicting libraries have been imported. <TAB> libs = [""PyQt4"", ""PyQt5"", ""PySide""] <TAB> libs.remove(lib) <TAB> for lib2 in libs: <TAB> <TAB> lib2 += "".QtCore"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError( <TAB> <TAB> <TAB> <TAB> ""Refusing to import %s because %s is already "" ""imported."" % (lib, lib2) <TAB> <TAB> <TAB> )",if lib2 in libs :,if lib2 in sys . modules :,False,96.72,70.91,,,
"def _poll ( fds , timeout ) : <TAB> if timeout is not None : <TAB> <TAB> timeout = int ( timeout * 1000 ) # timeout is in milliseconds <TAB> fd_map = {} <TAB> pollster = select.poll() <TAB> for fd in fds: <TAB> <TAB> pollster.register(fd, select.POLLIN) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fd_map[fd.fileno()] = fd <TAB> <TAB> else: <TAB> <TAB> <TAB> fd_map[fd] = fd <TAB> ls = [] <TAB> for fd, event in pollster.poll(timeout): <TAB> <TAB> if event & select.POLLNVAL: <TAB> <TAB> <TAB> raise ValueError(""invalid file descriptor %i"" % fd) <TAB> <TAB> ls.append(fd_map[fd]) <TAB> return ls",if fd . fileno ( ) in fd_map :,"if hasattr ( fd , ""fileno"" ) :",False,95.68,64.17,,,
"def default ( cls , connection = None ) : <TAB> """""" show the default connection, or make CONNECTION the default """""" <TAB> if connection is not None : <TAB> <TAB> target = cls . _get_config_filename ( connection ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if os . path . exists ( cls . _default_symlink ) : <TAB> <TAB> <TAB> <TAB> os . remove ( cls . _default_symlink ) <TAB> <TAB> <TAB> os . symlink ( target , cls . _default_symlink ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cls . _no_config_file_error ( target ) <TAB> if os . path . exists ( cls . _default_symlink ) : <TAB> <TAB> print ( "" Default connection is  "" + cls . _default_connection ( ) ) <TAB> else : <TAB> <TAB> print ( "" There is no default connection set "" )",if os . path . exists ( target ) :,if os . path . exists ( target ) :,True,100.0,99.58,,,
"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB> <TAB> record = line . split ( "" / "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> if record[0] == ""D"": <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, record[1])) <TAB> <TAB> <TAB> <TAB> self.queue_url(urljoin(base_url, ""%s/CVS/Entries"" % (record[1])))","if record [ 0 ] == ""CVS"" :",if len ( record ) == 6 and record [ 1 ] :,False,94.26,63.86,,,
"def _GetCSVRow ( self , value ) : <TAB> row = [ ] <TAB> for type_info in value . __class__ . type_infos : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> row . extend ( self . _GetCSVRow ( value . Get ( type_info . name ) ) ) <TAB> <TAB> elif isinstance ( type_info , rdf_structs . ProtoBinary ) : <TAB> <TAB> <TAB> row . append ( text . Asciify ( value . Get ( type_info . name ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> row . append ( str ( value . Get ( type_info . name ) ) ) <TAB> return row","if isinstance ( type_info , rdf_structs . ProtoArray ) :","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) :",False,98.55,73.36,,,
"def get_history ( self , state , dict_ , passive = PASSIVE_OFF ) : <TAB> if self . key in dict_ : <TAB> <TAB> return History . from_scalar_attribute ( self , state , dict_ [ self . key ] ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> passive ^ = INIT_OK <TAB> <TAB> current = self . get ( state , dict_ , passive = passive ) <TAB> <TAB> if current is PASSIVE_NO_RESULT : <TAB> <TAB> <TAB> return HISTORY_BLANK <TAB> <TAB> else : <TAB> <TAB> <TAB> return History . from_scalar_attribute ( self , state , current )","if self . key == ""state"" :",if passive & INIT_OK :,False,94.49,63.47,,,
"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB> <TAB> result + = ( current , ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> elif current . _parent is None : <TAB> <TAB> <TAB> raise sa_exc . InvalidRequestError ( <TAB> <TAB> <TAB> <TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> current = current . _parent <TAB> return result",if current . _parent is None :,if current . _parent is upto :,False,98.5,73.16,,,
"def get_by_uri ( self , uri : str ) - > bytes : <TAB> userId , bucket , key = self . _parse_uri ( uri ) <TAB> try : <TAB> <TAB> with db . session_scope ( ) as dbsession : <TAB> <TAB> <TAB> result = db_archivedocument . get ( userId , bucket , key , session = dbsession ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return utils . ensure_bytes ( self . _decode ( result ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ObjectKeyNotFoundError ( userId , bucket , key , caused_by = None ) <TAB> except Exception as err : <TAB> <TAB> logger . debug ( "" cannot get data: exception -  "" + str ( err ) ) <TAB> <TAB> raise err",if result :,if result :,True,100.0,74.51,,,
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB> <TAB> <TAB> pass <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break","elif message [ ""type"" ] == ""websocket.disconnect"" :","elif message [ ""type"" ] == ""websocket.disconnect"" :",True,100.0,74.27,,,
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> if r is None : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y )",if e :,elif r :,False,98.4,73.36,,,
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event )",if self . scroll_rect ( ) . is_visible ( ) :,if self . scrolling :,False,94.55,72.44,,,
"def copy_from ( self , other ) : <TAB> if self is other : <TAB> <TAB> return # Myself! <TAB> self.strictness = other.strictness # sets behaviors in bulk <TAB> for name in self.all_behaviors: <TAB> <TAB> self.set_behavior(name, other.get_behavior(name)) <TAB> for name in self._plain_attrs: <TAB> <TAB> val = getattr(other, name) <TAB> <TAB> if isinstance(val, set): <TAB> <TAB> <TAB> val = val.copy() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = val.copy() <TAB> <TAB> setattr(self, name, val)","elif isinstance ( val , dict ) :","elif decimal and isinstance ( val , decimal . Decimal ) :",False,95.57,69.41,,,
"def __array_wrap__ ( self , out_arr , context = None ) : <TAB> if self . dim is None : <TAB> <TAB> return out_arr <TAB> else : <TAB> <TAB> this = self [ : ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return Quantity . __array_wrap__ ( self [ : ] , out_arr , context = context ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return out_arr","if isinstance ( this , ( list , tuple ) ) :","if isinstance ( this , Quantity ) :",False,94.89,71.23,,,
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """""" Check if the function argument list has a dictionary as an arg. """""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> if token . ClosesScope ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token . OpensScope ( ) : <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False","if token . match ( ""dictionary"" ) :","if token . value == ""{"" :",False,96.68,95.16,,,
"def save_all_changed_extensions ( self ) : <TAB> """""" Save configuration changes to the user config file. """""" <TAB> has_changes = False <TAB> for ext_name in self . extensions : <TAB> <TAB> options = self . extensions [ ext_name ] <TAB> <TAB> for opt in options : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> has_changes = True <TAB> if has_changes : <TAB> <TAB> self . ext_userCfg . Save ( )",if opt . changed :,"if self . set_extension_value ( ext_name , opt ) :",False,89.08,87.7,,,
"def to_dict ( self ) : <TAB> out = { } <TAB> for key in ACTIVITY_KEYS : <TAB> <TAB> attr = getattr ( self , key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out [ key ] = str ( attr ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out [ key ] = attr <TAB> if self . streak : <TAB> <TAB> out [ "" streak "" ] = self . streak <TAB> return out","if isinstance ( attr , str ) :","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) :",False,91.76,68.6,,,
"def clean_publication_date ( cls , cleaned_input ) : <TAB> for add_channel in cleaned_input . get ( "" add_channels "" , [ ] ) : <TAB> <TAB> is_published = add_channel . get ( "" is_published "" ) <TAB> <TAB> publication_date = add_channel . get ( "" publication_date "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> add_channel [ "" publication_date "" ] = datetime . date . today ( )",if is_published and publication_date :,if is_published and not publication_date :,False,97.97,72.17,,,
"def _random_blur ( self , batch , sigma_max ) : <TAB> for i in range ( len ( batch ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Random sigma <TAB> <TAB> <TAB> sigma = random.uniform(0.0, sigma_max) <TAB> <TAB> <TAB> batch[i] = scipy.ndimage.filters.gaussian_filter(batch[i], sigma) <TAB> return batch",if self . _random_blur :,if bool ( random . getrandbits ( 1 ) ) :,False,91.16,65.15,,,
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> if dsn [ i ] . isspace ( ) : <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> if not param_match : <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret","if param == ""*"" :",if i >= length :,False,97.04,64.75,,,
"def set_environment_vars ( env , source_env ) : <TAB> """""" Copy allowed environment variables from |source_env|. """""" <TAB> if not source_env : <TAB> <TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB> <TAB> if is_forwarded_environment_variable ( name ) : <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = file_host.rebase_to_worker_root(value) <TAB> <TAB> <TAB> env[name] = value","if not isinstance ( value , six . string_types ) :","if os . getenv ( ""TRUSTED_HOST"" ) and should_rebase_environment_value ( name ) :",False,89.19,93.38,,,
"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i, entry in enumerate(self.reprentries): <TAB> <TAB> if entry.style == ""long"": <TAB> <TAB> <TAB> tw.line("""") <TAB> <TAB> entry.toterminal(tw) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> next_entry = self.reprentries[i + 1] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry.style == ""long"" <TAB> <TAB> <TAB> <TAB> or entry.style == ""short"" <TAB> <TAB> <TAB> <TAB> and next_entry.style == ""long"" <TAB> <TAB> <TAB> ): <TAB> <TAB> <TAB> <TAB> tw.sep(self.entrysep) <TAB> if self.extraline: <TAB> <TAB> tw.line(self.extraline)","if last_style is not None and last_style . style == ""short"" :",if i < len ( self . reprentries ) - 1 :,False,92.91,86.31,,,
"def __init__ ( self , loc , tabs = None ) : <TAB> if os . path . isdir ( loc ) : <TAB> <TAB> for item in os . listdir ( loc ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> path = os . path . join ( loc , item ) <TAB> <TAB> <TAB> self . append ( CronTab ( user = False , tabfile = path ) ) <TAB> elif os . path . isfile ( loc ) : <TAB> <TAB> self . append ( CronTab ( user = False , tabfile = loc ) )","if item . startswith ( ""_"" ) :","if item [ 0 ] == ""."" :",False,94.36,71.6,,,
"def import_data ( self , fname ) : <TAB> """""" Import data in current namespace """""" <TAB> if self . count ( ) : <TAB> <TAB> nsb = self . currentWidget ( ) <TAB> <TAB> nsb . refresh_table ( ) <TAB> <TAB> nsb . import_data ( fname ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . dockwidget . setVisible ( True ) <TAB> <TAB> <TAB> self . dockwidget . raise_ ( )",if self . dockwidget :,if self . dockwidget and not self . ismaximized :,False,94.65,66.57,,,
"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB> <TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB> <TAB> <TAB> <TAB> if tag == "" @menu "" : <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList",if child . h . startswith ( tag ) :,if child . h . startswith ( tag ) :,True,100.0,74.63,,,
"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB> <TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB> <TAB> if hasattr ( args [ 0 ] , "" iteritems "" ) : <TAB> <TAB> <TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> items = list ( args [ 0 ] . items ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> items = list ( args [ 0 ] ) <TAB> <TAB> self . _items = items <TAB> else : <TAB> <TAB> self . _items = [ ] <TAB> if kw : <TAB> <TAB> self . _items . extend ( kw . items ( ) )","elif hasattr ( args [ 0 ] , ""items"" ) :","elif hasattr ( args [ 0 ] , ""items"" ) :",True,100.0,74.59,,,
"def open ( self ) - > "" KeyValueDb "" : <TAB> """""" Create a new data base or open existing one """""" <TAB> if os . path . exists ( self . _name ) : <TAB> <TAB> if not os . path . isfile ( self . _name ) : <TAB> <TAB> <TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # ignore empty files <TAB> <TAB> <TAB> return self <TAB> <TAB> with open(self._name, ""rb"") as _in: # binary mode <TAB> <TAB> <TAB> self.set_records(pickle.load(_in)) <TAB> else: <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath(os.path.dirname(self._name)) <TAB> <TAB> self.commit() <TAB> return self",if self . _records :,if os . path . getsize ( self . _name ) == 0 :,False,94.03,92.83,,,
"def sortModules ( self ) : <TAB> super ( NeuronDecomposableNetwork , self ) . sortModules ( ) <TAB> self . _constructParameterInfo ( ) <TAB> # contains a list of lists of indices <TAB> self.decompositionIndices = {} <TAB> for neuron in self._neuronIterator(): <TAB> <TAB> self.decompositionIndices[neuron] = [] <TAB> for w in range(self.paramdim): <TAB> <TAB> inneuron, outneuron = self.paramInfo[w] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.decompositionIndices[inneuron].append(w) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.decompositionIndices[outneuron].append(w)",if inneuron in self . decompositionIndices :,if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules :,False,92.94,66.99,,,
"def visit_Options ( self , node : qlast . Options ) - > None : <TAB> for i , opt in enumerate ( node . options . values ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> self . write ( opt . name ) <TAB> <TAB> if not isinstance ( opt , qlast . Flag ) : <TAB> <TAB> <TAB> self . write ( f "" { opt . val } "" )",if i :,if i > 0 :,False,96.94,72.32,,,
"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> if possible_child_hash == item_hash : <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash",if possible_child_hash not in self . items :,if possible_child_hash not in self . items :,True,100.0,74.2,,,
"def __call__ ( self , text , * * kargs ) : <TAB> words = jieba . tokenize ( text , mode = "" search "" ) <TAB> token = Token ( ) <TAB> for ( w , start_pos , stop_pos ) in words : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> token . original = token . text = w <TAB> <TAB> token . pos = start_pos <TAB> <TAB> token . startchar = start_pos <TAB> <TAB> token . endchar = stop_pos <TAB> <TAB> yield token",if w == 0 :,if not accepted_chars . match ( w ) and len ( w ) <= 1 :,False,88.07,66.68,,,
"def test_analysis_jobs_cypher_syntax ( neo4j_session ) : <TAB> parameters = { <TAB> <TAB> "" AWS_ID "" : None , <TAB> <TAB> "" UPDATE_TAG "" : None , <TAB> <TAB> "" OKTA_ORG_ID "" : None , <TAB> } <TAB> for job_name in contents ( "" cartography.data.jobs.analysis "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> cartography . util . run_analysis_job ( job_name , neo4j_session , parameters ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> pytest . fail ( <TAB> <TAB> <TAB> <TAB> f "" run_analysis_job failed for analysis job  ' { job_name } '  with exception:  { e } "" <TAB> <TAB> <TAB> )","if not job_name . endswith ( "".cypher"" ) :","if not job_name . endswith ( "".json"" ) :",False,98.9,73.47,,,
"def _interleave_dataset_results_and_tensors ( dataset_results , flat_run_tensors ) : <TAB> flattened_results = [ ] <TAB> for idx in range ( len ( dataset_results ) + len ( flat_run_tensors ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> flattened_results . append ( dataset_results [ idx ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> flattened_results . append ( flat_run_tensors . pop ( 0 ) ) <TAB> return flattened_results",if flat_run_tensors [ idx ] . shape [ 0 ] == 1 :,if dataset_results . get ( idx ) :,False,88.22,67.93,,,
"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa.MedianBlur(k=iap.Choice([3, 5])) <TAB> seen = [False, False] <TAB> for i in sm.xrange(100): <TAB> <TAB> observed = aug.augment_image(self.base_img) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> seen[0] += True <TAB> <TAB> elif np.array_equal(observed, self.blur5x5): <TAB> <TAB> <TAB> seen[1] += True <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Unexpected result in MedianBlur@2"") <TAB> <TAB> if all(seen): <TAB> <TAB> <TAB> break <TAB> assert np.all(seen)","if np . array_equal ( observed , self . blur3x3 ) :","if np . array_equal ( observed , self . blur3x3 ) :",True,100.0,74.3,,,
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist : <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide )","if dist ( currentPos , self . ends [ color ] ) == 0 :",if minGuide == None :,False,94.08,71.76,,,
"def UpdateRepository ( self ) : <TAB> if hasattr ( self , "" commit_update "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not path . isdir ( "" .git/ "" ) : <TAB> <TAB> <TAB> <TAB> self . gitZipRepo ( ) <TAB> <TAB> <TAB> call ( [ "" git "" , "" reset "" , "" --hard "" , "" origin/ {} "" . format ( self . getBranch ) ] ) <TAB> <TAB> <TAB> self . ProcessCall_ ( [ "" git "" , "" pull "" , "" origin "" , self . getBranch ] ) <TAB> <TAB> <TAB> self . ProcessCall_ ( [ "" pip "" , "" install "" , "" -r "" , "" requirements.txt "" ] )","if self . getBranch != ""default"" :","if self . commit_update [ ""Updates"" ] != [ ] :",False,93.35,71.45,,,
"def callback ( result = Cr . NS_OK , message = None , success = None ) : <TAB> if success is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> success = Ci . koIAsyncCallback . RESULT_SUCCESSFUL <TAB> <TAB> else : <TAB> <TAB> <TAB> success = Ci . koIAsyncCallback . RESULT_ERROR <TAB> data = Namespace ( result = result , message = message , _com_interfaces_ = [ Ci . koIErrorInfo ] ) <TAB> self . _invoke_activate_callbacks ( success , data )",if result == Cr . NS_SUCCESSFUL :,if Cr . NS_SUCCEEDED ( result ) :,False,94.75,70.61,,,
"def get_location ( device ) : <TAB> location = [ ] <TAB> node = device <TAB> while node : <TAB> <TAB> position = node . get_position ( ) or "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> position = ""  [ %s ] "" % position <TAB> <TAB> location . append ( node . name + position ) <TAB> <TAB> node = node . parent <TAB> return ""  /  "" . join ( reversed ( location ) )",if position :,if position :,True,100.0,74.2,,,
"def load_checkpoint ( path , model , optimizer , reset_optimizer ) : <TAB> global global_step <TAB> global global_epoch <TAB> print ( "" Load checkpoint from:  {} "" . format ( path ) ) <TAB> checkpoint = _load ( path ) <TAB> model . load_state_dict ( checkpoint [ "" state_dict "" ] ) <TAB> if not reset_optimizer : <TAB> <TAB> optimizer_state = checkpoint [ "" optimizer "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" Load optimizer state from  {} "" . format ( path ) ) <TAB> <TAB> <TAB> optimizer . load_state_dict ( checkpoint [ "" optimizer "" ] ) <TAB> global_step = checkpoint [ "" global_step "" ] <TAB> global_epoch = checkpoint [ "" global_epoch "" ] <TAB> return model","if optimizer_state != ""default"" :",if optimizer_state is not None :,False,96.79,68.77,,,
"def run_command ( self , command : str , data : Dict [ str , object ] ) - > Dict [ str , object ] : <TAB> """""" Run a specific command from the registry. """""" <TAB> key = "" cmd_ "" + command <TAB> method = getattr ( self . __class__ , key , None ) <TAB> if method is None : <TAB> <TAB> return { "" error "" : "" Unrecognized command  ' %s ' "" % command } <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Only the above commands use some error formatting. <TAB> <TAB> <TAB> del data[""is_tty""] <TAB> <TAB> <TAB> del data[""terminal_width""] <TAB> <TAB> return method(self, **data)","if ""is_tty"" in data :","if command not in { ""check"" , ""recheck"" , ""run"" } :",False,91.73,91.42,,,
"def call_init ( self , node , instance ) : <TAB> # Call __init__ on each binding. <TAB> for b in instance.bindings: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> self._initialized_instances.add(b.data) <TAB> <TAB> node = self._call_init_on_binding(node, b) <TAB> return node",if b . data in self . _initialized_instances :,if b . data in self . _initialized_instances :,True,100.0,73.77,,,
"def get_request_headers ( ) - > Dict : <TAB> url = urlparse ( uri ) <TAB> candidates = [ <TAB> <TAB> "" %s :// %s "" % ( url . scheme , url . netloc ) , <TAB> <TAB> "" %s :// %s / "" % ( url . scheme , url . netloc ) , <TAB> <TAB> uri , <TAB> <TAB> "" * "" , <TAB> ] <TAB> for u in candidates : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> headers = dict ( DEFAULT_REQUEST_HEADERS ) <TAB> <TAB> <TAB> headers . update ( self . config . linkcheck_request_headers [ u ] ) <TAB> <TAB> <TAB> return headers <TAB> return { }",if u in self . config . linkcheck_request_headers :,if u in self . config . linkcheck_request_headers :,True,100.0,74.46,,,
"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB> <TAB> return <TAB> while True : <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self._get_video_packet() <TAB> <TAB> if video_packet.image == 0: <TAB> <TAB> <TAB> self._decode_video_packet(video_packet) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> if _debug: <TAB> <TAB> print(""Returning"", video_packet) <TAB> return video_packet.image",if skip_empty_frame :,if video_packet . image is not None or not skip_empty_frame :,False,94.14,68.59,,,
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( )",elif code == Path . CURVE3 :,elif code == Path . CURVE3 :,True,100.0,74.56,,,
"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """""" Constructor. """""" <TAB> self . layout = layout <TAB> if value is None : <TAB> <TAB> if string is None : <TAB> <TAB> <TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB> <TAB> self . value = np . array ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB> <TAB> <TAB> )",if len ( self . value ) != self . layout . gaDims :,"if self . value . shape != ( self . layout . gaDims , ) :",False,95.74,76.38,,,
"def to_dict ( self ) : <TAB> contexts_ = { } <TAB> for k , data in self . contexts . items ( ) : <TAB> <TAB> data_ = data . copy ( ) <TAB> <TAB> if "" context "" in data_ : <TAB> <TAB> <TAB> del data_ [ "" context "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del data_ [ "" loaded "" ] <TAB> <TAB> contexts_ [ k ] = data_ <TAB> return dict ( contexts = contexts_ )","if ""loaded"" in data_ :","if ""loaded"" in data_ :",True,100.0,74.29,,,
"def to_dict ( self ) : <TAB> contexts_ = { } <TAB> for k , data in self . contexts . items ( ) : <TAB> <TAB> data_ = data . copy ( ) <TAB> <TAB> if "" context "" in data_ : <TAB> <TAB> <TAB> del data_ [ "" context "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del data_ [ "" loaded "" ] <TAB> <TAB> contexts_ [ k ] = data_ <TAB> return dict ( contexts = contexts_ )","if ""loaded"" in data_ :",if check [ : - 1 ] in module :,False,93.06,63.57,,,
"def extract_from ( msg_body , content_type = "" text/plain "" ) : <TAB> try : <TAB> <TAB> if content_type == "" text/plain "" : <TAB> <TAB> <TAB> return extract_from_plain ( msg_body ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return extract_from_html ( msg_body ) <TAB> except Exception : <TAB> <TAB> log . exception ( "" ERROR extracting message "" ) <TAB> return msg_body","elif content_type == ""text/html"" :","elif content_type == ""text/html"" :",True,100.0,74.08,,,
"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB> <TAB> self . assertIn ( "" bbox "" , feature ) <TAB> <TAB> fid = feature [ "" id "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB> <TAB> elif fid == 2 : <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( )",if fid == 1 :,if fid == 1 :,True,100.0,74.64,,,
"def overrideCommand ( self , commandName , func ) : <TAB> # Override entries in c.k.masterBindingsDict <TAB> k = self <TAB> d = k.masterBindingsDict <TAB> for key in d: <TAB> <TAB> d2 = d.get(key) <TAB> <TAB> for key2 in d2: <TAB> <TAB> <TAB> bi = d2.get(key2) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> bi.func = func <TAB> <TAB> <TAB> <TAB> d2[key2] = bi",if bi . name == commandName :,if bi . commandName == commandName :,False,98.16,72.33,,,
"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB> <TAB> for spec in specs [ i ] . __sro__ : <TAB> <TAB> <TAB> comps = components . get ( spec ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB> <TAB> <TAB> <TAB> if r is not None : <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else : <TAB> <TAB> for iface in provided : <TAB> <TAB> <TAB> comps = components . get ( iface ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> r = comps . get ( name ) <TAB> <TAB> <TAB> <TAB> if r is not None : <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None",if comps is not None :,if comps :,False,96.38,72.63,,,
"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated ( request . version , self . min_version ) <TAB> <TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB> <TAB> social = value . copy ( ) <TAB> <TAB> for key in old_social_string_fields : <TAB> <TAB> <TAB> if social . get ( key ) : <TAB> <TAB> <TAB> <TAB> social [ key ] = value [ key ] [ 0 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> social [ key ] = "" "" <TAB> <TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value )",elif not social . get ( key ) :,elif social . get ( key ) == [ ] :,False,97.21,72.72,,,
"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated ( request . version , self . min_version ) <TAB> <TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB> <TAB> social = value . copy ( ) <TAB> <TAB> for key in old_social_string_fields : <TAB> <TAB> <TAB> if social . get ( key ) : <TAB> <TAB> <TAB> <TAB> social [ key ] = value [ key ] [ 0 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> social [ key ] = "" "" <TAB> <TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value )",elif not social . get ( key ) :,"if ref . namespace == ""http://www.w3.org/2001/XMLSchema"" :",False,91.39,68.27,,,
"def unescape ( text ) : <TAB> """""" Removes  ' \\ '  escaping from  ' text ' . """""" <TAB> rv = "" "" <TAB> i = 0 <TAB> while i < len ( text ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> rv + = text [ i + 1 ] <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> rv + = text [ i ] <TAB> <TAB> i + = 1 <TAB> return rv","if text [ i ] == ""\\"" :","if i + 1 < len ( text ) and text [ i ] == ""\\"" :",False,92.65,68.84,,,
"def wait_child_process ( signum , frame ) : <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> child_pid , status = os . waitpid ( - 1 , os . WNOHANG ) <TAB> <TAB> <TAB> if child_pid == 0 : <TAB> <TAB> <TAB> <TAB> stat_logger . info ( "" no child process was immediately available "" ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> exitcode = status >> 8 <TAB> <TAB> <TAB> stat_logger . info ( <TAB> <TAB> <TAB> <TAB> "" child process  %s  exit with exitcode  %s "" , child_pid , exitcode <TAB> <TAB> <TAB> ) <TAB> except OSError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stat_logger . warning ( <TAB> <TAB> <TAB> <TAB> "" current process has no existing unwaited-for child processes. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise",if e . errno == errno . ESRCH :,if e . errno == errno . ECHILD :,False,99.06,73.75,,,
"def translate_from_sortname ( name , sortname ) : <TAB> """""" ' Translate '  the artist name by reversing the sortname. """""" <TAB> for c in name : <TAB> <TAB> ctg = unicodedata . category ( c ) <TAB> <TAB> if ctg [ 0 ] == "" L "" and unicodedata . name ( c ) . find ( "" LATIN "" ) == - 1 : <TAB> <TAB> <TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname . split ( separator ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> parts = [ sortname ] <TAB> <TAB> <TAB> <TAB> separator = "" "" <TAB> <TAB> <TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name",if sortname . find ( separator ) == - 1 :,if separator in sortname :,False,95.8,96.58,,,
"def python_value ( self , value ) : <TAB> if value : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pp = lambda x : x . time ( ) <TAB> <TAB> <TAB> return format_date_time ( value , self . formats , pp ) <TAB> <TAB> elif isinstance ( value , datetime . datetime ) : <TAB> <TAB> <TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB> <TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value","if isinstance ( value , datetime . datetime ) :","if isinstance ( value , basestring ) :",False,96.94,72.79,,,
"def __init__ ( self , fileobj , info ) : <TAB> pages = [ ] <TAB> complete = False <TAB> while not complete : <TAB> <TAB> page = OggPage ( fileobj ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pages . append ( page ) <TAB> <TAB> <TAB> complete = page . complete or ( len ( page . packets ) > 1 ) <TAB> data = OggPage . to_packets ( pages ) [ 0 ] [ 7 : ] <TAB> super ( OggTheoraCommentDict , self ) . __init__ ( data , framing = False ) <TAB> self . _padding = len ( data ) - self . _size",if page . info == info :,if page . serial == info . serial :,False,96.22,71.98,,,
"def configure ( self ) : <TAB> # hack to configure 'from_' and 'to' and avoid exception <TAB> if ""from_"" in self.wmeta.properties: <TAB> <TAB> from_ = float(self.wmeta.properties[""from_""]) <TAB> <TAB> to = float(self.wmeta.properties.get(""to"", 0)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> to = from_ + 1 <TAB> <TAB> <TAB> self.wmeta.properties[""to""] = str(to) <TAB> super(TKSpinbox, self).configure()",if to < from_ :,if from_ > to :,False,96.9,70.36,,,
"def get_error_diagnostics ( self ) : <TAB> diagnostics = [ ] <TAB> if self . stdout is not None : <TAB> <TAB> with open ( self . stdout . name ) as fds : <TAB> <TAB> <TAB> contents = fds . read ( ) . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> diagnostics . append ( "" ab STDOUT: \n "" + contents ) <TAB> if self . stderr is not None : <TAB> <TAB> with open ( self . stderr . name ) as fds : <TAB> <TAB> <TAB> contents = fds . read ( ) . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> diagnostics . append ( "" ab STDERR: \n "" + contents ) <TAB> return diagnostics",if contents :,if contents . strip ( ) :,False,94.51,70.7,,,
"def set_environment_vars ( env , source_env ) : <TAB> """""" Copy allowed environment variables from |source_env|. """""" <TAB> if not source_env : <TAB> <TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> if os.getenv(""TRUSTED_HOST"") and should_rebase_environment_value(name): <TAB> <TAB> <TAB> <TAB> value = file_host.rebase_to_worker_root(value) <TAB> <TAB> <TAB> env[name] = value",if name in env :,if is_forwarded_environment_variable ( name ) :,False,94.08,92.75,,,
"def update_content ( self , more_content : StringList ) - > None : <TAB> if isinstance ( self . object , TypeVar ) : <TAB> <TAB> attrs = [ repr ( self . object . __name__ ) ] <TAB> <TAB> for constraint in self . object . __constraints__ : <TAB> <TAB> <TAB> attrs . append ( stringify_typehint ( constraint ) ) <TAB> <TAB> if self . object . __covariant__ : <TAB> <TAB> <TAB> attrs . append ( "" covariant=True "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> attrs . append ( "" contravariant=True "" ) <TAB> <TAB> more_content . append ( _ ( "" alias of TypeVar( %s ) "" ) % "" ,  "" . join ( attrs ) , "" "" ) <TAB> <TAB> more_content . append ( "" "" , "" "" ) <TAB> super ( ) . update_content ( more_content )",if self . object . __contravariant__ :,if self . object . __contravariant__ :,True,100.0,74.57,,,
"def after ( self , event , state ) : <TAB> group = event . group <TAB> for plugin in self . get_plugins ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> metrics . incr ( "" notifications.sent "" , instance = plugin . slug ) <TAB> <TAB> yield self . future ( plugin . rule_notify )",if group . name != plugin . slug :,"if not safe_execute ( plugin . should_notify , group = group , event = event ) :",False,81.5,63.85,,,
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> if not isinstance ( n , _strtypes ) : <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> elif n not in fields : <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )",if n . _name :,if n . _child . isidentical ( expr ) :,False,97.11,72.61,,,
"def build_filter ( arg ) : <TAB> filt = { } <TAB> if arg is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise UserError ( "" Arguments to --filter should be in form KEY=VAL "" ) <TAB> <TAB> key , val = arg . split ( "" = "" , 1 ) <TAB> <TAB> filt [ key ] = val <TAB> return filt","if ""="" not in arg :","if ""="" not in arg :",True,100.0,74.15,,,
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None",if prog . search ( line ) :,if prog . match ( line ) :,False,99.04,73.93,,,
"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> category = "" preprint "" <TAB> <TAB> elif node . is_registration : <TAB> <TAB> <TAB> category = "" registration "" <TAB> <TAB> else : <TAB> <TAB> <TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB> <TAB> index = index , <TAB> <TAB> doc_type = category , <TAB> <TAB> id = elastic_document_id , <TAB> <TAB> refresh = True , <TAB> <TAB> ignore = [ 404 ] , <TAB> )",if node . is_preprint :,"if isinstance ( node , Preprint ) :",False,96.13,71.29,,,
"def update ( self , preds , labels ) : <TAB> if not _is_numpy_ ( labels ) : <TAB> <TAB> raise ValueError ( "" The  ' labels '  must be a numpy ndarray. "" ) <TAB> if not _is_numpy_ ( preds ) : <TAB> <TAB> raise ValueError ( "" The  ' predictions '  must be a numpy ndarray. "" ) <TAB> for i , lbl in enumerate ( labels ) : <TAB> <TAB> value = preds [ i , 1 ] <TAB> <TAB> bin_idx = int ( value * self . _num_thresholds ) <TAB> <TAB> assert bin_idx < = self . _num_thresholds <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _stat_pos [ bin_idx ] + = 1.0 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _stat_neg [ bin_idx ] + = 1.0",if lbl == 0 :,if lbl :,False,97.88,73.62,,,
"def checkStatusClient ( self ) : <TAB> if str ( self . comboxBoxIPAddress . currentText ( ) ) != "" "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . btnEnable . setEnabled ( False ) <TAB> <TAB> <TAB> self . btncancel . setEnabled ( True ) <TAB> <TAB> <TAB> return None <TAB> <TAB> self . btnEnable . setEnabled ( True ) <TAB> <TAB> self . btncancel . setEnabled ( False )","if self . status == ""ok"" :","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ ""Status"" ] :",False,84.38,64.79,,,
"def colorizeDiffs ( sheet , col , row , cellval ) : <TAB> if not row or not col : <TAB> <TAB> return None <TAB> vcolidx = sheet . visibleCols . index ( col ) <TAB> rowidx = sheet . rows . index ( row ) <TAB> if vcolidx < len ( othersheet . visibleCols ) and rowidx < len ( othersheet . rows ) : <TAB> <TAB> otherval = othersheet . visibleCols [ vcolidx ] . getDisplayValue ( <TAB> <TAB> <TAB> othersheet . rows [ rowidx ] <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" color_diff "" <TAB> else : <TAB> <TAB> return "" color_diff_add """,if cellval == otherval :,if cellval . display != otherval :,False,97.24,72.57,,,
"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB> <TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB> <TAB> return detected <TAB> for wafvendor in self . checklist : <TAB> <TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> detected . append ( wafvendor ) <TAB> <TAB> <TAB> if not findall : <TAB> <TAB> <TAB> <TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected",if self . check ( wafvendor ) :,if self . wafdetections [ wafvendor ] ( self ) :,False,95.62,71.41,,,
"def get_repository_metadata_by_repository_id_changeset_revision ( <TAB> app , id , changeset_revision , metadata_only = False ) : <TAB> """""" Get a specified metadata record for a specified repository in the tool shed. """""" <TAB> if metadata_only : <TAB> <TAB> repository_metadata = get_repository_metadata_by_changeset_revision ( <TAB> <TAB> <TAB> app , id , changeset_revision <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return repository_metadata . metadata <TAB> <TAB> return None <TAB> return get_repository_metadata_by_changeset_revision ( app , id , changeset_revision )",if repository_metadata :,if repository_metadata and repository_metadata . metadata :,False,96.08,66.95,,,
"def get_repository_metadata_by_repository_id_changeset_revision ( <TAB> app , id , changeset_revision , metadata_only = False ) : <TAB> """""" Get a specified metadata record for a specified repository in the tool shed. """""" <TAB> if metadata_only : <TAB> <TAB> repository_metadata = get_repository_metadata_by_changeset_revision ( <TAB> <TAB> <TAB> app , id , changeset_revision <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return repository_metadata . metadata <TAB> <TAB> return None <TAB> return get_repository_metadata_by_changeset_revision ( app , id , changeset_revision )",if repository_metadata :,"if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != ""-"" :",False,87.99,57.75,,,
"def _validate_reports ( value , * args , * * kwargs ) : <TAB> from osf . models import OSFUser <TAB> for key , val in value . items ( ) : <TAB> <TAB> if not OSFUser . load ( key ) : <TAB> <TAB> <TAB> raise ValidationValueError ( "" Keys must be user IDs "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationTypeError ( "" Values must be dictionaries "" ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> "" category "" not in val <TAB> <TAB> <TAB> or "" text "" not in val <TAB> <TAB> <TAB> or "" date "" not in val <TAB> <TAB> <TAB> or "" retracted "" not in val <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise ValidationValueError ( <TAB> <TAB> <TAB> <TAB> ( "" Values must include `date`, `category`,  "" , "" `text`, `retracted` keys "" ) <TAB> <TAB> <TAB> )","if not isinstance ( val , dict ) :","if not isinstance ( val , dict ) :",True,100.0,74.62,,,
"def deselectItem ( self , item ) : <TAB> if self . isSelected ( item ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> listItem = self . _getListItem ( item ) <TAB> <TAB> <TAB> selections = self . getSelectedItems ( ) <TAB> <TAB> <TAB> selections . remove ( self . loadHandler . getSelection ( listItem ) ) <TAB> <TAB> <TAB> self . setSelections ( selections ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . deselectAll ( )",if self . loadHandler :,if self . multiSelect :,False,97.93,72.68,,,
"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB> <TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB> <TAB> if not key in self . options : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name, (description, default) in self.options.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.option_values[name] = default",if description :,if not name in self . option_values :,False,95.56,71.55,,,
"def setup_smart_indent ( self , view , lang ) : <TAB> # Configure a ""per-view"" instance <TAB> if type(view) == gedit.View: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr(view, ""smart_indent_instance"", SmartIndent()) <TAB> <TAB> <TAB> handler_id = view.connect( <TAB> <TAB> <TAB> <TAB> ""key-press-event"", view.smart_indent_instance.key_press_handler <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.handler_ids.append((handler_id, view)) <TAB> <TAB> view.smart_indent_instance.set_language(lang, view)","if getattr ( view , ""smart_indent_instance"" , None ) is None :","if getattr ( view , ""smart_indent_instance"" , False ) == False :",False,96.7,69.49,,,
"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> letters + = char <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if count > threshold : <TAB> <TAB> <TAB> <TAB> strings . append ( letters ) <TAB> <TAB> <TAB> letters = "" "" <TAB> <TAB> <TAB> count = 0 <TAB> if count > threshold : <TAB> <TAB> strings . append ( letters ) <TAB> return strings",if char in char_set :,if char in char_set :,True,100.0,74.4,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.14,,,
def __create_table ( self ) : <TAB> for i in range ( 256 ) : <TAB> <TAB> crcreg = i <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> crcreg = self . __CRCPOLYNOMIAL ^ ( crcreg >> 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> crcreg >> = 1 <TAB> <TAB> self . __crctable [ i ] = crcreg,if j == 0 :,if ( crcreg & 1 ) != 0 :,False,94.27,66.17,,,
"def destroy ( self ) : <TAB> """""" Flush all entries and empty cache """""" <TAB> # Note: this method is currently also used for dropping the cache <TAB> for i in range(len(self.cached_rows)): <TAB> <TAB> id_ = self.cached_rows[i] <TAB> <TAB> self.cached_rows[i] = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> inode = self.attrs[id_] <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> # We may have deleted that inode <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> del self.attrs[id_] <TAB> <TAB> <TAB> <TAB> self.setattr(inode) <TAB> assert len(self.attrs) == 0",if id_ in self . attrs :,if id_ is not None :,False,97.69,71.59,,,
"def set_config ( self ) : <TAB> """""" Set configuration options for QTextEdit. """""" <TAB> c = self . c <TAB> w = self . widget <TAB> w . setWordWrapMode ( QtGui . QTextOption . NoWrap ) <TAB> if 0 : # This only works when there is no style sheet. <TAB> <TAB> n = c.config.getInt(""qt-rich-text-zoom-in"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> w.zoomIn(n) <TAB> <TAB> <TAB> w.updateMicroFocus() <TAB> # tab stop in pixels - no config for this (yet) <TAB> w.setTabStopWidth(24)",if n > 0 :,"if n not in ( None , 0 ) :",False,94.66,94.24,,,
"def mouseDragEvent ( self , ev ) : <TAB> if self . movable and ev . button ( ) == QtCore . Qt . LeftButton : <TAB> <TAB> if ev . isStart ( ) : <TAB> <TAB> <TAB> self . moving = True <TAB> <TAB> <TAB> self . cursorOffset = self . pos ( ) - self . mapToParent ( ev . buttonDownPos ( ) ) <TAB> <TAB> <TAB> self . startPosition = self . pos ( ) <TAB> <TAB> ev . accept ( ) <TAB> <TAB> if not self . moving : <TAB> <TAB> <TAB> return <TAB> <TAB> self . setPos ( self . cursorOffset + self . mapToParent ( ev . pos ( ) ) ) <TAB> <TAB> self . sigDragged . emit ( self ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . moving = False <TAB> <TAB> <TAB> self . sigPositionChangeFinished . emit ( self )",if ev . isEnd ( ) :,if ev . isFinish ( ) :,False,98.85,73.79,,,
"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB> <TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB> <TAB> if not newParent . _element . text : <TAB> <TAB> <TAB> newParent . _element . text = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent )",if self . _element . text :,if self . _element . text is not None :,False,96.85,71.75,,,
"def _no_sp_or_bp ( self , bl ) : <TAB> for s in bl . vex . statements : <TAB> <TAB> for e in chain ( [ s ] , s . expressions ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB> <TAB> <TAB> <TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif e . tag == "" Ist_Put "" : <TAB> <TAB> <TAB> <TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB> <TAB> <TAB> <TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","if e . tag == ""Ist_Get"" :","if e . tag == ""Iex_Get"" :",False,98.97,73.74,,,
"def _get_import_chain ( self , * , until = None ) : <TAB> stack = inspect . stack ( ) [ 2 : ] <TAB> try : <TAB> <TAB> for frameinfo in stack : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> data = dedent ( "" "" . join ( frameinfo . code_context ) ) <TAB> <TAB> <TAB> <TAB> if data . strip ( ) == until : <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> <TAB> yield frameinfo . filename , frameinfo . lineno , data . strip ( ) <TAB> <TAB> <TAB> <TAB> del data <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> del frameinfo <TAB> finally : <TAB> <TAB> del stack",if until is None :,if not frameinfo . code_context :,False,96.84,72.44,,,
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> elif "" status "" in line : <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError","elif ""error"" in line and line [ ""error"" ] . strip ( ) :","elif ""error"" in line :",False,92.44,68.27,,,
"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> if dep == goal_node_index : <TAB> <TAB> <TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> path = self . get_cycle_path ( <TAB> <TAB> <TAB> self . get_by_address ( dep ) , goal_node_index <TAB> <TAB> ) # self.nodelist[dep], goal_node_index) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path.insert(0, curr_node[""address""]) <TAB> <TAB> <TAB> return path <TAB> return []",if path :,if len ( path ) > 0 :,False,96.38,70.77,,,
"def prompt ( default = None ) : <TAB> editor = "" nano "" <TAB> with tempfile . NamedTemporaryFile ( mode = "" r+ "" ) as tmpfile : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tmpfile . write ( default ) <TAB> <TAB> <TAB> tmpfile . flush ( ) <TAB> <TAB> child_pid = os . fork ( ) <TAB> <TAB> is_child = child_pid == 0 <TAB> <TAB> if is_child : <TAB> <TAB> <TAB> os . execvp ( editor , [ editor , tmpfile . name ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . waitpid ( child_pid , 0 ) <TAB> <TAB> <TAB> tmpfile . seek ( 0 ) <TAB> <TAB> <TAB> return tmpfile . read ( ) . strip ( )",if default :,if default :,True,100.0,74.49,,,
"def _get_annotated_template ( self , template ) : <TAB> changed = False <TAB> if template . get ( "" version "" , "" 0.12.0 "" ) > = "" 0.13.0 "" : <TAB> <TAB> using_js = self . spider . _filter_js_urls ( template [ "" url "" ] ) <TAB> <TAB> body = "" rendered_body "" if using_js else "" original_body "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> template [ "" body "" ] = body <TAB> <TAB> <TAB> changed = True <TAB> if changed or not template . get ( "" annotated "" ) : <TAB> <TAB> _build_sample ( template ) <TAB> return template","if template [ ""body"" ] != body :","if template . get ( ""body"" ) != body :",False,95.93,71.76,,,
"def collect ( self , paths ) : <TAB> for path in paths or ( ) : <TAB> <TAB> relpath = os . path . relpath ( path , self . _artifact_root ) <TAB> <TAB> dst = os . path . join ( self . _directory , relpath ) <TAB> <TAB> safe_mkdir ( os . path . dirname ( dst ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> shutil . copytree ( path , dst ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shutil . copy ( path , dst ) <TAB> <TAB> self . _relpaths . add ( relpath )",if self . _recursive :,if os . path . isdir ( path ) :,False,93.95,70.25,,,
"def dependencies ( context = None ) : <TAB> """""" Return all dependencies detected by knowit. """""" <TAB> deps = OrderedDict ( [ ] ) <TAB> try : <TAB> <TAB> initialize ( context ) <TAB> <TAB> for name , provider_cls in _provider_map . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> deps [ name ] = available_providers [ name ] . version <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> deps [ name ] = { } <TAB> except Exception : <TAB> <TAB> pass <TAB> return deps",if provider_cls == _provider_map and provider_cls == _provider_map :,if name in available_providers :,False,88.25,91.3,,,
"def _getaddrinfo ( self , host_bytes , port , family , socktype , proto , flags ) : <TAB> while True : <TAB> <TAB> ares = self . cares <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . __getaddrinfo ( host_bytes , port , family , socktype , proto , flags ) <TAB> <TAB> except gaierror : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise",if ares [ 0 ] != 0x0E :,if ares is self . cares :,False,93.43,69.91,,,
"def write_entries ( cmd , basename , filename ) : <TAB> ep = cmd . distribution . entry_points <TAB> if isinstance ( ep , basestring ) or ep is None : <TAB> <TAB> data = ep <TAB> elif ep is not None : <TAB> <TAB> data = [ ] <TAB> <TAB> for section , contents in ep . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> contents = EntryPoint . parse_group ( section , contents ) <TAB> <TAB> <TAB> <TAB> contents = "" \n "" . join ( map ( str , contents . values ( ) ) ) <TAB> <TAB> <TAB> data . append ( "" [ %s ] \n %s \n \n "" % ( section , contents ) ) <TAB> <TAB> data = "" "" . join ( data ) <TAB> cmd . write_or_delete_file ( "" entry points "" , filename , data , True )","if isinstance ( contents , dict ) :","if not isinstance ( contents , basestring ) :",False,97.81,72.95,,,
"def _highlight_do ( self ) : <TAB> new_hl_text = self . highlight_text . text ( ) <TAB> if new_hl_text != self . hl_text : <TAB> <TAB> self . hl_text = new_hl_text <TAB> <TAB> if self . hl is not None : <TAB> <TAB> <TAB> self . hl . setDocument ( None ) <TAB> <TAB> <TAB> self . hl = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . hl = Highlighter ( self . hl_text , parent = self . doc ) <TAB> <TAB> self . clear_highlight_button . setEnabled ( bool ( self . hl ) )",if self . hl_text :,if self . hl_text :,True,100.0,74.38,,,
"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB> <TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB> <TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> node . functions = list ( functions ) <TAB> <TAB> <TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB> <TAB> functions . append ( type ( node ) . __name__ ) <TAB> <TAB> for f in node . next_functions : <TAB> <TAB> <TAB> if f [ 0 ] : <TAB> <TAB> <TAB> <TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB> <TAB> <TAB> <TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB> <TAB> for t in node . saved_tensors : <TAB> <TAB> <TAB> traverse ( t )",if functions :,if node :,False,99.09,73.96,,,
"def compress ( self , data_list ) : <TAB> if data_list : <TAB> <TAB> page_id = data_list [ 1 ] <TAB> <TAB> if page_id in EMPTY_VALUES : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB> <TAB> return Page . objects . get ( pk = page_id ) <TAB> return None",if page_id not in Page . objects . filter ( pk = page_id ) . exists ( ) :,if not self . required :,False,84.75,67.47,,,
"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB> <TAB> if self . _is_ast_node ( name , item ) : <TAB> <TAB> <TAB> if name == "" Index "" : <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertEqual(type(x._fields), tuple)","if isinstance ( x , ( _Field , _Field ) ) :","if isinstance ( x , ast . AST ) :",False,95.39,71.37,,,
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB> <TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> if self . scan_attr ( attr ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace ( value ) <TAB> <TAB> <TAB> <TAB> url = self . process_attr ( value ) <TAB> <TAB> <TAB> <TAB> link = Link ( url = url ) <TAB> <TAB> <TAB> <TAB> self . links . append ( link ) <TAB> <TAB> <TAB> <TAB> self . current_link = link",if self . scan_html5 ( attr ) :,if self . strip :,False,96.55,72.98,,,
"def _initialize_asset_map ( cls ) : <TAB> # Generating a list of acceptable asset files reduces the possibility of <TAB> # path attacks. <TAB> cls._asset_name_to_path = {} <TAB> assets = os.listdir(ASSETS_PATH) <TAB> for asset in assets: <TAB> <TAB> path = os.path.join(ASSETS_PATH, asset) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cls._asset_name_to_path[os.path.basename(path)] = path",if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,True,100.0,73.94,,,
"def dataReceived ( self , data ) : <TAB> self . buf + = data <TAB> if self . _paused : <TAB> <TAB> log . startLogging ( sys . stderr ) <TAB> <TAB> log . msg ( "" dataReceived while transport paused! "" ) <TAB> <TAB> self . transport . loseConnection ( ) <TAB> else : <TAB> <TAB> self . transport . write ( data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . transport . loseConnection ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . pause ( )",if self . _is_connected :,"if self . buf . endswith ( b""\n0\n"" ) :",False,90.81,61.56,,,
"def test_case_sensitive ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB> <TAB> env . unset ( "" PYTHONCASEOK "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB> <TAB> loader = self . find_module ( ) <TAB> <TAB> self . assertIsNone ( loader )","if ""PYTHONCASEOK"" in env :","if b""PYTHONCASEOK"" in _bootstrap_external . _os . environ :",False,88.19,68.49,,,
"def manifest ( self ) : <TAB> """""" The current manifest dictionary. """""" <TAB> if self . reload : <TAB> <TAB> if not self . exists ( self . manifest_path ) : <TAB> <TAB> <TAB> return { } <TAB> <TAB> mtime = self . getmtime ( self . manifest_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _manifest = self . get_manifest ( ) <TAB> <TAB> <TAB> self . _mtime = mtime <TAB> return self . _manifest",if self . _mtime is None or mtime < self . _mtime :,if self . _mtime is None or mtime > self . _mtime :,False,98.21,97.93,,,
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> elif name == "" mean_module.constant "" : <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive )","if name == ""mean_module.constant"" :","if name == ""likelihood.noise_covar.raw_noise"" :",False,95.49,73.54,,,
"def process_plugin_result ( name , result ) : <TAB> if result : <TAB> <TAB> try : <TAB> <TAB> <TAB> jsonify ( test = result ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while jsonifying settings from plugin  {} , please contact the plugin author about this "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> del result [ "" __enabled "" ] <TAB> <TAB> <TAB> data [ name ] = result","if ""__enabled"" in result :","if ""__enabled"" in result :",True,100.0,74.45,,,
"def benchmarking ( net , ctx , num_iteration , datashape = 300 , batch_size = 64 ) : <TAB> input_shape = ( batch_size , 3 ) + ( datashape , datashape ) <TAB> data = mx . random . uniform ( - 1.0 , 1.0 , shape = input_shape , ctx = ctx , dtype = "" float32 "" ) <TAB> dryrun = 5 <TAB> for i in range ( dryrun + num_iteration ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tic = time . time ( ) <TAB> <TAB> ids , scores , bboxes = net ( data ) <TAB> <TAB> ids . asnumpy ( ) <TAB> <TAB> scores . asnumpy ( ) <TAB> <TAB> bboxes . asnumpy ( ) <TAB> toc = time . time ( ) - tic <TAB> return toc",if i % 10000 == 0 :,if i == dryrun :,False,96.95,73.0,,,
"def merge_weekdays ( base_wd , icu_wd ) : <TAB> result = [ ] <TAB> for left , right in zip ( base_wd , icu_wd ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( left ) <TAB> <TAB> <TAB> continue <TAB> <TAB> left = set ( left . split ( "" | "" ) ) <TAB> <TAB> right = set ( right . split ( "" | "" ) ) <TAB> <TAB> result . append ( "" | "" . join ( left | right ) ) <TAB> return result","if not left . startswith ( ""weekday"" ) :",if left == right :,False,92.89,65.41,,,
"def create_key ( self , request ) : <TAB> if self . _ignored_parameters : <TAB> <TAB> url , body = self . _remove_ignored_parameters ( request ) <TAB> else : <TAB> <TAB> url , body = request . url , request . body <TAB> key = hashlib . sha256 ( ) <TAB> key . update ( _to_bytes ( request . method . upper ( ) ) ) <TAB> key . update ( _to_bytes ( url ) ) <TAB> if request . body : <TAB> <TAB> key . update ( _to_bytes ( body ) ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for name , value in sorted ( request . headers . items ( ) ) : <TAB> <TAB> <TAB> <TAB> key . update ( _to_bytes ( name ) ) <TAB> <TAB> <TAB> <TAB> key . update ( _to_bytes ( value ) ) <TAB> return key . hexdigest ( )",if request . headers :,if self . _include_get_headers and request . headers != _DEFAULT_HEADERS :,False,92.57,71.71,,,
"def test_invalid_mountinfo ( self ) : <TAB> line = ( <TAB> <TAB> "" 20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root "" <TAB> <TAB> "" rw,errors=remount-ro,data=ordered "" <TAB> ) <TAB> elements = line . split ( ) <TAB> for i in range ( len ( elements ) + 1 ) : <TAB> <TAB> lines = [ "" "" . join ( elements [ 0 : i ] ) ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> expected = None <TAB> <TAB> else : <TAB> <TAB> <TAB> expected = ( "" /dev/mapper/vg0-root "" , "" ext4 "" , "" / "" ) <TAB> <TAB> self . assertEqual ( expected , util . parse_mount_info ( "" / "" , lines ) )",if i == 0 :,if i < 10 :,False,97.76,73.07,,,
"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB> <TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB> <TAB> if k in keep_current : <TAB> <TAB> <TAB> if keep_nested is not None : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield k , v","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.45,,,
"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB> <TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB> <TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB> <TAB> # reach leaf <TAB> <TAB> if cur_node_idx == -1: <TAB> <TAB> <TAB> continue <TAB> <TAB> rs, reach_leaf = HeteroSecureBoostingTreeGuest.traverse_a_tree( <TAB> <TAB> <TAB> tree, sample, cur_node_idx <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> node_pos[""reach_leaf_node""][t_idx] = True <TAB> <TAB> node_pos[""node_pos""][t_idx] = rs <TAB> return node_pos",if reach_leaf :,if reach_leaf :,True,100.0,74.41,,,
"def _pop_waiting_trial_id ( self ) - > Optional [ int ] : <TAB> # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB> for trial in self._storage.get_all_trials(self._study_id, deepcopy=False): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self._storage.set_trial_state(trial._trial_id, TrialState.RUNNING): <TAB> <TAB> <TAB> continue <TAB> <TAB> _logger.debug(""Trial {} popped from the trial queue."".format(trial.number)) <TAB> <TAB> return trial._trial_id <TAB> return None",if trial . _trial_id is None :,if trial . state != TrialState . WAITING :,False,95.82,69.65,,,
"def get_step_best ( self , step_models ) : <TAB> best_score = None <TAB> best_model = "" "" <TAB> for model in step_models : <TAB> <TAB> model_info = self . models_trained [ model ] <TAB> <TAB> score = model_info . get_score ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if best_score is None or score < best_score : <TAB> <TAB> <TAB> best_score = score <TAB> <TAB> <TAB> best_model = model <TAB> LOGGER . info ( f "" step  { self . n_step } , best model  { best_model } "" ) <TAB> return best_model",if score == 0 :,if score is None :,False,97.46,72.34,,,
"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB> <TAB> f = queue . popleft ( ) <TAB> <TAB> if f is not None and f . type in ( "" or "" , "" and "" , "" not "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> queue . appendleft ( None ) <TAB> <TAB> <TAB> for gf in f . filters : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( gf ) <TAB> <TAB> yield f",if block_end :,if block_end :,True,100.0,74.39,,,
"def _buffer_decode ( self , input , errors , final ) : <TAB> if self . decoder is None : <TAB> <TAB> ( output , consumed , byteorder ) = codecs . utf_16_ex_decode ( input , errors , 0 , final ) <TAB> <TAB> if byteorder == - 1 : <TAB> <TAB> <TAB> self . decoder = codecs . utf_16_le_decode <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . decoder = codecs . utf_16_be_decode <TAB> <TAB> elif consumed > = 2 : <TAB> <TAB> <TAB> raise UnicodeError ( "" UTF-16 stream does not start with BOM "" ) <TAB> <TAB> return ( output , consumed ) <TAB> return self . decoder ( input , self . errors , final )",elif byteorder == 1 :,elif byteorder == 1 :,True,100.0,74.5,,,
"def _load_db ( self ) : <TAB> try : <TAB> <TAB> with open ( self . db ) as db : <TAB> <TAB> <TAB> content = db . read ( 8 ) <TAB> <TAB> <TAB> db . seek ( 0 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = StringIO ( ) <TAB> <TAB> <TAB> <TAB> if self . encryptor : <TAB> <TAB> <TAB> <TAB> <TAB> self . encryptor . decrypt ( db , data ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json . loads ( data . getvalue ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return json . load ( db ) <TAB> except : <TAB> <TAB> return { "" creds "" : [ ] }","if content == b""Password"" :","if content == ( ""Salted__"" ) :",False,97.28,73.31,,,
"def _getbytes ( self , start , l = 1 ) : <TAB> out = [ ] <TAB> for ad in range ( l ) : <TAB> <TAB> offset = ad + start + self . base_address <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IOError ( "" not enough bytes "" ) <TAB> <TAB> out . append ( int_to_byte ( Byte ( offset ) ) ) <TAB> return b "" "" . join ( out )",if offset > len ( self . data ) :,if not is_mapped ( offset ) :,False,92.98,70.16,,,
"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> if config.get(""environment"") == ""prod"": <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if config . get ( ""environment"" ) == ""local"" :","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :",False,92.69,64.92,,,
"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB> <TAB> if row [ 0 ] == linenum : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> row [ refnum + 1 ] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> elif row[0] > linenum: <TAB> <TAB> <TAB> break <TAB> self.rows.insert(i, self.newRow(linenum, refnum, line))",if refnum + 1 < len ( self . rows ) :,if row [ refnum + 1 ] is None :,False,93.75,69.2,,,
"def __setattr__ ( self , name , val ) : <TAB> if self . __dict__ . get ( name , "" hamster_graphics_no_value_really "" ) == val : <TAB> <TAB> return <TAB> Sprite . __setattr__ ( self , name , val ) <TAB> if name == "" image_data "" : <TAB> <TAB> self . _surface = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __dict__ [ "" width "" ] = self . image_data . get_width ( ) <TAB> <TAB> <TAB> self . __dict__ [ "" height "" ] = self . image_data . get_height ( )",if self . image_data :,if self . image_data :,True,100.0,74.36,,,
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re.sub(""<Mock name='([^']+)'.*>"", ""\g<1>"", signature) <TAB> <TAB> signature = re.sub(""tensorflow"", ""tf"", signature) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr(obj, ""use_scope""): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""variable_scope_name, "" + signature[1:] <TAB> <TAB> <TAB> elif obj.use_scope is None: <TAB> <TAB> <TAB> <TAB> signature = signature[0] + ""[variable_scope_name,] "" + signature[1:] <TAB> # signature: arg list <TAB> return signature, return_annotation","if obj . use_scope == ""layer"" :",if obj . use_scope :,False,97.46,69.66,,,
"def L_op ( self , inputs , outputs , gout ) : <TAB> ( x , ) = inputs <TAB> ( gz , ) = gout <TAB> if x . type in complex_types : <TAB> <TAB> raise NotImplementedError ( ) <TAB> if outputs [ 0 ] . type in discrete_types : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ x . zeros_like ( dtype = theano . config . floatX ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ x . zeros_like ( ) ] <TAB> return ( gz * ( 1 - sqr ( tanh ( x ) ) ) , )",if x . type in discrete_types :,if x . type in discrete_types :,True,100.0,74.45,,,
"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB> <TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> <TAB> if output . lower ( ) == "" n "" : <TAB> <TAB> <TAB> return False","if output . lower ( ) == ""y"" :","if output . lower ( ) == ""y"" :",True,100.0,74.11,,,
"def replace_documentation_for_matching_shape ( self , event_name , section , * * kwargs ) : <TAB> if self . _shape_name == section . context . get ( "" shape "" ) : <TAB> <TAB> self . _replace_documentation ( event_name , section ) <TAB> for section_name in section . available_sections : <TAB> <TAB> sub_section = section . get_section ( section_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _replace_documentation ( event_name , sub_section ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . replace_documentation_for_matching_shape ( event_name , sub_section )","if self . _shape_name == sub_section . context . get ( ""shape"" ) :","if self . _shape_name == sub_section . context . get ( ""shape"" ) :",True,100.0,74.36,,,
"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB> <TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB> <TAB> if output . lower ( ) == "" y "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False","if output . lower ( ) == ""n"" :","if output . lower ( ) == ""n"" :",True,100.0,74.11,,,
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> if feature : <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ]",if index < 0 :,if index < 0 or index >= len ( self . features ) :,False,95.91,71.79,,,
"def _parse_locator ( self , locator ) : <TAB> prefix = None <TAB> criteria = locator <TAB> if not locator . startswith ( "" // "" ) : <TAB> <TAB> locator_parts = locator . partition ( "" = "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> prefix = locator_parts [ 0 ] <TAB> <TAB> <TAB> criteria = locator_parts [ 2 ] . strip ( ) <TAB> return ( prefix , criteria )",if len ( locator_parts ) == 3 :,if len ( locator_parts [ 1 ] ) > 0 :,False,93.97,69.86,,,
"def trakt_episode_data_generate ( self , data ) : <TAB> # Find how many unique season we have <TAB> uniqueSeasons = [] <TAB> for season, episode in data: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> uniqueSeasons.append(season) <TAB> # build the query <TAB> seasonsList = [] <TAB> for searchedSeason in uniqueSeasons: <TAB> <TAB> episodesList = [] <TAB> <TAB> for season, episode in data: <TAB> <TAB> <TAB> if season == searchedSeason: <TAB> <TAB> <TAB> <TAB> episodesList.append({""number"": episode}) <TAB> <TAB> seasonsList.append({""number"": searchedSeason, ""episodes"": episodesList}) <TAB> post_data = {""seasons"": seasonsList} <TAB> return post_data",if episode not in uniqueSeasons :,if season not in uniqueSeasons :,False,98.72,72.99,,,
"def __init__ ( self , data , n_bins ) : <TAB> bin_width = span / n_bins <TAB> bins = [ 0 ] * n_bins <TAB> for x in data : <TAB> <TAB> b = int ( mpfloor ( ( x - minimum ) / bin_width ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> b = 0 <TAB> <TAB> elif b > = n_bins : <TAB> <TAB> <TAB> b = n_bins - 1 <TAB> <TAB> bins [ b ] + = 1 <TAB> self . bins = bins <TAB> self . bin_width = bin_width",if b < 0 :,if b < 0 :,True,100.0,74.33,,,
"def infer_context ( typ , context = "" http://schema.org "" ) : <TAB> parsed_context = urlparse ( typ ) <TAB> if parsed_context . netloc : <TAB> <TAB> base = "" "" . join ( [ parsed_context . scheme , "" :// "" , parsed_context . netloc ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> context = urljoin ( base , parsed_context . path ) <TAB> <TAB> <TAB> typ = parsed_context . fragment . strip ( "" / "" ) <TAB> <TAB> elif parsed_context . path : <TAB> <TAB> <TAB> context = base <TAB> <TAB> <TAB> typ = parsed_context . path . strip ( "" / "" ) <TAB> return context , typ",if parsed_context . fragment :,if parsed_context . path and parsed_context . fragment :,False,96.83,72.54,,,
"def parse ( self , items ) : <TAB> for index , item in enumerate ( items ) : <TAB> <TAB> keys = self . build_key ( item ) <TAB> <TAB> if keys is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Update `items` <TAB> <TAB> self.items[tuple(keys)] = (index, item) <TAB> <TAB> # Update `table` <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log.info(""Unable to update table (keys: %r)"", keys)",if self . table . update_key ( keys ) :,"if not self . path_set ( self . table , keys , ( index , item ) ) :",False,88.84,65.36,,,
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """""" Return XML element converting dicts recursively. """""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> if tag == "" layers "" : <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> elif isinstance ( val , MutableMapping ) : <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem","if tag == ""variable"" :","if tag == ""config"" :",False,98.98,98.32,,,
"def _get_config_value ( self , section , key ) : <TAB> if section : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . error ( "" Error: Config section  ' %s '  not found "" , section ) <TAB> <TAB> <TAB> return None <TAB> <TAB> return self . config [ section ] . get ( key , self . config [ key ] ) <TAB> else : <TAB> <TAB> return self . config [ key ]",if section not in self . config :,if section not in self . config :,True,100.0,74.28,,,
"def h_line_down ( self , input ) : <TAB> end_this_line = self . value . find ( "" \n "" , self . cursor_position ) <TAB> if end_this_line == - 1 : <TAB> <TAB> if self . scroll_exit : <TAB> <TAB> <TAB> self . h_exit_down ( None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . cursor_position = len ( self . value ) <TAB> else : <TAB> <TAB> self . cursor_position = end_this_line + 1 <TAB> <TAB> for x in range ( self . cursorx ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif self . value [ self . cursor_position ] == "" \n "" : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor_position + = 1",if self . value [ self . cursor_position ] == input :,if self . cursor_position > len ( self . value ) - 1 :,False,96.44,71.5,,,
"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = fp . read ( bufsize ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if isinstance ( data , str ) : <TAB> <TAB> <TAB> <TAB> data = data . encode ( fp . encoding ) <TAB> <TAB> <TAB> m . update ( data ) <TAB> except IOError as msg : <TAB> <TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB> <TAB> return 1 <TAB> out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0",if not data :,if not data :,True,100.0,74.56,,,
"def main ( input ) : <TAB> logging . info ( "" Running Azure Cloud Custodian Policy  %s "" , input ) <TAB> context = { <TAB> <TAB> "" config_file "" : join ( function_directory , "" config.json "" ) , <TAB> <TAB> "" auth_file "" : join ( function_directory , "" auth.json "" ) , <TAB> } <TAB> event = None <TAB> subscription_id = None <TAB> if isinstance ( input , QueueMessage ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> event = input . get_json ( ) <TAB> <TAB> subscription_id = ResourceIdParser . get_subscription_id ( event [ "" subject "" ] ) <TAB> handler . run ( event , context , subscription_id )","if input . get_json ( ) [ ""subject"" ] == ""AzureCloudCustodian"" :",if input . dequeue_count > max_dequeue_count :,False,91.81,67.77,,,
"def maybeExtractTarball ( self ) : <TAB> if self . tarball : <TAB> <TAB> tar = self . computeTarballOptions ( ) + [ "" -xvf "" , self . tarball ] <TAB> <TAB> res = yield self . _Cmd ( tar , abandonOnFailure = False ) <TAB> <TAB> <IF-STMT> # error with tarball.. erase repo dir and tarball <TAB> <TAB> <TAB> yield self._Cmd([""rm"", ""-f"", self.tarball], abandonOnFailure=False) <TAB> <TAB> <TAB> yield self.runRmdir(self.repoDir(), abandonOnFailure=False)",if res :,if res :,True,100.0,74.18,,,
"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name , _val in val . items ( ) : <TAB> <TAB> <TAB> <TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB> <TAB> <TAB> <TAB> if action == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> new_action = watcher . set_opt ( key , val ) <TAB> <TAB> if new_action == 1 : <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher.do_action(action)","if isinstance ( val , dict ) :","if key == ""hooks"" :",False,97.07,67.7,,,
"def _import_playlists ( self , fns , library ) : <TAB> added = 0 <TAB> for filename in fns : <TAB> <TAB> name = _name_for ( filename ) <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> playlist = parse_m3u ( f , name , library = library ) <TAB> <TAB> <TAB> elif filename . endswith ( "" .pls "" ) : <TAB> <TAB> <TAB> <TAB> playlist = parse_pls ( f , name , library = library ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print_w ( "" Unsupported playlist type for  ' %s ' "" % filename ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . changed ( playlist ) <TAB> <TAB> library . add ( playlist ) <TAB> <TAB> added + = 1 <TAB> return added","if filename . endswith ( "".m3u"" ) :","if filename . endswith ( "".m3u"" ) or filename . endswith ( "".m3u8"" ) :",False,95.88,67.66,,,
"def unwrap_term_buckets ( self , timestamp , term_buckets ) : <TAB> for term_data in term_buckets : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . unwrap_interval_buckets ( <TAB> <TAB> <TAB> <TAB> timestamp , term_data [ "" key "" ] , term_data [ "" interval_aggs "" ] [ "" buckets "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . check_matches ( timestamp , term_data [ "" key "" ] , term_data )","if ""interval_aggs"" in term_data :","if ""interval_aggs"" in term_data :",True,100.0,74.21,,,
"def _get_exception ( flags , timeout_ms , payload_size ) : <TAB> if flags & FLAG_ERROR : <TAB> <TAB> if flags & FLAG_TIMEOUT : <TAB> <TAB> <TAB> return SpicommTimeoutError ( timeout_ms / 1000.0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return SpicommOverflowError ( payload_size ) <TAB> <TAB> return SpicommError ( ) <TAB> return None",if flags & FLAG_OVERFLOW :,if flags & FLAG_OVERFLOW :,True,100.0,73.94,,,
"def _get_pattern ( self , pattern_id ) : <TAB> """""" Get pattern item by id. """""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB> <TAB> if key in self . tagged_blocks : <TAB> <TAB> <TAB> data = self . tagged_blocks . get_data ( key ) <TAB> <TAB> <TAB> for pattern in data : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None",if pattern . id == pattern_id :,if pattern . pattern_id == pattern_id :,False,97.57,97.82,,,
"def print_quiet ( self , context , * args , * * kwargs ) : <TAB> for index , ( key , value ) in enumerate ( <TAB> <TAB> itertools . chain ( enumerate ( args ) , kwargs . items ( ) ) <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> self . format_quiet ( index , key , value , fields = context . get_input_fields ( ) ) <TAB> <TAB> <TAB> )",if self . verbosity > 1 :,"if self . filter ( index , key , value ) :",False,92.68,69.17,,,
"def complete ( self , block ) : <TAB> with self . _condition : <TAB> <TAB> if not self . _final : <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . _complete ( ) : <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _condition . wait_for ( self . _complete ) <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False",if self . _final :,if block :,False,96.8,72.25,,,
"def compression_rotator ( source , dest ) : <TAB> with open ( source , "" rb "" ) as sf : <TAB> <TAB> with gzip . open ( dest , "" wb "" ) as wf : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> data = sf . read ( CHUNK_SIZE ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> wf . write ( data ) <TAB> os . remove ( source )",if not data :,if not data :,True,100.0,74.29,,,
"def mockup ( self , records ) : <TAB> provider = TransipProvider ( "" "" , "" "" , "" "" ) <TAB> _dns_entries = [ ] <TAB> for record in records : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> entries_for = getattr ( provider , "" _entries_for_ {} "" . format ( record . _type ) ) <TAB> <TAB> <TAB> # Root records have '@' as name <TAB> <TAB> <TAB> name = record.name <TAB> <TAB> <TAB> if name == """": <TAB> <TAB> <TAB> <TAB> name = provider.ROOT_RECORD <TAB> <TAB> <TAB> _dns_entries.extend(entries_for(name, record)) <TAB> <TAB> <TAB> # NS is not supported as a DNS Entry, <TAB> <TAB> <TAB> # so it should cover the if statement <TAB> <TAB> <TAB> _dns_entries.append(DnsEntry(""@"", ""3600"", ""NS"", ""ns01.transip.nl."")) <TAB> self.mockupEntries = _dns_entries",if record . _type :,if record . _type in provider . SUPPORTS :,False,97.96,97.38,,,
"def parse_known_args ( self , args = None , namespace = None ) : <TAB> entrypoint = self . prog . split ( "" "" ) [ 0 ] <TAB> try : <TAB> <TAB> defs = get_defaults_for_argparse ( entrypoint ) <TAB> <TAB> ignore = defs . pop ( "" Ignore "" , None ) <TAB> <TAB> self . set_defaults ( * * defs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> set_notebook_diff_ignores ( ignore ) <TAB> except ValueError : <TAB> <TAB> pass <TAB> return super ( ConfigBackedParser , self ) . parse_known_args ( <TAB> <TAB> args = args , namespace = namespace <TAB> )",if ignore :,if ignore :,True,100.0,74.4,,,
"def _maybeRebuildAtlas ( self , threshold = 4 , minlen = 1000 ) : <TAB> n = len ( self . fragmentAtlas ) <TAB> if ( n > minlen ) and ( n > threshold * len ( self . data ) ) : <TAB> <TAB> self . fragmentAtlas . rebuild ( <TAB> <TAB> <TAB> list ( zip ( * self . _style ( [ "" symbol "" , "" size "" , "" pen "" , "" brush "" ] ) ) ) <TAB> <TAB> ) <TAB> <TAB> self . data [ "" sourceRect "" ] = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _sourceQRect . clear ( ) <TAB> <TAB> self . updateSpots ( )",if self . _sourceQRect :,if _USE_QRECT :,False,96.74,73.02,,,
"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self.trace_dispatch <TAB> <TAB> try: <TAB> <TAB> <TAB> self.frame_returning = frame <TAB> <TAB> <TAB> self.user_return(frame, arg) <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.frame_returning = None <TAB> <TAB> if self.quitting: <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self.stopframe is frame and self.stoplineno != -1: <TAB> <TAB> <TAB> self._set_stopinfo(None, None) <TAB> return self.trace_dispatch",if self . frame_returning is None :,if self . stopframe and frame . f_code . co_flags & CO_GENERATOR :,False,93.28,70.01,,,
"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . hosted_service_name is not None : <TAB> <TAB> <TAB> <TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( )",if self . storage_account_name is not None :,if self . storage_account_name is not None :,True,100.0,74.53,,,
"def make_log_msg ( self , msg , * other_messages ) : <TAB> MAX_MESSAGE_LENGTH = 1000 <TAB> if not other_messages : <TAB> <TAB> # assume that msg is a single string <TAB> <TAB> return msg[-MAX_MESSAGE_LENGTH:] <TAB> else: <TAB> <TAB> if len(msg): <TAB> <TAB> <TAB> msg += ""\n...\n"" <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len(msg) <TAB> <TAB> else: <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg += other_messages[0][-NEXT_MESSAGE_OFFSET:] <TAB> <TAB> <TAB> return self.make_log_msg(msg, *other_messages[1:]) <TAB> <TAB> else: <TAB> <TAB> <TAB> return self.make_log_msg(msg)",if len ( other_messages ) > NEXT_MESSAGE_OFFSET :,if NEXT_MESSAGE_OFFSET > 0 :,False,96.22,71.31,,,
"def wrapper ( # type: ignore <TAB> self: RequestHandler, *args, **kwargs) -> Optional[Awaitable[None]]: <TAB> if self.request.path.endswith(""/""): <TAB> <TAB> if self.request.method in (""GET"", ""HEAD""): <TAB> <TAB> <TAB> uri = self.request.path.rstrip(""/"") <TAB> <TAB> <TAB> if uri: # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> uri += ""?"" + self.request.query <TAB> <TAB> <TAB> <TAB> self.redirect(uri, permanent=True) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else: <TAB> <TAB> <TAB> raise HTTPError(404) <TAB> return method(self, *args, **kwargs)",if self . request . query :,if self . request . query :,True,100.0,74.31,,,
"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB> <TAB> var = d . upper ( ) <TAB> <TAB> if var == "" QTCORE "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env [ "" LIBPATH_ "" + var ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> core = env [ coreval ] <TAB> <TAB> <TAB> accu = [ ] <TAB> <TAB> <TAB> for lib in value : <TAB> <TAB> <TAB> <TAB> if lib in core : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu . append ( lib ) <TAB> <TAB> <TAB> env [ "" LIBPATH_ "" + var ] = accu",if value :,if value :,True,100.0,74.46,,,
"def _attach_children ( self , other , exclude_worldbody , dry_run = False ) : <TAB> for other_child in other . all_children ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self_child = self . get_children ( other_child . spec . name ) <TAB> <TAB> <TAB> self_child . _attach ( <TAB> <TAB> <TAB> <TAB> other_child , exclude_worldbody , dry_run <TAB> <TAB> <TAB> ) # pylint: disable=protected-access","if isinstance ( other_child , spec . Leaf ) :",if not other_child . spec . repeated :,False,93.13,68.74,,,
"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB> <TAB> if child . getchildren ( ) : <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree(child) <TAB> <TAB> else: <TAB> <TAB> <TAB> content = child.text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not type(ret_dict[child.tag]) == list: <TAB> <TAB> <TAB> <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB> <TAB> <TAB> ret_dict[child.tag].append(content or """") <TAB> <TAB> else: <TAB> <TAB> <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",if child . tag in ret_dict :,if ret_dict . has_key ( child . tag ) :,False,95.4,70.49,,,
"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB> <TAB> if child . getchildren ( ) : <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree(child) <TAB> <TAB> else: <TAB> <TAB> <TAB> content = child.text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not type(ret_dict[child.tag]) == list: <TAB> <TAB> <TAB> <TAB> ret_dict[child.tag] = [ret_dict[child.tag]] <TAB> <TAB> <TAB> ret_dict[child.tag].append(content or """") <TAB> <TAB> else: <TAB> <TAB> <TAB> ret_dict[child.tag] = content or """" <TAB> return ret_dict",if child . tag in ret_dict :,if item == value or item [ : - 1 ] == value :,False,93.28,67.84,,,
"def update_repository ( self , ignore_issues = False , force = False ) : <TAB> """""" Update. """""" <TAB> if not await self . common_update ( ignore_issues , force ) : <TAB> <TAB> return <TAB> # Get appdaemon objects. <TAB> if self.repository_manifest: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.content.path.remote = """" <TAB> if self.content.path.remote == ""apps"": <TAB> <TAB> self.data.domain = get_first_directory_in_directory( <TAB> <TAB> <TAB> self.tree, self.content.path.remote <TAB> <TAB> ) <TAB> <TAB> self.content.path.remote = f""apps/{self.data.name}"" <TAB> # Set local path <TAB> self.content.path.local = self.localpath","if self . content . path . remote == ""apps"" :",if self . data . content_in_root :,False,95.18,70.92,,,
"def addOutput ( self , data , isAsync = None , * * kwargs ) : <TAB> isAsync = _get_async_param ( isAsync , * * kwargs ) <TAB> if isAsync : <TAB> <TAB> self . terminal . eraseLine ( ) <TAB> <TAB> self . terminal . cursorBackward ( len ( self . lineBuffer ) + len ( self . ps [ self . pn ] ) ) <TAB> self . terminal . write ( data ) <TAB> if isAsync : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . terminal . nextLine ( ) <TAB> <TAB> self . terminal . write ( self . ps [ self . pn ] ) <TAB> <TAB> if self . lineBuffer : <TAB> <TAB> <TAB> oldBuffer = self . lineBuffer <TAB> <TAB> <TAB> self . lineBuffer = [ ] <TAB> <TAB> <TAB> self . lineBufferIndex = 0 <TAB> <TAB> <TAB> self . _deliverBuffer ( oldBuffer )",if self . lineBufferIndex == 0 :,if self . _needsNewline ( ) :,False,97.5,73.16,,,
"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB> <TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> status = self.legacy_get_dlc_status(dlc_title) <TAB> <TAB> <TAB> installed = True if status in [""installed"", ""updatable""] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else: <TAB> <TAB> if self.install_dir and os.path.exists(self.install_dir): <TAB> <TAB> <TAB> installed = True <TAB> return installed",if self . legacy_get_dlc_status :,if not installed :,False,95.17,72.51,,,
"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB> <TAB> sockname = None <TAB> <TAB> try : <TAB> <TAB> <TAB> sockname = self . sock . getsockname ( ) <TAB> <TAB> except ( socket . error , OSError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> self . sock . close ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> if os.path.exists(sockname): <TAB> <TAB> <TAB> <TAB> os.remove(sockname) <TAB> self.sock = None","if not isinstance ( self . sock , socket . SSLSocket ) :",if type ( sockname ) is str :,False,93.38,69.84,,,
"def post_file ( self , file_path , graph_type = "" edges "" , file_type = "" csv "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> base_path = self . server_base_path <TAB> with open ( file_path , "" rb "" ) as file : <TAB> <TAB> out = requests . post ( <TAB> <TAB> <TAB> f "" { base_path } /api/v2/upload/datasets/ { dataset_id } / { graph_type } / { file_type } "" , <TAB> <TAB> <TAB> verify = self . certificate_validation , <TAB> <TAB> <TAB> headers = { "" Authorization "" : f "" Bearer  { tok } "" } , <TAB> <TAB> <TAB> data = file . read ( ) , <TAB> <TAB> ) . json ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise Exception ( out ) <TAB> <TAB> return out","if out [ ""error"" ] != ""ok"" :","if not out [ ""success"" ] :",False,95.79,68.83,,,
"def _get_vqa_v2_image_raw_dataset ( directory , image_root_url , image_urls ) : <TAB> """""" Extract the VQA V2 image data set to directory unless it ' s there. """""" <TAB> for url in image_urls : <TAB> <TAB> filename = os . path . basename ( url ) <TAB> <TAB> download_url = os . path . join ( image_root_url , url ) <TAB> <TAB> path = generator_utils . maybe_download ( directory , filename , download_url ) <TAB> <TAB> unzip_dir = os . path . join ( directory , filename . strip ( "" .zip "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> zipfile . ZipFile ( path , "" r "" ) . extractall ( directory )",if os . path . exists ( unzip_dir ) :,if not tf . gfile . Exists ( unzip_dir ) :,False,96.39,96.52,,,
"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote ( environ [ key ] ) <TAB> <TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB> <TAB> if request_uri . startswith ( script_name ) : <TAB> <TAB> <TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> break <TAB> return self . app ( environ , start_response )",if key not in environ :,if key not in environ :,True,100.0,74.48,,,
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) : # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance(value, tf.keras.layers.Layer): <TAB> <TAB> <TAB> new_layer = self._instrument(value) <TAB> <TAB> <TAB> if new_layer is not value: <TAB> <TAB> <TAB> <TAB> setattr(model, key, new_layer) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for i, item in enumerate(value): <TAB> <TAB> <TAB> <TAB> if isinstance(item, tf.keras.layers.Layer): <TAB> <TAB> <TAB> <TAB> <TAB> value[i] = self._instrument(item) <TAB> return model","elif isinstance ( value , list ) :","elif isinstance ( value , list ) :",True,100.0,74.37,,,
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> if i == "" . "" or i == "" .. "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist",if pattern . match ( value ) :,if pattern . match ( value ) is not None :,False,98.3,73.15,,,
"def get_text ( self , nodelist ) : <TAB> """""" Return a string representation of the motif ' s properties listed on nodelist . """""" <TAB> retlist = [ ] <TAB> for node in nodelist : <TAB> <TAB> if node . nodeType == Node . TEXT_NODE : <TAB> <TAB> <TAB> retlist . append ( node . wholeText ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> retlist . append ( self . get_text ( node . childNodes ) ) <TAB> return re . sub ( r "" \ s+ "" , "" "" , "" "" . join ( retlist ) )",elif node . nodeType == Node . ELEMENT_NODE :,elif node . hasChildNodes :,False,93.64,72.28,,,
"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB> <TAB> if self . posts : <TAB> <TAB> <TAB> if self . latest : <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self . latest : <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path )",elif self . stories :,if self . stories :,False,99.02,73.7,,,
"def _get_python_wrapper_content ( self , job_class , args ) : <TAB> job = job_class ( [ "" -r "" , "" hadoop "" ] + list ( args ) ) <TAB> job . sandbox ( ) <TAB> with job . make_runner ( ) as runner : <TAB> <TAB> runner . _create_setup_wrapper_scripts ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with open ( runner . _spark_python_wrapper_path ) as f : <TAB> <TAB> <TAB> <TAB> return f . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None",if runner . _spark_python_wrapper_path :,if runner . _spark_python_wrapper_path :,True,100.0,74.33,,,
"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> w + = 1 <TAB> <TAB> elif ch == "" \t "" : <TAB> <TAB> <TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return w","if ch == ""\n"" :","if ch == "" "" :",False,97.01,64.93,,,
def run ( self ) : <TAB> # if the i3status process dies we want to restart it. <TAB> # We give up restarting if we have died too often <TAB> for _ in range(10): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> self.spawn_i3status() <TAB> <TAB> # check if we never worked properly and if so quit now <TAB> <TAB> if not self.ready: <TAB> <TAB> <TAB> break <TAB> <TAB> # limit restart rate <TAB> <TAB> self.lock.wait(5),if self . stopped :,if not self . py3_wrapper . running :,False,94.03,70.18,,,
"def translate_len ( <TAB> builder : IRBuilder , expr : CallExpr , callee : RefExpr ) - > Optional [ Value ] : <TAB> # Special case builtins.len <TAB> if len(expr.args) == 1 and expr.arg_kinds == [ARG_POS]: <TAB> <TAB> expr_rtype = builder.node_type(expr.args[0]) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # len() of fixed-length tuple can be trivially determined statically, <TAB> <TAB> <TAB> # though we still need to evaluate it. <TAB> <TAB> <TAB> builder.accept(expr.args[0]) <TAB> <TAB> <TAB> return Integer(len(expr_rtype.types)) <TAB> <TAB> else: <TAB> <TAB> <TAB> obj = builder.accept(expr.args[0]) <TAB> <TAB> <TAB> return builder.builtin_len(obj, -1) <TAB> return None","if isinstance ( expr_rtype , IRType ) :","if isinstance ( expr_rtype , RTuple ) :",False,98.94,73.17,,,
"def parse_auth ( val ) : <TAB> if val is not None : <TAB> <TAB> authtype , params = val . split ( "" "" , 1 ) <TAB> <TAB> if authtype in known_auth_schemes : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> params = parse_auth_params(params) <TAB> <TAB> return authtype, params <TAB> return val","if params == """" :","if authtype == ""Basic"" and '""' not in params :",False,92.05,63.2,,,
"def toxml ( self ) : <TAB> text = self . value <TAB> self . parent . setBidi ( getBidiType ( text ) ) <TAB> if not text . startswith ( HTML_PLACEHOLDER_PREFIX ) : <TAB> <TAB> if self . parent . nodeName == "" p "" : <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" \n  "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = "" \n  <TAB>  "" + text . replace ( "" \n "" , "" \n  <TAB>  "" ) <TAB> text = self . doc . normalizeEntities ( text ) <TAB> return text","if self . parent . nodeName == ""h"" :","elif self . parent . nodeName == ""li"" and self . parent . childNodes [ 0 ] == self :",False,89.32,67.67,,,
"def get_all_related_many_to_many_objects ( self ) : <TAB> try : # Try the cache first. <TAB> <TAB> return self._all_related_many_to_many_objects <TAB> except AttributeError: <TAB> <TAB> rel_objs = [] <TAB> <TAB> for klass in get_models(): <TAB> <TAB> <TAB> for f in klass._meta.many_to_many: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> rel_objs.append(RelatedObject(f.rel.to, klass, f)) <TAB> <TAB> self._all_related_many_to_many_objects = rel_objs <TAB> <TAB> return rel_objs",if f . rel . to and f . rel . to not in self . _related_many_objects :,if f . rel and self == f . rel . to . _meta :,False,92.86,68.46,,,
"def state_highstate ( self , state , dirpath ) : <TAB> opts = copy . copy ( self . config ) <TAB> opts [ "" file_roots "" ] = dict ( base = [ dirpath ] ) <TAB> HIGHSTATE = HighState ( opts ) <TAB> HIGHSTATE . push_active ( ) <TAB> try : <TAB> <TAB> high , errors = HIGHSTATE . render_highstate ( state ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> import pprint <TAB> <TAB> <TAB> pprint . pprint ( "" \n "" . join ( errors ) ) <TAB> <TAB> <TAB> pprint . pprint ( high ) <TAB> <TAB> out = HIGHSTATE . state . call_high ( high ) <TAB> <TAB> # pprint.pprint(out) <TAB> finally: <TAB> <TAB> HIGHSTATE.pop_active()",if errors :,if errors :,True,100.0,74.45,,,
"def _update_target_host ( self , target , target_host ) : <TAB> """""" Update target host. """""" <TAB> target_host = None if target_host == "" "" else target_host <TAB> if not target_host : <TAB> <TAB> for device_type , tgt in target . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> target_host = tgt <TAB> <TAB> <TAB> <TAB> break <TAB> if not target_host : <TAB> <TAB> target_host = "" llvm "" if tvm . runtime . enabled ( "" llvm "" ) else "" stackvm "" <TAB> if isinstance ( target_host , str ) : <TAB> <TAB> target_host = tvm . target . Target ( target_host ) <TAB> return target_host","if tgt . device_type == ""host"" :",if device_type . value == tvm . nd . cpu ( 0 ) . device_type :,False,91.84,82.23,,,
"def __console_writer ( self ) : <TAB> while True : <TAB> <TAB> self . __writer_event . wait ( ) <TAB> <TAB> self . __writer_event . clear ( ) <TAB> <TAB> if self . __console_view : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . log . debug ( "" Writing console view to STDOUT "" ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . console_markup . clear ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . __console_view ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . console_markup . TOTAL_RESET )",if self . console_view . clear :,if not self . short_only :,False,95.98,71.8,,,
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """""" Select the next marked node. """""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> if p and p . isMarked ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> elif p : <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p ) # Sets focus.",if not wrapped :,elif wrapped :,False,98.32,83.42,,,
"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB> <TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB> <TAB> <TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB> <TAB> <TAB> <TAB> if vm_details == "" Absent "" : <TAB> <TAB> <TAB> <TAB> <TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB> <TAB> <TAB> if not query_map [ alias ] [ driver ] : <TAB> <TAB> <TAB> <TAB> query_map [ alias ] . pop ( driver ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> query_map . pop ( alias ) <TAB> return query_map",if not query_map [ alias ] [ driver ] :,if not query_map [ alias ] :,False,98.43,73.85,,,
"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB> <TAB> already_test = [ ] <TAB> <TAB> for fname in lib_zip . namelist ( ) : <TAB> <TAB> <TAB> pname , fname = os . path . split ( fname ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and "" / "" not in pname : <TAB> <TAB> <TAB> <TAB> already_test . append ( pname ) <TAB> <TAB> <TAB> <TAB> if is_shadowing ( pname ) : <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs","if fname . startswith ( ""shadow"" ) :",if fname or ( pname and fname ) :,False,96.61,63.49,,,
"def make_chains ( chains_info ) : <TAB> chains = [ [ ] for _ in chains_info [ 0 ] [ 1 ] ] <TAB> for i , num_ids in enumerate ( chains_info [ : - 1 ] ) : <TAB> <TAB> num , ids = num_ids <TAB> <TAB> for j , ident in enumerate ( ids ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> next_chain_info = chains_info [ i + 1 ] <TAB> <TAB> <TAB> <TAB> previous = next_chain_info [ 1 ] [ j ] <TAB> <TAB> <TAB> <TAB> block = SimpleBlock ( num , ident , previous ) <TAB> <TAB> <TAB> <TAB> chains [ j ] . append ( block ) <TAB> chains = { i : make_generator ( chain ) for i , chain in enumerate ( chains ) } <TAB> return chains",if i + 1 < len ( chains_info ) :,"if ident != """" :",False,94.87,49.33,,,
"def filter_input ( mindate , maxdate , files ) : <TAB> mindate = parse ( mindate ) if mindate is not None else datetime . datetime . min <TAB> maxdate = parse ( maxdate ) if maxdate is not None else datetime . datetime . max <TAB> for line in fileinput . input ( files ) : <TAB> <TAB> tweet = json . loads ( line ) <TAB> <TAB> created_at = parse ( tweet [ "" created_at "" ] ) <TAB> <TAB> created_at = created_at . replace ( tzinfo = None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( json . dumps ( tweet ) )",if created_at < mindate or created_at > maxdate :,if mindate < created_at and maxdate > created_at :,False,94.46,71.27,,,
"def get ( self ) : <TAB> """""" If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called. """""" <TAB> if self . _exception is not _NONE : <TAB> <TAB> if self . _exception is None : <TAB> <TAB> <TAB> return self . value <TAB> <TAB> getcurrent ( ) . throw ( * self . _exception ) # pylint:disable=undefined-variable <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ConcurrentObjectUseError( <TAB> <TAB> <TAB> <TAB> ""This Waiter is already used by %r"" % (self.greenlet,) <TAB> <TAB> <TAB> ) <TAB> <TAB> self.greenlet = getcurrent() # pylint:disable=undefined-variable <TAB> <TAB> try: <TAB> <TAB> <TAB> return self.hub.switch() <TAB> <TAB> finally: <TAB> <TAB> <TAB> self.greenlet = None",if self . greenlet is not None :,if self . greenlet is not None :,True,100.0,74.51,,,
"def default_loader ( href , parse , encoding = None ) : <TAB> with open ( href ) as file : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = ElementTree . parse ( file ) . getroot ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = file . read ( ) <TAB> <TAB> <TAB> if encoding : <TAB> <TAB> <TAB> <TAB> data = data . decode ( encoding ) <TAB> return data",if parse :,"if parse == ""xml"" :",False,94.51,63.66,,,
def is_all_qud ( world ) : <TAB> m = True <TAB> for obj in world : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if obj . nice : <TAB> <TAB> <TAB> <TAB> m = m and True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> m = m and False <TAB> <TAB> else : <TAB> <TAB> <TAB> m = m and True <TAB> return m,"if isinstance ( obj , Quantum ) :",if obj . blond :,False,94.06,45.06,,,
"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB> <TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> if prefixed : <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) <TAB> <TAB> return <TAB> for region in self . view . sel ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> if prefixed : <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed )",if region in self . view . size ( ) :,if region . empty ( ) :,False,96.53,72.82,,,
"def add_fields ( self , params ) : <TAB> for ( key , val ) in params . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_params = { } <TAB> <TAB> <TAB> for k in val : <TAB> <TAB> <TAB> <TAB> new_params [ "" %s __ %s "" % ( key , k ) ] = val [ k ] <TAB> <TAB> <TAB> self . add_fields ( new_params ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . add_field ( key , val )","if isinstance ( val , dict ) :","if isinstance ( val , dict ) :",True,100.0,74.33,,,
"def find_magic ( self , f , pos , magic ) : <TAB> f . seek ( pos ) <TAB> block = f . read ( 32 * 1024 ) <TAB> if len ( block ) < len ( magic ) : <TAB> <TAB> return - 1 <TAB> p = block . find ( magic ) <TAB> while p < 0 : <TAB> <TAB> pos + = len ( block ) - len ( magic ) + 1 <TAB> <TAB> block = block [ 1 - len ( magic ) : ] + f . read ( 32 << 10 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> p = block . find ( magic ) <TAB> return pos + p",if len ( block ) < len ( magic ) :,if len ( block ) == len ( magic ) - 1 :,False,96.04,72.35,,,
"def check_strings ( self ) : <TAB> """""" Check that all strings have been consumed. """""" <TAB> for i , aList in enumerate ( self . string_tokens ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g . trace ( "" warning: line  %s . unused strings "" % i ) <TAB> <TAB> <TAB> for z in aList : <TAB> <TAB> <TAB> <TAB> print ( self . dump_token ( z ) )",if i not in aList :,if aList :,False,96.09,94.79,,,
"def get_tokens_unprocessed ( self , text ) : <TAB> from pygments . lexers . _cocoa_builtins import ( <TAB> <TAB> COCOA_INTERFACES , <TAB> <TAB> COCOA_PROTOCOLS , <TAB> <TAB> COCOA_PRIMITIVES , <TAB> ) <TAB> for index , token , value in RegexLexer . get_tokens_unprocessed ( self , text ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> value in COCOA_INTERFACES <TAB> <TAB> <TAB> <TAB> or value in COCOA_PROTOCOLS <TAB> <TAB> <TAB> <TAB> or value in COCOA_PRIMITIVES <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> token = Name . Builtin . Pseudo <TAB> <TAB> yield index , token , value",if token == Name . Builtin . Keyword :,if token is Name or token is Name . Class :,False,95.71,70.27,,,
"def key_from_key_value_dict ( key_info ) : <TAB> res = [ ] <TAB> if not "" key_value "" in key_info : <TAB> <TAB> return res <TAB> for value in key_info [ "" key_value "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> e = base64_to_long ( value [ "" rsa_key_value "" ] [ "" exponent "" ] ) <TAB> <TAB> <TAB> m = base64_to_long ( value [ "" rsa_key_value "" ] [ "" modulus "" ] ) <TAB> <TAB> <TAB> key = RSA . construct ( ( m , e ) ) <TAB> <TAB> <TAB> res . append ( key ) <TAB> return res","if ""rsa_key_value"" in value :","if ""rsa_key_value"" in value :",True,100.0,74.42,,,
"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB> <TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) <TAB> <TAB> return <TAB> for region in self . view . sel ( ) : <TAB> <TAB> if region . empty ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed )",if self . view . has_selection ( region ) :,if prefixed :,False,89.7,70.78,,,
def finalize ( self ) : <TAB> if self . ct < 1 : <TAB> <TAB> return <TAB> elif self . ct == 1 : <TAB> <TAB> return 0 <TAB> total = ct = 0 <TAB> dtp = None <TAB> while self . heap : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if dtp is None : <TAB> <TAB> <TAB> <TAB> dtp = heapq . heappop ( self . heap ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = heapq . heappop ( self . heap ) <TAB> <TAB> diff = dt - dtp <TAB> <TAB> ct + = 1 <TAB> <TAB> total + = total_seconds ( diff ) <TAB> <TAB> dtp = dt <TAB> return float ( total ) / ct,if self . ct == 1 :,if total == 0 :,False,96.55,96.24,,,
"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB> <TAB> self . _log . debug ( "" testing configuration "" ) <TAB> <TAB> verboseflag = "" -Q "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> verboseflag = "" -v "" <TAB> <TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB> <TAB> if p . wait ( ) != 0 : <TAB> <TAB> <TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB> <TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB> <TAB> os . remove ( config_path )","if self . _version < ( 3 , 5 ) :",if self . _log . isEnabledFor ( logging . DEBUG ) :,False,95.69,71.33,,,
"def exe ( self , ret ) : <TAB> if not ret : <TAB> <TAB> self . assertEqual ( ret , "" "" ) <TAB> else : <TAB> <TAB> assert os . path . isabs ( ret ) , ret <TAB> <TAB> # Note: os.stat() may return False even if the file is there <TAB> <TAB> # hence we skip the test, see: <TAB> <TAB> # http://stackoverflow.com/questions/3112546/os-path-exists-lies <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert os.path.isfile(ret), ret <TAB> <TAB> <TAB> if hasattr(os, ""access"") and hasattr(os, ""X_OK""): <TAB> <TAB> <TAB> <TAB> # XXX may fail on OSX <TAB> <TAB> <TAB> <TAB> self.assertTrue(os.access(ret, os.X_OK))",if os . stat ( ret ) . st_ino == ret . st_ino :,if POSIX :,False,91.97,70.87,,,
"def _do_cleanup ( sg_name , device_id ) : <TAB> masking_view_list = self . rest . get_masking_views_from_storage_group ( array , sg_name ) <TAB> for masking_view in masking_view_list : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . rest . delete_masking_view ( array , masking_view ) <TAB> <TAB> <TAB> self . rest . remove_vol_from_sg ( array , sg_name , device_id , extra_specs ) <TAB> <TAB> <TAB> self . rest . delete_volume ( array , device_id ) <TAB> <TAB> <TAB> self . rest . delete_storage_group ( array , sg_name )",if masking_view . device_id == device_id :,"if ""STG-"" in masking_view :",False,93.55,62.85,,,
"def hide_tooltip_if_necessary ( self , key ) : <TAB> """""" Hide calltip when necessary """""" <TAB> try : <TAB> <TAB> calltip_char = self . get_character ( self . calltip_position ) <TAB> <TAB> before = self . is_cursor_before ( self . calltip_position , char_offset = 1 ) <TAB> <TAB> other = key in ( Qt . Key_ParenRight , Qt . Key_Period , Qt . Key_Tab ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> QToolTip . hideText ( ) <TAB> except ( IndexError , TypeError ) : <TAB> <TAB> QToolTip . hideText ( )",if before and not other :,"if calltip_char not in ( ""?"" , ""("" ) or before or other :",False,89.17,69.86,,,
"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB> <TAB> if limit and len ( tags ) > = limit : <TAB> <TAB> <TAB> result [ "" HasMoreTags "" ] = True <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result",if exclusive_start_tag_key and key != exclusive_start_tag_key :,if exclusive_start_tag_key and key < exclusive_start_tag_key :,False,98.3,73.65,,,
"def parametrize_function_name ( request , function_name ) : <TAB> suffixes = [ ] <TAB> if "" parametrize "" in request . keywords : <TAB> <TAB> argnames = request . keywords [ "" parametrize "" ] . args [ : : 2 ] <TAB> <TAB> argnames = [ x . strip ( ) for names in argnames for x in names . split ( "" , "" ) ] <TAB> <TAB> for name in argnames : <TAB> <TAB> <TAB> value = request . getfuncargvalue ( name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value . __name__ <TAB> <TAB> <TAB> suffixes . append ( "" {} = {} "" . format ( name , value ) ) <TAB> return "" + "" . join ( [ function_name ] + suffixes )","if isinstance ( value , type ) :",if inspect . isclass ( value ) :,False,97.06,72.51,,,
"def add_entities ( self , positions ) : <TAB> e1 = EntityFactory ( ) <TAB> for p in positions : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> start , length = p <TAB> <TAB> else : <TAB> <TAB> <TAB> start , length = p , 1 <TAB> <TAB> EntityOccurrenceFactory ( <TAB> <TAB> <TAB> document = self . doc , <TAB> <TAB> <TAB> entity = e1 , <TAB> <TAB> <TAB> offset = start , <TAB> <TAB> <TAB> offset_end = start + length , <TAB> <TAB> <TAB> alias = "" AB "" , <TAB> <TAB> )","if isinstance ( p , tuple ) :","if isinstance ( p , tuple ) :",True,100.0,74.35,,,
"def transform_value ( value ) : <TAB> if isinstance ( value , collections . MutableMapping ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return DBRef ( value [ "" _ns "" ] , transform_value ( value [ "" _id "" ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return transform_dict ( SON ( value ) ) <TAB> elif isinstance ( value , list ) : <TAB> <TAB> return [ transform_value ( v ) for v in value ] <TAB> return value","if isinstance ( value , dict ) :","if ""_id"" in value and ""_ns"" in value :",False,89.39,64.43,,,
"def remove ( self , items ) : <TAB> """""" Remove messages from lease management. """""" <TAB> with self . _add_remove_lock : <TAB> <TAB> # Remove the ack ID from lease management, and decrement the <TAB> <TAB> # byte counter. <TAB> <TAB> for item in items: <TAB> <TAB> <TAB> if self._leased_messages.pop(item.ack_id, None) is not None: <TAB> <TAB> <TAB> <TAB> self._bytes -= item.byte_size <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> _LOGGER.debug(""Item %s was not managed."", item.ack_id) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _LOGGER.debug(""Bytes was unexpectedly negative: %d"", self._bytes) <TAB> <TAB> <TAB> self._bytes = 0",if self . _bytes < 0 :,if self . _bytes < 0 :,True,100.0,99.39,,,
"def parse_hgsub ( lines ) : <TAB> """""" Fills OrderedDict with hgsub file content passed as list of lines """""" <TAB> rv = OrderedDict ( ) <TAB> for l in lines : <TAB> <TAB> ls = l . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> name , value = l . split ( "" = "" , 1 ) <TAB> <TAB> rv [ name . strip ( ) ] = value . strip ( ) <TAB> return rv","if ls . startswith ( ""#"" ) :","if not ls or ls [ 0 ] == ""#"" :",False,90.94,64.37,,,
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> if self . _keys [ hash_ ] is self . _empty : <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self._keys[hash_] == key: <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self._keys[hash_] = self._deleted <TAB> <TAB> <TAB> self._values[hash_] = self._deleted <TAB> <TAB> <TAB> self._len -= 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self._rehash(hash_) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None",if hash_ == initial_hash :,if initial_hash == hash_ :,False,97.7,72.84,,,
"def atom ( token , no_symbol = False ) : <TAB> try : <TAB> <TAB> return int ( token ) <TAB> except ValueError : <TAB> <TAB> try : <TAB> <TAB> <TAB> return float ( token ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return token [ 1 : - 1 ] <TAB> <TAB> <TAB> elif no_symbol : <TAB> <TAB> <TAB> <TAB> return token <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return Symbol ( token )","if token . startswith ( ""#"" ) :","if token . startswith ( ""'"" ) or token . startswith ( '""' ) :",False,92.73,61.97,,,
"def __Suffix_Noun_Step1b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step1b : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> token = token [ : - 1 ] <TAB> <TAB> <TAB> self . suffixe_noun_step1b_success = True <TAB> <TAB> <TAB> break <TAB> return token",if token . endswith ( suffix ) :,if token . endswith ( suffix ) and len ( token ) > 5 :,False,91.47,66.62,,,
"def _guardAgainstUnicode ( self , data ) : <TAB> # Only accept byte strings or ascii unicode values, otherwise <TAB> # there is no way to correctly decode the data into bytes. <TAB> if _pythonMajorVersion < 3: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data = data.encode(""utf8"") <TAB> else: <TAB> <TAB> if isinstance(data, str): <TAB> <TAB> <TAB> # Only accept ascii unicode values. <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> return data.encode(""ascii"") <TAB> <TAB> <TAB> except UnicodeEncodeError: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> raise ValueError(""pyDes can only work with encoded strings, not Unicode."") <TAB> return data","if isinstance ( data , bytes ) :","if isinstance ( data , unicode ) :",False,98.76,73.24,,,
"def populate_resource_parameters ( self , tool_source ) : <TAB> root = getattr ( tool_source , "" root "" , None ) <TAB> if ( <TAB> <TAB> root is not None <TAB> <TAB> and hasattr ( self . app , "" job_config "" ) <TAB> <TAB> and hasattr ( self . app . job_config , "" get_tool_resource_xml "" ) <TAB> ) : <TAB> <TAB> resource_xml = self . app . job_config . get_tool_resource_xml ( <TAB> <TAB> <TAB> root . get ( "" id "" ) , self . tool_type <TAB> <TAB> ) <TAB> <TAB> if resource_xml is not None : <TAB> <TAB> <TAB> inputs = root . find ( "" inputs "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> inputs = parse_xml_string ( "" <inputs/> "" ) <TAB> <TAB> <TAB> <TAB> root . append ( inputs ) <TAB> <TAB> <TAB> inputs . append ( resource_xml )",if not inputs :,if inputs is None :,False,98.37,72.96,,,
"def test_arguments_regex ( self ) : <TAB> argument_matches = ( <TAB> <TAB> ( "" pip=1.1 "" , ( "" pip "" , "" 1.1 "" ) ) , <TAB> <TAB> ( "" pip==1.1 "" , None ) , <TAB> <TAB> ( "" pip=1.2=1 "" , ( "" pip "" , "" 1.2=1 "" ) ) , <TAB> ) <TAB> for argument , match in argument_matches : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertIsNone ( salt . utils . args . KWARG_REGEX . match ( argument ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> <TAB> salt . utils . args . KWARG_REGEX . match ( argument ) . groups ( ) , match <TAB> <TAB> <TAB> )",if match is None :,if match is None :,True,100.0,74.51,,,
"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB> <TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB> <TAB> if self . service_id : <TAB> <TAB> <TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected",if self . environment_id :,if self . environment_id :,True,100.0,74.16,,,
"def get_ip_info ( ipaddress ) : <TAB> """""" Returns device information by IP address """""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if ip . venture is not None : <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> if ip . device . venture is not None : <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . device is not None :,if ip . device is not None :,True,100.0,99.56,,,
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_place_handle ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if not event . get_place_handle ( ) :,if not event . get_date_object ( ) :,False,98.18,73.39,,,
"def killIfDead ( ) : <TAB> if not self . _isalive : <TAB> <TAB> self . log . debug ( <TAB> <TAB> <TAB> "" WampLongPoll: killing inactive WAMP session with transport  ' {0} ' "" . format ( <TAB> <TAB> <TAB> <TAB> self . _transport_id <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> self . onClose ( False , 5000 , "" session inactive "" ) <TAB> <TAB> self . _receive . _kill ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _parent . _transports [ self . _transport_id ] <TAB> else : <TAB> <TAB> self . log . debug ( <TAB> <TAB> <TAB> "" WampLongPoll: transport  ' {0} '  is still alive "" . format ( self . _transport_id ) <TAB> <TAB> ) <TAB> <TAB> self . _isalive = False <TAB> <TAB> self . reactor . callLater ( killAfter , killIfDead )",if self . _parent . _transports :,if self . _transport_id in self . _parent . _transports :,False,97.21,73.14,,,
"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> l . warning ( <TAB> <TAB> <TAB> <TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB> <TAB> <TAB> <TAB> "" element size. "" , <TAB> <TAB> <TAB> <TAB> self . name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self . _pack : <TAB> <TAB> <TAB> align = ty . alignment <TAB> <TAB> <TAB> if offset_so_far % align != 0 : <TAB> <TAB> <TAB> <TAB> offset_so_far + = align - offset_so_far % align <TAB> <TAB> offsets [ name ] = offset_so_far <TAB> <TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets",if ty . size == 0 :,"if isinstance ( ty , SimTypeBottom ) :",False,97.34,72.32,,,
"def get_override_css ( self ) : <TAB> """""" handls allow_css_overrides setting. """""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB> <TAB> filename = self . view . file_name ( ) <TAB> <TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for filetype in filetypes : <TAB> <TAB> <TAB> <TAB> if filename . endswith ( filetype ) : <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( css_filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" """,if filetypes :,if filename and filetypes :,False,98.49,73.09,,,
"def setFullCSSSource ( self , fullsrc , inline = False ) : <TAB> self . fullsrc = fullsrc <TAB> if type ( self . fullsrc ) == six . binary_type : <TAB> <TAB> self . fullsrc = six . text_type ( self . fullsrc , "" utf-8 "" ) <TAB> if inline : <TAB> <TAB> self . inline = inline <TAB> if self . fullsrc : <TAB> <TAB> self . srcFullIdx = self . fullsrc . find ( self . src ) <TAB> <TAB> if self . srcFullIdx < 0 : <TAB> <TAB> <TAB> del self . srcFullIdx <TAB> <TAB> self . ctxsrcFullIdx = self . fullsrc . find ( self . ctxsrc ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . ctxsrcFullIdx",if self . ctxsrcFullIdx < 0 :,if self . ctxsrcFullIdx < 0 :,True,100.0,74.51,,,
"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> width = self . statwidth ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB> <TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> width = self . colwidth ( ) <TAB> <TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB> <TAB> if i + 1 != len ( self . vars ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" space "" ] <TAB> return ret",if i + 1 < len ( self . vars ) - 1 :,if op . color :,False,95.2,72.57,,,
"def _get_requested_databases ( self ) : <TAB> """""" Returns a list of databases requested, not including ignored dbs """""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB> <TAB> for requested_namespace in self . _requested_namespaces : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <TAB> elif requested_namespace [ 0 ] not in IGNORE_DBS : <TAB> <TAB> <TAB> <TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases",if requested_namespace [ 0 ] in ALL_DBS :,"if requested_namespace [ 0 ] is ""*"" :",False,96.86,95.17,,,
"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB> <TAB> channel = add_channel [ "" channel "" ] <TAB> <TAB> defaults = { "" currency "" : channel . currency_code } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB> <TAB> if "" min_amount_spent "" in add_channel . keys ( ) : <TAB> <TAB> <TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB> <TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB> <TAB> <TAB> voucher = voucher , <TAB> <TAB> <TAB> channel = channel , <TAB> <TAB> <TAB> defaults = defaults , <TAB> <TAB> )","if ""discount_value"" in add_channel . keys ( ) :","if ""discount_value"" in add_channel . keys ( ) :",True,100.0,74.53,,,
"def read_xml ( path ) : <TAB> with tf . gfile . GFile ( path ) as f : <TAB> <TAB> root = etree . fromstring ( f . read ( ) ) <TAB> annotations = { } <TAB> for node in root . getchildren ( ) : <TAB> <TAB> key , val = node2dict ( node ) <TAB> <TAB> # If `key` is object, it's actually a list. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> annotations.setdefault(key, []).append(val) <TAB> <TAB> else: <TAB> <TAB> <TAB> annotations[key] = val <TAB> return annotations","if isinstance ( val , dict ) :","if key == ""object"" :",False,95.2,62.87,,,
"def get_ip_info ( ipaddress ) : <TAB> """""" Returns device information by IP address """""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> if ip . device is not None : <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> if ip . device . venture is not None : <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result",if ip . venture is not None :,if ip . venture is not None :,True,100.0,99.56,,,
"def test_large_headers ( self ) : <TAB> with ExpectLog ( gen_log , "" Unsatisfiable read "" , required = False ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . fetch ( "" / "" , headers = { "" X-Filler "" : "" a "" * 1000 } , raise_error = True ) <TAB> <TAB> <TAB> self . fail ( "" did not raise expected exception "" ) <TAB> <TAB> except HTTPError as e : <TAB> <TAB> <TAB> # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB> <TAB> <TAB> # 6585. However, many implementations just close the <TAB> <TAB> <TAB> # connection in this case, resulting in a missing response. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.assertIn(e.response.code, (431, 599))",if e . response . code != 431 :,if e . response is not None :,False,96.98,72.33,,,
"def validate_reserved_serial_no_consumption ( self ) : <TAB> for item in self . items : <TAB> <TAB> if item . s_warehouse and not item . t_warehouse and item . serial_no : <TAB> <TAB> <TAB> for sr in get_serial_nos ( item . serial_no ) : <TAB> <TAB> <TAB> <TAB> sales_order = frappe . db . get_value ( "" Serial No "" , sr , "" sales_order "" ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> msg = _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" (Serial No:  {0} ) cannot be consumed as it ' s reserverd to fullfill Sales Order  {1} . "" <TAB> <TAB> <TAB> <TAB> <TAB> ) . format ( sr , sales_order ) <TAB> <TAB> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Item  {0} {1} "" ) . format ( item . item_code , msg ) )",if sales_order :,if sales_order :,True,100.0,74.57,,,
"def force_decode ( string , encoding ) : <TAB> if isinstance ( string , str ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> string = string . decode ( encoding ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> # try decoding with utf-8, should only work for real UTF-8 <TAB> <TAB> <TAB> <TAB> string = string.decode(""utf-8"") <TAB> <TAB> <TAB> except UnicodeError: <TAB> <TAB> <TAB> <TAB> # last resort -- can't fail <TAB> <TAB> <TAB> <TAB> string = string.decode(""latin1"") <TAB> return string",if encoding :,if encoding :,True,100.0,74.31,,,
"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB> <TAB> new_parameter = copy . deepcopy ( hp ) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB> if new_parameter.name == """": <TAB> <TAB> <TAB> new_parameter.name = prefix <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_parameter.name = ""{}{}{}"".format(prefix, SPLITTER, new_parameter.name) <TAB> <TAB> new_parameters.append(new_parameter) <TAB> for hp in new_parameters: <TAB> <TAB> _add_hp(master_cs, hp)",elif new_parameter . name != prefix :,"elif not prefix == """" :",False,95.7,65.38,,,
"def __call__ ( self , * args , * * kwargs ) : <TAB> if self . log_file is not None : <TAB> <TAB> kwargs [ "" file "" ] = self . log_file <TAB> <TAB> print ( * args , * * kwargs ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # get immediate feedback <TAB> <TAB> <TAB> self.log_file.flush() <TAB> elif self.log_func is not None: <TAB> <TAB> self.log_func(*args, **kwargs)",if self . log_file . is_file_write ( ) :,"if hasattr ( self . log_file , ""flush"" ) :",False,93.27,63.07,,,
"def df_index_expr ( self , length_expr = None , as_range = False ) : <TAB> """""" Generate expression to get or create index of DF """""" <TAB> if isinstance ( self . index , types . NoneType ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> length_expr = df_length_expr ( self ) <TAB> <TAB> if as_range : <TAB> <TAB> <TAB> return f "" range( { length_expr } ) "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return f "" numpy.arange( { length_expr } ) "" <TAB> return "" self._index """,if length_expr is None :,if length_expr is None :,True,100.0,74.35,,,
"def _setWeight ( self , value ) : <TAB> if value is None : <TAB> <TAB> self . _fontWeight = None <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TextFormatException ( f "" Not a supported fontWeight:  { value } "" ) <TAB> <TAB> self . _fontWeight = value . lower ( )","if value . lower ( ) not in ( ""bold"" , ""bold"" ) :","if value . lower ( ) not in ( ""normal"" , ""bold"" ) :",False,97.39,72.28,,,
"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB> <TAB> self . _log . debug ( "" testing configuration "" ) <TAB> <TAB> verboseflag = "" -Q "" <TAB> <TAB> if self . _log . isEnabledFor ( logging . DEBUG ) : <TAB> <TAB> <TAB> verboseflag = "" -v "" <TAB> <TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB> <TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB> <TAB> os . remove ( config_path )",if p . returncode != 0 :,if p . wait ( ) != 0 :,False,97.65,72.77,,,
"def filter_queryset ( self , request , queryset , view ) : <TAB> kwargs = { } <TAB> for field in view . filterset_fields : <TAB> <TAB> value = request . GET . get ( field ) <TAB> <TAB> if not value : <TAB> <TAB> <TAB> continue <TAB> <TAB> if field == "" node_id "" : <TAB> <TAB> <TAB> value = get_object_or_none ( Node , pk = value ) <TAB> <TAB> <TAB> kwargs [ "" node "" ] = value <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> field = "" asset "" <TAB> <TAB> kwargs [ field ] = value <TAB> if kwargs : <TAB> <TAB> queryset = queryset . filter ( * * kwargs ) <TAB> logger . debug ( "" Filter  {} "" . format ( kwargs ) ) <TAB> return queryset","if field == ""asset_id"" :","elif field == ""asset_id"" :",False,98.87,73.54,,,
"def _find_closing_brace ( string , start_pos ) : <TAB> """""" Finds the corresponding closing brace after start_pos. """""" <TAB> bracks_open = 1 <TAB> for idx , char in enumerate ( string [ start_pos : ] ) : <TAB> <TAB> if char == "" ( "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> bracks_open + = 1 <TAB> <TAB> elif char == "" ) "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> bracks_open - = 1 <TAB> <TAB> <TAB> if not bracks_open : <TAB> <TAB> <TAB> <TAB> return start_pos + idx + 1",if len ( string [ start_pos + idx ] ) > bracks_open :,"if string [ idx + start_pos - 1 ] != ""\\"" :",False,86.24,55.8,,,
"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB> <TAB> i = host . rfind ( "" : "" ) <TAB> <TAB> j = host . rfind ( "" ] "" ) # ipv6 addresses have [...] <TAB> <TAB> if i > j: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> port = int(host[i + 1 :]) <TAB> <TAB> <TAB> except ValueError: <TAB> <TAB> <TAB> <TAB> raise InvalidURL(""nonnumeric port: '%s'"" % host[i + 1 :]) <TAB> <TAB> <TAB> host = host[:i] <TAB> <TAB> else: <TAB> <TAB> <TAB> port = self.default_port <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> host = host[1:-1] <TAB> self.host = host <TAB> self.port = port","if host . endswith ( ""["" ) :","if host and host [ 0 ] == ""["" and host [ - 1 ] == ""]"" :",False,91.59,63.75,,,
"def __getstate__ ( self ) : <TAB> state = { } <TAB> for cls in type ( self ) . mro ( ) : <TAB> <TAB> cls_slots = getattr ( cls , "" __slots__ "" , ( ) ) <TAB> <TAB> for slot in cls_slots : <TAB> <TAB> <TAB> if slot != "" __weakref__ "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> state [ slot ] = getattr ( self , slot ) <TAB> state [ "" _cookiejar_cookies "" ] = list ( self . cookiejar ) <TAB> del state [ "" cookiejar "" ] <TAB> return state","if getattr ( self , slot ) :","if hasattr ( self , slot ) :",False,98.52,73.28,,,
"def _evp_pkey_from_der_traditional_key ( self , bio_data , password ) : <TAB> key = self . _lib . d2i_PrivateKey_bio ( bio_data . bio , self . _ffi . NULL ) <TAB> if key != self . _ffi . NULL : <TAB> <TAB> key = self . _ffi . gc ( key , self . _lib . EVP_PKEY_free ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError ( "" Password was given but private key is not encrypted. "" ) <TAB> <TAB> return key <TAB> else : <TAB> <TAB> self . _consume_errors ( ) <TAB> <TAB> return None",if password != self . _ffi . b64 :,if password is not None :,False,94.39,71.02,,,
"def is_special ( s , i , directive ) : <TAB> """""" Return True if the body text contains the @ directive. """""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive[0] == ""@"" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in (""@others"", ""@all"") <TAB> while i < len(s): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True, i <TAB> <TAB> else: <TAB> <TAB> <TAB> i = skip_line(s, i) <TAB> <TAB> <TAB> if skip_flag: <TAB> <TAB> <TAB> <TAB> i = skip_ws(s, i) <TAB> return False, -1",if s [ i ] == directive :,"if match_word ( s , i , directive ) :",False,95.26,70.31,,,
"def _decorator ( coro_func ) : <TAB> fut = asyncio . ensure_future ( coro_func ( ) ) <TAB> self . _tests . append ( ( coro_func . __name__ , fut ) ) <TAB> if timeout_sec is not None : <TAB> <TAB> timeout_at = self . _loop . time ( ) + timeout_sec <TAB> <TAB> handle = self . MASTER_LOOP . call_at ( <TAB> <TAB> <TAB> timeout_at , self . _set_exception_if_not_done , fut , asyncio . TimeoutError ( ) <TAB> <TAB> ) <TAB> <TAB> fut . add_done_callback ( lambda * args : handle . cancel ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _global_timeout_at = timeout_at <TAB> return coro_func",if timeout_at is not None :,if timeout_at > self . _global_timeout_at :,False,95.01,72.14,,,
"def _load ( self , db , owner ) : <TAB> self . __init ( owner ) <TAB> db_result = db ( <TAB> <TAB> "" SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ? "" , <TAB> <TAB> self . owner . worldid , <TAB> ) <TAB> for ( <TAB> <TAB> ship_id , <TAB> <TAB> state_id , <TAB> ) in db_result : <TAB> <TAB> ship = WorldObject . get_object_by_id ( ship_id ) <TAB> <TAB> state = self . shipStates [ state_id ] <TAB> <TAB> # add move callbacks corresponding to given state <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ship.add_move_callback(Callback(BehaviorMoveCallback._arrived, ship)) <TAB> <TAB> self.add_new_unit(ship, state)","if state == ""arrived"" :",if state == self . shipStates . moving :,False,97.06,63.2,,,
"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB> <TAB> elif self . dots : <TAB> <TAB> <TAB> self . stream . write ( "" s "" ) <TAB> <TAB> <TAB> self . stream . flush ( ) <TAB> <TAB> return <TAB> _org_AddError ( self , test , err )",if self . verbose :,if self . showAll :,False,97.91,72.78,,,
"def _construct ( self , node ) : <TAB> self . flatten_mapping ( node ) <TAB> ret = self . construct_pairs ( node ) <TAB> keys = [ d [ 0 ] for d in ret ] <TAB> keys_sorted = sorted ( keys , key = _natsort_key ) <TAB> for key in keys : <TAB> <TAB> expected = keys_sorted . pop ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ConstructorError ( <TAB> <TAB> <TAB> <TAB> None , <TAB> <TAB> <TAB> <TAB> None , <TAB> <TAB> <TAB> <TAB> "" keys out of order:  "" <TAB> <TAB> <TAB> <TAB> "" expected  {}  got  {}  at  {} "" . format ( expected , key , node . start_mark ) , <TAB> <TAB> <TAB> ) <TAB> return dict ( ret )",if expected != key :,if key != expected :,False,98.0,73.1,,,
"def sample_pos_items_for_u ( u , num ) : <TAB> # sample num pos items for u-th user <TAB> pos_items = self.train_items[u] <TAB> n_pos_items = len(pos_items) <TAB> pos_batch = [] <TAB> while True: <TAB> <TAB> if len(pos_batch) == num: <TAB> <TAB> <TAB> break <TAB> <TAB> pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0] <TAB> <TAB> pos_i_id = pos_items[pos_id] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pos_batch.append(pos_i_id) <TAB> return pos_batch",if pos_i_id not in pos_items :,if pos_i_id not in pos_batch :,False,98.74,72.31,,,
"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> itype = fields [ - 2 ] <TAB> <TAB> if type != itype : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id",if type != fields [ - 2 ] :,if type != fields [ - 2 ] :,True,100.0,74.63,,,
"def uninstall_environments ( self , environments ) : <TAB> environments = [ <TAB> <TAB> env <TAB> <TAB> if not env . startswith ( self . conda_context . envs_path ) <TAB> <TAB> else os . path . basename ( env ) <TAB> <TAB> for env in environments <TAB> ] <TAB> return_codes = [ self . conda_context . exec_remove ( [ env ] ) for env in environments ] <TAB> final_return_code = 0 <TAB> for env , return_code in zip ( environments , return_codes ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . debug ( "" Conda environment  ' %s '  successfully removed. "" % env ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . debug ( "" Conda environment  ' %s '  could not be removed. "" % env ) <TAB> <TAB> <TAB> final_return_code = return_code <TAB> return final_return_code",if self . conda_context . exec_remove ( [ env ] ) :,if return_code == 0 :,False,93.68,71.92,,,
"def _add_hit_offset ( self , context_list , string_name , original_offset , value ) : <TAB> for context in context_list : <TAB> <TAB> hits_by_context_dict = self . hits_by_context . setdefault ( context , { } ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hits_by_context_dict [ string_name ] = ( <TAB> <TAB> <TAB> <TAB> original_offset , <TAB> <TAB> <TAB> <TAB> value . encode ( "" base64 "" ) , <TAB> <TAB> <TAB> )",if string_name in hits_by_context_dict :,if string_name not in hits_by_context_dict :,False,98.36,72.24,,,
"def detab ( self , text , length = None ) : <TAB> """""" Remove a tab from the front of each line of the given text. """""" <TAB> if length is None : <TAB> <TAB> length = self . tab_length <TAB> newtext = [ ] <TAB> lines = text . split ( "" \n "" ) <TAB> for line in lines : <TAB> <TAB> if line . startswith ( "" "" * length ) : <TAB> <TAB> <TAB> newtext . append ( line [ length : ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> newtext . append ( "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return "" \n "" . join ( newtext ) , "" \n "" . join ( lines [ len ( newtext ) : ] )","elif line . startswith ( ""\t"" * length ) :",elif not line . strip ( ) :,False,94.8,72.2,,,
"def dump ( self ) : <TAB> print ( self . package_name ) <TAB> for package , value in self . entries : <TAB> <TAB> print ( str ( package . version ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( ""  <TAB> [FILTERED] "" ) <TAB> <TAB> elif isinstance ( value , list ) : <TAB> <TAB> <TAB> variants = value <TAB> <TAB> <TAB> for variant in variants : <TAB> <TAB> <TAB> <TAB> print ( ""  <TAB>  %s "" % str ( variant ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( ""  <TAB>  %s "" % str ( package ) )","if isinstance ( value , dict ) :",if value is None :,False,95.86,71.55,,,
"def __lexical_scope ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> scope = Scope ( quasi ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> binding_name_set_stack [ - 1 ] . add_child ( scope ) <TAB> <TAB> binding_name_set_stack . append ( scope ) <TAB> <TAB> return func ( * args , * * kwargs ) <TAB> finally : <TAB> <TAB> if binding_name_set_stack [ - 1 ] is scope : <TAB> <TAB> <TAB> binding_name_set_stack . pop ( )",if scope not in binding_name_set_stack :,if quasi :,False,92.6,71.86,,,
"def getnotes ( self , origin = None ) : <TAB> if origin is None : <TAB> <TAB> result = self . translator_comments <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> result + = "" \n "" + self . developer_comments <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result = self . developer_comments <TAB> <TAB> return result <TAB> elif origin == "" translator "" : <TAB> <TAB> return self . translator_comments <TAB> elif origin in ( "" programmer "" , "" developer "" , "" source code "" ) : <TAB> <TAB> return self . developer_comments <TAB> else : <TAB> <TAB> raise ValueError ( "" Comment type not valid "" )","if origin == ""translator"" :",if self . developer_comments :,False,96.16,68.76,,,
"def fix_datetime_fields ( data : TableData , table : TableName ) - > None : <TAB> for item in data [ table ] : <TAB> <TAB> for field_name in DATE_FIELDS [ table ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item [ field_name ] = datetime . datetime . fromtimestamp ( <TAB> <TAB> <TAB> <TAB> <TAB> item [ field_name ] , tz = datetime . timezone . utc <TAB> <TAB> <TAB> <TAB> )",if field_name in item :,if item [ field_name ] is not None :,False,93.4,68.91,,,
"def _check_for_cart_error ( cart ) : <TAB> if cart . _safe_get_element ( "" Cart.Request.Errors "" ) is not None : <TAB> <TAB> error = cart . _safe_get_element ( "" Cart.Request.Errors.Error.Code "" ) . text <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise CartInfoMismatchException ( <TAB> <TAB> <TAB> <TAB> "" CartGet failed: AWS.ECommerceService.CartInfoMismatch  "" <TAB> <TAB> <TAB> <TAB> "" make sure AssociateTag, CartId and HMAC are correct  "" <TAB> <TAB> <TAB> <TAB> "" (dont use URLEncodedHMAC!!!) "" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise CartException ( "" CartGet failed:  "" + error )","if error in [ ""CartId"" , ""HMAC"" ] :","if error == ""AWS.ECommerceService.CartInfoMismatch"" :",False,94.27,67.99,,,
"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB> <TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> )",if geometry [ 0 ] > 90 or geometry [ 0 ] < - 90 :,if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :,False,97.32,72.56,,,
"def _mapper_output_protocol ( self , step_num , step_map ) : <TAB> map_key = self . _step_key ( step_num , "" mapper "" ) <TAB> if map_key in step_map : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . output_protocol ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . internal_protocol ( ) <TAB> else : <TAB> <TAB> # mapper is not a script substep, so protocols don't apply at all <TAB> <TAB> return RawValueProtocol()",if step_map [ map_key ] . is_output :,if step_map [ map_key ] >= ( len ( step_map ) - 1 ) :,False,91.44,68.63,,,
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> if env . cache_static : <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag )",if e . errno == errno . ENOENT :,if path == paths [ - 1 ] :,False,96.81,72.09,,,
"def ping ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> payload = payload . decode ( "" utf-8 "" ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Sending a ping data frame  "" <TAB> <TAB> <TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PING ) <TAB> with self . sock_send_lock : <TAB> <TAB> self . sock . send ( data )","if isinstance ( payload , bytes ) :","if isinstance ( payload , bytes ) :",True,100.0,74.46,,,
"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> if f . read ( ) . strip ( ) != "" Mains "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError : <TAB> <TAB> <TAB> continue <TAB> return False","if f . read ( ) . strip ( ) != ""Connected"" :","if f . read ( 1 ) == ""1"" :",False,95.62,71.77,,,
"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . validate_base_model ( model ) <TAB> <TAB> if hasattr ( model , "" _feincms_content_models "" ) : <TAB> <TAB> <TAB> self . validate_content_type ( model )","if hasattr ( model , ""_feincms_base_models"" ) :","if hasattr ( model , ""_create_content_base"" ) :",False,96.22,72.88,,,
"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> if module . padding_idx is not None : <TAB> <TAB> <TAB> module . weight . data [ module . padding_idx ] . zero_ ( )",if module . bias is not None :,if module . bias is not None :,True,100.0,74.49,,,
"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part.get_content_maintype() == ""multipart"": <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part.get_content_type() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part.get_filename() <TAB> <TAB> if not filename: <TAB> <TAB> <TAB> filename = PART_FN_TPL % (partnum) <TAB> <TAB> headers = dict(part) <TAB> <TAB> LOG.debug(headers) <TAB> <TAB> headers[""Content-Type""] = ctype <TAB> <TAB> payload = util.fully_decoded_payload(part) <TAB> <TAB> callback(data, filename, payload, headers) <TAB> <TAB> partnum = partnum + 1",if not ctype :,if ctype is None :,False,98.24,72.13,,,
"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB> <TAB> if dirs [ m , n ] == "" | "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> <TAB> mask [ m ] = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> elif dirs [ m , n ] == "" < "" : <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask","elif dirs [ m , n ] == "">"" :","elif dirs [ m , n ] == ""^"" :",False,98.62,73.4,,,
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line.strip() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT.match(line) <TAB> <TAB> if match: <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters: <TAB> <TAB> <TAB> if "","" in line or "";"" in line: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line",if not line :,"if line == """" :",False,96.78,60.95,,,
"def fetch ( self , * tileables , * * kw ) : <TAB> ret_list = False <TAB> if len ( tileables ) == 1 and isinstance ( tileables [ 0 ] , ( tuple , list ) ) : <TAB> <TAB> ret_list = True <TAB> <TAB> tileables = tileables [ 0 ] <TAB> elif len ( tileables ) > 1 : <TAB> <TAB> ret_list = True <TAB> result = self . _sess . fetch ( * tileables , * * kw ) <TAB> ret = [ ] <TAB> for r , t in zip ( result , tileables ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( r . item ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret . append ( r ) <TAB> if ret_list : <TAB> <TAB> return ret <TAB> return ret [ 0 ]","if isinstance ( t , ( tuple , list ) ) :","if hasattr ( t , ""isscalar"" ) and t . isscalar ( ) and getattr ( r , ""size"" , None ) == 1 :",False,88.17,61.04,,,
"def _convert ( container ) : <TAB> if _value_marker in container : <TAB> <TAB> force_list = False <TAB> <TAB> values = container . pop ( _value_marker ) <TAB> <TAB> if container . pop ( _list_marker , False ) : <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> values = values [ 0 ] <TAB> <TAB> if not container : <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert ( container ) <TAB> elif container . pop ( _list_marker , False ) : <TAB> <TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) )",if force_list :,if not force_list and len ( values ) == 1 :,False,95.14,71.47,,,
"def _transform_init_kwargs ( cls , kwargs ) : <TAB> transformed = [ ] <TAB> for field in list ( kwargs . keys ( ) ) : <TAB> <TAB> prop = getattr ( cls , field , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = kwargs . pop ( field ) <TAB> <TAB> <TAB> _transform_single_init_kwarg ( prop , field , value , kwargs ) <TAB> <TAB> <TAB> transformed . append ( ( field , value ) ) <TAB> return transformed",if prop is not None :,"if isinstance ( prop , MoneyProperty ) :",False,94.43,70.2,,,
"def haslayer ( self , cls ) : <TAB> """""" true if self has a layer that is an instance of cls. Superseded by  "" cls in self ""  syntax. """""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB> <TAB> return 1 <TAB> for f in self . packetfields : <TAB> <TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB> <TAB> if fvalue_gen is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f . islist : <TAB> <TAB> <TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB> <TAB> for fvalue in fvalue_gen : <TAB> <TAB> <TAB> if isinstance ( fvalue , Packet ) : <TAB> <TAB> <TAB> <TAB> ret = fvalue . haslayer ( cls ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self . payload . haslayer ( cls )",if ret :,if ret :,True,100.0,99.62,,,
def insert_broken_add_sometimes ( node ) : <TAB> if node . op == theano . tensor . add : <TAB> <TAB> last_time_replaced [ 0 ] = not last_time_replaced [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ off_by_half ( * node . inputs ) ] <TAB> return False,if last_time_replaced [ 0 ] :,if last_time_replaced [ 0 ] :,True,100.0,98.88,,,
"def testReadChunk10 ( self ) : <TAB> # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB> self.createTempFile() <TAB> with BZ2File(self.filename) as bz2f: <TAB> <TAB> text = """" <TAB> <TAB> while 1: <TAB> <TAB> <TAB> str = bz2f.read(10) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text += str <TAB> <TAB> self.assertEqual(text, self.TEXT)",if not str :,if not str :,True,100.0,98.98,,,
"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores boundless super face <TAB> sv_faces = [] <TAB> for i, face in enumerate(dcel_mesh.faces): <TAB> <TAB> if face.inners and face.outer: <TAB> <TAB> <TAB> ""Face ({}) has inner components! Sverchok cant show polygons with holes."".format( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face.outer or del_flag in face.flags: <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces.append([point_index[hedge.origin] for hedge in face.outer.loop_hedges]) <TAB> return sv_faces",if only_select and face . inners and face . outer . loop_hedges :,if only_select and not face . select :,False,95.21,71.18,,,
"def __check_dict_contains ( dct , dict_name , keys , comment = "" "" , result = True ) : <TAB> for key in keys : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = False <TAB> <TAB> <TAB> comment = __append_comment ( <TAB> <TAB> <TAB> <TAB> "" Missing  {0}  in  {1} "" . format ( key , dict_name ) , comment <TAB> <TAB> <TAB> ) <TAB> return result , comment",if not dct . get ( key ) :,if key not in six . iterkeys ( dct ) :,False,93.58,68.8,,,
"def _dump_arg_defaults ( kwargs ) : <TAB> """""" Inject default arguments for dump functions. """""" <TAB> if current_app : <TAB> <TAB> kwargs . setdefault ( "" cls "" , current_app . json_encoder ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs . setdefault ( "" ensure_ascii "" , False ) <TAB> <TAB> kwargs . setdefault ( "" sort_keys "" , current_app . config [ "" JSON_SORT_KEYS "" ] ) <TAB> else : <TAB> <TAB> kwargs . setdefault ( "" sort_keys "" , True ) <TAB> <TAB> kwargs . setdefault ( "" cls "" , JSONEncoder )","if ""sort_keys"" in current_app . config :","if not current_app . config [ ""JSON_AS_ASCII"" ] :",False,92.73,68.37,,,
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed",if value != 0 :,elif len ( value ) != 0 :,False,97.16,72.04,,,
"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tab = p . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> if tab [ 0 ] == "" socks "" : <TAB> <TAB> <TAB> <TAB> tab [ 0 ] = "" SOCKS4 "" <TAB> <TAB> <TAB> proxies . append ( <TAB> <TAB> <TAB> <TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB> <TAB> <TAB> ) # type, addr:port, username, password <TAB> <TAB> else: <TAB> <TAB> <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies","if ""="" in p :","if ""="" in p :",True,100.0,74.49,,,
"def predict ( collect_dir , keys ) : <TAB> run_all = len ( keys ) == 0 <TAB> validate_keys ( keys ) <TAB> for exp_cfg in cfg : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = exp_cfg [ "" key "" ] <TAB> <TAB> <TAB> _predict ( key , exp_cfg [ "" sample_img "" ] , collect_dir )",if run_all :,"if run_all or exp_cfg [ ""key"" ] in keys :",False,88.42,61.47,,,
"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB> <TAB> key = str ( k ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key + = "" /tcp "" <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result","if k . startswith ( ""tcp"" ) :","if ""/"" not in key :",False,94.34,70.8,,,
"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB> <TAB> key = str ( k ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key + = "" /tcp "" <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result","if k . startswith ( ""tcp"" ) :",if sentence_splitter,False,93.41,63.23,,,
"def post ( self , request , * args , * * kwargs ) : <TAB> self . comment_obj = get_object_or_404 ( Comment , id = request . POST . get ( "" commentid "" ) ) <TAB> if request . user == self . comment_obj . commented_by : <TAB> <TAB> form = LeadCommentForm ( request . POST , instance = self . comment_obj ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . form_valid ( form ) <TAB> <TAB> return self . form_invalid ( form ) <TAB> data = { "" error "" : "" You don ' t have permission to edit this comment. "" } <TAB> return JsonResponse ( data )",if form . is_valid ( ) :,if form . is_valid ( ) :,True,100.0,74.46,,,
"def trivia_list ( self , ctx : commands . Context ) : <TAB> """""" List available trivia categories. """""" <TAB> lists = set ( p . stem for p in self . _all_lists ( ) ) <TAB> if await ctx . embed_requested ( ) : <TAB> <TAB> await ctx . send ( <TAB> <TAB> <TAB> embed = discord . Embed ( <TAB> <TAB> <TAB> <TAB> title = _ ( "" Available trivia lists "" ) , <TAB> <TAB> <TAB> <TAB> colour = await ctx . embed_colour ( ) , <TAB> <TAB> <TAB> <TAB> description = "" ,  "" . join ( sorted ( lists ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> msg = box ( bold ( _ ( "" Available trivia lists "" ) ) + "" \n \n "" + "" ,  "" . join ( sorted ( lists ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await ctx . author . send ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await ctx . send ( msg )",if ctx . author :,if len ( msg ) > 1000 :,False,97.3,69.65,,,
"def validate ( self ) : <TAB> result = validators . SUCCESS <TAB> msgs = [ ] <TAB> for validator in self . _validators : <TAB> <TAB> res , err = validator . validate ( ) <TAB> <TAB> if res == validators . ERROR : <TAB> <TAB> <TAB> result = res <TAB> <TAB> elif res == validators . WARNING and result != validators . ERROR : <TAB> <TAB> <TAB> result = res <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msgs . append ( err ) <TAB> return result , "" \n "" . join ( msgs )",elif err :,if len ( err ) > 0 :,False,94.41,70.25,,,
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> if mod_type == imp . PY_SOURCE : <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code",elif mod_type == imp . PY_DIRECTORY :,elif mod_type == imp . PY_COMPILED :,False,99.04,73.81,,,
"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> if self . compress : <TAB> <TAB> f . compress = zlib . compressobj ( <TAB> <TAB> <TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB> <TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB> <TAB> if self . compress : <TAB> <TAB> <TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f . fileobj . close ( ) <TAB> <TAB> <TAB> <TAB> f . fileobj = None <TAB> <TAB> else : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> self . files . pop ( key )",if open_files == 0 :,if open_files > self . MAX_OPEN_FILES :,False,96.02,72.83,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.14,,,
"def init_author_file ( self ) : <TAB> self . author_map = { } <TAB> if self . ui . config ( "" git "" , "" authors "" ) : <TAB> <TAB> f = open ( self . repo . wjoin ( self . ui . config ( "" git "" , "" authors "" ) ) ) <TAB> <TAB> try : <TAB> <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> from_ , to = RE_AUTHOR_FILE . split ( line , 2 ) <TAB> <TAB> <TAB> <TAB> self . author_map [ from_ ] = to <TAB> <TAB> finally : <TAB> <TAB> <TAB> f . close ( )",if not line :,"if not line or line . startswith ( ""#"" ) :",False,95.31,67.06,,,
"def decode_imsi ( self , imsi ) : <TAB> new_imsi = "" "" <TAB> for a in imsi : <TAB> <TAB> c = hex ( a ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_imsi + = str ( c [ 3 ] ) + str ( c [ 2 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_imsi + = str ( c [ 2 ] ) + "" 0 "" <TAB> mcc = new_imsi [ 1 : 4 ] <TAB> mnc = new_imsi [ 4 : 6 ] <TAB> return new_imsi , mcc , mnc",if c [ 3 ] :,if len ( c ) == 4 :,False,94.54,70.93,,,
"def _get_infoset ( self , prefname ) : <TAB> """""" Return methods with the name starting with prefname. """""" <TAB> infoset = [ ] <TAB> excludes = ( "" %s infoset "" % prefname , ) <TAB> preflen = len ( prefname ) <TAB> for name in dir ( self . __class__ ) : <TAB> <TAB> if name . startswith ( prefname ) and name not in excludes : <TAB> <TAB> <TAB> member = getattr ( self . __class__ , name ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> infoset . append ( name [ preflen : ] . replace ( "" _ "" , "" "" ) ) <TAB> return infoset","if isinstance ( member , types . ClassType ) and isinstance ( member , types . ClassType ) :","if isinstance ( member , MethodType ) :",False,92.6,94.59,,,
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> if ttype == SCE_PL_UNUSED : <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> if self . opHash . has_key ( tval ) : <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break",if nestedCount == 0 :,if nestedCount <= 0 :,False,99.03,73.65,,,
"def findMarkForUnitTestNodes ( self ) : <TAB> """""" return the position of *all* non-ignored @mark-for-unit-test nodes. """""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> seen . append ( p . v ) <TAB> <TAB> <TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> elif p . h . startswith ( "" @mark-for-unit-tests "" ) : <TAB> <TAB> <TAB> <TAB> result . append ( p . copy ( ) ) <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> p . moveToThreadNext ( ) <TAB> return result",if p . v in seen :,if p . v in seen :,True,100.0,99.6,,,
"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB> <TAB> earlier_part = earlier [ "" part "" ] <TAB> <TAB> earlier_step = earlier [ "" step "" ] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts : <TAB> <TAB> <TAB> if earlier_part == current [ "" part "" ] and earlier_step == current [ "" step "" ] : <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB> <TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint )",if found :,if not found :,False,99.0,73.66,,,
"def unmark_first_parents ( event = None ) : <TAB> """""" Mark the node and all its parents. """""" <TAB> c = event . get ( "" c "" ) <TAB> if not c : <TAB> <TAB> return <TAB> changed = [ ] <TAB> for parent in c . p . self_and_parents ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parent . v . clearMarked ( ) <TAB> <TAB> <TAB> parent . setAllAncestorAtFileNodesDirty ( ) <TAB> <TAB> <TAB> changed . append ( parent . copy ( ) ) <TAB> if changed : <TAB> <TAB> # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB> <TAB> c.setChanged() <TAB> <TAB> c.redraw() <TAB> return changed",if parent . v :,if parent . isMarked ( ) :,False,97.83,96.16,,,
"def stop ( self ) : <TAB> self . _log ( "" Monitor stop "" ) <TAB> self . _stop_requested = True <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fd = os . open ( self . fifo_path , os . O_WRONLY ) <TAB> <TAB> <TAB> os . write ( fd , b "" X "" ) <TAB> <TAB> <TAB> os . close ( fd ) <TAB> except Exception as e : <TAB> <TAB> self . _log ( "" err while closing:  {0} "" . format ( str ( e ) ) ) <TAB> if self . _thread : <TAB> <TAB> self . _thread . join ( ) <TAB> <TAB> self . _thread = None",if self . fifo_path :,if os . path . exists ( self . fifo_path ) :,False,94.61,70.62,,,
"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB> <TAB> f = True <TAB> <TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB> if f : <TAB> <TAB> <TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB> <TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB> <TAB> cols2delete = [ x - 1 for x in cols2delete ]",if cols2delete [ r ] == c :,"if self . FindItemAtPosition ( ( r , c ) ) is not None :",False,91.75,68.71,,,
"def _load_objects ( self , obj_id_zset , limit , chunk_size = 1000 ) : <TAB> ct = i = 0 <TAB> while True : <TAB> <TAB> id_chunk = obj_id_zset [ i : i + chunk_size ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> i + = chunk_size <TAB> <TAB> for raw_data in self . _data [ id_chunk ] : <TAB> <TAB> <TAB> if not raw_data : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if self . _use_json : <TAB> <TAB> <TAB> <TAB> yield json . loads ( decode ( raw_data ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield raw_data <TAB> <TAB> <TAB> ct + = 1 <TAB> <TAB> <TAB> if limit and ct == limit : <TAB> <TAB> <TAB> <TAB> return",if id_chunk in self . _data :,if not id_chunk :,False,96.89,72.64,,,
"def _convert_example ( example , use_bfloat16 ) : <TAB> """""" Cast int64 into int32 and float32 to bfloat16 if use_bfloat16. """""" <TAB> for key in list ( example . keys ( ) ) : <TAB> <TAB> val = example [ key ] <TAB> <TAB> if tf . keras . backend . is_sparse ( val ) : <TAB> <TAB> <TAB> val = tf . sparse . to_dense ( val ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = tf . cast ( val , tf . int32 ) <TAB> <TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB> <TAB> example [ key ] = val",if use_bfloat16 and val . dtype == tf . float64 :,if val . dtype == tf . int64 :,False,95.89,95.99,,,
"def print_callees ( self , * amount ) : <TAB> width , list = self . get_print_list ( amount ) <TAB> if list : <TAB> <TAB> self . calc_callees ( ) <TAB> <TAB> self . print_call_heading ( width , "" called... "" ) <TAB> <TAB> for func in list : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . print_call_line ( width , func , self . all_callees [ func ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . print_call_line ( width , func , { } ) <TAB> <TAB> print >> self . stream <TAB> <TAB> print >> self . stream <TAB> return self",if func in self . all_callees :,if func in self . all_callees :,True,100.0,74.45,,,
"def on_task_input ( self , task , config ) : <TAB> if config is False : <TAB> <TAB> return <TAB> for entry in task . entries : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log_once ( <TAB> <TAB> <TAB> <TAB> "" Corrected ` %s ` url (replaced &amp; with &) "" % entry [ "" title "" ] , <TAB> <TAB> <TAB> <TAB> logger = log , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> entry [ "" url "" ] = entry [ "" url "" ] . replace ( "" &amp; "" , "" & "" )","if entry [ ""url"" ] :","if ""&amp;"" in entry [ ""url"" ] :",False,96.58,69.31,,,
"def function ( self , inputs , outputs , ignore_empty = False ) : <TAB> f = function ( inputs , outputs , mode = self . mode ) <TAB> if self . mode is not None or theano . config . mode != "" FAST_COMPILE "" : <TAB> <TAB> topo = f . maker . fgraph . toposort ( ) <TAB> <TAB> topo_ = [ node for node in topo if not isinstance ( node . op , self . ignore_topo ) ] <TAB> <TAB> if ignore_empty : <TAB> <TAB> <TAB> assert len ( topo_ ) < = 1 , topo_ <TAB> <TAB> else : <TAB> <TAB> <TAB> assert len ( topo_ ) == 1 , topo_ <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert type ( topo_ [ 0 ] . op ) is self . op <TAB> return f",if self . ignore_topo :,if len ( topo_ ) > 0 :,False,96.14,72.13,,,
"def _get_env_command ( self ) - > Sequence [ str ] : <TAB> """""" Get command sequence for `env` with configured flags. """""" <TAB> env_list = [ "" env "" ] <TAB> # Pass through configurable environment variables. <TAB> for key in [""http_proxy"", ""https_proxy""]: <TAB> <TAB> value = self.build_provider_flags.get(key) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Ensure item is treated as string and append it. <TAB> <TAB> value = str(value) <TAB> <TAB> env_list.append(f""{key}={value}"") <TAB> return env_list",if value is None :,if not value :,False,97.6,96.81,,,
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB> <TAB> <TAB> if redo : <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . callback ( )",if self . callback :,if self . callback :,True,100.0,74.49,,,
"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self.code: <TAB> <TAB> self.code = u""static-%s"" % uuid.uuid4() <TAB> if not self.site: <TAB> <TAB> placeholders = StaticPlaceholder.objects.filter( <TAB> <TAB> <TAB> code=self.code, site__isnull=True <TAB> <TAB> ) <TAB> <TAB> if self.pk: <TAB> <TAB> <TAB> placeholders = placeholders.exclude(pk=self.pk) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValidationError( <TAB> <TAB> <TAB> <TAB> _(""A static placeholder with the same site and code already exists"") <TAB> <TAB> <TAB> )",if all ( [ i in placeholders for i in placeholders ] ) :,if placeholders . exists ( ) :,False,94.12,69.88,,,
"def load_parser ( self ) : <TAB> result = OrderedDict ( ) <TAB> for name , flags in self . filenames : <TAB> <TAB> filename = self . get_filename ( name ) <TAB> <TAB> for match in sorted ( glob ( filename ) , key = self . file_key ) : <TAB> <TAB> <TAB> # Needed to allow overlapping globs, more specific first <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> result[match] = TextParser(match, os.path.relpath(match, self.base), flags) <TAB> return result",if match in result :,if match in result :,True,100.0,74.3,,,
"def __init__ ( self , selectable , name = None ) : <TAB> baseselectable = selectable <TAB> while isinstance ( baseselectable , Alias ) : <TAB> <TAB> baseselectable = baseselectable . element <TAB> self . original = baseselectable <TAB> self . supports_execution = baseselectable . supports_execution <TAB> if self . supports_execution : <TAB> <TAB> self . _execution_options = baseselectable . _execution_options <TAB> self . element = selectable <TAB> if name is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> name = getattr ( self . original , "" name "" , None ) <TAB> <TAB> name = _anonymous_label ( "" %% ( %d %s )s "" % ( id ( self ) , name or "" anon "" ) ) <TAB> self . name = name","if hasattr ( self . original , ""name"" ) :",if self . original . named_with_column :,False,94.9,66.33,,,
"def load_tour ( self , tour_id ) : <TAB> for tour_dir in self . tour_directories : <TAB> <TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yaml "" ) <TAB> <TAB> if not os . path . exists ( tour_path ) : <TAB> <TAB> <TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yml "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _load_tour_from_path ( tour_path )",if os . path . exists ( tour_path ) :,if os . path . exists ( tour_path ) :,True,100.0,74.28,,,
"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t.theme_style == ""Dark"": <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> c = t.primary_dark <TAB> <TAB> elif self.md_bg_color == t.accent_color: <TAB> <TAB> <TAB> c = t.accent_dark <TAB> return c",if self . md_bg_color == t . primary_color :,if self . md_bg_color == t . primary_color :,True,100.0,74.14,,,
"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB> <TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB> <TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB> <TAB> if shapes [ i ] is not None : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for j in range ( len ( data [ i ] ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data )",if i == 0 :,"if isinstance ( request , numbers . Integral ) :",False,96.14,71.87,,,
"def onClicked ( event ) : <TAB> if not self . path : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . makedirs ( mh . getPath ( "" render "" ) ) <TAB> <TAB> self . path = mh . getPath ( "" render "" ) <TAB> filename , ftype = mh . getSaveFileName ( <TAB> <TAB> os . path . splitext ( self . path ) [ 0 ] , <TAB> <TAB> "" PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*) "" , <TAB> ) <TAB> if filename : <TAB> <TAB> if "" Thumbnail "" in ftype : <TAB> <TAB> <TAB> self . image . save ( filename , iformat = "" PNG "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . image . save ( filename ) <TAB> <TAB> self . path = os . path . dirname ( filename )","if not os . path . isdir ( mh . getPath ( ""render"" ) ) :","if not os . path . exists ( mh . getPath ( ""render"" ) ) :",False,98.95,73.82,,,
"def _build_dom ( cls , content , mode ) : <TAB> assert mode in ( "" html "" , "" xml "" ) <TAB> if mode == "" html "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> THREAD_STORAGE . html_parser = HTMLParser ( ) <TAB> <TAB> dom = defusedxml . lxml . parse ( <TAB> <TAB> <TAB> StringIO ( content ) , parser = THREAD_STORAGE . html_parser <TAB> <TAB> ) <TAB> <TAB> return dom . getroot ( ) <TAB> else : <TAB> <TAB> if not hasattr ( THREAD_STORAGE , "" xml_parser "" ) : <TAB> <TAB> <TAB> THREAD_STORAGE . xml_parser = XMLParser ( ) <TAB> <TAB> dom = defusedxml . lxml . parse ( BytesIO ( content ) , parser = THREAD_STORAGE . xml_parser ) <TAB> <TAB> return dom . getroot ( )","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :","if not hasattr ( THREAD_STORAGE , ""html_parser"" ) :",True,100.0,74.55,,,
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( )",if code == Path . MOVE1 :,if code == Path . MOVETO :,False,98.91,73.71,,,
"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set() <TAB> for condfield in self.conditions: <TAB> <TAB> if condfield in sigmaparser.values: <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser.values[condfield] <TAB> <TAB> <TAB> for condvalue in self.conditions[condfield]: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> targets.update(self.conditions[condfield][condvalue]) <TAB> return targets",if condvalue in rulefieldvalues :,if condvalue in rulefieldvalues :,True,100.0,74.04,,,
"def create_image_upload ( ) : <TAB> if request . method == "" POST "" : <TAB> <TAB> image = request . form [ "" image "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> image_file = uploaded_file ( file_content = image ) <TAB> <TAB> <TAB> image_url = upload_local ( <TAB> <TAB> <TAB> <TAB> image_file , UPLOAD_PATHS [ "" temp "" ] [ "" image "" ] . format ( uuid = uuid4 ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" ok "" , "" image_url "" : image_url } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" no_image "" } )",if image :,if image :,True,100.0,74.47,,,
"def create_image_upload ( ) : <TAB> if request . method == "" POST "" : <TAB> <TAB> image = request . form [ "" image "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> image_file = uploaded_file ( file_content = image ) <TAB> <TAB> <TAB> image_url = upload_local ( <TAB> <TAB> <TAB> <TAB> image_file , UPLOAD_PATHS [ "" temp "" ] [ "" image "" ] . format ( uuid = uuid4 ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" ok "" , "" image_url "" : image_url } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" no_image "" } )",if image :,"if resp . match ( key [ : - 1 ] , val ) :",False,92.95,69.11,,,
"def accept_quality ( accept , default = 1 ) : <TAB> """""" Separates out the quality score from the accepted content_type """""" <TAB> quality = default <TAB> if accept and "" ; "" in accept : <TAB> <TAB> accept , rest = accept . split ( "" ; "" , 1 ) <TAB> <TAB> accept_quality = RE_ACCEPT_QUALITY . search ( rest ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> quality = float ( accept_quality . groupdict ( ) . get ( "" quality "" , quality ) . strip ( ) ) <TAB> return ( quality , accept . strip ( ) )",if accept_quality :,if accept_quality :,True,100.0,99.39,,,
"def save ( self , session = None , to = None , pickler = None ) : <TAB> if to and pickler : <TAB> <TAB> self . _save_to = ( pickler , to ) <TAB> if self . _save_to and len ( self ) > 0 : <TAB> <TAB> with self . _lock : <TAB> <TAB> <TAB> pickler , fn = self . _save_to <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> session . ui . mark ( _ ( "" Saving  %s  state to  %s "" ) % ( self , fn ) ) <TAB> <TAB> <TAB> pickler ( self , fn )",if session :,if session :,True,100.0,74.42,,,
"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB> <TAB> if k . isupper ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = "" ******************** "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict","if k == ""settings_module_safe"" :",if HIDDEN_SETTINGS . search ( k ) :,False,93.3,63.47,,,
def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >> = 1 <TAB> <TAB> <TAB> if part_h & 1 : <TAB> <TAB> <TAB> <TAB> part_l | = 1 << 31 <TAB> <TAB> <TAB> part_h >> = 1 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> part_h ^ = 0xD8000000 <TAB> <TAB> _table_h . append ( part_h ) <TAB> return _table_h,if rflag :,if rflag :,True,100.0,99.39,,,
"def dns_query ( server , timeout , protocol , qname , qtype , qclass ) : <TAB> request = dns . message . make_query ( qname , qtype , qclass ) <TAB> if protocol == "" tcp "" : <TAB> <TAB> response = dns . query . tcp ( <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> ) <TAB> else : <TAB> <TAB> response = dns . query . udp ( <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response = dns . query . tcp ( <TAB> <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> <TAB> ) <TAB> return response","if protocol == ""udp"" :",if response . flags & dns . flags . TC :,False,95.3,62.57,,,
"def sum_and_divide ( self , losses ) : <TAB> if self . total_divisor != 0 : <TAB> <TAB> output = torch . sum ( losses ) / self . total_divisor <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # remove from autograd graph if necessary <TAB> <TAB> <TAB> self.total_divisor = self.total_divisor.item() <TAB> <TAB> return output <TAB> return torch.sum(losses * 0)",if self . autograd_graph . shape [ 0 ] == 1 :,if torch . is_tensor ( self . total_divisor ) :,False,89.31,67.14,,,
"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB> <TAB> if chunk is not None : <TAB> <TAB> <TAB> self . wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . wait_counter + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB> <TAB> <TAB> <TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( self . poll_period )",if self . wait_counter < self . wait_cntr_max :,elif self . wait_counter < self . wait_cntr_max :,False,98.83,73.31,,,
"def test_find_directive_from_block ( self ) : <TAB> blocks = self . config . parser_root . find_blocks ( "" virtualhost "" ) <TAB> found = False <TAB> for vh in blocks : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> servername = vh . find_directives ( "" servername "" ) <TAB> <TAB> <TAB> self . assertEqual ( servername [ 0 ] . parameters [ 0 ] , "" certbot.demo "" ) <TAB> <TAB> <TAB> found = True <TAB> self . assertTrue ( found )","if vh . name == ""servername"" :","if vh . filepath . endswith ( ""sites-enabled/certbot.conf"" ) :",False,90.68,70.19,,,
"def assign_products ( request , discount_id ) : <TAB> """""" Assign products to given property group with given property_group_id. """""" <TAB> discount = lfs_get_object_or_404 ( Discount , pk = discount_id ) <TAB> for temp_id in request . POST . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> temp_id = temp_id . split ( "" - "" ) [ 1 ] <TAB> <TAB> <TAB> product = Product . objects . get ( pk = temp_id ) <TAB> <TAB> <TAB> discount . products . add ( product ) <TAB> html = [ [ "" #products-inline "" , products_inline ( request , discount_id , as_string = True ) ] ] <TAB> result = json . dumps ( <TAB> <TAB> { "" html "" : html , "" message "" : _ ( u "" Products have been assigned. "" ) } , cls = LazyEncoder <TAB> ) <TAB> return HttpResponse ( result , content_type = "" application/json "" )","if temp_id . endswith ( ""-product"" ) :","if temp_id . startswith ( ""product"" ) :",False,98.1,70.19,,,
"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB> <TAB> if combo . GetValue ( ) == 1 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> style = style | HTL . TR_VIRTUAL <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB> <TAB> self . SetAGWWindowStyleFlag ( style )",if combo . GetValue ( ) == 2 :,"if combo . GetLabel ( ) == ""TR_VIRTUAL"" :",False,95.67,66.8,,,
"def _set_autocomplete ( self , notebook ) : <TAB> if notebook : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> notebook = NotebookInfo ( notebook ) <TAB> <TAB> <TAB> obj , x = build_notebook ( notebook ) <TAB> <TAB> <TAB> self . form . widgets [ "" namespace "" ] . notebook = obj <TAB> <TAB> <TAB> self . form . widgets [ "" page "" ] . notebook = obj <TAB> <TAB> <TAB> logger . debug ( "" Notebook for autocomplete:  %s  ( %s ) "" , obj , notebook ) <TAB> <TAB> except : <TAB> <TAB> <TAB> logger . exception ( "" Could not set notebook:  %s "" , notebook ) <TAB> else : <TAB> <TAB> self . form . widgets [ "" namespace "" ] . notebook = None <TAB> <TAB> self . form . widgets [ "" page "" ] . notebook = None <TAB> <TAB> logger . debug ( "" Notebook for autocomplete unset "" )","if not isinstance ( notebook , NotebookInfo ) :","if isinstance ( notebook , str ) :",False,97.99,73.32,,,
"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB> <TAB> if subDomain : <TAB> <TAB> <TAB> self . emitHostname ( subDomain , event )","if subDomainElem . get ( ""domain"" , """" ) == """" :",if self . checkForStop ( ) :,False,85.7,61.99,,,
"def get_all_subnets ( self , subnet_ids = None , filters = None ) : <TAB> # Extract a list of all subnets <TAB> matches = itertools.chain(*[x.values() for x in self.subnets.values()]) <TAB> if subnet_ids: <TAB> <TAB> matches = [sn for sn in matches if sn.id in subnet_ids] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> unknown_ids = set(subnet_ids) - set(matches) <TAB> <TAB> <TAB> raise InvalidSubnetIdError(unknown_ids) <TAB> if filters: <TAB> <TAB> matches = generic_filter(filters, matches) <TAB> return matches",if len ( matches ) != len ( subnet_ids ) :,if len ( subnet_ids ) > len ( matches ) :,False,97.4,72.19,,,
"def _compat_map ( self , avs ) : <TAB> apps = { } <TAB> for av in avs : <TAB> <TAB> av . version = self <TAB> <TAB> app_id = av . application <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> apps [ amo . APP_IDS [ app_id ] ] = av <TAB> return apps",if app_id in amo . APP_IDS :,if app_id in amo . APP_IDS :,True,100.0,73.95,,,
"def generator ( self , data ) : <TAB> if self . _config . SILENT : <TAB> <TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB> <TAB> for var , val in task . environment_variables ( ) : <TAB> <TAB> <TAB> if self . _config . SILENT : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int ( task . UniqueProcessId ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( task . ImageFileName ) , <TAB> <TAB> <TAB> <TAB> <TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( var ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( val ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> )",if var in silent_vars :,if var in silent_vars :,True,100.0,74.59,,,
"def warn_if_repeatable_read ( self ) : <TAB> if "" mysql "" in self . current_engine ( ) . lower ( ) : <TAB> <TAB> cursor = self . connection_for_read ( ) . cursor ( ) <TAB> <TAB> if cursor . execute ( "" SELECT @@tx_isolation "" ) : <TAB> <TAB> <TAB> isolation = cursor . fetchone ( ) [ 0 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> <TAB> TxIsolationWarning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Polling results with transaction isolation level  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" repeatable-read within the same transaction  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" may give outdated results. Be sure to commit the  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" transaction for each poll iteration. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )","if isolation == ""READ"" :","if isolation == ""REPEATABLE-READ"" :",False,99.1,73.75,,,
"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB> <TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB> <TAB> lookup = "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> level = level_per_module [ "" "" ] <TAB> <TAB> for n in name . split ( "" . "" ) : <TAB> <TAB> <TAB> lookup + = n <TAB> <TAB> <TAB> if lookup in level_per_module : <TAB> <TAB> <TAB> <TAB> level = level_per_module [ lookup ] <TAB> <TAB> <TAB> lookup + = "" . "" <TAB> if level is False : <TAB> <TAB> return False <TAB> return record [ "" level "" ] . no > = level","if ""level"" in level_per_module :","if """" in level_per_module :",False,98.92,60.77,,,
"def _readStream ( self , handle : str , path : str ) - > None : <TAB> eof = False <TAB> file = Path ( path ) <TAB> with file . open ( "" w "" ) as f : <TAB> <TAB> while not eof : <TAB> <TAB> <TAB> response = await self . _client . send ( "" IO.read "" , { "" handle "" : handle } ) <TAB> <TAB> <TAB> eof = response . get ( "" eof "" , False ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f . write ( response . get ( "" data "" , "" "" ) ) <TAB> await self . _client . send ( "" IO.close "" , { "" handle "" : handle } )",if not eof :,if path :,False,98.01,73.4,,,
"def sendall ( self , data , flags = 0 ) : <TAB> if self . _sslobj : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" non-zero flags not allowed in calls to sendall() on  %s "" <TAB> <TAB> <TAB> <TAB> % self . __class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> amount = len ( data ) <TAB> <TAB> count = 0 <TAB> <TAB> while count < amount : <TAB> <TAB> <TAB> v = self . send ( data [ count : ] ) <TAB> <TAB> <TAB> count + = v <TAB> <TAB> return amount <TAB> else : <TAB> <TAB> return socket . sendall ( self , data , flags )",if flags != 0 :,if flags != 0 :,True,100.0,74.48,,,
"def run ( self ) : <TAB> utils . assert_main_thread ( ) <TAB> # As a convenience, we'll set up the connection <TAB> # if there isn't one. So F5 (etc) can be hit <TAB> # to get started. <TAB> if not channel: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> SwiDebugStartChromeCommand.run(self) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.window.run_command(""swi_debug_start"") <TAB> elif paused: <TAB> <TAB> logger.info(""Resuming..."") <TAB> <TAB> channel.send(webkit.Debugger.resume()) <TAB> else: <TAB> <TAB> logger.info(""Pausing..."") <TAB> <TAB> channel.send(webkit.Debugger.setSkipAllPauses(False)) <TAB> <TAB> channel.send(webkit.Debugger.pause())",if is_chrome :,if not chrome_launched ( ) :,False,96.86,70.71,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.46,,,
"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB> <TAB> ) <TAB> <TAB> if x . startswith ( home ) : <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = x . replace ( os . sep , os . altsep ) <TAB> <TAB> return x <TAB> else : <TAB> <TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB> <TAB> if x . startswith ( home ) : <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> return x",if os . sep in os . altsep :,"if builtins . __xonsh__ . env . get ( ""FORCE_POSIX_PATHS"" ) :",False,91.23,67.18,,,
"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB> <TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key, value in list(semanticTags.items()): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise TypeError(""At least one key is not a valid int position"") <TAB> <TAB> if not isinstance(value, list): <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value: <TAB> <TAB> <TAB> if not isinstance(x, str): <TAB> <TAB> <TAB> <TAB> raise TypeError( <TAB> <TAB> <TAB> <TAB> <TAB> ""At least one value of the provided dict is not a list of string"" <TAB> <TAB> <TAB> <TAB> ) <TAB> self.__semanticTags = semanticTags","if key . startswith ( ""semantic_"" ) :","if not isinstance ( key , int ) :",False,96.49,66.2,,,
"def _recv ( ) : <TAB> try : <TAB> <TAB> return sock . recv ( bufsize ) <TAB> except SSLWantReadError : <TAB> <TAB> pass <TAB> except socket . error as exc : <TAB> <TAB> error_code = extract_error_code ( exc ) <TAB> <TAB> if error_code is None : <TAB> <TAB> <TAB> raise <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> r , w , e = select . select ( ( sock , ) , ( ) , ( ) , sock . gettimeout ( ) ) <TAB> if r : <TAB> <TAB> return sock . recv ( bufsize )","if error_code in ( errno . EWOULDBLOCK , errno . EAGAIN ) :",if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK :,False,92.63,70.52,,,
"def _authenticate ( self ) : <TAB> oauth_token = self . options . get ( "" oauth_token "" ) <TAB> if oauth_token and not self . api . oauth_token : <TAB> <TAB> self . logger . info ( "" Attempting to authenticate using OAuth token "" ) <TAB> <TAB> self . api . oauth_token = oauth_token <TAB> <TAB> user = self . api . user ( schema = _user_schema ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . logger . info ( "" Successfully logged in as  {0} "" , user ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logger . error ( <TAB> <TAB> <TAB> <TAB> "" Failed to authenticate, the access token  "" "" is not valid "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return JustinTVPluginBase . _authenticate ( self )",if user :,if user :,True,100.0,74.55,,,
"def reverse ( self , * args ) : <TAB> assert self . _path is not None , "" Cannot reverse url regex  "" + self . regex . pattern <TAB> assert len ( args ) == self . _group_count , "" required number of arguments  "" "" not found "" <TAB> if not len ( args ) : <TAB> <TAB> return self . _path <TAB> converted_args = [ ] <TAB> for a in args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> a = str ( a ) <TAB> <TAB> converted_args . append ( escape . url_escape ( utf8 ( a ) , plus = False ) ) <TAB> return self . _path % tuple ( converted_args )","if not isinstance ( a , six . string_types ) :","if not isinstance ( a , ( unicode_type , bytes ) ) :",False,95.29,72.1,,,
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints","if len ( text ) > 1 and text [ - 2 ] in ""\n\x85\u2028\u2029"" :","if text [ 0 ] in "" \n\x85\u2028\u2029"" :",False,92.93,69.44,,,
"def find_package_modules ( package , mask ) : <TAB> import fnmatch <TAB> if hasattr ( package , "" __loader__ "" ) and hasattr ( package . __loader__ , "" _files "" ) : <TAB> <TAB> path = package . __name__ . replace ( "" . "" , os . path . sep ) <TAB> <TAB> mask = os . path . join ( path , mask ) <TAB> <TAB> for fnm in package . __loader__ . _files . iterkeys ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield os . path . splitext ( fnm ) [ 0 ] . replace ( os . path . sep , "" . "" ) <TAB> else : <TAB> <TAB> path = package . __path__ [ 0 ] <TAB> <TAB> for fnm in os . listdir ( path ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield "" %s . %s "" % ( package . __name__ , os . path . splitext ( fnm ) [ 0 ] )","if fnmatch . fnmatch ( fnm , mask ) :","if fnmatch . fnmatchcase ( fnm , mask ) :",False,98.17,73.35,,,
"def _condition ( ct ) : <TAB> for qobj in args : <TAB> <TAB> if qobj . connector == "" AND "" and not qobj . negated : <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj.children: <TAB> <TAB> <TAB> <TAB> kwargs.update(dict([child])) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise NotImplementedError(""Unsupported Q object"") <TAB> for attr, val in kwargs.items(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return False <TAB> return True","if not isinstance ( val , ct . value ) :","if getattr ( ct , attr ) != val :",False,94.51,69.64,,,
"def process ( self , resources ) : <TAB> session = local_session ( self . manager . session_factory ) <TAB> client = session . client ( "" logs "" ) <TAB> state = self . data . get ( "" state "" , True ) <TAB> key = self . resolve_key ( self . data . get ( "" kms-key "" ) ) <TAB> for r in resources : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> client . associate_kms_key ( logGroupName = r [ "" logGroupName "" ] , kmsKeyId = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . disassociate_kms_key ( logGroupName = r [ "" logGroupName "" ] ) <TAB> <TAB> except client . exceptions . ResourceNotFoundException : <TAB> <TAB> <TAB> continue",if state :,if state :,True,100.0,74.53,,,
"def get_xmm ( env , ii ) : <TAB> if is_gather ( ii ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return gen_reg_simd_unified ( env , "" xmm_evex "" , True ) <TAB> <TAB> return gen_reg_simd_unified ( env , "" xmm "" , False ) <TAB> <IF-STMT> <TAB> <TAB> return gen_reg ( env , "" xmm_evex "" ) <TAB> return gen_reg ( env , "" xmm "" )",if ii . evex :,"if ii . space == ""evex"" :",False,88.81,64.75,,,
"def parent ( self ) : <TAB> """""" Return the parent device. """""" <TAB> if self . _has_parent is None : <TAB> <TAB> _parent = self . _ctx . backend . get_parent ( self . _ctx . dev ) <TAB> <TAB> self . _has_parent = _parent is not None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _parent = Device ( _parent , self . _ctx . backend ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _parent = None <TAB> return self . _parent","if isinstance ( _parent , Device ) :",if self . _has_parent :,False,94.76,93.01,,,
"def cascade ( self , event = None ) : <TAB> """""" Cascade all Leo windows. """""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB> <TAB> w = frame and frame . top <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r = w . geometry ( ) # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w.setGeometry(QtCore.QRect(x, y, r.width(), r.height())) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x += 30 <TAB> <TAB> <TAB> y += 30 <TAB> <TAB> <TAB> if x > 200: <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta += 10",if w :,if w :,True,100.0,99.52,,,
"def _GetGoodDispatchAndUserName ( IDispatch , userName , clsctx ) : <TAB> # Get a dispatch object, and a 'user name' (ie, the name as <TAB> # displayed to the user in repr() etc. <TAB> if userName is None: <TAB> <TAB> if isinstance(IDispatch, str): <TAB> <TAB> <TAB> userName = IDispatch <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # We always want the displayed name to be a real string <TAB> <TAB> <TAB> userName = IDispatch.encode(""ascii"", ""replace"") <TAB> elif type(userName) == unicode: <TAB> <TAB> # As above - always a string... <TAB> <TAB> userName = userName.encode(""ascii"", ""replace"") <TAB> else: <TAB> <TAB> userName = str(userName) <TAB> return (_GetGoodDispatch(IDispatch, clsctx), userName)",elif type ( IDispatch ) == str :,"elif isinstance ( IDispatch , unicode ) :",False,96.51,71.58,,,
"def _infer_return_type ( * args ) : <TAB> """""" Look at the type of all args and divine their implied return type. """""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str # tempfile APIs return a str by default. <TAB> return return_type",if return_type is str :,if return_type is bytes :,False,98.99,98.8,,,
"def test_ESPnetDataset_h5file_1 ( h5file_1 ) : <TAB> dataset = IterableESPnetDataset ( <TAB> <TAB> path_name_type_list = [ ( h5file_1 , "" data4 "" , "" hdf5 "" ) ] , <TAB> <TAB> preprocess = preprocess , <TAB> ) <TAB> for key , data in dataset : <TAB> <TAB> if key == "" a "" : <TAB> <TAB> <TAB> assert data [ "" data4 "" ] . shape == ( <TAB> <TAB> <TAB> <TAB> 100 , <TAB> <TAB> <TAB> <TAB> 80 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert data [ "" data4 "" ] . shape == ( <TAB> <TAB> <TAB> <TAB> 150 , <TAB> <TAB> <TAB> <TAB> 80 , <TAB> <TAB> <TAB> )","elif key == ""b"" :","if key == ""b"" :",False,98.86,73.27,,,
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> if exclude_meta and field . meta : <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset : <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val",if field_val is None :,if field_val is _marker :,False,98.54,73.6,,,
"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB> <TAB> ret = [ ] <TAB> <TAB> when_response = list ( when_response ) <TAB> <TAB> for match in when_response : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if self . match_name : <TAB> <TAB> <TAB> <TAB> <TAB> match . name = self . match_name <TAB> <TAB> <TAB> <TAB> matches . append ( match ) <TAB> <TAB> <TAB> <TAB> ret . append ( match ) <TAB> <TAB> return ret <TAB> if self . match_name : <TAB> <TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB> <TAB> matches . append ( when_response ) <TAB> <TAB> return when_response","if isinstance ( match , Match ) :",if match not in matches :,False,96.85,71.86,,,
"def _set_chat_ids ( self , chat_id : SLT [ int ] ) - > None : <TAB> with self . __lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> f "" Can ' t set  { self . chat_id_name }  in conjunction with (already set)  "" <TAB> <TAB> <TAB> <TAB> f "" { self . username_name } s. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _chat_ids = self . _parse_chat_id ( chat_id )",if self . _chat_ids :,if chat_id and self . _usernames :,False,95.28,70.8,,,
"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if l [ 0 ] == "" Filename "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( l [ 2 ] ) <TAB> <TAB> <TAB> int ( l [ 3 ] ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> # <TAB> <TAB>  ret.append(improve(l[0])) <TAB> <TAB> ret.append(l[0]) <TAB> ret.sort() <TAB> for item in objlist: <TAB> <TAB> ret.append(item) <TAB> return ret","if l [ 0 ] == ""Version"" :",if len ( l ) < 5 :,False,95.15,62.81,,,
"def get_changed_module ( self ) : <TAB> source = self . resource . read ( ) <TAB> change_collector = codeanalyze . ChangeCollector ( source ) <TAB> if self . replacement is not None : <TAB> <TAB> change_collector . add_change ( self . skip_start , self . skip_end , self . replacement ) <TAB> for occurrence in self . occurrence_finder . find_occurrences ( self . resource ) : <TAB> <TAB> start , end = occurrence . get_primary_range ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . handle . occurred_inside_skip ( change_collector , occurrence ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . handle . occurred_outside_skip ( change_collector , occurrence ) <TAB> result = change_collector . get_changed ( ) <TAB> if result is not None and result != source : <TAB> <TAB> return result",if start < self . skip_start :,if self . skip_start <= start < self . skip_end :,False,95.63,72.08,,,
"def hpat_pandas_series_var_impl ( <TAB> self , axis = None , skipna = None , level = None , ddof = 1 , numeric_only = None ) : <TAB> if skipna is None : <TAB> <TAB> skipna = True <TAB> if skipna : <TAB> <TAB> valuable_length = len ( self . _data ) - numpy . sum ( numpy . isnan ( self . _data ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return numpy . nan <TAB> <TAB> return ( <TAB> <TAB> <TAB> numpy_like . nanvar ( self . _data ) * valuable_length / ( valuable_length - ddof ) <TAB> <TAB> ) <TAB> if len ( self . _data ) < = ddof : <TAB> <TAB> return numpy . nan <TAB> return self . _data . var ( ) * len ( self . _data ) / ( len ( self . _data ) - ddof )",if valuable_length <= ddof :,if valuable_length <= ddof :,True,100.0,74.59,,,
"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self # don't copy unless we need to <TAB> if condition is not Undefined: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif ""field"" in condition and ""type"" not in condition: <TAB> <TAB> <TAB> kwds = parse_shorthand(condition[""field""], context.get(""data"", None)) <TAB> <TAB> <TAB> copy = self.copy(deep=[""condition""]) <TAB> <TAB> <TAB> copy.condition.update(kwds) <TAB> return super(ValueChannelMixin, copy).to_dict( <TAB> <TAB> validate=validate, ignore=ignore, context=context <TAB> )","if isinstance ( condition , ( list , tuple ) ) :","if isinstance ( condition , core . SchemaBase ) :",False,97.07,72.08,,,
"def get_field_result ( self , result , field_name ) : <TAB> if isinstance ( result . field , models . ImageField ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> img = getattr ( result . obj , field_name ) <TAB> <TAB> <TAB> result . text = mark_safe ( <TAB> <TAB> <TAB> <TAB> ' <a href= "" %s ""  target= "" _blank ""  title= "" %s ""  data-gallery= "" gallery "" ><img src= "" %s ""  class= "" field_img "" /></a> ' <TAB> <TAB> <TAB> <TAB> % ( img . url , result . label , img . url ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . include_image = True <TAB> return result",if field_name :,if result . value :,False,97.7,72.55,,,
"def run ( self ) : <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> dp = self . queue_get_stoppable ( self . inq ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # cannot ignore None here. will lead to unsynced send/recv <TAB> <TAB> <TAB> obj = self.func(dp) <TAB> <TAB> <TAB> self.queue_put_stoppable(self.outq, obj) <TAB> except Exception: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pass # skip duplicated error messages <TAB> <TAB> else: <TAB> <TAB> <TAB> raise <TAB> finally: <TAB> <TAB> self.stop()",if dp is None :,if self . stopped ( ) :,False,93.5,67.95,,,
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> if isinstance ( in_arrays , tuple ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> elif isinstance ( in_arrays , dict ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results",if self . _progress_hook is not None :,if self . _progress_hook :,False,98.04,73.34,,,
"def merge ( self , other ) : <TAB> d = self . _name2ft <TAB> for name , ( f , t ) in other . _name2ft . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Don't print here by default, since doing <TAB> <TAB> <TAB> # <TAB> so breaks some of the buildbots <TAB> <TAB> <TAB> # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB> <TAB> <TAB> # <TAB> "" testers; summing outcomes."" <TAB> <TAB> <TAB> f2, t2 = d[name] <TAB> <TAB> <TAB> f = f + f2 <TAB> <TAB> <TAB> t = t + t2 <TAB> <TAB> d[name] = f, t",if name in d :,if name in d :,True,100.0,74.43,,,
"def _addSettingsToPanels ( self , category , left , right ) : <TAB> count = len ( profile . getSubCategoriesFor ( category ) ) + len ( <TAB> <TAB> profile . getSettingsForCategory ( category ) <TAB> ) <TAB> p = left <TAB> n = 0 <TAB> for title in profile . getSubCategoriesFor ( category ) : <TAB> <TAB> n + = 1 + len ( profile . getSettingsForCategory ( category , title ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p = right <TAB> <TAB> configBase . TitleRow ( p , _ ( title ) ) <TAB> <TAB> for s in profile . getSettingsForCategory ( category , title ) : <TAB> <TAB> <TAB> configBase . SettingRow ( p , s . getName ( ) )",if n > count :,if n > count / 2 :,False,97.97,73.18,,,
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> if pattern . match ( value ) is not None : <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist","if i . startswith ( ""."" ) :","if i == ""."" or i == "".."" :",False,95.18,67.58,,,
def check_network_private ( test_network ) : <TAB> test_net = ipaddress . IPNetwork ( test_network ) <TAB> test_start = test_net . network <TAB> test_end = test_net . broadcast <TAB> for network in settings . vpn . safe_priv_subnets : <TAB> <TAB> network = ipaddress . IPNetwork ( network ) <TAB> <TAB> net_start = network . network <TAB> <TAB> net_end = network . broadcast <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False,"if net_start . is_same_port ( test_start . ipv4 , net_end . ipv4 ) :",if test_start >= net_start and test_end <= net_end :,False,87.54,42.76,,,
"def _end_description ( self ) : <TAB> if self . _summaryKey == "" content "" : <TAB> <TAB> self . _end_content ( ) <TAB> else : <TAB> <TAB> value = self . popContent ( "" description "" ) <TAB> <TAB> context = self . _getContext ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> context [ "" textinput "" ] [ "" description "" ] = value <TAB> <TAB> elif self . inimage : <TAB> <TAB> <TAB> context [ "" image "" ] [ "" description "" ] = value <TAB> self . _summaryKey = None",if self . intextinput :,if self . intextinput :,True,100.0,74.35,,,
def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB> <TAB> for p in self . grammar . Productions [ 1 : ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p . prod : <TAB> <TAB> <TAB> <TAB> if not t in nullable : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> if len ( nullable ) == num_nullable : <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len ( nullable ) <TAB> return nullable,if p . name in nullable :,if p . len == 0 :,False,97.56,94.89,,,
"def process_bind_param ( self , value , dialect ) : <TAB> if value is not None : <TAB> <TAB> if MAX_METADATA_VALUE_SIZE is not None : <TAB> <TAB> <TAB> for k , v in list ( value . items ( ) ) : <TAB> <TAB> <TAB> <TAB> sz = total_size ( v ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> del value [ k ] <TAB> <TAB> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Refusing to bind metadata key  {}  due to size ( {} ) "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> k , sz <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> value = json_encoder . encode ( value ) . encode ( ) <TAB> return value",if sz > MAX_METADATA_VALUE_SIZE :,if sz > MAX_METADATA_VALUE_SIZE :,True,100.0,74.57,,,
"def process_input_line ( self , line , store_history = True ) : <TAB> """""" process the input, capturing stdout """""" <TAB> stdout = sys . stdout <TAB> splitter = self . IP . input_splitter <TAB> try : <TAB> <TAB> sys . stdout = self . cout <TAB> <TAB> splitter . push ( line ) <TAB> <TAB> more = splitter . push_accepts_more ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> source_raw = splitter . source_raw_reset ( ) [ 1 ] <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> # recent ipython #4504 <TAB> <TAB> <TAB> <TAB> source_raw = splitter.raw_reset() <TAB> <TAB> <TAB> self.IP.run_cell(source_raw, store_history=store_history) <TAB> finally: <TAB> <TAB> sys.stdout = stdout",if more :,if not more :,False,98.97,96.84,,,
"def _dump_section ( self , name , values , f ) : <TAB> doc = "" __doc__ "" <TAB> <IF-STMT> <TAB> <TAB> print ( "" #  %s "" % values [ doc ] , file = f ) <TAB> print ( "" %s ( "" % name , file = f ) <TAB> for k , v in values . items ( ) : <TAB> <TAB> if k . endswith ( "" __doc__ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = k + "" __doc__ "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( ""  <TAB> #  %s "" % values [ doc ] , file = f ) <TAB> <TAB> print ( ""  <TAB>  %s  =  %s , "" % ( k , pprint . pformat ( v , indent = 8 ) ) , file = f ) <TAB> print ( "" ) \n "" , file = f )",if doc :,if doc in values :,False,96.92,72.22,,,
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> if stored_session : <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) )","if isinstance ( expiration , datetime . datetime . datetime ) :",if not expiration . tzinfo :,False,95.24,71.74,,,
"def table_entry ( mode1 , bind_type1 , mode2 , bind_type2 ) : <TAB> with sock ( mode1 ) as sock1 : <TAB> <TAB> bind ( sock1 , bind_type1 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> with sock ( mode2 ) as sock2 : <TAB> <TAB> <TAB> <TAB> bind ( sock2 , bind_type2 ) <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return "" INUSE "" <TAB> <TAB> <TAB> elif exc . winerror == errno . WSAEACCES : <TAB> <TAB> <TAB> <TAB> return "" ACCESS "" <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" Success """,if exc . winerror == errno . EINVAL :,if exc . winerror == errno . WSAEADDRINUSE :,False,98.74,73.41,,,
"def __init__ ( self , ruleset ) : <TAB> # Organize rules by path <TAB> self.ruleset = ruleset <TAB> self.rules = {} <TAB> for filename in self.ruleset.rules: <TAB> <TAB> for rule in self.ruleset.rules[filename]: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> manage_dictionary(self.rules, rule.path, []) <TAB> <TAB> <TAB> self.rules[rule.path].append(rule)",if rule . path not in self . rules :,if not rule . enabled :,False,94.05,68.44,,,
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> if reply == "" !done "" : <TAB> <TAB> <TAB> return r",if j == - 1 :,if j == - 1 :,True,100.0,74.62,,,
"def _check_decorator_overload ( name : str , old : str , new : str ) - > int : <TAB> """""" Conditions for a decorator to overload an existing one. """""" <TAB> properties = _property_decorators ( name ) <TAB> if old == new : <TAB> <TAB> return _MERGE <TAB> elif old in properties and new in properties : <TAB> <TAB> p_old , p_new = properties [ old ] . precedence , properties [ new ] . precedence <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return _DISCARD <TAB> <TAB> elif p_old == p_new : <TAB> <TAB> <TAB> return _MERGE <TAB> <TAB> else : <TAB> <TAB> <TAB> return _REPLACE <TAB> raise OverloadedDecoratorError ( name , "" "" )",if p_old == p_new :,if p_old > p_new :,False,98.22,98.45,,,
"def validate_pk ( self ) : <TAB> try : <TAB> <TAB> self . _key = serialization . load_pem_private_key ( <TAB> <TAB> <TAB> self . key , password = None , backend = default_backend ( ) <TAB> <TAB> ) <TAB> <TAB> if self . _key . key_size > 2048 : <TAB> <TAB> <TAB> AWSValidationException ( <TAB> <TAB> <TAB> <TAB> "" The private key length is not supported. Only 1024-bit and 2048-bit are allowed. "" <TAB> <TAB> <TAB> ) <TAB> except Exception as err : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> raise AWSValidationException ( <TAB> <TAB> <TAB> "" The private key is not PEM-encoded or is not valid. "" <TAB> <TAB> )","if err . args [ 0 ] != ""InvalidKey.IsInvalid"" :","if isinstance ( err , AWSValidationException ) :",False,93.29,64.35,,,
"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB> <TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB> <TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> custom_statements = [ custom_statements ] <TAB> <TAB> statement = self . resource_policy [ "" Statement "" ] <TAB> <TAB> if not isinstance ( statement , list ) : <TAB> <TAB> <TAB> statement = [ statement ] <TAB> <TAB> for s in custom_statements : <TAB> <TAB> <TAB> if s not in statement : <TAB> <TAB> <TAB> <TAB> statement . append ( s ) <TAB> <TAB> self . resource_policy [ "" Statement "" ] = statement","if not isinstance ( custom_statements , list ) :","if not isinstance ( custom_statements , list ) :",True,100.0,74.59,,,
"def load ( self , repn ) : <TAB> for key in repn : <TAB> <TAB> tmp = self . _convert ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . declare ( tmp ) <TAB> <TAB> item = dict . __getitem__ ( self , tmp ) <TAB> <TAB> item . _active = True <TAB> <TAB> item . load ( repn [ key ] )",if tmp :,if tmp not in self :,False,95.63,70.49,,,
"def on_press_release ( x ) : <TAB> """""" Keyboard callback function. """""" <TAB> global is_recording , enable_trigger_record <TAB> press = keyboard . KeyboardEvent ( "" down "" , 28 , "" space "" ) <TAB> release = keyboard . KeyboardEvent ( "" up "" , 28 , "" space "" ) <TAB> if x . event_type == "" down "" and x . name == press . name : <TAB> <TAB> if ( not is_recording ) and enable_trigger_record : <TAB> <TAB> <TAB> sys . stdout . write ( "" Start Recording ...  "" ) <TAB> <TAB> <TAB> sys . stdout . flush ( ) <TAB> <TAB> <TAB> is_recording = True <TAB> if x . event_type == "" up "" and x . name == release . name : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> is_recording = False",if ( not is_recording ) and enable_trigger_record :,if is_recording == True :,False,94.71,83.32,,,
"def apply_mask ( self , mask , data_t , data_f ) : <TAB> ind_t , ind_f = 0 , 0 <TAB> out = [ ] <TAB> for m in cycle ( mask ) : <TAB> <TAB> if m : <TAB> <TAB> <TAB> if ind_t == len ( data_t ) : <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out . append ( data_t [ ind_t ] ) <TAB> <TAB> <TAB> ind_t + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out . append ( data_f [ ind_f ] ) <TAB> <TAB> <TAB> ind_f + = 1 <TAB> return out",if ind_f == len ( data_f ) :,if ind_f == len ( data_f ) :,True,100.0,74.47,,,
"def oo_contains_rule ( source , apiGroups , resources , verbs ) : <TAB> """""" Return true if the specified rule is contained within the provided source """""" <TAB> rules = source [ "" rules "" ] <TAB> if rules : <TAB> <TAB> for rule in rules : <TAB> <TAB> <TAB> if set ( rule [ "" apiGroups "" ] ) == set ( apiGroups ) : <TAB> <TAB> <TAB> <TAB> if set ( rule [ "" resources "" ] ) == set ( resources ) : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :","if set ( rule [ ""verbs"" ] ) == set ( verbs ) :",True,100.0,99.47,,,
"def _maybe_commit_artifact ( self , artifact_id ) : <TAB> artifact_status = self . _artifacts [ artifact_id ] <TAB> if artifact_status [ "" pending_count "" ] == 0 and artifact_status [ "" commit_requested "" ] : <TAB> <TAB> for callback in artifact_status [ "" pre_commit_callbacks "" ] : <TAB> <TAB> <TAB> callback ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _api . commit_artifact ( artifact_id ) <TAB> <TAB> for callback in artifact_status [ "" post_commit_callbacks "" ] : <TAB> <TAB> <TAB> callback ( )","if artifact_status [ ""pending_count"" ] == 0 and artifact_status [ ""commit_requested"" ] :","if artifact_status [ ""finalize"" ] :",False,89.74,66.77,,,
"def shuffler ( iterator , pool_size = 10 * * 5 , refill_threshold = 0.9 ) : <TAB> yields_between_refills = round ( pool_size * ( 1 - refill_threshold ) ) <TAB> # initialize pool; this step may or may not exhaust the iterator. <TAB> pool = take_n(pool_size, iterator) <TAB> while True: <TAB> <TAB> random.shuffle(pool) <TAB> <TAB> for i in range(yields_between_refills): <TAB> <TAB> <TAB> yield pool.pop() <TAB> <TAB> next_batch = take_n(yields_between_refills, iterator) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> pool.extend(next_batch) <TAB> # finish consuming whatever's left - no need for further randomization. <TAB> yield from pool",if next_batch is None :,if not next_batch :,False,97.55,72.37,,,
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> if isinstance ( key , ( int , long ) ) : <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> if k . lower ( ) == ikey : <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode: <TAB> <TAB> raise KeyError() <TAB> raise BadRequestKeyError(key)","elif isinstance ( key , type ) :","elif isinstance ( key , slice ) :",False,98.88,73.74,,,
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> if self . match_function ( path ) : <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file )",if self . match_function ( file ) :,if self . match_function ( file ) :,True,100.0,74.63,,,
"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB> <TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB> <TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB> <TAB> if not grade and not solution and not locked : <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB> <TAB> if grade_id in ids : <TAB> <TAB> <TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB> <TAB> ids . add ( grade_id )","if ""nbgrader"" not in cell . metadata :","if ""nbgrader"" not in cell . metadata :",True,100.0,74.63,,,
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> if self . _pos < start : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self . _pos == start : <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( )",if stop :,if stop is not None and self . _pos > stop :,False,95.14,70.72,,,
"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB> <TAB> username = user [ 0 ] <TAB> <TAB> settings = user [ 1 ] <TAB> <TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB> <TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB> <TAB> if "" event "" in settings : <TAB> <TAB> <TAB> if "" joined "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _client . removeUser ( username ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _client . userlist . modUser ( username , room , file_ )","elif ""removed"" in settings [ ""event"" ] :","elif ""left"" in settings [ ""event"" ] :",False,98.91,73.85,,,
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch(x) as case: <TAB> <TAB> if case(0): <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <TAB> print(""zero"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""one or two"") <TAB> <TAB> elif case(3, 4): <TAB> <TAB> <TAB> print(""three or four"") <TAB> <TAB> else: <TAB> <TAB> <TAB> print(""default"") <TAB> <TAB> <TAB> print(""another"")","elif case ( 1 , 2 ) :","elif case ( 1 , 2 ) :",True,100.0,74.13,,,
"def _populate ( ) : <TAB> for fname in glob . glob ( os . path . join ( os . path . dirname ( __file__ ) , "" data "" , "" *.json "" ) ) : <TAB> <TAB> with open ( fname ) as inf : <TAB> <TAB> <TAB> data = json . load ( inf ) <TAB> <TAB> <TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB> <TAB> <TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB> <TAB> <TAB> for item in data : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> LOGGER . warning ( "" Repeated emoji  {} "" . format ( item [ "" key "" ] ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> TABLE [ item [ "" key "" ] ] = item [ "" value "" ]","if item [ ""value"" ] in TABLE :","if item [ ""key"" ] in TABLE :",False,98.97,73.88,,,
"def slot_to_material ( bobject : bpy . types . Object , slot : bpy . types . MaterialSlot ) : <TAB> mat = slot . material <TAB> # Pick up backed material if present <TAB> if mat is not None: <TAB> <TAB> baked_mat = mat.name + ""_"" + bobject.name + ""_baked"" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mat = bpy.data.materials[baked_mat] <TAB> return mat",if baked_mat in bpy . data . materials :,if baked_mat in bpy . data . materials :,True,100.0,74.14,,,
"def __keyPress ( self , widget , event ) : <TAB> if event . key == "" G "" and event . modifiers & event . Modifiers . Control : <TAB> <TAB> if not all ( hasattr ( p , "" isGanged "" ) for p in self . getPlugs ( ) ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __ungang ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __gang ( ) <TAB> <TAB> return True <TAB> return False","if event . key == ""U"" :",if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) :,False,88.36,59.4,,,
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True","if isinstance ( expected , str ) :","if isinstance ( expected , str ) :",True,100.0,74.62,,,
"def hosts_to_domains ( self , hosts , exclusions = [ ] ) : <TAB> domains = [ ] <TAB> for host in hosts : <TAB> <TAB> elements = host . split ( "" . "" ) <TAB> <TAB> # recursively walk through the elements <TAB> <TAB> # extracting all possible (sub)domains <TAB> <TAB> while len(elements) >= 2: <TAB> <TAB> <TAB> # account for domains stored as hosts <TAB> <TAB> <TAB> if len(elements) == 2: <TAB> <TAB> <TAB> <TAB> domain = ""."".join(elements) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> # drop the host element <TAB> <TAB> <TAB> <TAB> domain = ""."".join(elements[1:]) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> domains.append(domain) <TAB> <TAB> <TAB> del elements[0] <TAB> return domains",if domain not in exclusions :,if domain not in domains + exclusions :,False,98.61,73.13,,,
"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self.send_queue.get(True, 6.0) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self.socket.sendall(request) <TAB> <TAB> <TAB> if self.send_queue is not None: <TAB> <TAB> <TAB> <TAB> self.send_queue.task_done() <TAB> <TAB> except queue.Empty: <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError: <TAB> <TAB> <TAB> self.stop_event.set()",if request is not None :,if self . socket is not None :,False,98.05,72.3,,,
"def get_url_args ( self , item ) : <TAB> if self . url_args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> url_args = self . url_args ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url_args = dict ( self . url_args ) <TAB> <TAB> url_args [ "" id "" ] = item . id <TAB> <TAB> return url_args <TAB> else : <TAB> <TAB> return dict ( operation = self . label , id = item . id )",if callable ( self . url_args ) :,"if hasattr ( self . url_args , ""__call__"" ) :",False,91.81,64.07,,,
"def list_projects ( self ) : <TAB> projects = [ ] <TAB> page = 1 <TAB> while True : <TAB> <TAB> repos = self . _client . get ( <TAB> <TAB> <TAB> "" /user/repos "" , { "" sort "" : "" full_name "" , "" page "" : page , "" per_page "" : 100 } <TAB> <TAB> ) <TAB> <TAB> page + = 1 <TAB> <TAB> for repo in repos : <TAB> <TAB> <TAB> projects . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : repo [ "" full_name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" name "" : repo [ "" full_name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" description "" : repo [ "" description "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" is_private "" : repo [ "" private "" ] , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> return projects",if page >= self . _client . num_repos :,if len ( repos ) < 100 :,False,95.95,72.38,,,
"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB> <TAB> if script . startswith ( "" http "" ) : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) )",elif subdir :,elif subdir :,True,100.0,74.53,,,
"def print_map ( node , l ) : <TAB> if node . title not in l : <TAB> <TAB> l [ node . title ] = [ ] <TAB> for n in node . children : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> w = { n . title : [ ] } <TAB> <TAB> <TAB> l [ node . title ] . append ( w ) <TAB> <TAB> <TAB> print_map ( n , w ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l [ node . title ] . append ( n . title )","if isinstance ( n , dict ) :",if len ( n . children ) > 0 :,False,94.18,70.34,,,
"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB> <TAB> if isinstance ( results [ i ] , dict ) : <TAB> <TAB> <TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0","elif isinstance ( results [ i ] , list ) :","elif isinstance ( results [ i ] , list ) :",True,100.0,74.56,,,
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> v [ "" _class "" ] == "" Question "" <TAB> <TAB> <TAB> or v [ "" _class "" ] == "" Message "" <TAB> <TAB> <TAB> or v [ "" _class "" ] == "" Announcement "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> v [ "" admin "" ] = None <TAB> return self . objs","if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",True,100.0,74.37,,,
"def qvec ( self ) : <TAB> # <TAB> <TAB> if self.polrep != 'stokes': <TAB> # <TAB> <TAB> <TAB> raise Exception(""qvec is not defined unless self.polrep=='stokes'"") <TAB> qvec = np.array([]) <TAB> if self.polrep == ""stokes"": <TAB> <TAB> qvec = self._imdict[""Q""] <TAB> elif self.polrep == ""circ"": <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> qvec = np.real(0.5 * (self.lrvec + self.rlvec)) <TAB> return qvec",if self . lrvec is not None and self . rlvec is not None :,if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 :,False,89.57,64.67,,,
"def display_value ( self , key , w ) : <TAB> if key == "" vdevices "" : <TAB> <TAB> # Very special case <TAB> <TAB> nids = [n[""deviceID""] for n in self.get_value(""devices"")] <TAB> <TAB> for device in self.app.devices.values(): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> b = Gtk.CheckButton(device.get_title(), False) <TAB> <TAB> <TAB> <TAB> b.set_tooltip_text(device[""id""]) <TAB> <TAB> <TAB> <TAB> self[""vdevices""].pack_start(b, False, False, 0) <TAB> <TAB> <TAB> <TAB> b.set_active(device[""id""] in nids) <TAB> <TAB> self[""vdevices""].show_all() <TAB> else: <TAB> <TAB> EditorDialog.display_value(self, key, w)","if device [ ""type"" ] == ""Gtk.Device"" :","if device [ ""id"" ] != self . app . daemon . get_my_id ( ) :",False,93.09,64.28,,,
"def _set_xflux_setting ( self , * * kwargs ) : <TAB> for key , value in kwargs . items ( ) : <TAB> <TAB> if key in self . _settings_map : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _set_xflux_screen_color ( value ) <TAB> <TAB> <TAB> <TAB> self . _current_color = str ( value ) <TAB> <TAB> <TAB> <TAB> # hackish - changing the current color unpauses xflux, <TAB> <TAB> <TAB> <TAB> # must reflect that with state change <TAB> <TAB> <TAB> <TAB> if self.state == self.states[""PAUSED""]: <TAB> <TAB> <TAB> <TAB> <TAB> self.state = self.states[""RUNNING""] <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> self._xflux.sendline(self._settings_map[key] + str(value)) <TAB> <TAB> <TAB> self._c()","if self . _settings_map [ key ] == ""screen_color"" :","if key == ""color"" :",False,94.96,71.73,,,
"def apply_acceleration ( self , veh_ids , acc ) : <TAB> """""" See parent class. """""" <TAB> # to hand the case of a single vehicle <TAB> if type(veh_ids) == str: <TAB> <TAB> veh_ids = [veh_ids] <TAB> <TAB> acc = [acc] <TAB> for i, vid in enumerate(veh_ids): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> this_vel = self.get_speed(vid) <TAB> <TAB> <TAB> next_vel = max([this_vel + acc[i] * self.sim_step, 0]) <TAB> <TAB> <TAB> self.kernel_api.vehicle.slowDown(vid, next_vel, 1e-3)",if self . kernel_api . vehicle . is_enabled ( vid ) :,if acc [ i ] is not None and vid in self . get_ids ( ) :,False,92.08,65.46,,,
"def largest_factor_relatively_prime ( a , b ) : <TAB> """""" Return the largest factor of a relatively prime to b. """""" <TAB> while 1 : <TAB> <TAB> d = gcd ( a , b ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> b = d <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> q , r = divmod ( a , d ) <TAB> <TAB> <TAB> if r > 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> a = q <TAB> return a",if d < 0 :,if d <= 1 :,False,97.75,97.41,,,
"def check_status ( self ) : <TAB> try : <TAB> <TAB> du = psutil . disk_usage ( "" / "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ServiceWarning ( <TAB> <TAB> <TAB> <TAB> "" {host} {percent} % d isk usage exceeds  {disk_usage} % "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> host = host , percent = du . percent , disk_usage = DISK_USAGE_MAX <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> except ValueError as e : <TAB> <TAB> self . add_error ( ServiceReturnedUnexpectedResult ( "" ValueError "" ) , e )",if du . disk_usage > DISK_USAGE_MAX :,if DISK_USAGE_MAX and du . percent >= DISK_USAGE_MAX :,False,93.9,70.98,,,
"def build_reply ( self , msg , text = None , private = False , threaded = False ) : <TAB> response = self . build_message ( text ) <TAB> if msg . is_group : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response . frm = self . bot_identifier <TAB> <TAB> <TAB> response . to = IRCPerson ( str ( msg . frm ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response . frm = IRCRoomOccupant ( str ( self . bot_identifier ) , msg . frm . room ) <TAB> <TAB> <TAB> response . to = msg . frm . room <TAB> else : <TAB> <TAB> response . frm = self . bot_identifier <TAB> <TAB> response . to = msg . frm <TAB> return response",if private :,if private :,True,100.0,74.5,,,
"def _dict_refs ( obj , named ) : <TAB> """""" Return key and value objects of a dict/proxy. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for k , v in _items ( obj ) : <TAB> <TAB> <TAB> <TAB> s = str ( k ) <TAB> <TAB> <TAB> <TAB> yield _NamedRef ( "" [K]  "" + s , k ) <TAB> <TAB> <TAB> <TAB> yield _NamedRef ( "" [V]  "" + s + "" :  "" + _repr ( v ) , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for k , v in _items ( obj ) : <TAB> <TAB> <TAB> <TAB> yield k <TAB> <TAB> <TAB> <TAB> yield v <TAB> except ( KeyError , ReferenceError , TypeError ) as x : <TAB> <TAB> warnings . warn ( "" Iterating  ' %s ' :  %r "" % ( _classof ( obj ) , x ) )",if named :,if named :,True,100.0,99.6,,,
"def fetch_images ( ) : <TAB> images = [ ] <TAB> marker = None <TAB> while True : <TAB> <TAB> batch = image_service . detail ( <TAB> <TAB> <TAB> context , <TAB> <TAB> <TAB> filters = filters , <TAB> <TAB> <TAB> marker = marker , <TAB> <TAB> <TAB> sort_key = "" created_at "" , <TAB> <TAB> <TAB> sort_dir = "" desc "" , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> images + = batch <TAB> <TAB> marker = batch [ - 1 ] [ "" id "" ] <TAB> return images","if batch [ - 1 ] [ ""id"" ] == ""images"" :",if not batch :,False,91.18,64.97,,,
"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB> <TAB> if data_list [ 1 ] in forms . fields . EMPTY_VALUES : <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_year "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_month "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> year = int ( data_list [ 1 ] ) <TAB> <TAB> month = int ( data_list [ 0 ] ) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange(year, month)[1] <TAB> <TAB> return date(year, month, day) <TAB> return None",if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,if data_list [ 0 ] in forms . fields . EMPTY_VALUES :,True,100.0,74.54,,,
"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB> <TAB> if key not in new : <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed.append(key) <TAB> <TAB> <TAB> added.append(key) <TAB> for key, value in new.items(): <TAB> <TAB> if key not in old: <TAB> <TAB> <TAB> added.append(key) <TAB> if removed: <TAB> <TAB> diff[""removed""] = sorted(removed) <TAB> if added: <TAB> <TAB> diff[""added""] = sorted(added) <TAB> return diff",if key not in old :,elif old [ key ] != new [ key ] :,False,94.79,70.02,,,
"def add_filters ( self , function ) : <TAB> try : <TAB> <TAB> subscription = self . exists ( function ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> response = self . _sns . call ( <TAB> <TAB> <TAB> <TAB> "" set_subscription_attributes "" , <TAB> <TAB> <TAB> <TAB> SubscriptionArn = subscription [ "" SubscriptionArn "" ] , <TAB> <TAB> <TAB> <TAB> AttributeName = "" FilterPolicy "" , <TAB> <TAB> <TAB> <TAB> AttributeValue = json . dumps ( self . filters ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> kappa . event_source . sns . LOG . debug ( response ) <TAB> except Exception : <TAB> <TAB> kappa . event_source . sns . LOG . exception ( <TAB> <TAB> <TAB> "" Unable to add filters for SNS topic  %s "" , self . arn <TAB> <TAB> )",if subscription :,if subscription :,True,100.0,74.52,,,
"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB> <TAB> logger = logging . getLogger ( ) <TAB> <TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB> <TAB> for m in self . modules ( ) : <TAB> <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> else : <TAB> <TAB> raise TypeError ( "" pretrained must be a str or None "" )","elif isinstance ( m , nn . BatchNorm2d ) :","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) :",False,95.5,71.72,,,
def test_is_native_login ( self ) : <TAB> for campaign in self . campaign_lists : <TAB> <TAB> native = campaigns . is_native_login ( campaign ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert_true ( native ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert_false ( native ) <TAB> native = campaigns . is_proxy_login ( self . invalid_campaign ) <TAB> assert_true ( native is None ),"if campaign == ""test"" :","if campaign == ""prereg"" or campaign == ""erpc"" :",False,92.57,62.59,,,
"def _process_filter ( self , query , host_state ) : <TAB> """""" Recursively parse the query structure. """""" <TAB> if not query : <TAB> <TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB> <TAB> if isinstance ( arg , list ) : <TAB> <TAB> <TAB> arg = self . _process_filter ( arg , host_state ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> arg = self . _parse_string ( arg , host_state ) <TAB> <TAB> if arg is not None : <TAB> <TAB> <TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result","elif isinstance ( arg , str ) :","elif isinstance ( arg , basestring ) :",False,98.79,98.6,,,
"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if APP_CONFIG . nobuild_files . match ( f ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> files . append ( f ) <TAB> <TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime","if f . startswith ( ""go_"" ) :","if not f . endswith ( "".go"" ) :",False,94.02,70.04,,,
"def ExcludePath ( self , path ) : <TAB> """""" Check to see if this is a service url and matches inbound_services. """""" <TAB> skip = False <TAB> for reserved_path in self . reserved_paths . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> not self . inbound_services <TAB> <TAB> <TAB> <TAB> or self . reserved_paths [ reserved_path ] not in self . inbound_services <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return ( True , self . reserved_paths [ reserved_path ] ) <TAB> return ( False , None )",if path in self . path_list :,if path . startswith ( reserved_path ) :,False,95.6,93.99,,,
"def param_cov ( self ) - > DataFrame : <TAB> """""" Parameter covariance """""" <TAB> if self . _param_cov is not None : <TAB> <TAB> param_cov = self . _param_cov <TAB> else : <TAB> <TAB> params = np . asarray ( self . params ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> param_cov = self . model . compute_param_cov ( params ) <TAB> <TAB> else : <TAB> <TAB> <TAB> param_cov = self . model . compute_param_cov ( params , robust = False ) <TAB> return DataFrame ( param_cov , columns = self . _names , index = self . _names )",if self . robust :,"if self . cov_type == ""robust"" :",False,94.68,95.72,,,
"def test_calculate_all_attentions ( module , atype ) : <TAB> m = importlib . import_module ( module ) <TAB> args = make_arg ( atype = atype ) <TAB> <IF-STMT> <TAB> <TAB> batch = prepare_inputs ( "" pytorch "" ) <TAB> else : <TAB> <TAB> raise NotImplementedError <TAB> model = m . E2E ( 6 , 5 , args ) <TAB> with chainer . no_backprop_mode ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> att_ws = model . calculate_all_attentions ( * batch ) [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError <TAB> <TAB> print ( att_ws . shape )","if module . startswith ( ""pytorch"" ) :","if ""pytorch"" in module :",False,91.58,69.21,,,
"def __eq__ ( self , other ) : <TAB> try : <TAB> <TAB> if self . type != other . type : <TAB> <TAB> <TAB> return False <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . askAnswer == other . askAnswer <TAB> <TAB> elif self . type == "" SELECT "" : <TAB> <TAB> <TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . graph == other . graph <TAB> except : <TAB> <TAB> return False","if self . type == ""SELECT"" :","if self . type == ""ASK"" :",False,98.42,73.14,,,
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> if v is None : # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value","if k . find ( ""unit"" ) >= 0 :","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) :",False,91.77,61.0,,,
"def get_connections ( data_about ) : <TAB> data = data_about . find ( "" h3 "" , text = "" Connections "" ) . findNext ( ) <TAB> connections = { } <TAB> for row in data . find_all ( "" tr "" ) : <TAB> <TAB> key = row . find_all ( "" td "" ) [ 0 ] . text <TAB> <TAB> value = row . find_all ( "" td "" ) [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> connections [ key ] = get_all_links ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> connections [ key ] = value . text <TAB> return connections","if key == ""links"" :","if ""Teams"" in key :",False,95.95,72.4,,,
"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB> <TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB> <TAB> if second_byte == None : <TAB> <TAB> <TAB> return "" XED_ILD_MAP1 "" <TAB> <TAB> if second_byte == 0x38 : <TAB> <TAB> <TAB> return "" XED_ILD_MAP2 "" <TAB> <TAB> if second_byte == 0x3A : <TAB> <TAB> <TAB> return "" XED_ILD_MAP3 "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) )",if first_byte == 0x0D :,if second_byte == 0x0F and self . amd_enabled :,False,94.61,70.54,,,
"def compress ( self , data_list ) : <TAB> if data_list : <TAB> <TAB> page_id = data_list [ 1 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if not self . required : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB> <TAB> return Page . objects . get ( pk = page_id ) <TAB> return None",if page_id not in Page . objects . filter ( pk = page_id ) . exists ( ) :,if page_id in EMPTY_VALUES :,False,86.55,68.31,,,
"def find_module ( self , fullname , path = None ) : <TAB> path = path or self . path_entry <TAB> # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB> for _ext in [""js"", ""pyj"", ""py""]: <TAB> <TAB> _filepath = os.path.join(self.path_entry, ""%s.%s"" % (fullname, _ext)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""module found at %s:%s"" % (_filepath, fullname)) <TAB> <TAB> <TAB> return VFSModuleLoader(_filepath, fullname) <TAB> print(""module %s not found"" % fullname) <TAB> raise ImportError() <TAB> return None",if os . path . exists ( _filepath ) :,if _filepath in VFS :,False,95.05,70.23,,,
"def __decToBin ( self , myDec ) : <TAB> n = 0 <TAB> binOfDec = "" "" <TAB> while myDec > 2 * * n : <TAB> <TAB> n = n + 1 <TAB> if ( myDec < 2 * * n ) & ( myDec != 0 ) : <TAB> <TAB> n = n - 1 <TAB> while n > = 0 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> myDec = myDec - 2 * * n <TAB> <TAB> <TAB> binOfDec = binOfDec + "" 1 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> binOfDec = binOfDec + "" 0 "" <TAB> <TAB> n = n - 1 <TAB> return binOfDec",if n < 2 * * n :,if myDec >= 2 ** n :,False,97.37,72.05,,,
"def __str__ ( self ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> NVMLError . _errcode_to_string [ self . value ] = str ( nvmlErrorString ( self . value ) ) <TAB> <TAB> return NVMLError . _errcode_to_string [ self . value ] <TAB> except NVMLError_Uninitialized : <TAB> <TAB> return "" NVML Error with code  %d "" % self . value",if self . value not in NVMLError . _errcode_to_string :,if self . value not in NVMLError . _errcode_to_string :,True,100.0,74.15,,,
"def abspath ( pathdir : str ) - > str : <TAB> if Path is not None and isinstance ( pathdir , Path ) : <TAB> <TAB> return pathdir . abspath ( ) <TAB> else : <TAB> <TAB> pathdir = path . abspath ( pathdir ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> pathdir = pathdir . decode ( fs_encoding ) <TAB> <TAB> <TAB> except UnicodeDecodeError as exc : <TAB> <TAB> <TAB> <TAB> raise UnicodeDecodeError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" multibyte filename not supported on  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" this filesystem encoding  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" ( %r ) "" % fs_encoding <TAB> <TAB> <TAB> <TAB> ) from exc <TAB> <TAB> return pathdir","if isinstance ( pathdir , str ) :","if isinstance ( pathdir , bytes ) :",False,98.87,73.61,,,
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isfile ( self . object ) : <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> elif hasattr ( self . object , "" read "" ) : <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs","if hasattr ( self . object , ""read"" ) :","if isinstance ( self . object , string_types ) and self . object . endswith ( "".vtkjs"" ) :",False,92.19,69.86,,,
"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB> <TAB> if pwd is None : <TAB> <TAB> <TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB> <TAB> <TAB> val = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val","if val . startswith ( ""uid"" ) :","elif isinstance ( val , text_or_bytes ) :",False,90.69,61.4,,,
"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB> <TAB> if node_settings is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings . external_account == external_account : <TAB> <TAB> <TAB> yield node",if node . is_linked :,if node is None :,False,96.19,71.25,,,
"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB> <TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB> <TAB> if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes : <TAB> <TAB> <TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> box_keys = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask_keys = [ ] <TAB> <TAB> return cls ( box_keys , mask_keys )","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :","if hasattr ( py_obj , ""masks"" ) and py_obj . masks :",True,100.0,74.5,,,
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> if not self . bytestream : <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> if self . bitnum == 8 : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1",if byte == 0 :,if self . bytenum == len ( self . bytestream ) - 1 :,False,94.48,70.64,,,
"def destroy ( self , wipe = False ) : <TAB> if self . state == self . UP : <TAB> <TAB> image = self . image ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . confirm_destroy ( image , self . full_name , abort = False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . warn ( "" tried to destroy  {0}  which didn ' t exist "" . format ( self . full_name ) ) <TAB> return True",if self . exists ( image ) :,if image :,False,94.2,71.58,,,
"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB> <TAB> <TAB> ) . json ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB> <TAB> <TAB> <TAB> if match is not None and len ( match . groups ( ) ) == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta","if resp . get ( ""Status"" ) == ""Accepted"" :","if ""Version"" in resp :",False,94.55,67.26,,,
"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts . append ( "" file "" ) <TAB> <TAB> elif stat . S_ISDIR ( st . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" dir "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB> <TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" link "" ) <TAB> return "" "" . join ( parts )",if stat . S_ISREG ( st . st_mode ) :,if stat . S_ISREG ( st . st_mode ) :,True,100.0,74.44,,,
"def changed ( self , action ) : <TAB> # Something was changed in the 'files' list <TAB> if len(action.key) >= 1 and action.key[0].lower() == ""files"": <TAB> <TAB> # Refresh project files model <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Don't clear the existing items if only inserting new things <TAB> <TAB> <TAB> self.update_model(clear=False) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Clear existing items <TAB> <TAB> <TAB> self.update_model(clear=True)","if action . key [ 0 ] . lower ( ) == ""project"" :","if action . type == ""insert"" :",False,92.5,69.27,,,
"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( "" es "" ) <TAB> for r in resources : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = self . manager . retry ( <TAB> <TAB> <TAB> <TAB> client . describe_elasticsearch_domain_config , <TAB> <TAB> <TAB> <TAB> DomainName = r [ "" DomainName "" ] , <TAB> <TAB> <TAB> <TAB> ignore_err_codes = ( "" ResourceNotFoundException "" , ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> r [ self . policy_attribute ] = json . loads ( <TAB> <TAB> <TAB> <TAB> <TAB> result . get ( "" DomainConfig "" ) . get ( "" AccessPolicies "" ) . get ( "" Options "" ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return super ( ) . process ( resources )","if r [ ""Domain"" ] :",if self . policy_attribute not in r :,False,96.33,68.12,,,
"def line_items ( self ) : <TAB> line_items = [ ] <TAB> for line in self . lines_str : <TAB> <TAB> line = line . split ( "" | "" ) <TAB> <TAB> line = line [ 1 : - 1 ] # del first and last empty item (consequence of split) <TAB> <TAB> items = [] <TAB> <TAB> for item in line: <TAB> <TAB> <TAB> i = re.search(r""(\S+([ \t]+\S+)*)+"", item) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> items.append(i.group()) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> items.append("" "") <TAB> <TAB> line_items.append(items) <TAB> return line_items",if i :,if i :,True,100.0,74.36,,,
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> if type ( f ) == unicode : <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> if type ( v ) == unicode : <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res )",elif type ( res ) == list :,elif not args . content_only :,False,96.21,72.23,,,
"def get_servers ( self , detail = True , search_opts = None ) : <TAB> rel_url = "" /servers/detail "" if detail else "" /servers "" <TAB> if search_opts is not None : <TAB> <TAB> qparams = { } <TAB> <TAB> for opt , val in search_opts . iteritems ( ) : <TAB> <TAB> <TAB> qparams [ opt ] = val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> query_string = "" ? %s "" % urllib . urlencode ( qparams ) <TAB> <TAB> <TAB> rel_url + = query_string <TAB> return self . api_get ( rel_url ) [ "" servers "" ]",if qparams :,if qparams :,True,100.0,74.41,,,
"def run ( self ) : <TAB> while not self . __exit__ : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sleep ( 10 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> o = self . playlist [ 0 ] <TAB> <TAB> self . playlist . remove ( o ) <TAB> <TAB> obj = json . loads ( o ) <TAB> <TAB> if not "" args "" in obj : <TAB> <TAB> <TAB> obj [ "" args "" ] = { "" ua "" : "" "" , "" header "" : "" "" , "" title "" : "" "" , "" referer "" : "" "" } <TAB> <TAB> obj [ "" play "" ] = False <TAB> <TAB> self . handle = launch_player ( obj [ "" urls "" ] , obj [ "" ext "" ] , * * obj [ "" args "" ] ) <TAB> <TAB> self . handle . wait ( )",if self . play :,if len ( self . playlist ) == 0 :,False,95.59,71.98,,,
"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB> <TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB> <TAB> <TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB> <TAB> <TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB> <TAB> <TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB> <TAB> <TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB> <TAB> <TAB> time . sleep ( 1 ) # spider rule <TAB> <TAB> <TAB> if not last_date: <TAB> <TAB> <TAB> <TAB> break <TAB> return result",if r . status_code == 200 :,if r . ok :,False,97.32,73.66,,,
"def __saveWork ( self , work , results ) : <TAB> """""" Stores the resulting last log line to the cache with the proxy key """""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> __cached = self.__cache[results[0]] <TAB> <TAB> <TAB> __cached[self.__TIME] = time.time() <TAB> <TAB> <TAB> __cached[self.__LINE] = results[1] <TAB> <TAB> <TAB> __cached[self.__LLU] = results[2] <TAB> except KeyError as e: <TAB> <TAB> # Could happen while switching jobs with work in the queue <TAB> <TAB> pass <TAB> except Exception as e: <TAB> <TAB> list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",if results [ 0 ] in self . __cache :,if results :,False,95.44,96.85,,,
"def read_notes ( rec ) : <TAB> found = [ ] <TAB> for tag in range ( 500 , 595 ) : <TAB> <TAB> if tag in ( 505 , 520 ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> fields = rec . get_fields ( str ( tag ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> for f in fields : <TAB> <TAB> <TAB> x = f . get_lower_subfields ( ) <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> found . append ( "" "" . join ( x ) . strip ( "" "" ) ) <TAB> if found : <TAB> <TAB> return "" \n \n "" . join ( found )",if not fields :,if not fields :,True,100.0,74.5,,,
"def serialize_to ( self , stream , alternate_script = None ) : <TAB> stream . write ( self . txo_ref . tx_ref . hash ) <TAB> stream . write_uint32 ( self . txo_ref . position ) <TAB> if alternate_script is not None : <TAB> <TAB> stream . write_string ( alternate_script ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> stream . write_string ( self . coinbase ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stream . write_string ( self . script . source ) <TAB> stream . write_uint32 ( self . sequence )",if self . coinbase is not None :,if self . is_coinbase :,False,96.81,72.37,,,
"def func_named ( self , arg ) : <TAB> result = None <TAB> target = "" do_ "" + arg <TAB> if target in dir ( self ) : <TAB> <TAB> result = target <TAB> else : <TAB> <TAB> <IF-STMT> # accept shortened versions of commands <TAB> <TAB> <TAB> funcs = [fname for fname in self.keywords if fname.startswith(arg)] <TAB> <TAB> <TAB> if len(funcs) == 1: <TAB> <TAB> <TAB> <TAB> result = ""do_"" + funcs[0] <TAB> return result",if arg in self . keywords :,if self . abbrev :,False,95.94,71.36,,,
"def static_login ( self , token , * , bot ) : <TAB> # Necessary to get aiohttp to stop complaining about session creation <TAB> self.__session = aiohttp.ClientSession( <TAB> <TAB> connector=self.connector, ws_response_class=DiscordClientWebSocketResponse <TAB> ) <TAB> old_token, old_bot = self.token, self.bot_token <TAB> self._token(token, bot=bot) <TAB> try: <TAB> <TAB> data = await self.request(Route(""GET"", ""/users/@me"")) <TAB> except HTTPException as exc: <TAB> <TAB> self._token(old_token, bot=old_bot) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise LoginFailure(""Improper token has been passed."") from exc <TAB> <TAB> raise <TAB> return data",if exc . response . status != 401 :,if exc . response . status == 401 :,False,98.8,72.9,,,
"def render_buttons ( self ) : <TAB> for x , button in enumerate ( self . button_list ) : <TAB> <TAB> gcolor = Gdk . color_parse ( self . color_list [ x ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fgcolor = Gdk . color_parse ( "" #FFFFFF "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fgcolor = Gdk . color_parse ( "" #000000 "" ) <TAB> <TAB> button . set_label ( self . color_list [ x ] ) <TAB> <TAB> button . set_sensitive ( True ) <TAB> <TAB> button . modify_bg ( Gtk . StateType . NORMAL , gcolor ) <TAB> <TAB> button . modify_fg ( Gtk . StateType . NORMAL , fgcolor )",if x == 0 :,"if util . get_hls_val ( self . color_list [ x ] , ""light"" ) < 99 :",False,87.77,62.59,,,
"def _set_text ( self , data ) : <TAB> lines = [ ] <TAB> for key , value in data . items ( ) : <TAB> <TAB> lines . append ( "" "" ) <TAB> <TAB> txt = yaml . dump ( { key : value } , default_flow_style = False ) <TAB> <TAB> title = self . titles . get ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lines . append ( "" #  %s "" % title ) <TAB> <TAB> lines . append ( txt . rstrip ( ) ) <TAB> txt = "" \n "" . join ( lines ) + "" \n "" <TAB> txt = txt . lstrip ( ) <TAB> self . edit . setPlainText ( txt )",if title :,if title :,True,100.0,74.48,,,
"def build_path ( self ) : <TAB> for variable in re_path_template . findall ( self . path ) : <TAB> <TAB> name = variable . strip ( "" {} "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # No 'user' parameter provided, fetch it from Auth instead. <TAB> <TAB> <TAB> value = self.api.auth.get_username() <TAB> <TAB> else: <TAB> <TAB> <TAB> try: <TAB> <TAB> <TAB> <TAB> value = quote(self.session.params[name]) <TAB> <TAB> <TAB> except KeyError: <TAB> <TAB> <TAB> <TAB> raise TweepError( <TAB> <TAB> <TAB> <TAB> <TAB> ""No parameter value found for path variable: %s"" % name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self.session.params[name] <TAB> <TAB> self.path = self.path.replace(variable, value)","if name == ""user"" :","if name == ""user"" and ""user"" not in self . session . params and self . api . auth :",False,92.91,62.58,,,
"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> prop_vals = entity [ prop_name ] <TAB> <TAB> <TAB> if isinstance ( prop_vals , ( list ) ) : <TAB> <TAB> <TAB> <TAB> num_prop_vals = len ( prop_vals ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes + = 2 * num_prop_vals <TAB> return writes","if prop_name . startswith ( ""builtin"" ) :",if not prop_name in entity . unindexed_properties ( ) :,False,93.99,61.32,,,
"def create_connection ( self , address , protocol_factory = None , * * kw ) : <TAB> """""" Helper method for creating a connection to an ``address``. """""" <TAB> protocol_factory = protocol_factory or self . create_protocol <TAB> if isinstance ( address , tuple ) : <TAB> <TAB> host , port = address <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . logger . debug ( "" Create connection  %s : %s "" , host , port ) <TAB> <TAB> _ , protocol = await self . _loop . create_connection ( <TAB> <TAB> <TAB> protocol_factory , host , port , * * kw <TAB> <TAB> ) <TAB> <TAB> await protocol . event ( "" connection_made "" ) <TAB> else : <TAB> <TAB> raise NotImplementedError ( "" Could not connect to  %s "" % str ( address ) ) <TAB> return protocol",if self . _loop :,if self . debug :,False,98.39,98.69,,,
def _increment_bracket_num ( self ) : <TAB> self . _current_bracket - = 1 <TAB> if self . _current_bracket < 0 : <TAB> <TAB> self . _current_bracket = self . _get_num_brackets ( ) - 1 <TAB> <TAB> self . _current_iteration + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _current_bracket = 0,if self . _current_iteration >= self . _get_num_brackets ( ) :,if self . _current_iteration > self . hyperband_iterations :,False,90.17,79.89,,,
"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> path = self . get_cycle_path ( <TAB> <TAB> <TAB> self . get_by_address ( dep ) , goal_node_index <TAB> <TAB> ) # self.nodelist[dep], goal_node_index) <TAB> <TAB> if len(path) > 0: <TAB> <TAB> <TAB> path.insert(0, curr_node[""address""]) <TAB> <TAB> <TAB> return path <TAB> return []",if dep == goal_node_index :,if dep == goal_node_index :,True,100.0,74.35,,,
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> if item . endswith ( "" / "" ) : <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> elif is_dict . match ( item ) : <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result",if records :,if records :,True,100.0,74.67,,,
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" )","if line [ 0 ] == ""#"" :","if line [ 0 ] == "" "" :",False,98.98,73.34,,,
"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB> <TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if index is not None : <TAB> <TAB> <TAB> del self . _subscribers [ index ] <TAB> <TAB> if not self . _subscribers : <TAB> <TAB> <TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) )",if web_sock == subscriber_web_sock :,if subscriber_web_sock == web_sock :,False,98.23,72.39,,,
"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB> <TAB> s = month_name [ themonth ] <TAB> <TAB> if encoding is not None : <TAB> <TAB> <TAB> s = s . decode ( encoding ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> s = "" %s %s "" % ( s , theyear ) <TAB> <TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s",if withyear :,if withyear :,True,100.0,74.33,,,
"def generate_sitemaps ( filename ) : <TAB> rows = ( line . strip ( ) . split ( "" \t "" ) for line in open ( filename ) ) <TAB> for sortkey , chunk in itertools . groupby ( rows , lambda row : row [ 0 ] ) : <TAB> <TAB> things = [ ] <TAB> <TAB> _chunk = list ( chunk ) <TAB> <TAB> for segment in _chunk : <TAB> <TAB> <TAB> sortkey = segment . pop ( 0 ) <TAB> <TAB> <TAB> last_modified = segment . pop ( - 1 ) <TAB> <TAB> <TAB> path = "" "" . join ( segment ) <TAB> <TAB> <TAB> things . append ( web . storage ( path = path , last_modified = last_modified ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> write ( "" sitemaps/sitemap_ %s .xml.gz "" % sortkey , sitemap ( things ) )",if things :,if things :,True,100.0,74.57,,,
"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _use_indexes . append ( t ) <TAB> <TAB> elif isinstance ( t , str ) : <TAB> <TAB> <TAB> self . _use_indexes . append ( Index ( t ) )","if isinstance ( t , Index ) :","if isinstance ( t , Index ) :",True,100.0,74.26,,,
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> if start < last_end : <TAB> <TAB> <TAB> <TAB> if not self . _is_expression ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( )",if result is None :,if result == self . source :,False,97.55,72.79,,,
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> if value . has_form ( "" List "" , None ) : <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> return value","if value . has_form ( ""List"" , None ) :",if any ( item is None for item in value ) :,False,95.0,62.81,,,
"def _reemit_nested_event ( self , event : Event ) : <TAB> source_index = self . index ( event . source ) <TAB> for attr in ( "" index "" , "" new_index "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> src_index = ensure_tuple_index ( event . index ) <TAB> <TAB> <TAB> setattr ( event , attr , ( source_index , ) + src_index ) <TAB> if not hasattr ( event , "" index "" ) : <TAB> <TAB> setattr ( event , "" index "" , source_index ) <TAB> # reemit with this object's EventEmitter of the same type if present <TAB> # otherwise just emit with the EmitterGroup itself <TAB> getattr(self.events, event.type, self.events)(event)","if hasattr ( event , attr ) :","if hasattr ( event , attr ) :",True,100.0,74.48,,,
"def check ( self ) : <TAB> """""" Perform required checks to conclude if it ' s safe to operate """""" <TAB> if self . interpreter . manual is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . error = self . process . error <TAB> <TAB> <TAB> self . tip = self . process . tip <TAB> <TAB> <TAB> return False <TAB> start = time . time ( ) <TAB> while not self . _status ( ) : <TAB> <TAB> if time . time ( ) - start > = 2 : # 2s <TAB> <TAB> <TAB> self.error = ""can't connect to the minserver on {}:{}"".format( <TAB> <TAB> <TAB> <TAB> self.interpreter.host, self.interpreter.port <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.tip = ""check your vagrant machine is running"" <TAB> <TAB> <TAB> return False <TAB> <TAB> time.sleep(0.1) <TAB> return True",if self . process . error :,if not self . process . healthy :,False,98.01,83.18,,,
"def apply ( self ) : <TAB> new_block = self . block . copy ( ) <TAB> new_block . clear ( ) <TAB> for inst in self . block . body : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> const_assign = self . _assign_const ( inst ) <TAB> <TAB> <TAB> new_block . append ( const_assign ) <TAB> <TAB> <TAB> inst = self . _assign_getitem ( inst , index = const_assign . target ) <TAB> <TAB> new_block . append ( inst ) <TAB> return new_block","if isinstance ( inst , ast . Constant ) :","if isinstance ( inst , Assign ) and inst . value in self . getattrs :",False,92.73,68.41,,,
"def _get_orientation ( self ) : <TAB> if self . state : <TAB> <TAB> rotation = [ 0 ] * 9 <TAB> <TAB> inclination = [ 0 ] * 9 <TAB> <TAB> gravity = [ ] <TAB> <TAB> geomagnetic = [ ] <TAB> <TAB> gravity = self . listener_a . values <TAB> <TAB> geomagnetic = self . listener_m . values <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ff_state = SensorManager . getRotationMatrix ( <TAB> <TAB> <TAB> <TAB> rotation , inclination , gravity , geomagnetic <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if ff_state : <TAB> <TAB> <TAB> <TAB> values = [ 0 , 0 , 0 ] <TAB> <TAB> <TAB> <TAB> values = SensorManager . getOrientation ( rotation , values ) <TAB> <TAB> <TAB> return values",if self . listener_a . state == SensorManager . STATE_POLY :,if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None :,False,92.78,67.88,,,
def getFirstSubGraph ( graph ) : <TAB> if len ( graph ) == 0 : <TAB> <TAB> return None <TAB> subg = { } <TAB> todo = [ graph . keys ( ) [ 0 ] ] <TAB> while len ( todo ) > 0 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subg [ todo [ 0 ] ] = graph [ todo [ 0 ] ] <TAB> <TAB> <TAB> todo . extend ( graph [ todo [ 0 ] ] ) <TAB> <TAB> <TAB> del graph [ todo [ 0 ] ] <TAB> <TAB> del todo [ 0 ] <TAB> return subg,if todo [ 0 ] in graph :,if todo [ 0 ] in graph . keys ( ) :,False,96.4,94.75,,,
"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable ( result ) : <TAB> <TAB> <TAB> <TAB> result = result ( rv ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> from werkzeug . http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date ( result ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> rv . headers [ "" Last-Modified "" ] = result <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . getLogger ( __name__ ) . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv","if isinstance ( result , datetime ) :","if not isinstance ( result , basestring ) :",False,98.26,73.04,,,
"def set_invoice_details ( self , row ) : <TAB> invoice_details = self . invoice_details . get ( row . voucher_no , { } ) <TAB> if row . due_date : <TAB> <TAB> invoice_details . pop ( "" due_date "" , None ) <TAB> row . update ( invoice_details ) <TAB> if row . voucher_type == "" Sales Invoice "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_delivery_notes ( row ) <TAB> <TAB> if self . filters . show_sales_person and row . sales_team : <TAB> <TAB> <TAB> row . sales_person = "" ,  "" . join ( row . sales_team ) <TAB> <TAB> <TAB> del row [ "" sales_team "" ]",if self . filters . delivery_notes :,if self . filters . show_delivery_notes :,False,98.21,73.4,,,
"def process ( output ) : <TAB> modules = { } <TAB> for line in output : <TAB> <TAB> name , size , instances , depends , state , _ = line . split ( "" "" , 5 ) <TAB> <TAB> instances = int ( instances ) <TAB> <TAB> module = { <TAB> <TAB> <TAB> "" size "" : size , <TAB> <TAB> <TAB> "" instances "" : instances , <TAB> <TAB> <TAB> "" state "" : state , <TAB> <TAB> } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module [ "" depends "" ] = [ value for value in depends . split ( "" , "" ) if value ] <TAB> <TAB> modules [ name ] = module <TAB> return modules",if depends :,"if depends != ""-"" :",False,96.42,69.56,,,
"def _get_host_from_zc_service_info ( service_info : zeroconf . ServiceInfo ) : <TAB> """""" Get hostname or IP + port from zeroconf service_info. """""" <TAB> host = None <TAB> port = None <TAB> if ( <TAB> <TAB> service_info <TAB> <TAB> and service_info . port <TAB> <TAB> and ( service_info . server or len ( service_info . addresses ) > 0 ) <TAB> ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> host = socket . inet_ntoa ( service_info . addresses [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> host = service_info . server . lower ( ) <TAB> <TAB> port = service_info . port <TAB> return ( host , port )",if service_info . server :,if len ( service_info . addresses ) > 0 :,False,95.57,86.19,,,
"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> if module . bias is not None : <TAB> <TAB> <TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module . weight . data [ module . padding_idx ] . zero_ ( )",if module . padding_idx is not None :,if module . padding_idx is not None :,True,100.0,74.49,,,
"def visitFromImport ( self , import_stmt , import_info ) : <TAB> new_pairs = [ ] <TAB> if not import_info . is_star_import ( ) : <TAB> <TAB> for name , alias in import_info . names_and_aliases : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> pyname = self . pymodule [ alias or name ] <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> except exceptions . AttributeNotFoundError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> new_pairs . append ( ( name , alias ) ) <TAB> return importinfo . FromImport ( import_info . module_name , import_info . level , new_pairs )",if pyname == import_info . module_name :,"if occurrences . same_pyname ( self . pyname , pyname ) :",False,93.87,69.9,,,
"def _apply_patches ( self ) : <TAB> try : <TAB> <TAB> s = Subprocess ( <TAB> <TAB> <TAB> log = self . logfile , cwd = self . build_dir , verbose = self . options . verbose <TAB> <TAB> ) <TAB> <TAB> for patch in self . patches : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for ed , source in patch . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> s . shell ( "" ed -  %s  <  %s "" % ( source , ed ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> s . shell ( "" patch -p0 <  %s "" % patch ) <TAB> except : <TAB> <TAB> logger . error ( "" Failed to patch ` %s `. \n %s "" % ( self . build_dir , sys . exc_info ( ) [ 1 ] ) ) <TAB> <TAB> sys . exit ( 1 )","if isinstance ( patch , dict ) :",if type ( patch ) is dict :,False,97.44,72.57,,,
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> if i == "" . "" or i == "" .. "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> if pattern . match ( value ) is not None : <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist",if not os . path . isdir ( path ) :,if os . path . isdir ( path ) :,False,99.06,74.12,,,
"def remove_invalid_dirs ( paths , bp_dir , module_name ) : <TAB> ret = [ ] <TAB> for path in paths : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . warning ( ' Dir  "" %s ""  of module  "" %s ""  does not exist ' , path , module_name ) <TAB> return ret",if os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . isdir ( path ) and os . path . islink ( path ) :,"if os . path . isdir ( os . path . join ( bp_dir , path ) ) :",False,61.26,59.89,,,
"def update_sockets ( self ) : <TAB> inputs = self . inputs <TAB> inputs_n = "" ABabcd "" <TAB> penta_sockets = pentagon_dict [ self . grid_type ] . input_sockets <TAB> for socket in inputs_n : <TAB> <TAB> if socket in penta_sockets : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> inputs [ socket ] . hide_safe = False <TAB> <TAB> else : <TAB> <TAB> <TAB> inputs [ socket ] . hide_safe = True",if not inputs [ socket ] . hide_safe :,if inputs [ socket ] . hide_safe :,False,98.17,72.97,,,
"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i, char in enumerate(sentence): <TAB> <TAB> pos = pos_list[i] <TAB> <TAB> if pos == ""B"": <TAB> <TAB> <TAB> begin = i <TAB> <TAB> elif pos == ""E"": <TAB> <TAB> <TAB> yield sentence[begin : i + 1] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len(sentence): <TAB> <TAB> yield sentence[nexti:]","elif pos == ""F"" :","elif pos == ""S"" :",False,98.88,73.39,,,
"def validate ( self ) : <TAB> if self . data . get ( "" encrypted "" , True ) : <TAB> <TAB> key = self . data . get ( "" target_key "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise PolicyValidationError ( <TAB> <TAB> <TAB> <TAB> "" Encrypted snapshot copy requires kms key on  %s "" % ( self . manager . data , ) <TAB> <TAB> <TAB> ) <TAB> return self","if key and not key . lower ( ) . startswith ( ""s3://"" ) :",if not key :,False,85.15,63.61,,,
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> if isinstance ( filename_data , list ) : <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> if data : <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories","if filename . endswith ( "".git"" ) :",if not filename . startswith ( os . sep ) :,False,96.33,62.82,,,
"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB> <TAB> value = body . get ( attribute ) <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> if isinstance ( value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> body [ attribute ] = value . strip ( ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> utils . check_string_length ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception . InvalidInput as error : <TAB> <TAB> <TAB> <TAB> <TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg )",if check_length :,if check_length :,True,100.0,74.59,,,
"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB> <TAB> if match ( s ) : <TAB> <TAB> <TAB> yield x <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation )","elif isinstance ( s , Solid ) :",elif not x . is_atom ( ) and not s . is_atom ( ) :,False,82.63,65.18,,,
"def wait_or_kill ( self ) : <TAB> """""" Wait for the program to terminate, or kill it after 5s. """""" <TAB> if self . instance . poll ( ) is None : <TAB> <TAB> # We try one more time to kill gracefully using Ctrl-C. <TAB> <TAB> logger.info(""Interrupting %s and waiting..."", self.coord) <TAB> <TAB> self.instance.send_signal(signal.SIGINT) <TAB> <TAB> # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB> <TAB> t = monotonic_time() <TAB> <TAB> while monotonic_time() - t < 5: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> logger.info(""Terminated %s."", self.coord) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> time.sleep(0.1) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.kill()",if self . instance . poll ( ) is None :,if self . instance . poll ( ) is not None :,False,99.02,98.25,,,
"def sort_collection ( self , models , many ) : <TAB> ordering = self . ordering <TAB> if not many or not ordering : <TAB> <TAB> return models <TAB> for key in reversed ( ordering ) : <TAB> <TAB> reverse = key [ 0 ] == "" - "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> key = key [ 1 : ] <TAB> <TAB> models = sorted ( models , key = partial ( deep_getattr , key = key ) , reverse = reverse ) <TAB> return models",if reverse :,if reverse :,True,100.0,74.32,,,
"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [] <TAB> <TAB> for old_id, new_id in sorted(self.label_map.items(), key=lambda x: x[1]): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> palette.append(self.PALETTE[old_id]) <TAB> <TAB> palette = type(self.PALETTE)(palette) <TAB> elif palette is None: <TAB> <TAB> if self.PALETTE is None: <TAB> <TAB> <TAB> palette = np.random.randint(0, 255, size=(len(class_names), 3)) <TAB> <TAB> else: <TAB> <TAB> <TAB> palette = self.PALETTE <TAB> return palette",if old_id in class_names :,if new_id != - 1 :,False,96.69,71.53,,,
"def _find_tcl_dir ( ) : <TAB> lib_dirs = [ os . path . dirname ( _x ) for _x in sys . path if _x . lower ( ) . endswith ( "" lib "" ) ] <TAB> for lib_dir in lib_dirs : <TAB> <TAB> base_dir = os . path . join ( lib_dir , TclLibrary . FOLDER ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for root , _ , files in os . walk ( base_dir ) : <TAB> <TAB> <TAB> <TAB> if TclLibrary . INIT_TCL in files : <TAB> <TAB> <TAB> <TAB> <TAB> return root",if os . path . isdir ( base_dir ) :,if os . path . exists ( base_dir ) :,False,98.47,73.25,,,
"def __next__ ( self ) : <TAB> """""" Special paging functionality """""" <TAB> if self . iter is None : <TAB> <TAB> self . iter = iter ( self . objs ) <TAB> try : <TAB> <TAB> return next ( self . iter ) <TAB> except StopIteration : <TAB> <TAB> self . iter = None <TAB> <TAB> self . objs = [ ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . page + = 1 <TAB> <TAB> <TAB> self . _connection . get_response ( self . action , self . params , self . page , self ) <TAB> <TAB> <TAB> return next ( self ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise",if self . page < self . limit :,if int ( self . page ) < int ( self . total_pages ) :,False,92.76,77.2,,,
"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB> <TAB> if k == "" user "" : <TAB> <TAB> <TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( lst , k , v ) <TAB> return lst","elif k == ""date"" :","elif k == ""created_at"" :",False,97.03,73.22,,,
"def real_type ( self ) : <TAB> # Find the real type representation by updating it as required <TAB> real_type = self.type <TAB> if self.flag_indicator: <TAB> <TAB> real_type = ""#"" <TAB> if self.is_vector: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> real_type = ""Vector<{}>"".format(real_type) <TAB> <TAB> else: <TAB> <TAB> <TAB> real_type = ""vector<{}>"".format(real_type) <TAB> if self.is_generic: <TAB> <TAB> real_type = ""!{}"".format(real_type) <TAB> if self.is_flag: <TAB> <TAB> real_type = ""flags.{}?{}"".format(self.flag_index, real_type) <TAB> return real_type",if self . flag_index == 0 :,if self . use_vector_id :,False,96.74,71.89,,,
"def check_fs ( path ) : <TAB> with open ( path , "" rb "" ) as f : <TAB> <TAB> code = python_bytes_to_unicode ( f . read ( ) , errors = "" replace "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module = _load_module ( evaluator , path , code ) <TAB> <TAB> <TAB> module_name = sys_path . dotted_path_in_sys_path ( <TAB> <TAB> <TAB> <TAB> evaluator . project . sys_path , path <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if module_name is not None : <TAB> <TAB> <TAB> <TAB> add_module ( evaluator , module_name , module ) <TAB> <TAB> <TAB> return module",if code :,if name in code :,False,98.18,72.64,,,
"def infoCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] , checkPrimary = True ) <TAB> i = 0 <TAB> count = len ( users ) <TAB> for user in users : <TAB> <TAB> i + = 1 <TAB> <TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB> <TAB> if not cal : <TAB> <TAB> <TAB> continue <TAB> <TAB> result = gapi . call ( <TAB> <TAB> <TAB> cal . calendarList ( ) , "" get "" , soft_errors = True , calendarId = calendarId <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( f "" User:  { user } , Calendar: { display . current_count ( i , count ) } "" ) <TAB> <TAB> <TAB> _showCalendar ( result , 1 , 1 )",if result :,if result :,True,100.0,74.54,,,
"def set_hidestate_input_sockets_to_cope_with_switchnum ( self ) : <TAB> tndict = get_indices_that_should_be_visible ( self . node_state ) <TAB> for key , value in tndict . items ( ) : <TAB> <TAB> socket = self . inputs [ key ] <TAB> <TAB> desired_hide_state = not ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> socket . hide_safe = desired_hide_state",if socket . hide_safe :,if not socket . hide == desired_hide_state :,False,91.46,68.41,,,
"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB> <TAB> if isinstance ( parent , pytest . Class ) : <TAB> <TAB> <TAB> class_name = parent . name <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module_name = parent . module . __name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #  are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #  the same module <TAB> if class_name and "".tasks."" not in module_name: <TAB> <TAB> return ""{}.{}"".format(module_name, class_name) <TAB> else: <TAB> <TAB> return module_name","elif isinstance ( parent , pytest . Module ) :","elif isinstance ( parent , pytest . Module ) :",True,100.0,74.57,,,
"def run ( self ) : <TAB> versions = versioneer . get_versions ( ) <TAB> tempdir = tempfile . mkdtemp ( ) <TAB> generated = os . path . join ( tempdir , "" rundemo "" ) <TAB> with open ( generated , "" wb "" ) as f : <TAB> <TAB> for line in open ( "" src/rundemo-template "" , "" rb "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f . write ( ( "" versions =  %r \n "" % ( versions , ) ) . encode ( "" ascii "" ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> f . write ( line ) <TAB> self . scripts = [ generated ] <TAB> rc = build_scripts . run ( self ) <TAB> os . unlink ( generated ) <TAB> os . rmdir ( tempdir ) <TAB> return rc","if line . startswith ( ""version="" ) :","if line . strip ( ) . decode ( ""ascii"" ) == ""#versions"" :",False,92.99,67.95,,,
"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB> <TAB> user = getattr ( request , "" user "" , None ) <TAB> <TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" email "" : user . email , <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : user . id , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if user . name : <TAB> <TAB> <TAB> <TAB> result [ "" name "" ] = user . name <TAB> else : <TAB> <TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) )",if user :,if user and user . is_authenticated ( ) :,False,96.09,71.99,,,
"def tokens_to_spans ( ) - > Iterable [ Tuple [ str , Optional [ Style ] ] ] : <TAB> """""" Convert tokens to spans. """""" <TAB> tokens = iter ( line_tokenize ( ) ) <TAB> line_no = 0 <TAB> _line_start = line_start - 1 <TAB> # Skip over tokens until line start <TAB> while line_no < _line_start: <TAB> <TAB> _token_type, token = next(tokens) <TAB> <TAB> yield (token, None) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line_no += 1 <TAB> # Generate spans until line end <TAB> for token_type, token in tokens: <TAB> <TAB> yield (token, _get_theme_style(token_type)) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> line_no += 1 <TAB> <TAB> <TAB> if line_no >= line_end: <TAB> <TAB> <TAB> <TAB> break","if _token_type == ""comment"" :","if token . endswith ( ""\n"" ) :",False,92.49,93.87,,,
"def encode ( self , encodeFun , value , defMode , maxChunkSize ) : <TAB> substrate , isConstructed = self . encodeValue ( encodeFun , value , defMode , maxChunkSize ) <TAB> tagSet = value . getTagSet ( ) <TAB> if tagSet : <TAB> <TAB> <IF-STMT> # primitive form implies definite mode <TAB> <TAB> <TAB> defMode = 1 <TAB> <TAB> return ( <TAB> <TAB> <TAB> self.encodeTag(tagSet[-1], isConstructed) <TAB> <TAB> <TAB> + self.encodeLength(len(substrate), defMode) <TAB> <TAB> <TAB> + substrate <TAB> <TAB> <TAB> + self._encodeEndOfOctets(encodeFun, defMode) <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return substrate # untagged value","if tagSet [ - 1 ] == ""primitive"" :",if not isConstructed :,False,93.79,62.91,,,
def _run ( self ) : <TAB> while True : <TAB> <TAB> request = self . _requests . get ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . shutdown ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . process ( request ) <TAB> <TAB> self . _requests . task_done ( ),if request is None :,if request is None :,True,100.0,98.93,,,
"def _decode_payload ( self , payload ) : <TAB> # we need to decrypt it <TAB> if payload[""enc""] == ""aes"": <TAB> <TAB> try: <TAB> <TAB> <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB> <TAB> except salt.crypt.AuthenticationError: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> payload[""load""] = self.crypticle.loads(payload[""load""]) <TAB> return payload","if self . _config . get ( ""salt.crypticle.use_aes_auth"" , False ) :",if not self . _update_aes ( ) :,False,88.34,63.5,,,
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> if self . any_match : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return not self . inverse # True <TAB> <TAB> else: <TAB> <TAB> <TAB> if not result: <TAB> <TAB> <TAB> <TAB> return self.inverse # False <TAB> if self.any_match: <TAB> <TAB> return self.inverse # False <TAB> else: <TAB> <TAB> return not self.inverse # True",if result :,if result :,True,100.0,74.48,,,
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> if self . use_prop or self . get_prop_name ( ) : <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value","if isinstance ( value , float ) :","elif isinstance ( value , float ) :",False,98.82,73.24,,,
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """""" iterate over all modules """""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> if not clients : <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> if module . is_compatible_with ( client ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module",if clients :,if clients is not None :,False,98.24,80.39,,,
"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB> <TAB> for pricing_rule in pricing_rules : <TAB> <TAB> <TAB> if pricing_rule . condition : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules",if doc . search ( pricing_rule . condition ) :,"if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) :",False,92.87,68.54,,,
"def build_query_string ( kv_data , ignore_none = True ) : <TAB> # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB> query_string = """" <TAB> for k, v in kv_data.iteritems(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if query_string != """": <TAB> <TAB> <TAB> query_string += ""&"" <TAB> <TAB> else: <TAB> <TAB> <TAB> query_string = ""?"" <TAB> <TAB> query_string += k + ""="" + str(v) <TAB> return query_string","if ignore_none and k == ""test"" :",if ignore_none is True and kv_data [ k ] is None :,False,93.62,67.31,,,
"def sample ( self , * * config ) : <TAB> """""" Sample a configuration from this search space. """""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB> <TAB> if k in striped_keys : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB> <TAB> <TAB> <TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret [ k ] = v <TAB> return ret","if isinstance ( v , ConfigSpace ) :","if isinstance ( v , NestedSpace ) :",False,98.86,98.73,,,
"def task_failed ( self , task_id , hostname , reason ) : <TAB> logger . debug ( "" task  %d  failed with message  %s "" , task_id , str ( reason ) ) <TAB> if hostname in self . host_dict : <TAB> <TAB> host_status = self . host_dict [ hostname ] <TAB> <TAB> host_status . task_failed ( task_id ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . task_host_failed_dict [ task_id ] = set ( ) <TAB> <TAB> self . task_host_failed_dict [ task_id ] . add ( hostname )",if task_id not in self . task_host_failed_dict :,if task_id not in self . task_host_failed_dict :,True,100.0,74.33,,,
"def match ( path ) : <TAB> for pat , _type , _property , default_title in patterns : <TAB> <TAB> m = web . re_compile ( "" ^ "" + pat ) . match ( path ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> prefix = m . group ( ) <TAB> <TAB> <TAB> extra = web . lstrips ( path , prefix ) <TAB> <TAB> <TAB> tokens = extra . split ( "" / "" , 2 ) <TAB> <TAB> <TAB> # `extra` starts with ""/"". So first token is always empty. <TAB> <TAB> <TAB> middle = web.listget(tokens, 1, """") <TAB> <TAB> <TAB> suffix = web.listget(tokens, 2, """") <TAB> <TAB> <TAB> if suffix: <TAB> <TAB> <TAB> <TAB> suffix = ""/"" + suffix <TAB> <TAB> <TAB> return _type, _property, default_title, prefix, middle, suffix <TAB> return None, None, None, None, None, None",if m :,if m :,True,100.0,74.55,,,
"def _get_cached_resources ( self , ids ) : <TAB> key = self . get_cache_key ( None ) <TAB> if self . _cache . load ( ) : <TAB> <TAB> resources = self . _cache . get ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . log . debug ( "" Using cached results for get_resources "" ) <TAB> <TAB> <TAB> m = self . get_model ( ) <TAB> <TAB> <TAB> id_set = set ( ids ) <TAB> <TAB> <TAB> return [ r for r in resources if r [ m . id ] in id_set ] <TAB> return None",if resources :,if resources is not None :,False,97.21,71.89,,,
"def has_api_behaviour ( self , protocol ) : <TAB> config = get_config ( ) <TAB> try : <TAB> <TAB> r = self . session . get ( <TAB> <TAB> <TAB> f "" { protocol } :// { self . event . host } : { self . event . port } "" , <TAB> <TAB> <TAB> timeout = config . network_timeout , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> except requests . exceptions . SSLError : <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> f "" { [ protocol ] }  protocol not accepted on  { self . event . host } : { self . event . port } "" <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> f "" Failed probing  { self . event . host } : { self . event . port } "" , exc_info = True <TAB> <TAB> )",if r . status_code == requests . codes . ok :,"if ( ""k8s"" in r . text ) or ( '""code""' in r . text and r . status_code != 200 ) :",False,89.61,64.25,,,
"def get_file_type ( self , context , parent_context = None ) : <TAB> file_type = context . get ( self . file_type_name , None ) <TAB> if file_type == "" "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> file_type = parent_context . get ( self . file_type_name , self . default_file_type ) <TAB> <TAB> else : <TAB> <TAB> <TAB> file_type = self . default_file_type <TAB> return file_type",if parent_context :,if parent_context :,True,100.0,74.1,,,
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> if box == self . level . bounds : <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add : <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( )",if remove :,if boxedChunks . issubset ( selectedChunks ) :,False,96.0,71.62,,,
"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """""" Splits punctuation on a piece of text. """""" <TAB> if never_split is not None and text in never_split : <TAB> <TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB> <TAB> char = chars [ i ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> output . append ( [ char ] ) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else : <TAB> <TAB> <TAB> if start_new_word : <TAB> <TAB> <TAB> <TAB> output . append ( [ ] ) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output [ - 1 ] . append ( char ) <TAB> <TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ]",if char in self . _punctuation_chars :,if _is_punctuation ( char ) :,False,96.96,97.08,,,
"def _save_images ( notebook ) : <TAB> if os . getenv ( "" NB_NO_IMAGES "" ) == "" 1 "" : <TAB> <TAB> return <TAB> logged = False <TAB> for filename , img_bytes in _iter_notebook_images ( notebook ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> log . info ( "" Saving images "" ) <TAB> <TAB> <TAB> logged = True <TAB> <TAB> with open ( filename , "" wb "" ) as f : <TAB> <TAB> <TAB> f . write ( img_bytes )",if logged :,if not logged :,False,98.18,72.66,,,
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None : <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide )",if guideDist < minDist :,if minDist == None or guideDist < minDist :,False,97.27,72.7,,,
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> elif tp == "" flush "" : <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" write_flush "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass","if tp == ""write"" :","if tp == ""write"" :",True,100.0,74.59,,,
"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB> <TAB> for base in bases : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> if hasattr ( base , "" garbage "" ) : <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile : <TAB> <TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB> <TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB> <TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs )","if hasattr ( base , ""trace"" ) :","if hasattr ( base , ""trace"" ) :",True,100.0,74.55,,,
"def generatePidEncryptionTable ( ) : <TAB> table = [ ] <TAB> for counter1 in range ( 0 , 0x100 ) : <TAB> <TAB> value = counter1 <TAB> <TAB> for counter2 in range ( 0 , 8 ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> <TAB> value = value ^ 0xEDB88320 <TAB> <TAB> table . append ( value ) <TAB> return table",if counter1 == counter2 :,if value & 1 == 0 :,False,95.38,70.92,,,
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> if "" init "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) )","if ""stage"" not in item . keywords :","if ""stage"" not in item . keywords :",True,100.0,74.3,,,
"def python_value ( self , value ) : <TAB> if value : <TAB> <TAB> if isinstance ( value , basestring ) : <TAB> <TAB> <TAB> pp = lambda x : x . time ( ) <TAB> <TAB> <TAB> return format_date_time ( value , self . formats , pp ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB> <TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value","elif isinstance ( value , datetime . datetime ) :","elif isinstance ( value , datetime . datetime ) :",True,100.0,74.43,,,
"def list_interesting_hosts ( self ) : <TAB> hosts = [ ] <TAB> targets = self . target [ "" other "" ] <TAB> for target in targets : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> hosts . append ( <TAB> <TAB> <TAB> <TAB> { "" ip "" : target . ip , "" description "" : target . domain + ""  /  "" + target . name } <TAB> <TAB> <TAB> ) <TAB> return hosts","if target . type in [ ""interesting"" , ""interesting"" ] :",if self . is_interesting ( target ) and target . status and target . status != 400 :,False,84.74,59.82,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 18 :,if tt == 24 :,False,98.86,73.7,,,
"def _wait_for_finish ( self ) - > PollExitResponse : <TAB> while True : <TAB> <TAB> if self . _backend : <TAB> <TAB> <TAB> poll_exit_resp = self . _backend . interface . communicate_poll_exit ( ) <TAB> <TAB> logger . info ( "" got exit ret:  %s "" , poll_exit_resp ) <TAB> <TAB> if poll_exit_resp : <TAB> <TAB> <TAB> done = poll_exit_resp . done <TAB> <TAB> <TAB> pusher_stats = poll_exit_resp . pusher_stats <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _on_finish_progress ( pusher_stats , done ) <TAB> <TAB> <TAB> if done : <TAB> <TAB> <TAB> <TAB> return poll_exit_resp <TAB> <TAB> time . sleep ( 2 )",if pusher_stats :,if pusher_stats :,True,100.0,74.41,,,
"def listing_items ( method ) : <TAB> marker = None <TAB> once = True <TAB> items = [ ] <TAB> while once or items : <TAB> <TAB> for i in items : <TAB> <TAB> <TAB> yield i <TAB> <TAB> if once or marker : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> items = method ( parms = { "" marker "" : marker } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> items = method ( ) <TAB> <TAB> <TAB> if len ( items ) == 10000 : <TAB> <TAB> <TAB> <TAB> marker = items [ - 1 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> marker = None <TAB> <TAB> <TAB> once = False <TAB> <TAB> else : <TAB> <TAB> <TAB> items = [ ]","if isinstance ( method , ( list , tuple ) ) :",if marker :,False,95.15,72.07,,,
"def call ( monad , * args ) : <TAB> for arg , name in izip ( args , ( "" hour "" , "" minute "" , "" second "" , "" microsecond "" ) ) : <TAB> <TAB> if not isinstance ( arg , NumericMixin ) or arg . type is not int : <TAB> <TAB> <TAB> throw ( <TAB> <TAB> <TAB> <TAB> TypeError , <TAB> <TAB> <TAB> <TAB> "" ' %s '  argument of time(...) function must be of  ' int '  type. Got:  %r "" <TAB> <TAB> <TAB> <TAB> % ( name , type2str ( arg . type ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> throw ( NotImplementedError ) <TAB> return ConstMonad . new ( time ( * tuple ( arg . value for arg in args ) ) )",if arg . type is None :,"if not isinstance ( arg , ConstMonad ) :",False,96.06,71.72,,,
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> if sign is None : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if ki != 0 : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq",if ki < slop :,if sign * ki < - slop :,False,97.42,72.53,,,
"def walk_links ( self ) : <TAB> link_info_list = [ ] <TAB> for item in self . content : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> link_info = LinkInfo ( link = item , name = item . name , sections = ( ) ) <TAB> <TAB> <TAB> link_info_list . append ( link_info ) <TAB> <TAB> else : <TAB> <TAB> <TAB> link_info_list . extend ( item . walk_links ( ) ) <TAB> return link_info_list","if isinstance ( item , LinkInfo ) :","if isinstance ( item , Link ) :",False,98.13,72.64,,,
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key.get_path() <TAB> subkeys = [] <TAB> for k in self.keys: <TAB> <TAB> test_path = k.get_path() <TAB> <TAB> if test_path.lower().startswith(parent_path.lower()): <TAB> <TAB> <TAB> sub = test_path[len(parent_path) :] <TAB> <TAB> <TAB> if sub.startswith(""\\""): <TAB> <TAB> <TAB> <TAB> sub = sub[1:] <TAB> <TAB> <TAB> end_slash = sub.find(""\\"") <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sub = sub[:end_slash] <TAB> <TAB> <TAB> if not sub: <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys.append(sub) <TAB> return subkeys",if end_slash > 0 :,if end_slash >= 0 :,False,99.07,73.17,,,
"def load_dict ( dict_path , reverse = False ) : <TAB> word_dict = { } <TAB> with open ( dict_path , "" rb "" ) as fdict : <TAB> <TAB> for idx , line in enumerate ( fdict ) : <TAB> <TAB> <TAB> line = cpt . to_text ( line ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> word_dict [ idx ] = line . strip ( "" \n "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> word_dict [ line . strip ( "" \n "" ) ] = idx <TAB> return word_dict",if reverse :,if reverse :,True,100.0,74.37,,,
"def test_network ( coords , feats , model , batch_sizes , forward_only = True ) : <TAB> for batch_size in batch_sizes : <TAB> <TAB> bcoords = batched_coordinates ( [ coords for i in range ( batch_size ) ] ) <TAB> <TAB> bfeats = torch . cat ( [ feats for i in range ( batch_size ) ] , 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with torch . no_grad ( ) : <TAB> <TAB> <TAB> <TAB> time , length = forward ( bcoords , bfeats , model ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time , length = train ( bcoords , bfeats , model ) <TAB> <TAB> print ( f "" { net . __name__ } \t { voxel_size } \t { batch_size } \t { length } \t { time } "" ) <TAB> <TAB> torch . cuda . empty_cache ( )",if forward_only :,if forward_only :,True,100.0,74.57,,,
"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB> <TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB> <TAB> self . utexc = True <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB> <TAB> if self . utexc is not True : <TAB> <TAB> <TAB> self . utexc [ indices ] = True",if self . utexc is None :,if self . utexc is False :,False,98.12,72.99,,,
"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB> <TAB> module_directory = join ( directory , module ) <TAB> <TAB> has_module_directory = isdir ( module_directory ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> has_module = has_module_directory or exists ( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> ) # could be a bare modulefile <TAB> <TAB> else: <TAB> <TAB> <TAB> modulefile = join(module_directory, version) <TAB> <TAB> <TAB> has_modulefile = exists(modulefile) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB> if has_module: <TAB> <TAB> <TAB> break <TAB> return has_module","if version == """" :",if not version :,False,97.17,64.14,,,
"def get_editops ( self ) : <TAB> if not self . _editops : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _editops = editops ( self . _opcodes , self . _str1 , self . _str2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _editops = editops ( self . _str1 , self . _str2 ) <TAB> return self . _editops",if self . _opcodes :,if self . _opcodes :,True,100.0,74.07,,,
"def to_representation ( self , data ) : <TAB> value = super ( CredentialTypeSerializer , self ) . to_representation ( data ) <TAB> # translate labels and help_text for credential fields ""managed by Tower"" <TAB> if value.get(""managed_by_tower""): <TAB> <TAB> value[""name""] = _(value[""name""]) <TAB> <TAB> for field in value.get(""inputs"", {}).get(""fields"", []): <TAB> <TAB> <TAB> field[""label""] = _(field[""label""]) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> field[""help_text""] = _(field[""help_text""]) <TAB> return value","if field . get ( ""help_text"" ) :","if ""help_text"" in field :",False,96.06,70.32,,,
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d","if isinstance ( v [ i ] , dict ) :","if isinstance ( v [ i ] , dict ) :",True,100.0,74.47,,,
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> if ss [ "" branch "" ] : <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> if ss [ "" revision "" ] : <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text","if ss [ ""patch"" ] :","if ss [ ""patch"" ] is not None :",False,98.19,72.95,,,
"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . median [ i ] . update ( xi ) <TAB> <TAB> if self . with_scaling : <TAB> <TAB> <TAB> self . iqr [ i ] . update ( xi ) <TAB> return self",if self . with_median :,if self . with_centering :,False,97.3,72.11,,,
"def start_response ( self , status , headers , exc_info = None ) : <TAB> if exc_info : <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . started : <TAB> <TAB> <TAB> <TAB> six . reraise ( exc_info [ 0 ] , exc_info [ 1 ] , exc_info [ 2 ] ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> exc_info = None <TAB> self . request . status = int ( status [ : 3 ] ) <TAB> for key , val in headers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . request . set_content_length ( int ( val ) ) <TAB> <TAB> elif key . lower ( ) == "" content-type "" : <TAB> <TAB> <TAB> self . request . content_type = val <TAB> <TAB> else : <TAB> <TAB> <TAB> self . request . headers_out . add ( key , val ) <TAB> return self . write","if key . lower ( ) == ""content-length"" :","if key . lower ( ) == ""content-length"" :",True,100.0,74.6,,,
"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB> <TAB> y = self . _curve . b <TAB> else : <TAB> <TAB> result = self . sqrtp ( <TAB> <TAB> <TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB> <TAB> ) <TAB> <TAB> if len ( result ) == 1 : <TAB> <TAB> <TAB> y = result [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> y1 , y2 = result <TAB> <TAB> <TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return ec . Point ( self . _curve , x , y )",elif len ( result ) == 2 :,elif len ( result ) == 2 :,True,100.0,74.63,,,
"def trace ( self , ee , rname ) : <TAB> print ( type ( self ) ) <TAB> self . traceIndent ( ) <TAB> guess = "" "" <TAB> if self . inputState . guessing > 0 : <TAB> <TAB> guess = ""  [guessing] "" <TAB> print ( ( ee + rname + guess ) ) <TAB> for i in xrange ( 1 , self . k + 1 ) : <TAB> <TAB> if i != 1 : <TAB> <TAB> <TAB> print ( "" ,  "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = self . LT ( i ) . getText ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = "" null "" <TAB> <TAB> print ( "" LA( %s ) ==  %s "" % ( i , v ) ) <TAB> print ( "" \n "" )",if self . LA ( i ) . isValid ( ) :,if self . LT ( i ) :,False,96.58,72.85,,,
"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = {} <TAB> for _, name, data_type, not_null, _, primary_key in rows: <TAB> <TAB> parts = [data_type] <TAB> <TAB> if primary_key: <TAB> <TAB> <TAB> parts.append(""PRIMARY KEY"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts.append(""NOT NULL"") <TAB> <TAB> result[name] = "" "".join(parts) <TAB> return result",if not_null :,if not_null :,True,100.0,74.28,,,
"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB> <TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB> <TAB> <TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB> <TAB> <TAB> <TAB> if c . strip ( ) . startswith ( "" CSRF-Token- "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB> <TAB> <TAB> <TAB> <TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break","if self . _CSRFtoken == """" :",if self . _CSRFtoken != None :,False,97.44,70.4,,,
"def _update_from_item ( self , row , download_item ) : <TAB> progress_stats = download_item . progress_stats <TAB> for key in self . columns : <TAB> <TAB> column = self . columns [ key ] [ 0 ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Not the best place but we build the playlist status here <TAB> <TAB> <TAB> status = ""{0} {1}/{2}"".format( <TAB> <TAB> <TAB> <TAB> progress_stats[""status""], <TAB> <TAB> <TAB> <TAB> progress_stats[""playlist_index""], <TAB> <TAB> <TAB> <TAB> progress_stats[""playlist_size""], <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self.SetStringItem(row, column, status) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.SetStringItem(row, column, progress_stats[key])","if key == ""status"" :","if key == ""status"" and progress_stats [ ""playlist_index"" ] :",False,95.06,67.16,,,
"def unmarshal_package_repositories ( cls , data : Any ) - > List [ "" PackageRepository "" ] : <TAB> repositories = list ( ) <TAB> if data is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( f "" invalid package-repositories:  { data !r} "" ) <TAB> <TAB> for repository in data : <TAB> <TAB> <TAB> package_repo = cls . unmarshal ( repository ) <TAB> <TAB> <TAB> repositories . append ( package_repo ) <TAB> return repositories","if not isinstance ( data , list ) :","if not isinstance ( data , list ) :",True,100.0,74.3,,,
"def remove_message ( e = None ) : <TAB> itop = scanbox . nearest ( 0 ) <TAB> sel = scanbox . curselection ( ) <TAB> if not sel : <TAB> <TAB> dialog ( <TAB> <TAB> <TAB> root , <TAB> <TAB> <TAB> "" No Message To Remove "" , <TAB> <TAB> <TAB> "" Please select a message to remove "" , <TAB> <TAB> <TAB> "" "" , <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> "" OK "" , <TAB> <TAB> ) <TAB> <TAB> return <TAB> todo = [ ] <TAB> for i in sel : <TAB> <TAB> line = scanbox . get ( i ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> todo . append ( string . atoi ( scanparser . group ( 1 ) ) ) <TAB> mhf . removemessages ( todo ) <TAB> rescan ( ) <TAB> fixfocus ( min ( todo ) , itop )","if scanparser . group ( 0 ) == ""Message"" :",if scanparser . match ( line ) >= 0 :,False,96.02,67.46,,,
"def test_patches ( ) : <TAB> print ( <TAB> <TAB> "" Botocore version:  {}  aiohttp version:  {} "" . format ( <TAB> <TAB> <TAB> botocore . __version__ , aiohttp . __version__ <TAB> <TAB> ) <TAB> ) <TAB> success = True <TAB> for obj , digests in chain ( _AIOHTTP_DIGESTS . items ( ) , _API_DIGESTS . items ( ) ) : <TAB> <TAB> digest = hashlib . sha1 ( getsource ( obj ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Digest of  {} : {}  not found in:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> obj . __qualname__ , digest , digests <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> success = False <TAB> assert success",if digest not in digests :,if digest not in digests :,True,100.0,74.56,,,
"def sample_admin_user ( ) : <TAB> """""" List of iris messages """""" <TAB> with iris_ctl . db_from_config ( sample_db_config ) as ( conn , cursor ) : <TAB> <TAB> cursor . execute ( <TAB> <TAB> <TAB> "" SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1 "" <TAB> <TAB> ) <TAB> <TAB> result = cursor . fetchone ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return result [ 0 ]",if result :,if result :,True,100.0,99.19,,,
"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB> <TAB> for rightname in kerning [ leftname ] : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> for rightname2 in groups [ rightname ] : <TAB> <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname2 ) <TAB> <TAB> <TAB> <TAB> <TAB> if not includeAll : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> rightnames.add(rightname)",if rightname in groups :,"if rightname [ 0 ] == ""@"" :",False,95.67,63.52,,,
"def build ( self , input_shape ) : <TAB> if isinstance ( input_shape , list ) and len ( input_shape ) == 2 : <TAB> <TAB> self . data_mode = "" disjoint "" <TAB> <TAB> self . F = input_shape [ 0 ] [ - 1 ] <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . data_mode = "" single "" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . data_mode = "" batch "" <TAB> <TAB> self . F = input_shape [ - 1 ]",if input_shape [ 0 ] == 1 :,if len ( input_shape ) == 2 :,False,94.44,70.66,,,
"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB> <TAB> # most common case: extend a range <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _range[0] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> <TAB> elif i == _range[1] + 1: <TAB> <TAB> <TAB> _range[1] = i <TAB> <TAB> <TAB> merge_ranges(l) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l.append([i, i]) <TAB> l.sort(key=lambda x: x[0])",if i == _range [ 0 ] + 1 :,if i == _range [ 0 ] - 1 :,False,98.67,72.79,,,
"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB> <TAB> ctype , line , col , char = cmd <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if char != "" \n "" : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB> <TAB> <TAB> <TAB> del buf [ line + 1 ] <TAB> <TAB> elif ctype == "" I "" : <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB> <TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf )","if ctype == ""D"" :","if ctype == ""D"" :",True,100.0,74.65,,,
"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB> <TAB> try : <TAB> <TAB> <TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> uri , unused = uri_tuple <TAB> <TAB> if os . path . exists ( uri ) == True : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB> <TAB> return <TAB> open_dropped_files ( files )",if os . path . isfile ( uri ) :,if utils . is_media_file ( uri ) == True :,False,93.71,71.17,,,
"def __walk_proceed_remote_dir_act ( self , r , args ) : <TAB> dirjs , filejs = args <TAB> j = r . json ( ) <TAB> if "" list "" not in j : <TAB> <TAB> self . pd ( <TAB> <TAB> <TAB> "" Key  ' list '  not found in the response of directory listing request: \n {} "" . format ( <TAB> <TAB> <TAB> <TAB> j <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> return const . ERequestFailed <TAB> paths = j [ "" list "" ] <TAB> for path in paths : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dirjs . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> filejs . append ( path ) <TAB> return const . ENoError",if path in dirjs :,"if path [ ""isdir"" ] :",False,96.86,67.82,,,
"def TaskUpdatesVerbose ( task , progress ) : <TAB> if isinstance ( task . info . progress , int ) : <TAB> <TAB> info = task . info <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> progress = "" %d %%  ( %s ) "" % ( info . progress , info . state ) <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" Task  %s  (key: %s , desc: %s ) -  %s "" <TAB> <TAB> <TAB> % ( info . name . info . name , info . key , info . description , progress ) <TAB> <TAB> )",if info . progress :,"if not isinstance ( progress , str ) :",False,94.5,70.31,,,
"def dump_constants ( header ) : <TAB> output = StringIO . StringIO ( ) <TAB> output . write ( header ) <TAB> for attribute in dir ( FSEvents ) : <TAB> <TAB> value = getattr ( FSEvents , attribute ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> output . write ( ""  <TAB>  %s  =  %s \n "" % ( attribute , hex ( value ) ) ) <TAB> content = output . getvalue ( ) <TAB> output . close ( ) <TAB> return content","if isinstance ( value , int ) :","if attribute . startswith ( ""k"" ) and isinstance ( value , int ) :",False,91.85,63.03,,,
"def _ensure_data_is_loaded ( <TAB> self , <TAB> sql_object , <TAB> input_params , <TAB> stdin_file , <TAB> stdin_filename = "" - "" , <TAB> stop_after_analysis = False , ) : <TAB> data_loads = [ ] <TAB> # Get each ""table name"" which is actually the file name <TAB> for filename in sql_object.qtable_names: <TAB> <TAB> data_load = self._load_data( <TAB> <TAB> <TAB> filename, <TAB> <TAB> <TAB> input_params, <TAB> <TAB> <TAB> stdin_file=stdin_file, <TAB> <TAB> <TAB> stdin_filename=stdin_filename, <TAB> <TAB> <TAB> stop_after_analysis=stop_after_analysis, <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data_loads.append(data_load) <TAB> return data_loads",if data_load is not None :,if data_load is not None :,True,100.0,74.35,,,
"def _get_instantiation ( self ) : <TAB> if self . _data is None : <TAB> <TAB> f , l , c , o = c_object_p ( ) , c_uint ( ) , c_uint ( ) , c_uint ( ) <TAB> <TAB> SourceLocation_loc ( self , byref ( f ) , byref ( l ) , byref ( c ) , byref ( o ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f = File ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = None <TAB> <TAB> self . _data = ( f , int ( l . value ) , int ( c . value ) , int ( c . value ) ) <TAB> return self . _data",if f . exists ( ) :,if f :,False,96.95,73.11,,,
"def _get_all_info_lines ( data ) : <TAB> infos = [ ] <TAB> for row in data : <TAB> <TAB> splitrow = row . split ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if splitrow [ 0 ] == "" INFO: "" : <TAB> <TAB> <TAB> <TAB> infos . append ( "" "" . join ( splitrow [ 1 : ] ) ) <TAB> return infos","if splitrow [ 0 ] . startswith ( ""INFO"" ) :",if len ( splitrow ) > 0 :,False,89.72,61.85,,,
"def _brush_modified_cb ( self , settings ) : <TAB> """""" Updates the brush ' s base setting adjustments on brush changes """""" <TAB> for cname in settings : <TAB> <TAB> adj = self . brush_adjustment . get ( cname , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = self . brush . get_base_value ( cname ) <TAB> <TAB> adj . set_value ( value )",if adj is None :,if adj is None :,True,100.0,99.16,,,
"def migrate_node_facts ( facts ) : <TAB> """""" Migrate facts from various roles into node """""" <TAB> params = { <TAB> <TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB> <TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params.keys(): <TAB> <TAB> if role in facts: <TAB> <TAB> <TAB> for param in params[role]: <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> facts[""node""][param] = facts[role].pop(param) <TAB> return facts",if param in facts [ role ] :,if param in facts [ role ] :,True,100.0,99.39,,,
"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" When setting content_range to a list/tuple, it must  "" <TAB> <TAB> <TAB> <TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB> <TAB> <TAB> ) <TAB> <TAB> if len ( value ) == 2 : <TAB> <TAB> <TAB> begin , end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else : <TAB> <TAB> <TAB> begin , end , length = value <TAB> <TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB> <TAB> return None <TAB> return value",if len ( value ) != 3 :,"if len ( value ) not in ( 2 , 3 ) :",False,96.43,71.59,,,
"def clean ( self ) : <TAB> data = super ( ) . clean ( ) <TAB> if data . get ( "" expires "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data [ "" expires "" ] = make_aware ( <TAB> <TAB> <TAB> <TAB> datetime . combine ( data [ "" expires "" ] , time ( hour = 23 , minute = 59 , second = 59 ) ) , <TAB> <TAB> <TAB> <TAB> self . instance . event . timezone , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data [ "" expires "" ] = data [ "" expires "" ] . replace ( hour = 23 , minute = 59 , second = 59 ) <TAB> <TAB> if data [ "" expires "" ] < now ( ) : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The new expiry date needs to be in the future. "" ) ) <TAB> return data",if self . instance . event . timezone :,"if isinstance ( data [ ""expires"" ] , date ) :",False,94.66,68.37,,,
"def _build ( self , obj , stream , context ) : <TAB> if self . include_name : <TAB> <TAB> name , obj = obj <TAB> <TAB> for sc in self . subcons : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sc . _build ( obj , stream , context ) <TAB> <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> for sc in self . subcons : <TAB> <TAB> <TAB> stream2 = BytesIO ( ) <TAB> <TAB> <TAB> context2 = context . __copy__ ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> sc . _build ( obj , stream2 , context2 ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> context . __update__ ( context2 ) <TAB> <TAB> <TAB> <TAB> stream . write ( stream2 . getvalue ( ) ) <TAB> <TAB> <TAB> <TAB> return <TAB> raise SelectError ( "" no subconstruct matched "" , obj )",if name in sc . name :,if sc . name == name :,False,98.28,73.45,,,
"def records ( account_id ) : <TAB> """""" Fetch locks data """""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB> <TAB> if "" RevisionDate "" in r : <TAB> <TAB> <TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) )","if ""LockDate"" in r :","if ""LockDate"" in r :",True,100.0,99.54,,,
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> if isinstance ( test , ast . Const ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if not test . value : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope )","if isinstance ( body , ast . If ) :",if type ( test . value ) in self . _const_types :,False,90.69,68.97,,,
"def validate_max_discount ( self ) : <TAB> if self . rate_or_discount == "" Discount Percentage "" and self . get ( "" items "" ) : <TAB> <TAB> for d in self . items : <TAB> <TAB> <TAB> max_discount = frappe . get_cached_value ( "" Item "" , d . item_code , "" max_discount "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> throw ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" Max discount allowed for item:  {0}  is  {1} % "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . item_code , max_discount <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",if max_discount > 0 :,if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) :,False,92.09,69.05,,,
"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB> rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB> if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB> <TAB> for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB> <TAB> <TAB> if i_type [ 0 : 3 ] == "" cce "" : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if i_value == product_yaml :,"if not checks . is_cce_value_valid ( ""CCE-"" + str ( i_value ) ) :",False,86.73,63.39,,,
"def parse_calendar_eras ( data , calendar ) : <TAB> eras = data . setdefault ( "" eras "" , { } ) <TAB> for width in calendar . findall ( "" eras/* "" ) : <TAB> <TAB> width_type = NAME_MAP [ width . tag ] <TAB> <TAB> widths = eras . setdefault ( width_type , { } ) <TAB> <TAB> for elem in width . getiterator ( ) : <TAB> <TAB> <TAB> if elem . tag == "" era "" : <TAB> <TAB> <TAB> <TAB> _import_type_text ( widths , elem , type = int ( elem . attrib . get ( "" type "" ) ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> eras [ width_type ] = Alias ( <TAB> <TAB> <TAB> <TAB> <TAB> _translate_alias ( [ "" eras "" , width_type ] , elem . attrib [ "" path "" ] ) <TAB> <TAB> <TAB> <TAB> )","elif elem . tag == ""alias"" :","elif elem . tag == ""alias"" :",True,100.0,74.59,,,
"def validate_grammar ( ) - > None : <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE : <TAB> <TAB> fn_productions = get_productions ( fn ) <TAB> <TAB> if all ( p . name == fn_productions [ 0 ] . name for p in fn_productions ) : <TAB> <TAB> <TAB> # all the production names are the same, ensure that the `convert_` function <TAB> <TAB> <TAB> # is named correctly <TAB> <TAB> <TAB> production_name = fn_productions[0].name <TAB> <TAB> <TAB> expected_name = f""convert_{production_name}"" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> f""The conversion function for '{production_name}' "" <TAB> <TAB> <TAB> <TAB> <TAB> + f""must be called '{expected_name}', not '{fn.__name__}'."" <TAB> <TAB> <TAB> <TAB> )",if not callable ( expected_name ) :,if fn . __name__ != expected_name :,False,95.6,71.97,,,
"def validate_grammar ( ) - > None : <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE : <TAB> <TAB> fn_productions = get_productions ( fn ) <TAB> <TAB> if all ( p . name == fn_productions [ 0 ] . name for p in fn_productions ) : <TAB> <TAB> <TAB> # all the production names are the same, ensure that the `convert_` function <TAB> <TAB> <TAB> # is named correctly <TAB> <TAB> <TAB> production_name = fn_productions[0].name <TAB> <TAB> <TAB> expected_name = f""convert_{production_name}"" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise Exception( <TAB> <TAB> <TAB> <TAB> <TAB> f""The conversion function for '{production_name}' "" <TAB> <TAB> <TAB> <TAB> <TAB> + f""must be called '{expected_name}', not '{fn.__name__}'."" <TAB> <TAB> <TAB> <TAB> )",if not callable ( expected_name ) :,"if "":"" in row [ ""Splitratio"" ] :",False,95.76,66.97,,,
"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef.error: <TAB> <TAB> if testdef.exception: <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise testdef.exception <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> raise Exception(testdef.exception) <TAB> <TAB> else: <TAB> <TAB> <TAB> raise Exception(""Test parse failure"")","if testdef . exception . __class__ . __name__ == ""InvalidTestDefinition"" :","if isinstance ( testdef . exception , Exception ) :",False,86.13,58.94,,,
"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB> <TAB> if count < = 0 : <TAB> <TAB> <TAB> quotas_ok [ quota ] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa . results [ quota ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok",if avail [ 0 ] > 0 :,if avail [ 1 ] is not None and avail [ 1 ] < count :,False,94.13,69.86,,,
"def reverse ( self ) : <TAB> """""" Reverse *IN PLACE*. """""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB> <TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB> <TAB> li + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lb = lb . rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri - = 1 <TAB> <TAB> if ri < 0 : <TAB> <TAB> <TAB> rb = rb . leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1",if li < BLOCKLEN :,if li >= BLOCKLEN :,False,98.23,98.58,,,
"def __manipulate_item ( self , item ) : <TAB> if self . _Cursor__manipulate : <TAB> <TAB> db = self . _Cursor__collection . database <TAB> <TAB> son = db . _fix_outgoing ( item , self . _Cursor__collection ) <TAB> else : <TAB> <TAB> son = item <TAB> if self . __wrap is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return getattr ( self . _Cursor__collection , son [ self . __wrap . type_field ] ) ( son ) <TAB> <TAB> return self . __wrap ( son , collection = self . _Cursor__collection ) <TAB> else : <TAB> <TAB> return son","if hasattr ( self . _Cursor__collection , son [ self . __wrap . type_field ] ) :",if self . __wrap . type_field in son :,False,91.46,70.47,,,
"def apply_transforms ( self ) : <TAB> """""" Apply all of the stored transforms, in priority order. """""" <TAB> self . document . reporter . attach_observer ( self . document . note_transform_message ) <TAB> while self . transforms : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Unsorted initially, and whenever a transform is added. <TAB> <TAB> <TAB> self.transforms.sort() <TAB> <TAB> <TAB> self.transforms.reverse() <TAB> <TAB> <TAB> self.sorted = 1 <TAB> <TAB> priority, transform_class, pending, kwargs = self.transforms.pop() <TAB> <TAB> transform = transform_class(self.document, startnode=pending) <TAB> <TAB> transform.apply(**kwargs) <TAB> <TAB> self.applied.append((priority, transform_class, pending, kwargs))",if self . sorted :,if not self . sorted :,False,98.84,73.4,,,
"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter(params) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sql = sql_to_string(sql) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv.params <TAB> <TAB> else: <TAB> <TAB> <TAB> params = () <TAB> for param in params or (): <TAB> <TAB> if param is None: <TAB> <TAB> <TAB> rv.append(""NULL"") <TAB> <TAB> param = safe_repr(param) <TAB> <TAB> rv.append(param) <TAB> return sql, rv",if conv . params is not None :,if params :,False,96.55,72.17,,,
"def on_execution_item ( self , cpath , execution ) : <TAB> if not isinstance ( execution , dict ) : <TAB> <TAB> return <TAB> if "" executor "" in execution and execution . get ( "" executor "" ) != "" jmeter "" : <TAB> <TAB> return <TAB> scenario = execution . get ( "" scenario "" , None ) <TAB> <IF-STMT> <TAB> <TAB> return <TAB> if isinstance ( scenario , str ) : <TAB> <TAB> scenario_name = scenario <TAB> <TAB> scenario = self . get_named_scenario ( scenario_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> scenario = None <TAB> <TAB> scenario_path = Path ( "" scenarios "" , scenario_name ) <TAB> else : <TAB> <TAB> scenario_path = cpath . copy ( ) <TAB> <TAB> scenario_path . add_component ( "" scenario "" ) <TAB> if scenario is not None : <TAB> <TAB> self . check_jmeter_scenario ( scenario_path , scenario )",if scenario is None :,if not scenario :,False,96.51,72.01,,,
"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB> <TAB> if self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> return <TAB> <TAB> while not self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> args = self . _ipc_requests . get ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> for filename in args : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB> <TAB> self . become_active_window ( ) <TAB> finally : <TAB> <TAB> self . after ( 50 , self . _poll_ipc_requests )",if os . path . isfile ( filename ) :,if os . path . isfile ( filename ) :,True,100.0,74.57,,,
"def get_scroll_distance_to_element ( driver , element ) : <TAB> try : <TAB> <TAB> scroll_position = driver . execute_script ( "" return window.scrollY; "" ) <TAB> <TAB> element_location = None <TAB> <TAB> element_location = element . location [ "" y "" ] <TAB> <TAB> element_location = element_location - 130 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> element_location = 0 <TAB> <TAB> distance = element_location - scroll_position <TAB> <TAB> return distance <TAB> except Exception : <TAB> <TAB> return 0",if element_location < 130 :,if element_location < 0 :,False,98.34,72.66,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 18 :,if tt == 16 :,False,98.42,73.07,,,
"def _validate_and_define ( params , key , value ) : <TAB> ( key , force_generic ) = _validate_key ( _unescape ( key ) ) <TAB> if key in params : <TAB> <TAB> raise SyntaxError ( f ' duplicate key  "" { key } "" ' ) <TAB> cls = _class_for_key . get ( key , GenericParam ) <TAB> emptiness = cls . emptiness ( ) <TAB> if value is None : <TAB> <TAB> if emptiness == Emptiness . NEVER : <TAB> <TAB> <TAB> raise SyntaxError ( "" value cannot be empty "" ) <TAB> <TAB> value = cls . from_value ( value ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> value = cls . from_wire_parser ( dns . wire . Parser ( _unescape ( value ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = cls . from_value ( value ) <TAB> params [ key ] = value",if force_generic :,if force_generic :,True,100.0,74.59,,,
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> if field_val is _marker : <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset : <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val","if field_name in ( ""meta"" , ""meta"" ) :",if exclude_meta and field . meta :,False,94.49,63.32,,,
"def tearDown ( self ) : <TAB> """""" Shutdown the server. """""" <TAB> try : <TAB> <TAB> if self . server : <TAB> <TAB> <TAB> self . server . stop ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self )",if self . sl_hdlr :,if self . sl_hdlr :,True,100.0,74.13,,,
"def _wait_for_async_copy ( self , share_name , file_path ) : <TAB> count = 0 <TAB> share_client = self . fsc . get_share_client ( share_name ) <TAB> file_client = share_client . get_file_client ( file_path ) <TAB> properties = file_client . get_file_properties ( ) <TAB> while properties . copy . status != "" success "" : <TAB> <TAB> count = count + 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . fail ( "" Timed out waiting for async copy to complete. "" ) <TAB> <TAB> self . sleep ( 6 ) <TAB> <TAB> properties = file_client . get_file_properties ( ) <TAB> self . assertEqual ( properties . copy . status , "" success "" )",if count > 5 :,if count > 10 :,False,98.7,73.39,,,
"def __new__ ( <TAB> cls , <TAB> message_type : OrderBookMessageType , <TAB> content : Dict [ str , any ] , <TAB> timestamp : Optional [ float ] = None , <TAB> * args , <TAB> * * kwargs , ) : <TAB> if timestamp is None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" timestamp must not be None when initializing snapshot messages. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> timestamp = int ( time . time ( ) ) <TAB> return super ( KucoinOrderBookMessage , cls ) . __new__ ( <TAB> <TAB> cls , message_type , content , timestamp = timestamp , * args , * * kwargs <TAB> )",if message_type is OrderBookMessageType . SNAPSHOT :,if message_type is OrderBookMessageType . SNAPSHOT :,True,100.0,74.5,,,
"def _drop_unique_features ( <TAB> X : DataFrame , feature_metadata : FeatureMetadata , max_unique_ratio ) - > list : <TAB> features_to_drop = [ ] <TAB> X_len = len ( X ) <TAB> max_unique_value_count = X_len * max_unique_ratio <TAB> for column in X : <TAB> <TAB> unique_value_count = len ( X [ column ] . unique ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> features_to_drop . append ( column ) <TAB> <TAB> elif feature_metadata . get_feature_type_raw ( column ) in [ <TAB> <TAB> <TAB> R_CATEGORY , <TAB> <TAB> <TAB> R_OBJECT , <TAB> <TAB> ] and ( unique_value_count > max_unique_value_count ) : <TAB> <TAB> <TAB> features_to_drop . append ( column ) <TAB> return features_to_drop","if feature_metadata . get_feature_type_raw ( column ) in [ R_CATEGORY , R_OBJECT , R_OBJECT ] :",if unique_value_count == 1 :,False,88.77,70.47,,,
"def get_src_findex_by_pad ( s , S , padding_mode , align_corners ) : <TAB> if padding_mode == "" zero "" : <TAB> <TAB> return get_src_findex_with_zero_pad ( s , S ) <TAB> elif padding_mode == "" reflect "" : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return get_src_findex_with_reflect_pad ( s , S , True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sf = get_src_findex_with_reflect_pad ( s , S , False ) <TAB> <TAB> <TAB> return get_src_findex_with_repeat_pad ( sf , S ) <TAB> elif padding_mode == "" repeat "" : <TAB> <TAB> return get_src_findex_with_repeat_pad ( s , S )",if align_corners :,if align_corners :,True,100.0,74.38,,,
"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB> <TAB> result + = ( current , ) <TAB> <TAB> if current . _parent is upto : <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise sa_exc . InvalidRequestError ( <TAB> <TAB> <TAB> <TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> current = current . _parent <TAB> return result",if current . _parent is upto :,elif current . _parent is None :,False,97.0,71.59,,,
"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> old_val = self [ name ] <TAB> <TAB> <TAB> if old_val == val : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Computed attributed  ' {} '  already exists  "" <TAB> <TAB> <TAB> <TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self [ name ] = val <TAB> else : <TAB> <TAB> super ( ) . __setattr__ ( name , val )",if name in self :,if name in self :,True,100.0,74.49,,,
"def get_fnlist ( bbhandler , pkg_pn , preferred ) : <TAB> """""" Get all recipe file names """""" <TAB> <IF-STMT> <TAB> <TAB> ( latest_versions , preferred_versions ) = bb . providers . findProviders ( <TAB> <TAB> <TAB> bbhandler . config_data , bbhandler . cooker . recipecaches [ "" "" ] , pkg_pn <TAB> <TAB> ) <TAB> fn_list = [ ] <TAB> for pn in sorted ( pkg_pn ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fn_list . append ( preferred_versions [ pn ] [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn_list . extend ( pkg_pn [ pn ] ) <TAB> return fn_list",if preferred [ pn ] [ 0 ] == pkg_pn [ pn ] [ 0 ] :,if preferred :,False,82.9,89.7,,,
"def links_extracted ( self , _ , links ) : <TAB> links_deduped = { } <TAB> for link in links : <TAB> <TAB> link_fingerprint = link . meta [ FIELD_FINGERPRINT ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> links_deduped [ link_fingerprint ] = link <TAB> [ <TAB> <TAB> self . _redis_pipeline . hmset ( fingerprint , self . _create_link_extracted ( link ) ) <TAB> <TAB> for ( fingerprint , link ) in links_deduped . items ( ) <TAB> ] <TAB> self . _redis_pipeline . execute ( )",if link_fingerprint in self . _links_deduped :,if link_fingerprint in links_deduped :,False,97.17,72.48,,,
"def __call__ ( self , name , rawtext , text , lineno , inliner , options = None , content = None ) : <TAB> options = options or { } <TAB> content = content or [ ] <TAB> issue_nos = [ each . strip ( ) for each in utils . unescape ( text ) . split ( "" , "" ) ] <TAB> config = inliner . document . settings . env . app . config <TAB> ret = [ ] <TAB> for i , issue_no in enumerate ( issue_nos ) : <TAB> <TAB> node = self . make_node ( name , issue_no , config , options = options ) <TAB> <TAB> ret . append ( node ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> sep = nodes . raw ( text = "" ,  "" , format = "" html "" ) <TAB> <TAB> <TAB> ret . append ( sep ) <TAB> return ret , [ ]",if i == 0 :,if i != len ( issue_nos ) - 1 :,False,94.89,72.13,,,
"def init_messengers ( messengers ) : <TAB> for messenger in messengers : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> module_path = messenger [ "" type "" ] <TAB> <TAB> <TAB> messenger [ "" type "" ] = messenger [ "" type "" ] . split ( "" . "" ) [ - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> module_path = "" oncall.messengers. "" + messenger [ "" type "" ] <TAB> <TAB> instance = getattr ( importlib . import_module ( module_path ) , messenger [ "" type "" ] ) ( <TAB> <TAB> <TAB> messenger <TAB> <TAB> ) <TAB> <TAB> for transport in instance . supports : <TAB> <TAB> <TAB> _active_messengers [ transport ] . append ( instance )","if ""."" in messenger [ ""type"" ] :","if ""."" in messenger [ ""type"" ] :",True,100.0,74.5,,,
"def _process_enum_definition ( self , tok ) : <TAB> fields = [ ] <TAB> for field in tok . fields : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> expression = self . expression_parser . parse ( field . expression ) <TAB> <TAB> else : <TAB> <TAB> <TAB> expression = None <TAB> <TAB> fields . append ( c_ast . CEnumField ( name = field . name . first , value = expression ) ) <TAB> name = tok . enum_name <TAB> if name : <TAB> <TAB> name = "" enum  %s "" % tok . enum_name . first <TAB> else : <TAB> <TAB> name = self . _make_anonymous_type ( "" enum "" ) <TAB> return c_ast . CTypeDefinition ( <TAB> <TAB> name = name , <TAB> <TAB> type_definition = c_ast . CEnum ( <TAB> <TAB> <TAB> attributes = tok . attributes , fields = fields , name = name <TAB> <TAB> ) , <TAB> )",if field . expression :,if field . expression :,True,100.0,74.59,,,
def result_iterator ( ) : <TAB> try : <TAB> <TAB> # reverse to keep finishing order <TAB> <TAB> fs.reverse() <TAB> <TAB> while fs: <TAB> <TAB> <TAB> # Careful not to keep a reference to the popped future <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> yield fs.pop().result() <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> yield fs.pop().result(end_time - time.time()) <TAB> finally: <TAB> <TAB> for future in fs: <TAB> <TAB> <TAB> future.cancel(),if end_time is None :,if timeout is None :,False,97.38,97.54,,,
"def has_encrypted_ssh_key_data ( self ) : <TAB> try : <TAB> <TAB> ssh_key_data = self . get_input ( "" ssh_key_data "" ) <TAB> except AttributeError : <TAB> <TAB> return False <TAB> try : <TAB> <TAB> pem_objects = validate_ssh_private_key ( ssh_key_data ) <TAB> <TAB> for pem_object in pem_objects : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> except ValidationError : <TAB> <TAB> pass <TAB> return False",if self . _pem_object . has_encrypted_ssh_key ( pem_object ) :,"if pem_object . get ( ""key_enc"" , False ) :",False,90.02,62.21,,,
"def test_seq_object_transcription_method ( self ) : <TAB> for nucleotide_seq in test_seqs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> <TAB> repr ( Seq . transcribe ( nucleotide_seq ) ) , <TAB> <TAB> <TAB> <TAB> repr ( nucleotide_seq . transcribe ( ) ) , <TAB> <TAB> <TAB> )","if isinstance ( nucleotide_seq , Seq . Seq ) :","if isinstance ( nucleotide_seq , Seq . Seq ) :",True,100.0,73.97,,,
"def max_elevation ( self ) : <TAB> max_el = None <TAB> for y in xrange ( self . height ) : <TAB> <TAB> for x in xrange ( self . width ) : <TAB> <TAB> <TAB> el = self . elevation [ "" data "" ] [ y ] [ x ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> max_el = el <TAB> return max_el",if el > max_el :,if max_el is None or el > max_el :,False,93.37,69.92,,,
"def stress ( mapping , index ) : <TAB> for count in range ( OPERATIONS ) : <TAB> <TAB> function = random . choice ( functions ) <TAB> <TAB> function ( mapping , index ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( "" \r "" , len ( mapping ) , "" "" * 7 , end = "" "" ) <TAB> print ( )",if count % 10000 == 0 :,if count % 1000 == 0 :,False,97.33,72.36,,,
"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB> <TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB> <TAB> if "" terminology "" not in source . all_flags : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB> <TAB> except UnitNotFound : <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> missing.append((source.context, source.source, """")) <TAB> if missing: <TAB> <TAB> self.add_units(None, missing)",if add :,if not add :,False,98.85,73.3,,,
"def get_generators ( self ) : <TAB> """""" Get a dict with all registered generators, indexed by name """""" <TAB> generators = { } <TAB> for core in self . db . find ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _generators = core . get_generators ( { } ) <TAB> <TAB> <TAB> if _generators : <TAB> <TAB> <TAB> <TAB> generators [ str ( core . name ) ] = _generators <TAB> return generators",if core . name in self . _generators :,"if hasattr ( core , ""get_generators"" ) :",False,91.8,78.09,,,
"def act ( self , state ) : <TAB> if self . body . env . clock . frame < self . training_start_step : <TAB> <TAB> return policy_util . random ( state , self , self . body ) . cpu ( ) . squeeze ( ) . numpy ( ) <TAB> else : <TAB> <TAB> action = self . action_policy ( state , self , self . body ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> action = self . scale_action ( torch . tanh ( action ) ) # continuous action bound <TAB> <TAB> return action.cpu().squeeze().numpy()",if self . scale_action is not None :,if not self . body . is_discrete :,False,94.72,71.26,,,
"def try_open_completions_event ( self , event = None ) : <TAB> "" (./) Open completion list after pause with no movement. "" <TAB> lastchar = self . text . get ( "" insert-1c "" ) <TAB> if lastchar in TRIGGERS : <TAB> <TAB> args = TRY_A if lastchar == "" . "" else TRY_F <TAB> <TAB> self . _delayed_completion_index = self . text . index ( "" insert "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . text . after_cancel ( self . _delayed_completion_id ) <TAB> <TAB> self . _delayed_completion_id = self . text . after ( <TAB> <TAB> <TAB> self . popupwait , self . _delayed_open_completions , args <TAB> <TAB> )",if self . _delayed_completion_id != - 1 :,if self . _delayed_completion_id is not None :,False,97.24,72.17,,,
"def token_is_available ( self ) : <TAB> if self . token : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> "" https://api.shodan.io/account/profile?key= {0} "" . format ( self . token ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except Exception as ex : <TAB> <TAB> <TAB> logger . error ( str ( ex ) ) <TAB> return False","if resp . status_code == 200 and resp . status_code == 200 and resp . status_code == ""ok"" :","if resp and resp . status_code == 200 and ""member"" in resp . json ( ) :",False,89.34,68.71,,,
"def next_bar_ ( self , event ) : <TAB> bars = event . bar_dict <TAB> self . _current_minute = self . _minutes_since_midnight ( <TAB> <TAB> self . ucontext . now . hour , self . ucontext . now . minute <TAB> ) <TAB> for day_rule , time_rule , func in self . _registry : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with ExecutionContext ( EXECUTION_PHASE . SCHEDULED ) : <TAB> <TAB> <TAB> <TAB> with ModifyExceptionFromType ( EXC_TYPE . USER_EXC ) : <TAB> <TAB> <TAB> <TAB> <TAB> func ( self . ucontext , bars ) <TAB> self . _last_minute = self . _current_minute",if day_rule == self . _current_minute :,if day_rule ( ) and time_rule ( ) :,False,94.95,70.85,,,
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> if c == "" & "" and not decode : <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> elif decode : <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) )","elif c == ""&"" :","elif c == ""-"" and decode :",False,98.12,73.35,,,
"def admin_audit_get ( admin_id ) : <TAB> if settings . app . demo_mode : <TAB> <TAB> resp = utils . demo_get_cache ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return utils . jsonify ( resp ) <TAB> if not flask . g . administrator . super_user : <TAB> <TAB> return utils . jsonify ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" error "" : REQUIRES_SUPER_USER , <TAB> <TAB> <TAB> <TAB> "" error_msg "" : REQUIRES_SUPER_USER_MSG , <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> 400 , <TAB> <TAB> ) <TAB> admin = auth . get_by_id ( admin_id ) <TAB> resp = admin . get_audit_events ( ) <TAB> if settings . app . demo_mode : <TAB> <TAB> utils . demo_set_cache ( resp ) <TAB> return utils . jsonify ( resp )",if resp :,if resp :,True,100.0,74.53,,,
"def vjp ( self , argnum , outgrad , ans , vs , gvs , args , kwargs ) : <TAB> try : <TAB> <TAB> return self . vjps [ argnum ] ( outgrad , ans , vs , gvs , * args , * * kwargs ) <TAB> except KeyError : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errstr = "" Gradient of  {0}  not yet implemented. "" <TAB> <TAB> else : <TAB> <TAB> <TAB> errstr = "" Gradient of  {0}  w.r.t. arg number  {1}  not yet implemented. "" <TAB> <TAB> raise NotImplementedError ( errstr . format ( self . fun . __name__ , argnum ) )","if self . fun . __name__ == ""vjp"" :",if self . vjps == { } :,False,92.46,65.14,,,
"def update ( self , * args , * * kwargs ) : <TAB> assert not self . readonly <TAB> longest_key = 0 <TAB> _dict = self . _dict <TAB> reverse = self . reverse <TAB> casereverse = self . casereverse <TAB> for iterable in args + ( kwargs , ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> iterable = iterable . items ( ) <TAB> <TAB> for key , value in iterable : <TAB> <TAB> <TAB> longest_key = max ( longest_key , len ( key ) ) <TAB> <TAB> <TAB> _dict [ key ] = value <TAB> <TAB> <TAB> reverse [ value ] . append ( key ) <TAB> <TAB> <TAB> casereverse [ value . lower ( ) ] [ value ] + = 1 <TAB> self . _longest_key = max ( self . _longest_key , longest_key )","if isinstance ( iterable , dict ) :","if isinstance ( iterable , ( dict , StenoDictionary ) ) :",False,97.12,72.51,,,
"def update_ui ( self , window ) : <TAB> view = window . get_active_view ( ) <TAB> self . set_status ( view ) <TAB> lang = "" plain_text "" <TAB> if view : <TAB> <TAB> buf = view . get_buffer ( ) <TAB> <TAB> language = buf . get_language ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lang = language . get_id ( ) <TAB> <TAB> self . setup_smart_indent ( view , lang )",if language :,if language :,True,100.0,74.14,,,
"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB> <TAB> if name not in skip : <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB> <TAB> if name not in skip : <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . unop_test ( a , res , expr , name )","if name in ( ""a"" , ""b"" ) :","if hasattr ( a , name ) :",False,92.18,66.18,,,
"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """""" Returns the full height of the item to be inserted in the form """""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB> <TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB> <TAB> # Set radio button layout <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 0.03 + ctrl.labelHeight * 3 <TAB> <TAB> elif item[""layout""] == ""vert"": <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl.labelHeight * len(item[""options""])","if item [ ""layout"" ] == ""horizontal"" :","if item [ ""layout"" ] == ""horiz"" :",False,98.64,98.35,,,
"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB> <TAB> if key in ( "" disabled "" , "" is_up "" ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> value = value == "" true "" <TAB> <TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json )",if value :,if value is not None :,False,97.81,72.46,,,
"def _read_json_content ( self , body_is_optional = False ) : <TAB> if "" content-length "" not in self . headers : <TAB> <TAB> return self . send_error ( 411 ) if not body_is_optional else { } <TAB> try : <TAB> <TAB> content_length = int ( self . headers . get ( "" content-length "" ) ) <TAB> <TAB> if content_length == 0 and body_is_optional : <TAB> <TAB> <TAB> return { } <TAB> <TAB> request = json . loads ( self . rfile . read ( content_length ) . decode ( "" utf-8 "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return request <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Bad request "" ) <TAB> self . send_error ( 400 )","if request [ ""content-type"" ] == ""application/json"" :","if isinstance ( request , dict ) and ( request or body_is_optional ) :",False,91.88,64.67,,,
"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> code , tags , used , refname = entry <TAB> <TAB> for fullname in list ( used ) : <TAB> <TAB> <TAB> if used [ fullname ] == docname : <TAB> <TAB> <TAB> <TAB> used . pop ( fullname ) <TAB> <TAB> if len ( used ) == 0 : <TAB> <TAB> <TAB> modules . pop ( modname )","if modname != ""viewcode"" :",if entry is False :,False,95.74,64.01,,,
"def frames ( self ) : <TAB> """""" an array of all the frames (including iframes) in the current window """""" <TAB> from thug . DOM . W3C . HTML . HTMLCollection import HTMLCollection <TAB> frames = set ( ) <TAB> for frame in self . _findAll ( [ "" frame "" , "" iframe "" ] ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> DOMImplementation . createHTMLElement ( self . window . doc , frame ) <TAB> <TAB> frames . add ( frame . _node ) <TAB> return HTMLCollection ( self . doc , list ( frames ) )",if frame . _node is None :,"if not getattr ( frame , ""_node"" , None ) :",False,92.5,93.2,,,
"def check ( self , * * kw ) : <TAB> if not kw : <TAB> <TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB> <TAB> if "" file "" in kw : <TAB> <TAB> <TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw )","if ""dir"" in kw :","if ""dir"" in kw :",True,100.0,74.4,,,
"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB> <TAB> duplicates = [ ] <TAB> <TAB> for other_folder , other_path in folders . items ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path : <TAB> <TAB> <TAB> <TAB> duplicates . append ( other_folder ) <TAB> <TAB> if len ( duplicates ) : <TAB> <TAB> <TAB> self . duplicates [ folder ] = duplicates",if other_folder == folder :,if other_folder == folder :,True,100.0,74.39,,,
"def next ( self , buf , pos ) : <TAB> if pos > = len ( buf ) : <TAB> <TAB> return EOF , "" "" , pos <TAB> mo = self . tokens_re . match ( buf , pos ) <TAB> if mo : <TAB> <TAB> text = mo . group ( ) <TAB> <TAB> type , regexp , test_lit = self . tokens [ mo . lastindex - 1 ] <TAB> <TAB> pos = mo . end ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> type = self . literals . get ( text , type ) <TAB> <TAB> return type , text , pos <TAB> else : <TAB> <TAB> c = buf [ pos ] <TAB> <TAB> return self . symbols . get ( c , None ) , c , pos + 1",if test_lit :,if test_lit :,True,100.0,74.54,,,
"def step ( self , action ) : <TAB> """""" Repeat action, sum reward, and max over last observations. """""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _obs_buffer [ 0 ] = obs <TAB> <TAB> if i == self . _skip - 1 : <TAB> <TAB> <TAB> self . _obs_buffer [ 1 ] = obs <TAB> <TAB> total_reward + = reward <TAB> <TAB> if done : <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self._obs_buffer.max(axis=0) <TAB> return max_frame, total_reward, done, info",if i == 0 :,if i == self . _skip - 2 :,False,96.83,94.99,,,
"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB> <TAB> arg = arg [ 1 : ] <TAB> try : <TAB> <TAB> value = int ( arg , base = 16 ) <TAB> <TAB> if not ( 0 < = value < = 0xFFFFFF ) : <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB> <TAB> arg = arg . replace ( "" "" , "" _ "" ) <TAB> <TAB> method = getattr ( discord . Colour , arg , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return method ( )",if method is None :,"if arg . startswith ( ""from_"" ) or method is None or not inspect . ismethod ( method ) :",False,90.14,64.98,,,
"def run ( self , * * inputs ) : <TAB> if self . inputs . copy_inputs : <TAB> <TAB> self . inputs . subjects_dir = os . getcwd ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> inputs [ "" subjects_dir "" ] = self . inputs . subjects_dir <TAB> <TAB> for originalfile in [ self . inputs . in_file , self . inputs . in_norm ] : <TAB> <TAB> <TAB> copy2subjdir ( self , originalfile , folder = "" mri "" ) <TAB> return super ( SegmentCC , self ) . run ( * * inputs )",if self . inputs . subjects_dir :,"if ""subjects_dir"" in inputs :",False,95.3,65.88,,,
"def get_queryset ( self ) : <TAB> if not hasattr ( self , "" _queryset "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> qs = self . queryset <TAB> <TAB> else : <TAB> <TAB> <TAB> qs = self . model . _default_manager . get_queryset ( ) <TAB> <TAB> # If the queryset isn't already ordered we need to add an <TAB> <TAB> # artificial ordering here to make sure that all formsets <TAB> <TAB> # constructed from this queryset have the same form order. <TAB> <TAB> if not qs.ordered: <TAB> <TAB> <TAB> qs = qs.order_by(self.model._meta.pk.name) <TAB> <TAB> # Removed queryset limiting here. As per discussion re: #13023 <TAB> <TAB> # on django-dev, max_num should not prevent existing <TAB> <TAB> # related objects/inlines from being displayed. <TAB> <TAB> self._queryset = qs <TAB> return self._queryset",if self . queryset is not None :,if self . queryset is not None :,True,100.0,74.56,,,
"def visit_simple_stmt ( self , node : Node ) - > Iterator [ Line ] : <TAB> """""" Visit a statement without nested statements. """""" <TAB> is_suite_like = node . parent and node . parent . type in STATEMENT <TAB> if is_suite_like : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield from self . visit_default ( node ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from self . line ( + 1 ) <TAB> <TAB> <TAB> yield from self . visit_default ( node ) <TAB> <TAB> <TAB> yield from self . line ( - 1 ) <TAB> else : <TAB> <TAB> if not self . is_pyi or not node . parent or not is_stub_suite ( node . parent ) : <TAB> <TAB> <TAB> yield from self . line ( ) <TAB> <TAB> yield from self . visit_default ( node )","if node . type in ( ""if"" , ""else"" ) :",if self . is_pyi and is_stub_body ( node ) :,False,94.18,60.11,,,
"def rawDataReceived ( self , data ) : <TAB> if self . timeout > 0 : <TAB> <TAB> self . resetTimeout ( ) <TAB> self . _pendingSize - = len ( data ) <TAB> if self . _pendingSize > 0 : <TAB> <TAB> self . _pendingBuffer . write ( data ) <TAB> else : <TAB> <TAB> passon = b "" "" <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> data , passon = data [ : self . _pendingSize ] , data [ self . _pendingSize : ] <TAB> <TAB> self . _pendingBuffer . write ( data ) <TAB> <TAB> rest = self . _pendingBuffer <TAB> <TAB> self . _pendingBuffer = None <TAB> <TAB> self . _pendingSize = None <TAB> <TAB> rest . seek ( 0 , 0 ) <TAB> <TAB> self . _parts . append ( rest . read ( ) ) <TAB> <TAB> self . setLineMode ( passon . lstrip ( b "" \r \n "" ) )",if len ( data ) > self . _pendingSize :,if self . _pendingSize < 0 :,False,96.61,72.64,,,
"def handle ( self , * args , * * options ) : <TAB> app_name = options . get ( "" app_name "" ) <TAB> job_name = options . get ( "" job_name "" ) <TAB> # hack since we are using job_name nargs='?' for -l to work <TAB> if app_name and not job_name: <TAB> <TAB> job_name = app_name <TAB> <TAB> app_name = None <TAB> if options.get(""list_jobs""): <TAB> <TAB> print_jobs(only_scheduled=False, show_when=True, show_appname=True) <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print(""Run a single maintenance job. Please specify the name of the job."") <TAB> <TAB> <TAB> return <TAB> <TAB> self.runjob(app_name, job_name, options)",if job_name :,if not job_name :,False,98.87,73.04,,,
"def _exportReceived ( self , content , error = False , server = None , context = { } , * * kwargs ) : <TAB> if error : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . error . emit ( content [ "" message "" ] , True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . error . emit ( "" Can ' t export the project from the server "" , True ) <TAB> <TAB> self . finished . emit ( ) <TAB> <TAB> return <TAB> self . finished . emit ( )","if ""message"" in content :",if content :,False,95.9,66.3,,,
"def __iter__ ( self ) : <TAB> n = self . n <TAB> k = self . k <TAB> j = int ( np . ceil ( n / k ) ) <TAB> for i in range ( k ) : <TAB> <TAB> test_index = np . zeros ( n , dtype = bool ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> test_index [ i * j : ( i + 1 ) * j ] = True <TAB> <TAB> else : <TAB> <TAB> <TAB> test_index [ i * j : ] = True <TAB> <TAB> train_index = np . logical_not ( test_index ) <TAB> <TAB> yield train_index , test_index",if i < k - 1 :,if i < k - 1 :,True,100.0,74.45,,,
"def addType ( self , graphene_type ) : <TAB> meta = get_meta ( graphene_type ) <TAB> if meta : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _typeMap [ meta . name ] = graphene_type <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Type  {typeName}  already exists in the registry. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> typeName = meta . name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" Cannot add unnamed type or a non-type to registry. "" )",if meta . name in self . _typeMap :,if not graphene_type in self . _typeMap :,False,97.0,72.42,,,
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize )",elif size <= 6 :,elif size <= 6 :,True,100.0,74.56,,,
"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> out . append ( sep ) <TAB> <TAB> if isinstance ( item , ParseResults ) : <TAB> <TAB> <TAB> out + = item . _asStringList ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out . append ( str ( item ) ) <TAB> return out",if sep :,if out and sep :,False,97.01,71.84,,,
"def open_file_input ( cli_parsed ) : <TAB> files = glob . glob ( os . path . join ( cli_parsed . d , "" *report.html "" ) ) <TAB> if len ( files ) > 0 : <TAB> <TAB> print ( "" \n [*] Done! Report written in the  "" + cli_parsed . d + ""  folder! "" ) <TAB> <TAB> print ( "" Would you like to open the report now? [Y/n] "" ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> response = input ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> return strtobool ( response ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> print ( "" Please respond with y or n "" ) <TAB> else : <TAB> <TAB> print ( "" [*] No report files found to open, perhaps no hosts were successful "" ) <TAB> <TAB> return False","if response == ""y"" :","if response == """" :",False,99.15,58.04,,,
"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB> <TAB> <TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ valname ] = value <TAB> for name in config : <TAB> <TAB> if name in self . values : <TAB> <TAB> <TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config","if ""."" in valname :","if ""."" in valname :",True,100.0,74.46,,,
"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB> <TAB> try : <TAB> <TAB> <TAB> result_list . append ( f . get_result ( ) ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> exc_info = sys . exc_info ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if not isinstance ( e , self . quiet_exceptions ) : <TAB> <TAB> <TAB> <TAB> <TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB> <TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB> <TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB> <TAB> return list ( result_list )",if exc_info is None :,if exc_info is None :,True,100.0,74.62,,,
"def test01e_json ( self ) : <TAB> "" Testing GeoJSON input/output. "" <TAB> if not GEOJSON : <TAB> <TAB> return <TAB> for g in self . geometries . json_geoms : <TAB> <TAB> geom = OGRGeometry ( g . wkt ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( g . json , geom . json ) <TAB> <TAB> <TAB> self . assertEqual ( g . json , geom . geojson ) <TAB> <TAB> self . assertEqual ( OGRGeometry ( g . wkt ) , OGRGeometry ( geom . json ) )","if g . geometryType == ""Feature"" :","if not hasattr ( g , ""not_equal"" ) :",False,91.84,70.17,,,
"def __init__ ( self , hub = None ) : # pylint: disable=unused-argument <TAB> if resolver._resolver is None: <TAB> <TAB> _resolver = resolver._resolver = _DualResolver() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _resolver.network_resolver.nameservers[:] = config.resolver_nameservers <TAB> <TAB> if config.resolver_timeout: <TAB> <TAB> <TAB> _resolver.network_resolver.lifetime = config.resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance(resolver._resolver, _DualResolver) <TAB> self._resolver = resolver._resolver",if config . resolver_nameservers :,if config . resolver_nameservers :,True,100.0,74.14,,,
"def __iadd__ ( self , term ) : <TAB> if isinstance ( term , ( int , long ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _gmp . mpz_add_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( term ) ) <TAB> <TAB> <TAB> return self <TAB> <TAB> if - 65535 < term < 0 : <TAB> <TAB> <TAB> _gmp . mpz_sub_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( - term ) ) <TAB> <TAB> <TAB> return self <TAB> <TAB> term = Integer ( term ) <TAB> _gmp . mpz_add ( self . _mpz_p , self . _mpz_p , term . _mpz_p ) <TAB> return self",if 0 <= term < 65535 :,if 0 <= term < 65536 :,False,98.76,73.41,,,
"def copy ( dst , src ) : <TAB> for ( k , v ) in src . iteritems ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d = { } <TAB> <TAB> <TAB> dst [ k ] = d <TAB> <TAB> <TAB> copy ( d , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> dst [ k ] = v","if isinstance ( v , dict ) :","if isinstance ( v , dict ) :",True,100.0,74.09,,,
"def generator ( self , data ) : <TAB> self . procs = OrderedDict ( ) <TAB> for task in data : <TAB> <TAB> self . recurse_task ( task , 0 , 0 , self . procs ) <TAB> for offset , name , level , pid , ppid , uid , euid , gid in self . procs . values ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> Address ( offset ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( name ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( level ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( pid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( ppid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( uid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( gid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( euid ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> )",if offset :,if offset :,True,100.0,74.63,,,
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> if not father_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False",if family :,if family :,True,100.0,74.42,,,
"def _arctic_task_exec ( request ) : <TAB> request . start_time = time . time ( ) <TAB> logging . debug ( <TAB> <TAB> "" Executing asynchronous request for  {} / {} "" . format ( <TAB> <TAB> <TAB> request . library , request . symbol <TAB> <TAB> ) <TAB> ) <TAB> result = None <TAB> try : <TAB> <TAB> request . is_running = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = mongo_retry ( request . fun ) ( * request . args , * * request . kwargs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = request . fun ( * request . args , * * request . kwargs ) <TAB> except Exception as e : <TAB> <TAB> request . exception = e <TAB> finally : <TAB> <TAB> request . data = result <TAB> <TAB> request . end_time = time . time ( ) <TAB> <TAB> request . is_running = False <TAB> return result",if request . retry :,if request . mongo_retry :,False,98.6,73.84,,,
"def _setup_styles ( self ) : <TAB> for ttype , ndef in self . style : <TAB> <TAB> escape = EscapeSequence ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> escape . fg = self . _color_index ( ndef [ "" color "" ] ) <TAB> <TAB> if ndef [ "" bgcolor "" ] : <TAB> <TAB> <TAB> escape . bg = self . _color_index ( ndef [ "" bgcolor "" ] ) <TAB> <TAB> if self . usebold and ndef [ "" bold "" ] : <TAB> <TAB> <TAB> escape . bold = True <TAB> <TAB> if self . useunderline and ndef [ "" underline "" ] : <TAB> <TAB> <TAB> escape . underline = True <TAB> <TAB> self . style_string [ str ( ttype ) ] = ( escape . color_string ( ) , escape . reset_string ( ) )","if ndef [ ""color"" ] :","if ndef [ ""color"" ] :",True,100.0,74.57,,,
"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB> <TAB> if char != self . int_to_char [ self . blank_index ] : <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> if remove_repetitions and i != 0 and char == sequence[i - 1]: <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> string += "" "" <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string",elif remove_repetitions and char == sequence [ i - 1 ] :,elif char == self . labels [ self . space_index ] :,False,94.47,70.44,,,
"def arith_expr ( self , nodelist ) : <TAB> node = self . com_node ( nodelist [ 0 ] ) <TAB> for i in range ( 2 , len ( nodelist ) , 2 ) : <TAB> <TAB> right = self . com_node ( nodelist [ i ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> node = Add ( node , right , lineno = nodelist [ 1 ] . context ) <TAB> <TAB> elif nodelist [ i - 1 ] . type == token . MINUS : <TAB> <TAB> <TAB> node = Sub ( node , right , lineno = nodelist [ 1 ] . context ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected token:  %s "" % nodelist [ i - 1 ] [ 0 ] ) <TAB> return node",if nodelist [ i - 1 ] . type == token . MINUS :,if nodelist [ i - 1 ] . type == token . PLUS :,False,98.74,73.74,,,
"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB> <TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> start , stop = index . start , index . stop <TAB> <TAB> new_start , new_stop = None , None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB> if stop is not None : <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB> <TAB> new_index = [ ] <TAB> <TAB> for ind in index : <TAB> <TAB> <TAB> new_index . append ( length - ind ) <TAB> return new_index",if start is not None :,if start is not None :,True,100.0,74.56,,,
"def getRoots ( job ) : <TAB> if job not in visited : <TAB> <TAB> visited . add ( job ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> list ( map ( lambda p : getRoots ( p ) , job . _directPredecessors ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> roots . add ( job ) <TAB> <TAB> # The following call ensures we explore all successor edges. <TAB> <TAB> list(map(lambda c: getRoots(c), job._children + job._followOns))",if job . _directPredecessors :,if len ( job . _directPredecessors ) > 0 :,False,94.17,69.64,,,
"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB> <TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB> <TAB> <TAB> if current is not None : <TAB> <TAB> <TAB> <TAB> collected . append ( current ) <TAB> return collected",if element in comparator_node :,"if self . _is_true ( self . visit ( comparator_node , element ) ) :",False,89.66,69.04,,,
"def func ( x , y ) : <TAB> try : <TAB> <TAB> if x > y : <TAB> <TAB> <TAB> z = x + 2 * math . sin ( y ) <TAB> <TAB> <TAB> return z * * 2 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else : <TAB> <TAB> <TAB> return 2 * * 3 <TAB> except ValueError : <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> foo + = i <TAB> <TAB> return foo <TAB> except TypeError : <TAB> <TAB> return 42 <TAB> else : <TAB> <TAB> return 33 <TAB> finally : <TAB> <TAB> print ( "" finished "" )",elif x < y :,elif x == y :,False,98.22,73.48,,,
"def set_filter ( self , dataset_opt ) : <TAB> """""" This function create and set the pre_filter to the obj as attributes """""" <TAB> self . pre_filter = None <TAB> for key_name in dataset_opt . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> new_name = key_name . replace ( "" filters "" , "" filter "" ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> filt = instantiate_filters ( getattr ( dataset_opt , key_name ) ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> log . exception ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Error trying to create  {} ,  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> new_name , getattr ( dataset_opt , key_name ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( self , new_name , filt )","if key_name . startswith ( ""filters"" ) :","if ""filter"" in key_name :",False,96.77,82.16,,,
"def _add_states_to_lookup ( <TAB> self , trackers_as_states , trackers_as_actions , domain , online = False ) : <TAB> """""" Add states to lookup dict """""" <TAB> for states in trackers_as_states : <TAB> <TAB> active_form = self . _get_active_form_name ( states [ - 1 ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # modify the states <TAB> <TAB> <TAB> states = self._modified_states(states) <TAB> <TAB> <TAB> feature_key = self._create_feature_key(states) <TAB> <TAB> <TAB> # even if there are two identical feature keys <TAB> <TAB> <TAB> # their form will be the same <TAB> <TAB> <TAB> # because of `active_form_...` feature <TAB> <TAB> <TAB> self.lookup[feature_key] = active_form",if online :,if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) :,False,89.88,82.13,,,
"def list_loaded_payloads ( self ) : <TAB> print ( helpers . color ( "" \n  [*] Available Payloads: \n "" ) ) <TAB> lastBase = None <TAB> x = 1 <TAB> for name in sorted ( self . active_payloads . keys ( ) ) : <TAB> <TAB> parts = name . split ( "" / "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( ) <TAB> <TAB> lastBase = parts [ 0 ] <TAB> <TAB> print ( "" \t %s ) \t %s "" % ( x , "" {0: <24} "" . format ( name ) ) ) <TAB> <TAB> x + = 1 <TAB> print ( "" \n "" ) <TAB> return",if lastBase == parts [ 0 ] :,if lastBase and parts [ 0 ] != lastBase :,False,96.26,71.89,,,
"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB> <TAB> if - 1024 < item < 1024 : <TAB> <TAB> <TAB> return str ( item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return vw . reprPointer ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB> <TAB> return reprComplex ( vw , item ) # recurse <TAB> elif ptype is dict: <TAB> <TAB> return ""{%s}"" % "","".join( <TAB> <TAB> <TAB> [""%s:%s"" % (reprSmart(vw, k), reprSmart(vw, v)) for k, v in item.items()] <TAB> <TAB> ) <TAB> else: <TAB> <TAB> return repr(item)",elif item >= 0 :,elif vw . isValidPointer ( item ) :,False,96.78,71.72,,,
"def ConfigSectionMap ( section ) : <TAB> config = ConfigParser . RawConfigParser ( ) <TAB> configurations = config_manager ( ) # Class from mkchromecast.config <TAB> configf = configurations.configf <TAB> config.read(configf) <TAB> dict1 = {} <TAB> options = config.options(section) <TAB> for option in options: <TAB> <TAB> try: <TAB> <TAB> <TAB> dict1[option] = config.get(section, option) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> DebugPrint(""skip: %s"" % option) <TAB> <TAB> except: <TAB> <TAB> <TAB> print(""Exception on %s!"" % option) <TAB> <TAB> <TAB> dict1[option] = None <TAB> return dict1",if dict1 [ option ] is None :,if dict1 [ option ] == - 1 :,False,97.17,71.93,,,
"def ConfigSectionMap ( section ) : <TAB> config = ConfigParser . RawConfigParser ( ) <TAB> configurations = config_manager ( ) # Class from mkchromecast.config <TAB> configf = configurations.configf <TAB> config.read(configf) <TAB> dict1 = {} <TAB> options = config.options(section) <TAB> for option in options: <TAB> <TAB> try: <TAB> <TAB> <TAB> dict1[option] = config.get(section, option) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> DebugPrint(""skip: %s"" % option) <TAB> <TAB> except: <TAB> <TAB> <TAB> print(""Exception on %s!"" % option) <TAB> <TAB> <TAB> dict1[option] = None <TAB> return dict1",if dict1 [ option ] is None :,"if s . get ( ""status"" ) == ""Failure""",False,92.67,64.31,,,
"def redirect_aware_commmunicate ( p , sys = _sys ) : <TAB> """""" Variant of process.communicate that works with in process I/O redirection. """""" <TAB> assert sys is not None <TAB> out , err = p . communicate ( ) <TAB> if redirecting_io ( sys = sys ) : <TAB> <TAB> if out : <TAB> <TAB> <TAB> # We don't unicodify in Python2 because sys.stdout may be a <TAB> <TAB> <TAB> # cStringIO.StringIO object, which does not accept Unicode strings <TAB> <TAB> <TAB> out = unicodify(out) <TAB> <TAB> <TAB> sys.stdout.write(out) <TAB> <TAB> <TAB> out = None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> err = unicodify(err) <TAB> <TAB> <TAB> sys.stderr.write(err) <TAB> <TAB> <TAB> err = None <TAB> return out, err",if err :,if err :,True,100.0,99.5,,,
"def __exit__ ( self , * args , * * kwargs ) : <TAB> self . _samples_cache = { } <TAB> if is_validation_enabled ( ) and isinstance ( self . prior , dict ) : <TAB> <TAB> extra = set ( self . prior ) - self . _param_hits <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" pyro.module prior did not find params [ ' {} ' ].  "" <TAB> <TAB> <TAB> <TAB> "" Did you instead mean one of [ ' {} ' ]? "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" ' ,  ' "" . join ( extra ) , "" ' ,  ' "" . join ( self . _param_misses ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return super ( ) . __exit__ ( * args , * * kwargs )",if extra :,if extra :,True,100.0,74.56,,,
def __download_thread ( self ) : <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . __current_download = self . __queue . get ( ) <TAB> <TAB> <TAB> self . __download_file ( self . __current_download ) <TAB> <TAB> time . sleep ( 0.1 ),if self . __current_download is None :,if not self . __queue . empty ( ) :,False,90.52,85.88,,,
"def plot_timer_command ( args ) : <TAB> import nnabla . monitor as M <TAB> format_unit = dict ( <TAB> <TAB> s = "" seconds "" , <TAB> <TAB> m = "" minutes "" , <TAB> <TAB> h = "" hours "" , <TAB> <TAB> d = "" days "" , <TAB> ) <TAB> if not args . ylabel : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . ylabel = "" Total elapsed time [ {} ] "" . format ( format_unit [ args . time_unit ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> args . ylabel = "" Elapsed time [ {} /iter] "" . format ( format_unit [ args . time_unit ] ) <TAB> plot_any_command ( <TAB> <TAB> args , M . plot_time_elapsed , dict ( elapsed = args . elapsed , unit = args . time_unit ) <TAB> ) <TAB> return True",if args . elapsed :,if args . elapsed :,True,100.0,74.57,,,
"def plot_timer_command ( args ) : <TAB> import nnabla . monitor as M <TAB> format_unit = dict ( <TAB> <TAB> s = "" seconds "" , <TAB> <TAB> m = "" minutes "" , <TAB> <TAB> h = "" hours "" , <TAB> <TAB> d = "" days "" , <TAB> ) <TAB> if not args . ylabel : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> args . ylabel = "" Total elapsed time [ {} ] "" . format ( format_unit [ args . time_unit ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> args . ylabel = "" Elapsed time [ {} /iter] "" . format ( format_unit [ args . time_unit ] ) <TAB> plot_any_command ( <TAB> <TAB> args , M . plot_time_elapsed , dict ( elapsed = args . elapsed , unit = args . time_unit ) <TAB> ) <TAB> return True",if args . elapsed :,if requestor_has_access_to_all or page . is_visible,False,93.16,72.38,,,
"def find ( self , pattern ) : <TAB> """""" Find pages in database. """""" <TAB> results = self . _search_keyword ( pattern ) <TAB> pat = re . compile ( "" (.*?)( %s )(.*?)(  \ (.* \ ))?$ "" % re . escape ( pattern ) , re . I ) <TAB> if results : <TAB> <TAB> for name , keyword , url in results : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> keyword = pat . sub ( <TAB> <TAB> <TAB> <TAB> <TAB> r "" \ 1 \ 033[1;31m \ 2 \ 033[0m \ 3 \ 033[1;33m \ 4 \ 033[0m "" , keyword <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> print ( "" %s  -  %s "" % ( keyword , name ) ) <TAB> else : <TAB> <TAB> raise RuntimeError ( "" %s : nothing appropriate. "" % pattern )",if url :,if os . isatty ( sys . stdout . fileno ( ) ) :,False,94.62,95.38,,,
"def _certonly_new_request_common ( self , mock_client , args = None ) : <TAB> with mock . patch ( <TAB> <TAB> "" certbot._internal.main._find_lineage_for_domains_and_certname "" <TAB> ) as mock_renewal : <TAB> <TAB> mock_renewal . return_value = ( "" newcert "" , None ) <TAB> <TAB> with mock . patch ( "" certbot._internal.main._init_le_client "" ) as mock_init : <TAB> <TAB> <TAB> mock_init . return_value = mock_client <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> args = [ ] <TAB> <TAB> <TAB> args + = "" -d foo.bar -a standalone certonly "" . split ( ) <TAB> <TAB> <TAB> self . _call ( args )",if args is None :,if args is None :,True,100.0,74.41,,,
"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB> <TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB> <TAB> elif hasattr ( args [ 0 ] , "" items "" ) : <TAB> <TAB> <TAB> items = list ( args [ 0 ] . items ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> items = list ( args [ 0 ] ) <TAB> <TAB> self . _items = items <TAB> else : <TAB> <TAB> self . _items = [ ] <TAB> if kw : <TAB> <TAB> self . _items . extend ( kw . items ( ) )","if hasattr ( args [ 0 ] , ""iteritems"" ) :","if hasattr ( args [ 0 ] , ""iteritems"" ) :",True,100.0,74.59,,,
"def test08_ExceptionTypes ( self ) : <TAB> self . assertTrue ( issubclass ( db . DBError , Exception ) ) <TAB> for i , j in db . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertTrue ( issubclass ( j , db . DBError ) , msg = i ) <TAB> <TAB> <TAB> if i not in ( "" DBKeyEmptyError "" , "" DBNotFoundError "" ) : <TAB> <TAB> <TAB> <TAB> self . assertFalse ( issubclass ( j , KeyError ) , msg = i ) <TAB> # This two exceptions have two bases <TAB> self.assertTrue(issubclass(db.DBKeyEmptyError, KeyError)) <TAB> self.assertTrue(issubclass(db.DBNotFoundError, KeyError))","if isinstance ( j , Exception ) :","if i . startswith ( ""DB"" ) and i . endswith ( ""Error"" ) :",False,90.57,63.91,,,
"def _delegate_to_sinks ( self , value : Any ) - > None : <TAB> for sink in self . _sinks : <TAB> <TAB> if isinstance ( sink , AgentT ) : <TAB> <TAB> <TAB> await sink . send ( value = value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> await cast ( TopicT , sink ) . send ( value = value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await maybe_async ( cast ( Callable , sink ) ( value ) )","elif isinstance ( sink , TopicT ) :","elif isinstance ( sink , ChannelT ) :",False,98.04,72.93,,,
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """""" Select first block delimited by start_tag and end_tag """""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> if str_in [ pos ] == start_tag : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel",if str_in [ pos ] == end_tag :,elif str_in [ pos ] == end_tag :,False,98.84,97.69,,,
"def confirm ( request ) : <TAB> details = request . session . get ( "" reauthenticate "" ) <TAB> if not details : <TAB> <TAB> return redirect ( "" home "" ) <TAB> # Monkey patch request <TAB> request.user = User.objects.get(pk=details[""user_pk""]) <TAB> if request.method == ""POST"": <TAB> <TAB> confirm_form = PasswordConfirmForm(request, request.POST) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> request.session.pop(""reauthenticate"") <TAB> <TAB> <TAB> request.session[""reauthenticate_done""] = True <TAB> <TAB> <TAB> return redirect(""social:complete"", backend=details[""backend""]) <TAB> else: <TAB> <TAB> confirm_form = PasswordConfirmForm(request) <TAB> context = {""confirm_form"": confirm_form} <TAB> context.update(details) <TAB> return render(request, ""accounts/confirm.html"", context)",if confirm_form . is_valid ( ) :,if confirm_form . is_valid ( ) :,True,100.0,74.36,,,
"def verify_credentials ( self ) : <TAB> if self . enabled : <TAB> <TAB> response = requests . get ( <TAB> <TAB> <TAB> "" https://api.exotel.com/v1/Accounts/ {sid} "" . format ( sid = self . account_sid ) , <TAB> <TAB> <TAB> auth = ( self . api_key , self . api_token ) , <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid credentials "" ) )",if response . status_code != 200 and response . status_code != 401 :,if response . status_code != 200 :,False,92.72,71.49,,,
"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB> <TAB> icon = "" class "" <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> icon = "" method_priv "" <TAB> <TAB> elif tok . visibility == "" protected "" : <TAB> <TAB> <TAB> icon = "" method_prot "" <TAB> <TAB> else : <TAB> <TAB> <TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] )","if tok . visibility == ""private"" :","if tok . visibility == ""private"" :",True,100.0,74.42,,,
"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem.tag == ""kw"" and elem.get(""type"") != ""teardown"" <TAB> <TAB> start = event == ""start"" <TAB> <TAB> if omit and start: <TAB> <TAB> <TAB> omitted_kws += 1 <TAB> <TAB> if not omitted_kws: <TAB> <TAB> <TAB> yield event, elem <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> elem.clear() <TAB> <TAB> if omit and not start: <TAB> <TAB> <TAB> omitted_kws -= 1","if elem . tag == ""kw"" and elem . get ( ""type"" ) == ""teardown"" :",elif not start :,False,88.36,64.13,,,
"def on_double_click ( self , event ) : <TAB> # TODO: don't act when the click happens below last item <TAB> path = self.get_selected_path() <TAB> kind = self.get_selected_kind() <TAB> name = self.get_selected_name() <TAB> if kind == ""file"": <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.open_file(path) <TAB> <TAB> else: <TAB> <TAB> <TAB> self.open_path_with_system_app(path) <TAB> elif kind == ""dir"": <TAB> <TAB> self.request_focus_into(path) <TAB> return ""break""","if name == ""default"" :",if self . should_open_name_in_thonny ( name ) :,False,91.58,63.11,,,
"def search_cve ( db : DatabaseInterface , product : Product ) - > dict : <TAB> result = { } <TAB> for query_result in db . fetch_multiple ( QUERIES [ "" cve_lookup "" ] ) : <TAB> <TAB> cve_entry = CveDbEntry ( * query_result ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result [ cve_entry . cve_id ] = { <TAB> <TAB> <TAB> <TAB> "" score2 "" : cve_entry . cvss_v2_score , <TAB> <TAB> <TAB> <TAB> "" score3 "" : cve_entry . cvss_v3_score , <TAB> <TAB> <TAB> <TAB> "" cpe_version "" : build_version_string ( cve_entry ) , <TAB> <TAB> <TAB> } <TAB> return result","if product . get_cve_type ( cve_entry . cve_id ) == ""cpe"" :","if _product_matches_cve ( product , cve_entry ) :",False,90.89,65.62,,,
"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB> <TAB> if not f . endswith ( "" .go "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> files . append ( f ) <TAB> <TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime","if not f . endswith ( "".md"" ) :",if APP_CONFIG . nobuild_files . match ( f ) :,False,91.15,61.29,,,
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> if old_mtime == mtime : <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache[filename] = old_mtime, result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function(filename) <TAB> with lock: <TAB> <TAB> cache[filename] = mtime, result # at the end <TAB> <TAB> if len(cache) > max_size: <TAB> <TAB> <TAB> cache.popitem(last=False) <TAB> return result",if cache :,if filename in cache :,False,98.18,72.42,,,
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE.findall(s): <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast(TupleStr4, item) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> typ = ""number"" <TAB> <TAB> <TAB> val = item[0] <TAB> <TAB> elif item[1]: <TAB> <TAB> <TAB> typ = ""name"" <TAB> <TAB> <TAB> val = item[1] <TAB> <TAB> elif item[2]: <TAB> <TAB> <TAB> typ = item[2] <TAB> <TAB> <TAB> val = item[2] <TAB> <TAB> elif item[3]: <TAB> <TAB> <TAB> typ = item[3] <TAB> <TAB> <TAB> val = item[3] <TAB> <TAB> yield Token(typ, val)",if item [ 0 ] :,if item [ 0 ] :,True,100.0,74.42,,,
"def _show_encoders ( self , * args , * * kwargs ) : <TAB> if issubclass ( self . current_module . __class__ , BasePayload ) : <TAB> <TAB> encoders = self . current_module . get_encoders ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> headers = ( "" Encoder "" , "" Name "" , "" Description "" ) <TAB> <TAB> <TAB> print_table ( headers , * encoders , max_column_length = 100 ) <TAB> <TAB> <TAB> return <TAB> print_error ( "" No encoders available "" )",if encoders :,if encoders :,True,100.0,74.25,,,
"def __init__ ( self ) : <TAB> Builder . __init__ ( self , commandName = "" VCExpress.exe "" , formatName = "" msvcProject "" ) <TAB> for key in [ "" VS90COMNTOOLS "" , "" VC80COMNTOOLS "" , "" VC71COMNTOOLS "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . programDir = os . path . join ( os . environ [ key ] , "" .. "" , "" IDE "" ) <TAB> if self . programDir is None : <TAB> <TAB> for version in [ "" 9.0 "" , "" 8 "" , "" .NET 2003 "" ] : <TAB> <TAB> <TAB> msvcDir = ( <TAB> <TAB> <TAB> <TAB> "" C: \\ Program Files \\ Microsoft Visual Studio  %s \\ Common7 \\ IDE "" % version <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if os . path . exists ( msvcDir ) : <TAB> <TAB> <TAB> <TAB> self . programDir = msvcDir",if os . environ . has_key ( key ) :,if os . environ . has_key ( key ) :,True,100.0,74.61,,,
"def _inner ( * args , * * kwargs ) : <TAB> component_manager = args [ 0 ] . component_manager <TAB> for condition_name in condition_names : <TAB> <TAB> condition_result , err_msg = component_manager . evaluate_condition ( condition_name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ComponentStartConditionNotMetError ( err_msg ) <TAB> if not component_manager . all_components_running ( * components ) : <TAB> <TAB> raise ComponentsNotStartedError ( <TAB> <TAB> <TAB> f "" the following required components have not yet started:  { json . dumps ( components ) } "" <TAB> <TAB> ) <TAB> return method ( * args , * * kwargs )",if condition_result is None :,if not condition_result :,False,97.03,72.45,,,
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> if not svalue : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self . tk . getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return self . tk . getint ( svalue ) <TAB> <TAB> except ( ValueError , TclError ) : <TAB> <TAB> <TAB> pass <TAB> return value",if self . _is_float :,"elif ""."" in svalue :",False,95.29,63.21,,,
"def check_songs ( ) : <TAB> desc = numeric_phrase ( "" %d  song "" , "" %d  songs "" , len ( songs ) ) <TAB> with Task ( _ ( "" Rescan songs "" ) , desc ) as task : <TAB> <TAB> task . copool ( check_songs ) <TAB> <TAB> for i , song in enumerate ( songs ) : <TAB> <TAB> <TAB> song = song . _song <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> app . library . reload ( song ) <TAB> <TAB> <TAB> task . update ( ( float ( i ) + 1 ) / len ( songs ) ) <TAB> <TAB> <TAB> yield",if app . library :,if song in app . library :,False,97.92,72.8,,,
"def initialize ( self ) : <TAB> nn . init . xavier_uniform_ ( self . linear . weight . data ) <TAB> if self . linear . bias is not None : <TAB> <TAB> self . linear . bias . data . uniform_ ( - 1.0 , 1.0 ) <TAB> if self . self_layer : <TAB> <TAB> nn . init . xavier_uniform_ ( self . linear_self . weight . data ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . linear_self . bias . data . uniform_ ( - 1.0 , 1.0 )",if self . linear_self . bias is not None :,if self . linear_self . bias is not None :,True,100.0,74.39,,,
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return not self . inverse # True <TAB> <TAB> else: <TAB> <TAB> <TAB> if not result: <TAB> <TAB> <TAB> <TAB> return self.inverse # False <TAB> <IF-STMT> <TAB> <TAB> return self.inverse # False <TAB> else: <TAB> <TAB> return not self.inverse # True",elif self . inverse :,if self . any_match :,False,93.36,70.21,,,
"def toterminal ( self , tw ) : <TAB> for element in self . chain : <TAB> <TAB> element [ 0 ] . toterminal ( tw ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tw . line ( "" "" ) <TAB> <TAB> <TAB> tw . line ( element [ 2 ] , yellow = True ) <TAB> super ( ExceptionChainRepr , self ) . toterminal ( tw )",if element [ 1 ] :,if element [ 2 ] is not None :,False,93.62,69.43,,,
"def runMainLoop ( self ) : <TAB> """""" The curses gui main loop. """""" <TAB> # pylint: disable=no-member <TAB> # <TAB> # Do NOT change g.app! <TAB> self.curses_app = LeoApp() <TAB> stdscr = curses.initscr() <TAB> if 1: # Must follow initscr. <TAB> <TAB> self.dump_keys() <TAB> try: <TAB> <TAB> self.curses_app.run() <TAB> <TAB> # run calls CApp.main(), which calls CGui.run(). <TAB> finally: <TAB> <TAB> curses.nocbreak() <TAB> <TAB> stdscr.keypad(0) <TAB> <TAB> curses.echo() <TAB> <TAB> curses.endwin() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> g.pr(""Exiting Leo..."")",if self . curses_app . is_alive ( ) :,"if ""shutdown"" in g . app . debug :",False,94.82,69.49,,,
"def test_chunkcoding ( self ) : <TAB> for native , utf8 in zip ( * [ StringIO ( f ) . readlines ( ) for f in self . tstring ] ) : <TAB> <TAB> u = self . decode ( native ) [ 0 ] <TAB> <TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] )",if self . is_chunked :,if self . roundtriptest :,False,95.95,72.88,,,
"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB> <TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB> <TAB> <TAB> for line in f . readlines ( ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB> <TAB> if explicit : <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist_file , <TAB> <TAB> <TAB> )","if line . startswith ( ""Allow list"" ) :","if not line . startswith ( ""#"" ) :",False,97.64,72.42,,,
"def get_all_extensions ( subtree = None ) : <TAB> if subtree is None : <TAB> <TAB> subtree = full_extension_tree ( ) <TAB> result = [ ] <TAB> if isinstance ( subtree , dict ) : <TAB> <TAB> for value in subtree . values ( ) : <TAB> <TAB> <TAB> if isinstance ( value , dict ) : <TAB> <TAB> <TAB> <TAB> result + = get_all_extensions ( value ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> result + = value . extensions <TAB> <TAB> <TAB> elif isinstance ( value , ( list , tuple ) ) : <TAB> <TAB> <TAB> <TAB> result + = value <TAB> elif isinstance ( subtree , ( ContentTypeMapping , ContentTypeDetector ) ) : <TAB> <TAB> result = subtree . extensions <TAB> elif isinstance ( subtree , ( list , tuple ) ) : <TAB> <TAB> result = subtree <TAB> return result","elif isinstance ( value , ContentTypeMapping ) :","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) :",False,97.36,72.64,,,
"def _configuration_dict_to_commandlist ( name , config_dict ) : <TAB> command_list = [ "" config: %s "" % name ] <TAB> for key , value in config_dict . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> b = "" true "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> b = "" false "" <TAB> <TAB> <TAB> command_list . append ( "" %s : %s "" % ( key , b ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> command_list . append ( "" %s : %s "" % ( key , value ) ) <TAB> return command_list","if key == ""enabled"" :",if type ( value ) is bool :,False,96.1,66.68,,,
"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None : <TAB> <TAB> <TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB> <TAB> if line . startswith ( "" vermagic "" ) : <TAB> <TAB> <TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB> <TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo","if line . startswith ( ""#"" ) :",if not line :,False,96.26,68.72,,,
"def zip_random_open_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile.ZipFile(f, ""r"", compression) as zipfp: <TAB> <TAB> zipdata1 = [] <TAB> <TAB> with zipfp.open(TESTFN) as zipopen1: <TAB> <TAB> <TAB> while True: <TAB> <TAB> <TAB> <TAB> read_data = zipopen1.read(randint(1, 1024)) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> zipdata1.append(read_data) <TAB> <TAB> testdata = """".join(zipdata1) <TAB> <TAB> self.assertEqual(len(testdata), len(self.data)) <TAB> <TAB> self.assertEqual(testdata, self.data)",if not read_data :,if not read_data :,True,100.0,99.3,,,
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self . ctl : <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> if value : <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args )",if age <= 0 :,if self . _call_count > self . ctl or age > self . ttl :,False,92.06,69.41,,,
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> if type ( v ) == unicode : <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> elif not args . content_only : <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res )",if type ( f ) == unicode :,if type ( f ) == unicode :,True,100.0,74.56,,,
"def _finalize_setup_keywords ( self ) : <TAB> for ep in pkg_resources . iter_entry_points ( "" distutils.setup_keywords "" ) : <TAB> <TAB> value = getattr ( self , ep . name , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ep . require ( installer = self . fetch_build_egg ) <TAB> <TAB> <TAB> ep . load ( ) ( self , ep . name , value )",if value is not None :,if value is not None :,True,100.0,74.14,,,
"def test_attributes_types ( self ) : <TAB> if not self . connection . strategy . pooled : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . connection . refresh_server_info ( ) <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> type ( self . connection . server . schema . attribute_types [ "" cn "" ] ) , AttributeTypeInfo <TAB> <TAB> )",if self . connection . server . schema . attribute_types is None :,if not self . connection . server . info :,False,90.82,69.27,,,
"def to_key ( literal_or_identifier ) : <TAB> """""" returns string representation of this object """""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k )","elif isinstance ( k , bool ) :","elif isinstance ( k , bool ) :",True,100.0,99.59,,,
"def list2rec ( x , test = False ) : <TAB> if test : <TAB> <TAB> vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 0 ] , int ( x [ 1 ] ) , int ( x [ 2 ] ) ) <TAB> <TAB> label = - 1 # label unknown <TAB> <TAB> return vid, label <TAB> else: <TAB> <TAB> vid = ""{}_{:06d}_{:06d}"".format(x[1], int(x[2]), int(x[3])) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vid = ""{}/{}"".format(convert_label(x[0]), vid) <TAB> <TAB> else: <TAB> <TAB> <TAB> assert level == 1 <TAB> <TAB> label = class_mapping[convert_label(x[0])] <TAB> <TAB> return vid, label",if level == 2 :,if level == 2 :,True,100.0,74.4,,,
"def _expand_env ( self , snapcraft_yaml ) : <TAB> environment_keys = [ "" name "" , "" version "" ] <TAB> for key in snapcraft_yaml : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> replacements = environment_to_replacements ( <TAB> <TAB> <TAB> get_snapcraft_global_environment ( self . project ) <TAB> <TAB> ) <TAB> <TAB> snapcraft_yaml [ key ] = replace_attr ( snapcraft_yaml [ key ] , replacements ) <TAB> return snapcraft_yaml",if key not in environment_keys :,if any ( ( key == env_key for env_key in environment_keys ) ) :,False,87.81,66.57,,,
"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self.storySettingsData: <TAB> <TAB> name = data[""name""] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if ""requires"" in data: <TAB> <TAB> <TAB> <TAB> set = self.getSetting(data[""requires""]) <TAB> <TAB> <TAB> <TAB> for i in self.ctrls[name]: <TAB> <TAB> <TAB> <TAB> <TAB> i.Enable(set not in [""off"", ""false"", ""0""])",if name in self . ctrls :,if name in self . ctrls :,True,100.0,74.26,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ChallengePhaseCreateSerializer , self ) . __init__ ( * args , * * kwargs ) <TAB> context = kwargs . get ( "" context "" ) <TAB> if context : <TAB> <TAB> challenge = context . get ( "" challenge "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> kwargs [ "" data "" ] [ "" challenge "" ] = challenge . pk <TAB> <TAB> test_annotation = context . get ( "" test_annotation "" ) <TAB> <TAB> if test_annotation : <TAB> <TAB> <TAB> kwargs [ "" data "" ] [ "" test_annotation "" ] = test_annotation",if challenge :,if challenge :,True,100.0,74.42,,,
def set_inactive ( self ) : <TAB> for title in self . gramplet_map : <TAB> <TAB> if self . gramplet_map [ title ] . pui : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . gramplet_map [ title ] . pui . active = False,if self . gramplet_map [ title ] . pui . active == True :,"if self . gramplet_map [ title ] . gstate != ""detached"" :",False,91.77,50.86,,,
"def authenticate ( username , password ) : <TAB> try : <TAB> <TAB> u = User . objects . get ( username = username ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> userLogger . info ( "" User logged in :  %s "" , username ) <TAB> <TAB> <TAB> return u <TAB> <TAB> else : <TAB> <TAB> <TAB> userLogger . warn ( "" Attempt to log in to :  %s "" , username ) <TAB> <TAB> <TAB> return False <TAB> except DoesNotExist : <TAB> <TAB> return False",if u . is_authenticated ( password ) :,"if check_password_hash ( u . password , password ) :",False,92.81,70.96,,,
def _check_date ( self ) : <TAB> if not self . value : <TAB> <TAB> return None <TAB> if not self . allow_date_in_past : <TAB> <TAB> if self . value < self . date_or_datetime ( ) . today ( ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . value = self . date_or_datetime ( ) . today ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . value = self . date_or_datetime ( ) . today ( ) + datetime . timedelta ( 1 ),if self . value > self . date_or_datetime ( ) . today ( ) :,if self . allow_todays_date :,False,90.63,92.63,,,
"def update ( self , E = None , * * F ) : <TAB> if E : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Update with `E` dictionary <TAB> <TAB> <TAB> for k in E: <TAB> <TAB> <TAB> <TAB> self[k] = E[k] <TAB> <TAB> else: <TAB> <TAB> <TAB> # Update with `E` items <TAB> <TAB> <TAB> for (k, v) in E: <TAB> <TAB> <TAB> <TAB> self[k] = v <TAB> # Update with `F` dictionary <TAB> for k in F: <TAB> <TAB> self[k] = F[k]","if isinstance ( E , dict ) :","if hasattr ( E , ""keys"" ) :",False,96.07,63.3,,,
"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> quotas_ok [ quota ] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa . results [ quota ] <TAB> <TAB> if avail [ 1 ] is not None and avail [ 1 ] < count : <TAB> <TAB> <TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok",if count == 0 :,if count <= 0 :,False,98.9,73.77,,,
"def gen_env_vars ( ) : <TAB> for fd_id , fd in zip ( STDIO_DESCRIPTORS , ( stdin , stdout , stderr ) ) : <TAB> <TAB> is_atty = fd . isatty ( ) <TAB> <TAB> yield ( cls . TTY_ENV_TMPL . format ( fd_id ) , cls . encode_env_var_value ( int ( is_atty ) ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield ( cls . TTY_PATH_ENV . format ( fd_id ) , os . ttyname ( fd . fileno ( ) ) or b "" "" )",if fd_id :,if is_atty :,False,96.96,72.91,,,
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , bytes ) : <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> elif isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r","elif isinstance ( k , bytes ) :","if isinstance ( k , bytes ) :",False,98.62,73.41,,,
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> if nodeid not in self . _nodes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> if attval . value_callback : <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value",if attr not in node . attributes :,if attr not in node . attributes :,True,100.0,74.61,,,
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> if not param_match : <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> if i > = length : <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret",if i >= length :,if dsn [ i ] . isspace ( ) :,False,96.19,71.54,,,
"def connect ( self , buttons ) : <TAB> for button in buttons : <TAB> <TAB> assert button is not None <TAB> <TAB> handled = False <TAB> <TAB> for handler_idx in range ( 0 , len ( self . __signal_handlers ) ) : <TAB> <TAB> <TAB> ( obj_class , signal , handler , handler_id ) = self . __signal_handlers [ <TAB> <TAB> <TAB> <TAB> handler_idx <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> handler_id = button . connect ( signal , handler ) <TAB> <TAB> <TAB> <TAB> handled = True <TAB> <TAB> <TAB> self . __signal_handlers [ handler_idx ] = ( <TAB> <TAB> <TAB> <TAB> obj_class , <TAB> <TAB> <TAB> <TAB> signal , <TAB> <TAB> <TAB> <TAB> handler , <TAB> <TAB> <TAB> <TAB> handler_id , <TAB> <TAB> <TAB> ) <TAB> <TAB> assert handled",if button is not None :,"if isinstance ( button , obj_class ) :",False,96.65,72.1,,,
"def _parse_display ( display ) : <TAB> """""" Parse an X11 display value """""" <TAB> try : <TAB> <TAB> host , dpynum = display . rsplit ( "" : "" , 1 ) <TAB> <TAB> if host . startswith ( "" [ "" ) and host . endswith ( "" ] "" ) : <TAB> <TAB> <TAB> host = host [ 1 : - 1 ] <TAB> <TAB> idx = dpynum . find ( "" . "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> screen = int ( dpynum [ idx + 1 : ] ) <TAB> <TAB> <TAB> dpynum = dpynum [ : idx ] <TAB> <TAB> else : <TAB> <TAB> <TAB> screen = 0 <TAB> except ( ValueError , UnicodeEncodeError ) : <TAB> <TAB> raise ValueError ( "" Invalid X11 display "" ) from None <TAB> return host , dpynum , screen",if idx >= 0 :,if idx >= 0 :,True,100.0,99.57,,,
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> if os . path . isdir ( fn ) : <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .md "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path )","elif fn . endswith ( "".md"" ) :","elif fn . endswith ( "".png"" ) :",False,98.8,73.6,,,
"def _sync_get ( self , identifier , * args , * * kw ) : <TAB> self . _mutex . acquire ( ) <TAB> try : <TAB> <TAB> try : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self . _values [ identifier ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB> <TAB> <TAB> return value <TAB> finally : <TAB> <TAB> self . _mutex . release ( )",if identifier in self . _values :,if identifier in self . _values :,True,100.0,74.54,,,
"def _query_fd ( self ) : <TAB> if self . stream is None : <TAB> <TAB> self . _last_stat = None , None <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> st = os . stat ( self . _filename ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self . _last_stat = None , None <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _last_stat = st [ stat . ST_DEV ] , st [ stat . ST_INO ]",if e . errno != errno . ENOENT :,if e . errno != errno . ENOENT :,True,100.0,74.46,,,
"def get_place_name ( self , place_handle ) : <TAB> """""" Obtain a place name """""" <TAB> text = "" "" <TAB> if place_handle : <TAB> <TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB> <TAB> <TAB> if place_title != "" "" : <TAB> <TAB> <TAB> <TAB> if len ( place_title ) > 25 : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title [ : 24 ] + "" ... "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text",if place :,if place :,True,100.0,99.44,,,
"def test_decoder_state ( self ) : <TAB> # Check that getstate() and setstate() handle the state properly <TAB> u = ""abc123"" <TAB> for encoding in all_unicode_encodings: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.check_state_handling_decode(encoding, u, u.encode(encoding)) <TAB> <TAB> <TAB> self.check_state_handling_encode(encoding, u, u.encode(encoding))","if encoding != ""utf-8"" :",if encoding not in broken_unicode_with_stateful :,False,91.47,59.87,,,
"def cleanup ( self ) : <TAB> if os . path . exists ( self . meta_gui_dir ) : <TAB> <TAB> for f in os . listdir ( self . meta_gui_dir ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> os . remove ( os . path . join ( self . meta_gui_dir , f ) )","if f . endswith ( "".gui"" ) :","if os . path . splitext ( f ) [ 1 ] == "".desktop"" :",False,84.23,64.74,,,
"def _have_applied_incense ( self ) : <TAB> for applied_item in inventory . applied_items ( ) . all ( ) : <TAB> <TAB> self . logger . info ( applied_item ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> mins = format_time ( applied_item . expire_ms * 1000 ) <TAB> <TAB> <TAB> self . logger . info ( <TAB> <TAB> <TAB> <TAB> "" Not applying incense, currently active:  %s ,  %s  minutes remaining "" , <TAB> <TAB> <TAB> <TAB> applied_item . item . name , <TAB> <TAB> <TAB> <TAB> mins , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logger . info ( "" "" ) <TAB> <TAB> <TAB> return False <TAB> return False",if applied_item . active :,if applied_item . expire_ms > 0 :,False,97.15,72.76,,,
"def get_closest_point ( self , point ) : <TAB> point = to_point ( point ) <TAB> cp , cd = None , None <TAB> for p0 , p1 in iter_pairs ( self . pts , self . connected ) : <TAB> <TAB> diff = p1 - p0 <TAB> <TAB> l = diff . length <TAB> <TAB> d = diff / l <TAB> <TAB> pp = p0 + d * max ( 0 , min ( l , ( point - p0 ) . dot ( d ) ) ) <TAB> <TAB> dist = ( point - pp ) . length <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cp , cd = pp , dist <TAB> return cp",if dist > cp and dist < cp :,if not cp or dist < cd :,False,95.53,71.35,,,
"def process_return ( lines ) : <TAB> for line in lines : <TAB> <TAB> m = re . fullmatch ( r "" (?P<param> \ w+) \ s+: \ s+(?P<type>[ \ w.]+) "" , line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Once this is in scanpydoc, we can use the fancy hover stuff <TAB> <TAB> <TAB> yield f'**{m[""param""]}** : :class:`~{m[""type""]}`' <TAB> <TAB> else: <TAB> <TAB> <TAB> yield line",if m :,if m :,True,100.0,74.14,,,
"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB> <TAB> for node in level : <TAB> <TAB> <TAB> if node . binary == BINARY_MISSING : <TAB> <TAB> <TAB> <TAB> missing . append ( node ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> invalid . append ( node ) <TAB> <TAB> <TAB> elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) : <TAB> <TAB> <TAB> <TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads",elif node . binary == BINARY_INVALID :,elif node . binary == BINARY_INVALID :,True,100.0,74.41,,,
"def safe_parse_date ( date_hdr ) : <TAB> """""" Parse a Date: or Received: header into a unix timestamp. """""" <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB> <TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB> <TAB> if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB> <TAB> return None","if date_hdr . startswith ( ""Date"" ) :","if "";"" in date_hdr :",False,95.27,90.22,,,
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed",if value != 0 :,if value != 1 :,False,98.86,73.57,,,
"def _rewrite_prepend_append ( self , string , prepend , append = None ) : <TAB> if append is None : <TAB> <TAB> append = prepend <TAB> if not isinstance ( string , StringElem ) : <TAB> <TAB> string = StringElem ( string ) <TAB> string . sub . insert ( 0 , prepend ) <TAB> if unicode ( string ) . endswith ( u "" \n "" ) : <TAB> <TAB> # Try and remove the last character from the tree <TAB> <TAB> try: <TAB> <TAB> <TAB> lastnode = string.flatten()[-1] <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> lastnode.sub[-1] = lastnode.sub[-1].rstrip(u""\n"") <TAB> <TAB> except IndexError: <TAB> <TAB> <TAB> pass <TAB> <TAB> string.sub.append(append + u""\n"") <TAB> else: <TAB> <TAB> string.sub.append(append) <TAB> return string","if lastnode . sub [ - 1 ] != u""\n"" :","if isinstance ( lastnode . sub [ - 1 ] , unicode ) :",False,96.06,65.86,,,
"def parse_indentless_sequence_entry ( self ) : <TAB> if self . check_token ( BlockEntryToken ) : <TAB> <TAB> token = self . get_token ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . states . append ( self . parse_indentless_sequence_entry ) <TAB> <TAB> <TAB> return self . parse_block_node ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . state = self . parse_indentless_sequence_entry <TAB> <TAB> <TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> token = self . peek_token ( ) <TAB> event = SequenceEndEvent ( token . start_mark , token . start_mark ) <TAB> self . state = self . states . pop ( ) <TAB> return event",if token . end_mark == BlockEntryToken . EOF :,"if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) :",False,92.57,68.81,,,
"def walk_directory ( directory , verbose = False ) : <TAB> """""" Iterates a directory ' s text files and their contents. """""" <TAB> for dir_path , _ , filenames in os . walk ( directory ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> file_path = os . path . join ( dir_path , filename ) <TAB> <TAB> <TAB> if os . path . isfile ( file_path ) and not filename . startswith ( "" . "" ) : <TAB> <TAB> <TAB> <TAB> with io . open ( file_path , "" r "" , encoding = "" utf-8 "" ) as file : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> print ( "" Reading  {} "" . format ( filename ) ) <TAB> <TAB> <TAB> <TAB> <TAB> doc_text = file . read ( ) <TAB> <TAB> <TAB> <TAB> <TAB> yield filename , doc_text",if verbose :,if verbose :,True,100.0,99.6,,,
"def set_bounds ( self , x , y , width , height ) : <TAB> if self . native : <TAB> <TAB> # Root level widgets may require vertical adjustment to <TAB> <TAB> # account for toolbars, etc. <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vertical_shift = self.frame.vertical_shift <TAB> <TAB> else: <TAB> <TAB> <TAB> vertical_shift = 0 <TAB> <TAB> self.native.Size = Size(width, height) <TAB> <TAB> self.native.Location = Point(x, y + vertical_shift)",if self . frame . vertical_shift :,if self . interface . parent is None :,False,95.75,69.73,,,
"def _check_x11 ( self , command = None , * , exc = None , exit_status = None , * * kwargs ) : <TAB> """""" Check requesting X11 forwarding """""" <TAB> with ( yield from self . connect ( ) ) as conn : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with self . assertRaises ( exc ) : <TAB> <TAB> <TAB> <TAB> yield from _create_x11_process ( conn , command , * * kwargs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> proc = yield from _create_x11_process ( conn , command , * * kwargs ) <TAB> <TAB> <TAB> yield from proc . wait ( ) <TAB> <TAB> <TAB> self . assertEqual ( proc . exit_status , exit_status ) <TAB> yield from conn . wait_closed ( )",if exc :,if exc :,True,100.0,99.54,,,
"def repr ( self ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> from infogami . infobase . utils import prepr <TAB> <TAB> <TAB> return prepr ( self . obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return repr ( self . obj ) <TAB> except : <TAB> <TAB> return "" failed "" <TAB> return render_template ( "" admin/memory/object "" , self . obj )",if self . debug :,"if isinstance ( self . obj , ( dict , web . threadeddict ) ) :",False,87.75,65.48,,,
"def add ( self , tag , values ) : <TAB> if tag not in self . different : <TAB> <TAB> if tag not in self : <TAB> <TAB> <TAB> self [ tag ] = values <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . different . add ( tag ) <TAB> <TAB> <TAB> self [ tag ] = [ "" "" ] <TAB> self . counts [ tag ] + = 1",if self . counts [ tag ] == 0 :,elif self [ tag ] != values :,False,91.33,69.16,,,
"def _on_geturl ( self , event ) : <TAB> selected = self . _status_list . get_selected ( ) <TAB> if selected != - 1 : <TAB> <TAB> object_id = self . _status_list . GetItemData ( selected ) <TAB> <TAB> download_item = self . _download_list . get_item ( object_id ) <TAB> <TAB> url = download_item . url <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> clipdata = wx . TextDataObject ( ) <TAB> <TAB> <TAB> clipdata . SetText ( url ) <TAB> <TAB> <TAB> wx . TheClipboard . Open ( ) <TAB> <TAB> <TAB> wx . TheClipboard . SetData ( clipdata ) <TAB> <TAB> <TAB> wx . TheClipboard . Close ( )",if wx . TheClipboard . IsOpened ( ) :,if not wx . TheClipboard . IsOpened ( ) :,False,98.69,73.19,,,
"def escape2null ( text ) : <TAB> """""" Return a string with escape-backslashes converted to nulls. """""" <TAB> parts = [ ] <TAB> start = 0 <TAB> while True : <TAB> <TAB> found = text . find ( "" \\ "" , start ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> parts . append ( text [ start : ] ) <TAB> <TAB> <TAB> return "" "" . join ( parts ) <TAB> <TAB> parts . append ( text [ start : found ] ) <TAB> <TAB> parts . append ( "" \x00 "" + text [ found + 1 : found + 2 ] ) <TAB> <TAB> start = found + 2 # skip character after escape",if found == - 1 :,if found == - 1 :,True,100.0,99.47,,,
def _process_inner_views ( self ) : <TAB> for view in self . baseviews : <TAB> <TAB> for inner_class in view . get_uninit_inner_views ( ) : <TAB> <TAB> <TAB> for v in self . baseviews : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> view . get_init_inner_views ( ) . append ( v ),"if isinstance ( v , inner_class ) :","if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) :",False,86.97,66.79,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26 : <TAB> <TAB> <TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34 : <TAB> <TAB> <TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 18 :,if tt == 18 :,True,100.0,74.57,,,
"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB> <TAB> if _file . suffix == "" .py "" and _file . name not in skip_files : <TAB> <TAB> <TAB> with _file . open ( ) as f : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB> <TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB> <TAB> for error in errors : <TAB> <TAB> <TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB> <TAB> print ( line [ : - 1 ] ) <TAB> <TAB> assert False",if f . read ( ) == comment :,if comment not in f . read ( ) :,False,97.69,72.62,,,
"def _get_planner ( name , path , source ) : <TAB> for klass in _planners : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> LOG . debug ( "" %r  accepted  %r  (filename  %r ) "" , klass , name , path ) <TAB> <TAB> <TAB> return klass <TAB> <TAB> LOG . debug ( "" %r  rejected  %r "" , klass , name ) <TAB> raise ansible . errors . AnsibleError ( NO_METHOD_MSG + repr ( invocation ) )",if klass . match ( path ) :,"if klass . detect ( path , source ) :",False,95.28,70.93,,,
"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB> <TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> idx - = 1 <TAB> <TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB> <TAB> _lt = _l . __class__ <TAB> <TAB> if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) : <TAB> <TAB> <TAB> ostream . write ( ""  -  "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ostream . write ( ""  +  "" )",if hasConst :,if hasConst :,True,100.0,74.54,,,
"def cluster_info_query ( self ) : <TAB> if self . _major_version > = 90600 : <TAB> <TAB> extra = ( <TAB> <TAB> <TAB> "" , CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END, "" <TAB> <TAB> <TAB> ""  slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver() "" <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> extra = "" timeline_id "" + extra + "" , pg_catalog.pg_control_checkpoint() "" <TAB> <TAB> else : <TAB> <TAB> <TAB> extra = "" 0 "" + extra <TAB> else : <TAB> <TAB> extra = "" 0, NULL, NULL, NULL "" <TAB> return ( "" SELECT  "" + self . TL_LSN + "" ,  {2} "" ) . format ( <TAB> <TAB> self . wal_name , self . lsn_name , extra <TAB> )",if self . _timeline_checkpoint :,"if self . role == ""standby_leader"" :",False,96.21,69.8,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> self . country = kwargs . pop ( "" country "" ) <TAB> self . fields_needed = kwargs . pop ( "" fields_needed "" , [ ] ) <TAB> super ( DynamicManagedAccountForm , self ) . __init__ ( * args , * * kwargs ) <TAB> # build our form using the country specific fields and falling <TAB> # back to our default set <TAB> for f in self.fields_needed: <TAB> <TAB> <IF-STMT> # pragma: no branch <TAB> <TAB> <TAB> field_name, field = FIELDS_BY_COUNTRY[self.country][f] <TAB> <TAB> <TAB> self.fields[field_name] = field",if f in FIELDS_BY_COUNTRY :,"if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :",False,93.76,69.55,,,
"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB> <TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB> <TAB> <TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB> <TAB> <TAB> if not query_map [ alias ] [ driver ] : <TAB> <TAB> <TAB> <TAB> query_map [ alias ] . pop ( driver ) <TAB> <TAB> if not query_map [ alias ] : <TAB> <TAB> <TAB> query_map . pop ( alias ) <TAB> return query_map","if vm_details [ ""vm_name"" ] == query_map [ alias ] [ driver ] :","if vm_details == ""Absent"" :",False,92.64,72.09,,,
"def on_strokes_edited ( self ) : <TAB> strokes = self . _strokes ( ) <TAB> if strokes : <TAB> <TAB> translation = self . _engine . raw_lookup ( strokes ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fmt = _ ( "" {strokes}  maps to  {translation} "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fmt = _ ( "" {strokes}  is not in the dictionary "" ) <TAB> <TAB> info = self . _format_label ( fmt , ( strokes , ) , translation ) <TAB> else : <TAB> <TAB> info = "" "" <TAB> self . strokes_info . setText ( info )",if translation :,if translation is not None :,False,97.26,71.85,,,
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> if self . owner != tid : <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> if self . waiters : <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( )",if self . count == 0 :,if self . count == 0 :,True,100.0,74.39,,,
"def _cat_blob ( self , gcs_uri ) : <TAB> """""" :py:meth:`cat_file`, minus decompression. """""" <TAB> blob = self . _get_blob ( gcs_uri ) <TAB> if not blob : <TAB> <TAB> return # don't cat nonexistent files <TAB> start = 0 <TAB> while True: <TAB> <TAB> end = start + _CAT_CHUNK_SIZE <TAB> <TAB> try: <TAB> <TAB> <TAB> chunk = blob.download_as_string(start=start, end=end) <TAB> <TAB> except google.api_core.exceptions.RequestRangeNotSatisfiable: <TAB> <TAB> <TAB> return <TAB> <TAB> yield chunk <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> start = end",if start >= end :,if len ( chunk ) < _CAT_CHUNK_SIZE :,False,93.88,95.3,,,
"def device_iter ( * * kwargs ) : <TAB> for dev in backend . enumerate_devices ( ) : <TAB> <TAB> d = Device ( dev , backend ) <TAB> <TAB> tests = ( val == _try_getattr ( d , key ) for key , val in kwargs . items ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> yield d",if tests :,if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) :,False,76.29,61.72,,,
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB> <TAB> <TAB> if isfile ( self . object ) : <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs","elif isinstance ( self . object , bytes ) :","elif hasattr ( self . object , ""read"" ) :",False,96.96,67.15,,,
"def _execute_with_error ( command , error , message ) : <TAB> try : <TAB> <TAB> cli . invocation = cli . invocation_cls ( <TAB> <TAB> <TAB> cli_ctx = cli , <TAB> <TAB> <TAB> parser_cls = cli . parser_cls , <TAB> <TAB> <TAB> commands_loader_cls = cli . commands_loader_cls , <TAB> <TAB> <TAB> help_cls = cli . help_cls , <TAB> <TAB> ) <TAB> <TAB> cli . invocation . execute ( command . split ( ) ) <TAB> except CLIError as ex : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" {} \n Expected:  {} \n Actual:  {} "" . format ( message , error , ex ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return <TAB> except Exception as ex : <TAB> <TAB> raise ex <TAB> raise AssertionError ( "" exception not raised for  ' {0} ' "" . format ( message ) )",if error :,if error not in str ( ex ) :,False,97.14,72.0,,,
"def ray_intersection ( self , p , line ) : <TAB> p = Vector ( center ( line . sites ) ) <TAB> min_r = BIG_FLOAT <TAB> nearest = None <TAB> for v_i , v_j in self . edges : <TAB> <TAB> bound = LineEquation2D . from_two_points ( v_i , v_j ) <TAB> <TAB> intersection = bound . intersect_with_line ( line ) <TAB> <TAB> if intersection is not None : <TAB> <TAB> <TAB> r = ( p - intersection ) . length <TAB> <TAB> <TAB> # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> nearest = intersection <TAB> <TAB> <TAB> <TAB> min_r = r <TAB> return nearest",if r < min_r :,if r < min_r :,True,100.0,74.5,,,
"def CalculateChecksum ( data ) : <TAB> # The checksum is just a sum of all the bytes. I swear. <TAB> if isinstance(data, bytearray): <TAB> <TAB> total = sum(data) <TAB> elif isinstance(data, bytes): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Python 2 bytes (str) index as single-character strings. <TAB> <TAB> <TAB> total = sum(map(ord, data)) <TAB> <TAB> else: <TAB> <TAB> <TAB> # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB> <TAB> <TAB> total = sum(data) <TAB> else: <TAB> <TAB> # Unicode strings (should never see?) <TAB> <TAB> total = sum(map(ord, data)) <TAB> return total & 0xFFFFFFFF",if PY2 :,"if data and isinstance ( data [ 0 ] , bytes ) :",False,93.98,68.87,,,
"def __mul__ ( self , other : Union [ "" Tensor "" , float ] ) - > "" Tensor "" : <TAB> if isinstance ( other , Tensor ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> errstr = ( <TAB> <TAB> <TAB> <TAB> f "" Given backens are inconsistent. Found  ' { self . backend . name } ' "" <TAB> <TAB> <TAB> <TAB> f "" and  ' { other . backend . name } ' "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise ValueError ( errstr ) <TAB> <TAB> other = other . array <TAB> array = self . backend . multiply ( self . array , other ) <TAB> return Tensor ( array , backend = self . backend )",if self . backend . name != other . backend . name :,if self . backend . name != other . backend . name :,True,100.0,74.52,,,
"def next_item ( self , direction ) : <TAB> """""" Selects next menu item, based on self._direction """""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self.select(start) <TAB> <TAB> <TAB> break <TAB> <TAB> if i >= len(self.items): <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0: <TAB> <TAB> <TAB> i = len(self.items) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self.select(i): <TAB> <TAB> <TAB> break <TAB> <TAB> i += direction <TAB> <TAB> if start < 0: <TAB> <TAB> <TAB> start = 0",if i == - 1 :,if i == start :,False,98.75,95.46,,,
"def resolve_none ( self , data ) : <TAB> # replace None to '_' <TAB> for tok_idx in range(len(data)): <TAB> <TAB> for feat_idx in range(len(data[tok_idx])): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data[tok_idx][feat_idx] = ""_"" <TAB> return data",if data [ tok_idx ] [ feat_idx ] == None :,if data [ tok_idx ] [ feat_idx ] is None :,False,96.95,70.98,,,
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> if n . _child . isidentical ( expr ) : <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> if not isinstance ( n , _strtypes ) : <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) )",if n not in fields :,elif n not in fields :,False,99.04,73.86,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24 : <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 10 :,if tt == 10 :,True,100.0,74.56,,,
"def func_std_string ( func_name ) : # match what old profile produced <TAB> if func_name[:2] == (""~"", 0): <TAB> <TAB> # special case for built-in functions <TAB> <TAB> name = func_name[2] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""{%s}"" % name[1:-1] <TAB> <TAB> else: <TAB> <TAB> <TAB> return name <TAB> else: <TAB> <TAB> return ""%s:%d(%s)"" % func_name","if name [ 0 ] == ""@"" :","if name . startswith ( ""<"" ) and name . endswith ( "">"" ) :",False,89.11,60.19,,,
"def f ( ) : <TAB> try : <TAB> <TAB> # Intra-buffer read then buffer-flushing read <TAB> <TAB> for n in cycle([1, 19]): <TAB> <TAB> <TAB> s = bufio.read(n) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # list.append() is atomic <TAB> <TAB> <TAB> results.append(s) <TAB> except Exception as e: <TAB> <TAB> errors.append(e) <TAB> <TAB> raise",if not s :,if not s :,True,100.0,74.06,,,
"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try: <TAB> <TAB> self.rpcserver.stop() <TAB> <TAB> if self.backend_rpcserver: <TAB> <TAB> <TAB> self.backend_rpcserver.stop() <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.cluster_rpcserver.stop() <TAB> except Exception: <TAB> <TAB> pass <TAB> if self.coordination: <TAB> <TAB> try: <TAB> <TAB> <TAB> coordination.COORDINATOR.stop() <TAB> <TAB> except Exception: <TAB> <TAB> <TAB> pass <TAB> super(Service, self).stop(graceful=True)",if self . cluster_rpcserver :,if self . cluster_rpcserver :,True,100.0,74.29,,,
"def download ( cls , architecture , path = "" ./ "" ) : <TAB> if cls . sanity_check ( architecture ) : <TAB> <TAB> architecture_file = download_file ( <TAB> <TAB> <TAB> cls . architecture_map [ architecture ] , directory = path <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return None <TAB> <TAB> print ( "" Coreml model  {}  is saved in [ {} ] "" . format ( architecture , path ) ) <TAB> <TAB> return architecture_file <TAB> else : <TAB> <TAB> return None",if not architecture_file :,if not architecture_file :,True,100.0,74.32,,,
"def opps_output_converter ( kpt_list ) : <TAB> kpts = [ ] <TAB> mpii_keys = to_opps_converter . keys ( ) <TAB> for mpii_idx in range ( 0 , 16 ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> model_idx = to_opps_converter [ mpii_idx ] <TAB> <TAB> <TAB> x , y = kpt_list [ model_idx ] <TAB> <TAB> <TAB> if x < 0 or y < 0 : <TAB> <TAB> <TAB> <TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> kpts + = [ x , y , 1.0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB> return kpts",if mpii_keys [ mpii_idx ] in to_opps_converter . keys ( ) :,if mpii_idx in mpii_keys :,False,93.33,71.67,,,
"def _get_headers ( self , headers = None ) : <TAB> request_headers = headers or { } <TAB> # Auth headers if access_token is present <TAB> if self._client.client.config: <TAB> <TAB> config = self._client.client.config <TAB> <TAB> if ""Authorization"" not in request_headers and config.token: <TAB> <TAB> <TAB> request_headers.update( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""Authorization"": ""{} {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> config.authentication_type, config.token <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> request_headers.update({config.header: config.header_service}) <TAB> return request_headers",if config . header_service :,if config . header and config . header_service :,False,98.44,72.21,,,
"def _get_headers ( self , headers = None ) : <TAB> request_headers = headers or { } <TAB> # Auth headers if access_token is present <TAB> if self._client.client.config: <TAB> <TAB> config = self._client.client.config <TAB> <TAB> if ""Authorization"" not in request_headers and config.token: <TAB> <TAB> <TAB> request_headers.update( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> ""Authorization"": ""{} {}"".format( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> config.authentication_type, config.token <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> request_headers.update({config.header: config.header_service}) <TAB> return request_headers",if config . header_service :,"if o [ ""symbol"" ] == convert_to_exchange_trading_pair ( trading_pair )",False,91.19,64.39,,,
"def reset_two_factor_hotp ( ) : <TAB> uid = request . form [ "" uid "" ] <TAB> otp_secret = request . form . get ( "" otp_secret "" , None ) <TAB> if otp_secret : <TAB> <TAB> user = Journalist . query . get ( uid ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) <TAB> <TAB> db . session . commit ( ) <TAB> <TAB> return redirect ( url_for ( "" admin.new_user_two_factor "" , uid = uid ) ) <TAB> else : <TAB> <TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid )",if user and user . two_factor_hotp_secret == otp_secret :,"if not validate_hotp_secret ( user , otp_secret ) :",False,93.23,70.78,,,
"def ctx_for_video ( self , vurl ) : <TAB> "" Get a context dict for a given video URL "" <TAB> ctx = self . get_context_dict ( ) <TAB> for portal , match , context_fn in self . PORTALS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ctx . update ( context_fn ( vurl ) ) <TAB> <TAB> <TAB> <TAB> ctx [ "" portal "" ] = portal <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> return ctx",if match and portal . match ( vurl ) :,if match . search ( vurl ) :,False,96.86,72.26,,,
"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB> <TAB> opts = dict ( ) <TAB> <TAB> opts [ "" type "" ] = "" episode "" <TAB> <TAB> result = guessit ( name , options = opts ) <TAB> <TAB> res = dict ( ) <TAB> <TAB> if "" episode "" in result : <TAB> <TAB> <TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" episode "" ] = 0 <TAB> <TAB> if "" season "" in result : <TAB> <TAB> <TAB> res [ "" season "" ] = result [ "" season "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" season "" ] = 0 <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB> <TAB> return jsonify ( data = res ) <TAB> else : <TAB> <TAB> return "" "" , 400","if ""subtitle_language"" in result :","if ""subtitle_language"" in result :",True,100.0,74.67,,,
"def package_files ( package_path , directory_name ) : <TAB> paths = [ ] <TAB> directory_path = os . path . join ( package_path , directory_name ) <TAB> for ( path , directories , filenames ) in os . walk ( directory_path ) : <TAB> <TAB> relative_path = os . path . relpath ( path , package_path ) <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . append ( os . path . join ( relative_path , filename ) ) <TAB> return paths","if not filename . endswith ( "".py"" ) :","if filename [ 0 ] == ""."" :",False,93.55,70.61,,,
"def parse_simple ( d , data ) : <TAB> units = { } <TAB> for v in data [ d ] : <TAB> <TAB> key = v [ "" name "" ] <TAB> <TAB> if not key : <TAB> <TAB> <TAB> continue <TAB> <TAB> key_to_insert = make_key ( key ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> index = 2 <TAB> <TAB> <TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB> <TAB> <TAB> while tmp in units : <TAB> <TAB> <TAB> <TAB> index + = 1 <TAB> <TAB> <TAB> <TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB> <TAB> <TAB> key_to_insert = tmp <TAB> <TAB> units [ key_to_insert ] = v [ "" id "" ] <TAB> return units",if units :,if key_to_insert in units :,False,96.73,73.08,,,
"def parse_clademodelc ( branch_type_no , line_floats , site_classes ) : <TAB> """""" Parse results specific to the clade model C. """""" <TAB> if not site_classes or len ( line_floats ) == 0 : <TAB> <TAB> return <TAB> for n in range ( len ( line_floats ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> site_classes [ n ] [ "" branch types "" ] = { } <TAB> <TAB> site_classes [ n ] [ "" branch types "" ] [ branch_type_no ] = line_floats [ n ] <TAB> return site_classes",if n not in site_classes :,"if site_classes [ n ] . get ( ""branch types"" ) is None :",False,90.33,80.9,,,
"def track_modules ( self , * modules ) : <TAB> """""" Add module names to the tracked list. """""" <TAB> already_tracked = self . session . GetParameter ( "" autodetect_build_local_tracked "" ) or [ ] <TAB> needed = set ( modules ) <TAB> if not needed . issubset ( already_tracked ) : <TAB> <TAB> needed . update ( already_tracked ) <TAB> <TAB> with self . session as session : <TAB> <TAB> <TAB> session . SetParameter ( "" autodetect_build_local_tracked "" , needed ) <TAB> <TAB> <TAB> for module_name in modules : <TAB> <TAB> <TAB> <TAB> module_obj = self . GetModuleByName ( module_name ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> # Clear the module's profile. This will force it to <TAB> <TAB> <TAB> <TAB> <TAB> # reload a new profile. <TAB> <TAB> <TAB> <TAB> <TAB> module_obj.profile = None",if module_obj :,if module_obj :,True,100.0,99.55,,,
"def set_job_on_hold ( self , value , blocking = True ) : <TAB> trigger = False <TAB> # don't run any locking code beyond this... <TAB> if not self._job_on_hold.acquire(blocking=blocking): <TAB> <TAB> return False <TAB> try: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self._job_on_hold.set() <TAB> <TAB> else: <TAB> <TAB> <TAB> self._job_on_hold.clear() <TAB> <TAB> <TAB> if self._job_on_hold.counter == 0: <TAB> <TAB> <TAB> <TAB> trigger = True <TAB> finally: <TAB> <TAB> self._job_on_hold.release() <TAB> # locking code is now safe to run again <TAB> if trigger: <TAB> <TAB> self._continue_sending() <TAB> return True",if value :,if value :,True,100.0,74.33,,,
"def moveToThreadNext ( self ) : <TAB> """""" Move a position to threadNext position. """""" <TAB> p = self <TAB> if p . v : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> p . moveToFirstChild ( ) <TAB> <TAB> elif p . hasNext ( ) : <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> while p : <TAB> <TAB> <TAB> <TAB> if p . hasNext ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> <TAB> <TAB> <TAB> break # found <TAB> <TAB> <TAB> <TAB> p.moveToParent() <TAB> <TAB> <TAB> # not found. <TAB> return p",if p . hasNext ( ) :,if p . v . children :,False,97.9,96.05,,,
"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images[0] <TAB> for img in images: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> elif img.width >= width and img.width * img.height > image.width * image.height: <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image",if img . width == width and img . height == height :,if img . width == width and img . height == height :,True,100.0,74.33,,,
"def _check_input_types ( self ) : <TAB> if len ( self . base_features ) == 0 : <TAB> <TAB> return True <TAB> input_types = self . primitive . input_types <TAB> if input_types is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> input_types = [ input_types ] <TAB> <TAB> for t in input_types : <TAB> <TAB> <TAB> zipped = list ( zip ( t , self . base_features ) ) <TAB> <TAB> <TAB> if all ( [ issubclass ( f . variable_type , v ) for v , f in zipped ] ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return True <TAB> return False","if not isinstance ( input_types , list ) :",if type ( input_types [ 0 ] ) != list :,False,94.66,70.72,,,
"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB> <TAB> try : <TAB> <TAB> <TAB> result_list . append ( f . get_result ( ) ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> if exc_info is None : <TAB> <TAB> <TAB> <TAB> exc_info = sys . exc_info ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB> <TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB> <TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB> <TAB> return list ( result_list )",if e . args [ 0 ] in self . _multiple_exceptions :,"if not isinstance ( e , self . quiet_exceptions ) :",False,95.15,71.35,,,
"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB> <TAB> if step_num < hparams . lrn_step : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 10 <TAB> <TAB> elif step_num < 35000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 100 <TAB> <TAB> else : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB> <TAB> fd [ model . lrn_rate ] = lrn_rate",elif step_num < 10000 :,elif step_num < 30000 :,False,98.82,73.38,,,
"def topic_exists ( self , arn ) : <TAB> response = self . _conn . get_all_topics ( ) <TAB> topics = response [ "" ListTopicsResponse "" ] [ "" ListTopicsResult "" ] [ "" Topics "" ] <TAB> current_topics = [ ] <TAB> if len ( topics ) > 0 : <TAB> <TAB> for topic in topics : <TAB> <TAB> <TAB> topic_arn = topic [ "" TopicArn "" ] <TAB> <TAB> <TAB> current_topics . append ( topic_arn ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if arn in current_topics :,if arn in current_topics :,True,100.0,74.33,,,
"def assertStartsWith ( self , expectedPrefix , text , msg = None ) : <TAB> if not text . startswith ( expectedPrefix ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> text = text [ : len ( expectedPrefix ) + 5 ] + "" ... "" <TAB> <TAB> standardMsg = "" {}  not found at the start of  {} "" . format ( <TAB> <TAB> <TAB> repr ( expectedPrefix ) , repr ( text ) <TAB> <TAB> ) <TAB> <TAB> self . fail ( self . _formatMessage ( msg , standardMsg ) )",if msg is None :,if len ( expectedPrefix ) + 5 < len ( text ) :,False,90.86,68.49,,,
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> <IF-STMT> # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re.match(PROCTYPE_MATCH, k): <TAB> <TAB> <TAB> raise serializers.ValidationError(""Process types can only contain [a-z]"") <TAB> <TAB> if not re.match(MEMLIMIT_MATCH, str(v)): <TAB> <TAB> <TAB> raise serializers.ValidationError( <TAB> <TAB> <TAB> <TAB> ""Limit format: <number><unit>, where unit = B, K, M or G"" <TAB> <TAB> <TAB> ) <TAB> return value",if v is NoneType :,if v is None :,False,98.6,72.73,,,
"def open ( self ) - > "" KeyValueJsonDb "" : <TAB> """""" Create a new data base or open existing one """""" <TAB> if os . path . exists ( self . _name ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( self . _name , "" r "" ) as _in : <TAB> <TAB> <TAB> <TAB> self . set_records ( json . load ( _in ) ) <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> # file corrupted, reset it. <TAB> <TAB> <TAB> self.commit() <TAB> else: <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath(os.path.dirname(self._name)) <TAB> <TAB> self.commit() <TAB> return self",if not os . path . isfile ( self . _name ) :,if not os . path . isfile ( self . _name ) :,True,100.0,99.57,,,
"def _calculate ( self ) : <TAB> before = self . before . data <TAB> after = self . after . data <TAB> self . deleted = { } <TAB> self . updated = { } <TAB> self . created = after . copy ( ) <TAB> for path , f in before . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . deleted [ path ] = f <TAB> <TAB> <TAB> continue <TAB> <TAB> del self . created [ path ] <TAB> <TAB> if f . mtime < after [ path ] . mtime : <TAB> <TAB> <TAB> self . updated [ path ] = after [ path ]",if path in self . created :,if path not in after :,False,96.72,72.31,,,
"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d: list = async_to_sync(get_account_id_to_name_mapping)() <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d.keys(): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> <TAB> else: <TAB> <TAB> <TAB> if account_id in config.get(""celery.test_account_ids"", []): <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account.delay(account_id) <TAB> stats.count(f""{function}.success"") <TAB> return True","if account_id in config . get ( ""celery.test_account_ids"" , [ ] ) :","if config . get ( ""environment"" ) == ""prod"" :",False,92.94,65.81,,,
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> if defaults is None : <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass",if config is None :,if config is None :,True,100.0,74.6,,,
"def PopulateProjectId ( project_id = None ) : <TAB> """""" Fills in a project_id from the boto config file if one is not provided. """""" <TAB> if not project_id : <TAB> <TAB> default_id = boto . config . get_value ( "" GSUtil "" , "" default_project_id "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProjectIdException ( "" MissingProjectId "" ) <TAB> <TAB> return default_id <TAB> return project_id",if default_id is None :,if not default_id :,False,95.78,94.98,,,
"def set ( self , name , value ) : <TAB> with self . _object_cache_lock : <TAB> <TAB> old_value = self . _object_cache . get ( name ) <TAB> <TAB> ret = not old_value or int ( old_value . metadata . resource_version ) < int ( <TAB> <TAB> <TAB> value . metadata . resource_version <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _object_cache [ name ] = value <TAB> return ret , old_value",if ret :,if ret :,True,100.0,74.19,,,
"def remove ( self , url ) : <TAB> try : <TAB> <TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> was_selected = i in self . selectedindices ( ) <TAB> <TAB> self . list . delete ( i ) <TAB> <TAB> del self . items [ i ] <TAB> <TAB> if not self . items : <TAB> <TAB> <TAB> self . mp . hidepanel ( self . name ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if i > = len ( self . items ) : <TAB> <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> self . list . select_set ( i )",if was_selected :,elif was_selected :,False,98.72,73.44,,,
"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB> <TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB> <TAB> path = join ( dir_path , p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files(path, paths) <TAB> <TAB> elif isfile(path) and path.endswith("".csv""): <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths.append(path) <TAB> return paths",if isdir ( path ) and isdir ( path ) :,if isdir ( path ) :,False,97.15,72.96,,,
"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if isinstance ( value , dict ) : <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient ( <TAB> <TAB> <TAB> <TAB> <TAB> key , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" api_version "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" support_list_or_not "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" resource_get_api_version "" ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value ( ) <TAB> raise CLIError ( <TAB> <TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> )","if isinstance ( value , resource_provider ) :",if str . lower ( key ) == str . lower ( resource_provider ) :,False,94.72,70.32,,,
"def compute_rule_hash ( self , rule ) : <TAB> buf = "" %d - %d - %s - "" % ( <TAB> <TAB> rule . get ( "" FromPort "" , 0 ) or 0 , <TAB> <TAB> rule . get ( "" ToPort "" , 0 ) or 0 , <TAB> <TAB> rule . get ( "" IpProtocol "" , "" -1 "" ) or "" -1 "" , <TAB> ) <TAB> for a , ke in self . RULE_ATTRS : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> ev = [ e [ ke ] for e in rule [ a ] ] <TAB> <TAB> ev . sort ( ) <TAB> <TAB> for e in ev : <TAB> <TAB> <TAB> buf + = "" %s - "" % e <TAB> # mask to generate the same numeric value across all Python versions <TAB> return zlib.crc32(buf.encode(""ascii"")) & 0xFFFFFFFF",if ke not in rule :,if a not in rule :,False,98.89,73.8,,,
"def analysis_sucess_metrics ( analysis_time : float , allow_exception = False ) : <TAB> try : <TAB> <TAB> anchore_engine . subsys . metrics . counter_inc ( name = "" anchore_analysis_success "" ) <TAB> <TAB> anchore_engine . subsys . metrics . histogram_observe ( <TAB> <TAB> <TAB> "" anchore_analysis_time_seconds "" , <TAB> <TAB> <TAB> analysis_time , <TAB> <TAB> <TAB> buckets = ANALYSIS_TIME_SECONDS_BUCKETS , <TAB> <TAB> <TAB> status = "" success "" , <TAB> <TAB> ) <TAB> except : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing "" <TAB> <TAB> <TAB> )",if allow_exception :,if allow_exception :,True,100.0,74.47,,,
"def decide_file_icon ( file ) : <TAB> if file . state == File . ERROR : <TAB> <TAB> return FileItem . icon_error <TAB> elif isinstance ( file . parent , Track ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return FileItem . icon_saved <TAB> <TAB> elif file . state == File . PENDING : <TAB> <TAB> <TAB> return FileItem . match_pending_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return FileItem . match_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB> elif file . state == File . PENDING : <TAB> <TAB> return FileItem . icon_file_pending <TAB> else : <TAB> <TAB> return FileItem . icon_file",if file . state == File . SAVE :,if file . state == File . NORMAL :,False,98.75,73.56,,,
"def deleteMenu ( self , menuName ) : <TAB> try : <TAB> <TAB> menu = self . getMenu ( menuName ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . destroy ( menu ) <TAB> <TAB> <TAB> self . destroyMenu ( menuName ) <TAB> <TAB> else : <TAB> <TAB> <TAB> g . es ( "" can ' t delete menu: "" , menuName ) <TAB> except Exception : <TAB> <TAB> g . es ( "" exception deleting "" , menuName , "" menu "" ) <TAB> <TAB> g . es_exception ( )",if menu :,if menu :,True,100.0,74.31,,,
"def parser ( cls , buf ) : <TAB> ( type_ , code , csum ) = struct . unpack_from ( cls . _PACK_STR , buf ) <TAB> msg = cls ( type_ , code , csum ) <TAB> offset = cls . _MIN_LEN <TAB> if len ( buf ) > offset : <TAB> <TAB> cls_ = cls . _ICMPV6_TYPES . get ( type_ , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> msg . data = cls_ . parser ( buf , offset ) <TAB> <TAB> else : <TAB> <TAB> <TAB> msg . data = buf [ offset : ] <TAB> return msg , None , None",if cls_ :,if cls_ :,True,100.0,74.42,,,
"def _load_dataset_area ( self , dsid , file_handlers , coords ) : <TAB> """""" Get the area for *dsid*. """""" <TAB> try : <TAB> <TAB> return self . _load_area_def ( dsid , file_handlers ) <TAB> except NotImplementedError : <TAB> <TAB> if any ( x is None for x in coords ) : <TAB> <TAB> <TAB> logger . warning ( "" Failed to load coordinates for  ' {} ' "" . format ( dsid ) ) <TAB> <TAB> <TAB> return None <TAB> <TAB> area = self . _make_area_from_coords ( coords ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( "" No coordinates found for  %s "" , str ( dsid ) ) <TAB> <TAB> return area",if area is None :,if area is None :,True,100.0,99.51,,,
"def __getattr__ ( self , name ) : <TAB> if Popen . verbose : <TAB> <TAB> sys . stdout . write ( "" Getattr:  %s ... "" % name ) <TAB> if name in Popen . __slots__ : <TAB> <TAB> return object . __getattribute__ ( self , name ) <TAB> else : <TAB> <TAB> if self . popen is not None : <TAB> <TAB> <TAB> if Popen . verbose : <TAB> <TAB> <TAB> <TAB> print ( "" from Popen "" ) <TAB> <TAB> <TAB> return getattr ( self . popen , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return self . emu_wait <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise Exception ( "" subprocess emulation: not implemented:  %s "" % name )",if self . emu_wait is not None :,"if name == ""wait"" :",False,95.96,67.41,,,
"def update ( self , time_delta ) : <TAB> super ( ) . update ( time_delta ) <TAB> n = self . menu . selected_option <TAB> if n == self . last : <TAB> <TAB> return <TAB> self . last = n <TAB> s = "" "" <TAB> for i in range ( len ( self . files ) ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> for l in open ( self . files [ i ] [ 1 ] ) : <TAB> <TAB> <TAB> <TAB> x = l . strip ( ) <TAB> <TAB> <TAB> <TAB> if len ( x ) > 1 and x [ 0 ] == "" # "" : <TAB> <TAB> <TAB> <TAB> <TAB> x = "" <b><u> "" + x [ 1 : ] + ""  </u></b> "" <TAB> <TAB> <TAB> <TAB> s + = x + "" <br> "" <TAB> self . set_text ( s )","if self . files [ i ] [ 0 ] == "".txt"" :",if self . files [ i ] [ 0 ] == n :,False,97.84,69.45,,,
"def wrapper ( * args , * * kwargs ) : <TAB> list_args , empty = _apply_defaults ( func , args , kwargs ) <TAB> if len ( dimensions ) > len ( list_args ) : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" %s  takes  %i  parameters, but  %i  dimensions were passed "" <TAB> <TAB> <TAB> % ( func . __name__ , len ( list_args ) , len ( dimensions ) ) <TAB> <TAB> ) <TAB> for dim , value in zip ( dimensions , list_args ) : <TAB> <TAB> if dim is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val_dim = ureg . get_dimensionality ( value ) <TAB> <TAB> <TAB> raise DimensionalityError ( value , "" a quantity of "" , val_dim , dim ) <TAB> return func ( * args , * * kwargs )","if isinstance ( value , int ) :",if not ureg . Quantity ( value ) . check ( dim ) :,False,94.97,70.81,,,
"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB> <TAB> for width in VALUES : <TAB> <TAB> <TAB> strlen = abs ( width * height ) <TAB> <TAB> <TAB> if size : <TAB> <TAB> <TAB> <TAB> strlen * = size <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> data = "" A "" * strlen <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> if size : <TAB> <TAB> <TAB> <TAB> arguments = ( data , size , width , height ) + extra <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arguments = ( data , width , height ) + extra <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> func ( * arguments ) <TAB> <TAB> <TAB> except ( ValueError , imageop . error ) : <TAB> <TAB> <TAB> <TAB> pass",if strlen > 0 :,if strlen < MAX_LEN :,False,98.04,73.59,,,
"def wait_send_all_might_not_block ( self ) - > None : <TAB> with self . _send_conflict_detector : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise trio . ClosedResourceError ( "" file was already closed "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> await trio . lowlevel . wait_writable ( self . _fd_holder . fd ) <TAB> <TAB> except BrokenPipeError as e : <TAB> <TAB> <TAB> # kqueue: raises EPIPE on wait_writable instead <TAB> <TAB> <TAB> # of sending, which is annoying <TAB> <TAB> <TAB> raise trio.BrokenResourceError from e",if self . _fd_holder . fd is not None :,if self . _fd_holder . closed :,False,96.69,72.23,,,
"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB> <TAB> if "" = "" in p : <TAB> <TAB> <TAB> tab = p . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tab [ 0 ] = "" SOCKS4 "" <TAB> <TAB> <TAB> proxies . append ( <TAB> <TAB> <TAB> <TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB> <TAB> <TAB> ) # type, addr:port, username, password <TAB> <TAB> else: <TAB> <TAB> <TAB> proxies.append((""HTTP"", p, None, None)) <TAB> return proxies","if tab [ 0 ] == ""SOCKS4"" :","if tab [ 0 ] == ""socks"" :",False,98.78,73.47,,,
"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB> <TAB> return passed_class <TAB> else : <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> if isinstance(pyclass, pyobjects.AbstractClass): <TAB> <TAB> <TAB> supers = pyclass.get_superclasses() <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return pyobjects.PyObject(supers[0]) <TAB> <TAB> return passed_self",if len ( supers ) == 1 :,if supers :,False,95.21,71.21,,,
"def update_output_mintime ( job ) : <TAB> try : <TAB> <TAB> return output_mintime [ job ] <TAB> except KeyError : <TAB> <TAB> for job_ in chain ( [ job ] , self . depending [ job ] ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> t = output_mintime [ job_ ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> t = job_ . output_mintime <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> output_mintime [ job ] = t <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> output_mintime [ job ] = None",if t is not None :,if t is not None :,True,100.0,74.4,,,
"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB> <TAB> for x in notifications_list : <TAB> <TAB> <TAB> split_provider_id = x . split ( "" : "" ) # email:id <TAB> <TAB> <TAB> if len(split_provider_id) == 2: <TAB> <TAB> <TAB> <TAB> _id = split_provider_id[1] <TAB> <TAB> <TAB> <TAB> cursor = self.get_by_id(_id) <TAB> <TAB> <TAB> <TAB> <IF-STMT> # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result.append(cursor) <TAB> return result",if cursor :,if cursor :,True,100.0,74.29,,,
"def stop ( self ) : <TAB> with self . lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return <TAB> <TAB> self . task_queue . put ( None ) <TAB> <TAB> self . result_queue . put ( None ) <TAB> <TAB> process = self . process <TAB> <TAB> self . process = None <TAB> <TAB> self . task_queue = None <TAB> <TAB> self . result_queue = None <TAB> process . join ( timeout = 0.1 ) <TAB> if process . exitcode is None : <TAB> <TAB> os . kill ( process . pid , signal . SIGKILL ) <TAB> <TAB> process . join ( )",if self . process is None :,if not self . process :,False,96.96,72.25,,,
"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB> <TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB> <TAB> <TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB> <TAB> choice = data [ "" choice "" ] <TAB> <TAB> if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) : <TAB> <TAB> <TAB> return flask . abort ( <TAB> <TAB> <TAB> <TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _answer_prompt ( choice )",if not self . _prompt :,if self . _prompt is None :,False,97.69,72.59,,,
"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames: <TAB> <TAB> logging.info(""[osx] receiving from macOS : %s"", filename) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if sabnzbd.filesystem.get_ext(filename) in VALID_ARCHIVES + VALID_NZB_FILES: <TAB> <TAB> <TAB> <TAB> sabnzbd.add_nzbfile(filename, keep=True)",if os . path . exists ( filename ) :,if os . path . exists ( filename ) :,True,100.0,74.04,,,
"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self.CloseFailureIO() <TAB> with support.catch_unraisable_exception() as cm: <TAB> <TAB> with self.assertRaises(AttributeError): <TAB> <TAB> <TAB> self.tp(rawio).xyzzy <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self.assertIsNone(cm.unraisable) <TAB> <TAB> elif cm.unraisable is not None: <TAB> <TAB> <TAB> self.assertEqual(cm.unraisable.exc_type, OSError)",if cm . unraisable is not None :,if not IOBASE_EMITS_UNRAISABLE :,False,95.53,70.16,,,
"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> f = urllib . urlopen ( url , postdata ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = urllib . urlopen ( url ) <TAB> <TAB> response = f . read ( ) <TAB> except : <TAB> <TAB> import traceback <TAB> <TAB> import logging , sys <TAB> <TAB> cla , exc , tb = sys . exc_info ( ) <TAB> <TAB> logging . error ( url ) <TAB> <TAB> if postdata : <TAB> <TAB> <TAB> logging . error ( "" with post data "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . error ( "" without post data "" ) <TAB> <TAB> logging . error ( exc . args ) <TAB> <TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB> <TAB> response = "" "" <TAB> return response",if postdata :,if postdata != { } :,False,97.75,73.24,,,
"def check_single_file ( fn , fetchuri ) : <TAB> """""" Determine if a single downloaded file is something we can ' t handle """""" <TAB> with open ( fn , "" r "" , errors = "" surrogateescape "" ) as f : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> ' Fetching  "" %s ""  returned a single HTML page - check the URL is correct and functional ' <TAB> <TAB> <TAB> <TAB> % fetchuri <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 )",if f . read ( fetchuri ) == fetchuri :,"if ""<html"" in f . read ( 100 ) . lower ( ) :",False,91.37,64.49,,,
"def update_properties ( self , update_dict ) : <TAB> signed_attribute_changed = False <TAB> for k , value in update_dict . items ( ) : <TAB> <TAB> if getattr ( self , k ) != value : <TAB> <TAB> <TAB> setattr ( self , k , value ) <TAB> <TAB> <TAB> signed_attribute_changed = signed_attribute_changed or ( <TAB> <TAB> <TAB> <TAB> k in self . payload_arguments <TAB> <TAB> <TAB> ) <TAB> if signed_attribute_changed : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . status = UPDATED <TAB> <TAB> self . timestamp = clock . tick ( ) <TAB> <TAB> self . sign ( ) <TAB> return self",if self . status == SIGNING :,if self . status != NEW :,False,97.76,72.86,,,
"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB> <TAB> if event != item . event : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB> <TAB> if item . has_variations : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> )",if variations not in item . variations :,if not any ( var . item == item for var in variations ) :,False,92.68,68.91,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18 : <TAB> <TAB> <TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.56,,,
"def connections ( self ) : <TAB> # Connections look something like this: <TAB> # socket:[102422] <TAB> fds = self.open_files <TAB> socket = ""socket:["" <TAB> result = [] <TAB> functions = [pwndbg.net.tcp, pwndbg.net.unix, pwndbg.net.netlink] <TAB> for fd, path in fds.items(): <TAB> <TAB> if socket not in path: <TAB> <TAB> <TAB> continue <TAB> <TAB> inode = path[len(socket) : -1] <TAB> <TAB> inode = int(inode) <TAB> <TAB> for func in functions: <TAB> <TAB> <TAB> for x in func(): <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> x.fd = fd <TAB> <TAB> <TAB> <TAB> <TAB> result.append(x) <TAB> return tuple(result)",if x . inode == inode :,if x . inode == inode :,True,100.0,74.42,,,
"def _movement_finished ( self ) : <TAB> if self . in_ship_map : <TAB> <TAB> # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ship = self.session.world.ship_map.get(self._next_target.to_tuple()) <TAB> <TAB> <TAB> if ship is not None and ship() is self: <TAB> <TAB> <TAB> <TAB> del self.session.world.ship_map[self._next_target.to_tuple()] <TAB> super()._movement_finished()",if self . _next_target . to_tuple ( ) not in self . session . world . ship_map :,if self . _next_target is not None :,False,90.05,67.62,,,
"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 : # at least one complete IP address <TAB> <TAB> while 1: <TAB> <TAB> <TAB> if p + 1 == self.get_ptr(): <TAB> <TAB> <TAB> <TAB> tmp_str += ""#"" <TAB> <TAB> <TAB> tmp_str += self.get_ip_address(p) <TAB> <TAB> <TAB> p += 4 <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> tmp_str += "", "" <TAB> tmp_str += ""] "" <TAB> if self.get_ptr() % 4: # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str += ""nonsense ptr field: %d "" % self.get_ptr() <TAB> return tmp_str",if p >= 7 :,if p >= self . get_len ( ) :,False,96.8,72.0,,,
"def source_shapes ( self ) : <TAB> """""" Prints debug information about the sources in this provider. """""" <TAB> if logger . isEnabledFor ( logging . DEBUG ) : <TAB> <TAB> for i , source in enumerate ( self . sources ) : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> name = "" anonymous "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = self . keys [ i ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> shape = source . shape ( ) <TAB> <TAB> <TAB> except NotImplementedError : <TAB> <TAB> <TAB> <TAB> shape = "" N/A "" <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> ' Data source  "" %s "" : entries= %s , shape= %s ' , name , len ( source ) , shape <TAB> <TAB> <TAB> )",if i == 0 :,if self . keys is None :,False,97.33,93.9,,,
def swap_actions ( actions ) : <TAB> for mutexgroup in mutex_groups : <TAB> <TAB> mutex_actions = mutexgroup . _group_actions <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # make a best guess as to where we should store the group <TAB> <TAB> <TAB> targetindex = actions.index(mutexgroup._group_actions[0]) <TAB> <TAB> <TAB> # insert the _ArgumentGroup container <TAB> <TAB> <TAB> actions[targetindex] = mutexgroup <TAB> <TAB> <TAB> # remove the duplicated individual actions <TAB> <TAB> <TAB> actions = [action for action in actions if action not in mutex_actions] <TAB> return actions,if mutexgroup . _group_actions :,"if contains_actions ( mutex_actions , actions ) :",False,93.89,56.93,,,
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> if not dep_cnts : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> if dep_cnt : <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps(services, container_by_name, dep_cnt, init_service) <TAB> <TAB> <TAB> deps.update(new_deps) <TAB> return deps",if dep_cnt [ 0 ] not in init_service :,"if init_service and init_service in dep_cnt [ ""_deps"" ] :",False,93.96,63.92,,,
"def make_dump_list_by_name_list ( name_list ) : <TAB> info_list = [ ] <TAB> for info_name in name_list : <TAB> <TAB> info = next ( ( x for x in DUMP_LIST if x . info_name == info_name ) , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RuntimeError ( ' Unknown info name:  "" {} "" ' . format ( info_name ) ) <TAB> <TAB> info_list . append ( info ) <TAB> return info_list",if info is None :,if not info :,False,96.78,71.56,,,
"def create ( self , private = False ) : <TAB> try : <TAB> <TAB> if private : <TAB> <TAB> <TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( <TAB> <TAB> <TAB> <TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e )",if e . response . status_code == 404 :,"if e . error == ""user_is_bot"" :",False,95.93,70.01,,,
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> if j == - 1 : <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> if reply == "" !done "" : <TAB> <TAB> <TAB> return r",if not i :,if len ( i ) == 0 :,False,96.72,72.45,,,
"def _load_logfile ( self , lfn ) : <TAB> enc_key = self . decryption_key_func ( ) <TAB> with open ( os . path . join ( self . logdir , lfn ) ) as fd : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> with DecryptingStreamer ( <TAB> <TAB> <TAB> <TAB> fd , mep_key = enc_key , name = "" EventLog/DS( %s ) "" % lfn <TAB> <TAB> <TAB> ) as streamer : <TAB> <TAB> <TAB> <TAB> lines = streamer . read ( ) <TAB> <TAB> <TAB> <TAB> streamer . verify ( _raise = IOError ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lines = fd . read ( ) <TAB> <TAB> if lines : <TAB> <TAB> <TAB> for line in lines . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> event = Event . Parse ( line . strip ( ) ) <TAB> <TAB> <TAB> <TAB> self . _events [ event . event_id ] = event",if self . decrypt :,if enc_key :,False,98.26,73.49,,,
"def set_ok_port ( self , cookie , request ) : <TAB> if cookie . port_specified : <TAB> <TAB> req_port = request_port ( request ) <TAB> <TAB> if req_port is None : <TAB> <TAB> <TAB> req_port = "" 80 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> req_port = str ( req_port ) <TAB> <TAB> for p in cookie . port . split ( "" , "" ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> int ( p ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> debug ( "" bad port  %s  (not numeric) "" , p ) <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> debug ( "" request port ( %s ) not found in  %s "" , req_port , cookie . port ) <TAB> <TAB> <TAB> return False <TAB> return True",if p == req_port :,if p == req_port :,True,100.0,74.62,,,
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> if attr not in node . attributes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> if attval . value_callback : <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value",if nodeid not in self . _nodes :,if nodeid not in self . _nodes :,True,100.0,74.61,,,
"def data_logging_status ( self , trail_name , trail_details , api_client ) : <TAB> for es in api_client . get_event_selectors ( TrailName = trail_name ) [ "" EventSelectors "" ] : <TAB> <TAB> has_wildcard = { <TAB> <TAB> <TAB> u "" Values "" : [ u "" arn:aws:s3::: "" ] , <TAB> <TAB> <TAB> u "" Type "" : u "" AWS::S3::Object "" , <TAB> <TAB> } in es [ "" DataResources "" ] <TAB> <TAB> is_logging = trail_details [ "" IsLogging "" ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if has_wildcard and is_logging :,if has_wildcard and is_logging and self . is_fresh ( trail_details ) :,False,93.17,70.26,,,
"def pytest_deselected ( items ) : <TAB> if sb_config . dashboard : <TAB> <TAB> sb_config . item_count - = len ( items ) <TAB> <TAB> for item in items : <TAB> <TAB> <TAB> test_id , display_id = _get_test_ids_ ( item ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> sb_config . _results . pop ( test_id )",if test_id in sb_config . _results :,if test_id in sb_config . _results . keys ( ) :,False,95.52,70.02,,,
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> if self . _flags [ fname ] == 1 : <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> if fname not in self . _flags : <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func )",if output in input :,if output == input :,False,98.73,73.92,,,
"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if firstHeading : <TAB> <TAB> <TAB> <TAB> output ( "" |} "" ) <TAB> <TAB> <TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else : <TAB> <TAB> <TAB> output ( "" |- "" ) <TAB> <TAB> <TAB> output ( <TAB> <TAB> <TAB> <TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB> <TAB> <TAB> <TAB> + m [ 0 ] <TAB> <TAB> <TAB> <TAB> + "" </tt></span> || ||  "" <TAB> <TAB> <TAB> <TAB> + m [ 1 ] <TAB> <TAB> <TAB> ) <TAB> output ( "" |} "" )","if m [ 0 ] == ""header"" :","if m [ 0 ] == """" :",False,98.98,52.74,,,
"def test_getitem ( self ) : <TAB> n = 200 <TAB> d = deque ( range ( n ) ) <TAB> l = list ( range ( n ) ) <TAB> for i in range ( n ) : <TAB> <TAB> d . popleft ( ) <TAB> <TAB> l . pop ( 0 ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d . append ( i ) <TAB> <TAB> <TAB> l . append ( i ) <TAB> <TAB> for j in range ( 1 - len ( l ) , len ( l ) ) : <TAB> <TAB> <TAB> assert d [ j ] == l [ j ] <TAB> d = deque ( "" superman "" ) <TAB> self . assertEqual ( d [ 0 ] , "" s "" ) <TAB> self . assertEqual ( d [ - 1 ] , "" n "" ) <TAB> d = deque ( ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , 0 ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , - 1 )",if len ( d ) == n :,if random . random ( ) < 0.5 :,False,96.8,72.52,,,
"def get_num ( line , char_ptr , num_chars ) : <TAB> char_ptr = char_ptr + 1 <TAB> numstr = "" "" <TAB> good = "" -.0123456789 "" <TAB> while char_ptr < num_chars : <TAB> <TAB> digit = line [ char_ptr ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> numstr = numstr + digit <TAB> <TAB> <TAB> char_ptr = char_ptr + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return numstr",if digit in good :,if good . find ( digit ) != - 1 :,False,92.19,68.09,,,
"def read_digits ( source , start , first_code ) : <TAB> body = source . body <TAB> position = start <TAB> code = first_code <TAB> if code is not None and 48 < = code < = 57 : # 0 - 9 <TAB> <TAB> while True: <TAB> <TAB> <TAB> position += 1 <TAB> <TAB> <TAB> code = char_code_at(body, position) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return position <TAB> raise GraphQLSyntaxError( <TAB> <TAB> source, <TAB> <TAB> position, <TAB> <TAB> u""Invalid number, expected digit but got: {}."".format(print_char_code(code)), <TAB> )","if code == u""0"" :",if not ( code is not None and 48 <= code <= 57 ) :,False,92.24,58.88,,,
"def get_aws_metadata ( headers , provider = None ) : <TAB> if not provider : <TAB> <TAB> provider = boto . provider . get_default ( ) <TAB> metadata_prefix = provider . metadata_prefix <TAB> metadata = { } <TAB> for hkey in headers . keys ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> val = urllib . unquote_plus ( headers [ hkey ] ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = unicode ( val , "" utf-8 "" ) <TAB> <TAB> <TAB> except UnicodeDecodeError : <TAB> <TAB> <TAB> <TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = val <TAB> <TAB> <TAB> del headers [ hkey ] <TAB> return metadata",if hkey . startswith ( metadata_prefix ) :,if hkey . lower ( ) . startswith ( metadata_prefix ) :,False,97.76,72.86,,,
"def _process_rtdest ( self ) : <TAB> LOG . debug ( "" Processing RT NLRI destination... "" ) <TAB> if self . _rtdest_queue . is_empty ( ) : <TAB> <TAB> return <TAB> else : <TAB> <TAB> processed_any = False <TAB> <TAB> while not self . _rtdest_queue . is_empty ( ) : <TAB> <TAB> <TAB> # We process the first destination in the queue. <TAB> <TAB> <TAB> next_dest = self._rtdest_queue.pop_first() <TAB> <TAB> <TAB> if next_dest: <TAB> <TAB> <TAB> <TAB> next_dest.process() <TAB> <TAB> <TAB> <TAB> processed_any = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Since RT destination were updated we update RT filters <TAB> <TAB> <TAB> self._core_service.update_rtfilters()",if processed_any :,if processed_any :,True,100.0,74.43,,,
"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB> <TAB> if header_name in headers : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB> <TAB> <TAB> return headers . get ( header_name )",if self . revs_enabled :,if self . revs_enabled :,True,100.0,74.51,,,
"def add_external_deps ( self , deps ) : <TAB> for dep in deps : <TAB> <TAB> if hasattr ( dep , "" el "" ) : <TAB> <TAB> <TAB> dep = dep . el <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidArguments ( "" Argument is not an external dependency "" ) <TAB> <TAB> self . external_deps . append ( dep ) <TAB> <TAB> if isinstance ( dep , dependencies . Dependency ) : <TAB> <TAB> <TAB> self . process_sourcelist ( dep . get_sources ( ) )","if not isinstance ( dep , dependencies . ExternalDependency ) :","if not isinstance ( dep , dependencies . Dependency ) :",False,98.22,73.08,,,
"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r = await ws . recv ( ) <TAB> <TAB> <TAB> if isinstance ( r , bytes ) : <TAB> <TAB> <TAB> <TAB> r = r . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> msg = json . loads ( r ) <TAB> <TAB> <TAB> stream = msg . get ( "" stream "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB> <TAB> logging . warn ( wse ) <TAB> <TAB> await self . close ( ) <TAB> <TAB> asyncio . ensure_future ( self . _ensure_ws ( ) )",if stream :,if stream is not None :,False,97.9,72.56,,,
"def generate_and_check_random ( ) : <TAB> random_size = 256 <TAB> while True : <TAB> <TAB> random = os . urandom ( random_size ) <TAB> <TAB> a = int . from_bytes ( random , "" big "" ) <TAB> <TAB> A = pow ( g , a , p ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> a_for_hash = big_num_for_hash ( A ) <TAB> <TAB> <TAB> u = int . from_bytes ( sha256 ( a_for_hash , b_for_hash ) , "" big "" ) <TAB> <TAB> <TAB> if u > 0 : <TAB> <TAB> <TAB> <TAB> return ( a , a_for_hash , u )",if A > 0 :,"if is_good_mod_exp_first ( A , p ) :",False,92.12,71.08,,,
"def write ( self , datagram , address ) : <TAB> """""" Write a datagram. """""" <TAB> try : <TAB> <TAB> return self . socket . sendto ( datagram , address ) <TAB> except OSError as se : <TAB> <TAB> no = se . args [ 0 ] <TAB> <TAB> if no == EINTR : <TAB> <TAB> <TAB> return self . write ( datagram , address ) <TAB> <TAB> elif no == EMSGSIZE : <TAB> <TAB> <TAB> raise error . MessageLengthError ( "" message too long "" ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # oh, well, drop the data. The only difference from UDP <TAB> <TAB> <TAB> # is that UDP won't ever notice. <TAB> <TAB> <TAB> # TODO: add TCP-like buffering <TAB> <TAB> <TAB> pass <TAB> <TAB> else: <TAB> <TAB> <TAB> raise",elif no == EBADF :,elif no == EAGAIN :,False,98.87,98.65,,,
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) )","if not isinstance ( child , minidom . Element ) :","if not isinstance ( child , minidom . Element ) :",True,100.0,74.56,,,
"def add_reversed_tensor ( i , X , reversed_X ) : <TAB> # Do not keep tensors that should stop the mapping. <TAB> if X in stop_mapping_at_tensors: <TAB> <TAB> return <TAB> if X not in reversed_tensors: <TAB> <TAB> reversed_tensors[X] = {""id"": (nid, i), ""tensor"": reversed_X} <TAB> else: <TAB> <TAB> tmp = reversed_tensors[X] <TAB> <TAB> if ""tensor"" in tmp and ""tensors"" in tmp: <TAB> <TAB> <TAB> raise Exception(""Wrong order, tensors already aggregated!"") <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> tmp[""tensors""] = [tmp[""tensor""], reversed_X] <TAB> <TAB> <TAB> del tmp[""tensor""] <TAB> <TAB> else: <TAB> <TAB> <TAB> tmp[""tensors""].append(reversed_X)","if ""tensors"" not in tmp :","if ""tensor"" in tmp :",False,98.23,72.84,,,
"def walk ( source , path , default , delimiter = "" . "" ) : <TAB> """""" Walk the sourch hash given the path and return the value or default if not found """""" <TAB> if not isinstance ( source , dict ) : <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> "" The source is not a walkable dict:  {}  path:  {} "" . format ( source , path ) <TAB> <TAB> ) <TAB> keys = path . split ( delimiter ) <TAB> max_depth = len ( keys ) <TAB> cur_depth = 0 <TAB> while cur_depth < max_depth : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> source = source [ keys [ cur_depth ] ] <TAB> <TAB> <TAB> cur_depth = cur_depth + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return default <TAB> return source",if keys [ cur_depth ] in source :,if keys [ cur_depth ] in source :,True,100.0,99.57,,,
"def _from_txt_get_vulns ( self ) : <TAB> file_vulns = [ ] <TAB> vuln_regex = ( <TAB> <TAB> ' SQL injection in a .*? was found at:  "" (.*?) "" ' <TAB> <TAB> ' , using HTTP method (.*?). The sent .*?data was:  "" (.*?) "" ' <TAB> ) <TAB> vuln_re = re . compile ( vuln_regex ) <TAB> for line in file ( self . OUTPUT_FILE ) : <TAB> <TAB> mo = vuln_re . search ( line ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> v = MockVuln ( "" TestCase "" , None , "" High "" , 1 , "" plugin "" ) <TAB> <TAB> <TAB> v . set_url ( URL ( mo . group ( 1 ) ) ) <TAB> <TAB> <TAB> v . set_method ( mo . group ( 2 ) ) <TAB> <TAB> <TAB> file_vulns . append ( v ) <TAB> return file_vulns",if mo :,if mo :,True,100.0,74.56,,,
"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB> <TAB> if self . att_name not in instance . _obj_cache : <TAB> <TAB> <TAB> rel_obj = self . get_obj ( instance ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB> <TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self",if rel_obj :,if rel_obj :,True,100.0,74.19,,,
"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else : <TAB> <TAB> <TAB> if pos_end > = pos_start : <TAB> <TAB> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end > = pos_start : <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges",if func in support_set :,if func . type in support_set :,False,98.14,72.74,,,
"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else : <TAB> <TAB> <TAB> if pos_end > = pos_start : <TAB> <TAB> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end > = pos_start : <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges",if func in support_set :,if name not in self . plugins_callback_order and plugin . is_activated,False,91.25,69.0,,,
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> elif token . token_type == TOKEN_VAR : <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> msg = "" "" . join ( result ) <TAB> if self . trimmed : <TAB> <TAB> msg = translation . trim_whitespace ( msg ) <TAB> return msg , vars",if token . token_type == TOKEN_CHAR :,if token . token_type == TOKEN_TEXT :,False,98.64,73.47,,,
"def test_build_root_config_overwrite ( self ) : <TAB> cfg = build_root_config ( "" tests.files.settings_overwrite "" ) <TAB> for key , val in DEFAULT_SPIDER_GLOBAL_CONFIG . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , [ "" zzz "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , val )","if key == ""global_configs"" :","if key == ""spider_modules"" :",False,96.75,72.65,,,
"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB> <TAB> try : <TAB> <TAB> <TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB> <TAB> <TAB> if limit < 0 : <TAB> <TAB> <TAB> <TAB> raise ValueError ( ) <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> if limit == 0: <TAB> <TAB> <TAB> <TAB> <TAB> return settings.MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> <TAB> return min(limit, settings.MAX_PAGE_SIZE) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except (KeyError, ValueError): <TAB> <TAB> <TAB> pass <TAB> return self.default_limit",if self . default_limit :,if settings . MAX_PAGE_SIZE :,False,96.76,72.6,,,
"def track_handler ( handler ) : <TAB> tid = handler . request . tid <TAB> for event in events_monitored : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> e = Event ( event , handler . request . execution_time ) <TAB> <TAB> <TAB> State . tenant_state [ tid ] . RecentEventQ . append ( e ) <TAB> <TAB> <TAB> State . tenant_state [ tid ] . EventQ . append ( e ) <TAB> <TAB> <TAB> break",if event . is_recent ( ) :,"if event [ ""handler_check"" ] ( handler ) :",False,92.06,62.08,,,
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_subscription ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt )",if tt == 0 :,if tt == 0 :,True,100.0,74.46,,,
"def GetCreateInstanceBinder ( self , info ) : <TAB> with self . _lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return self . _createInstanceBinders [ info ] <TAB> <TAB> b = runtime . SymplCreateInstanceBinder ( info ) <TAB> <TAB> self . _createInstanceBinders [ info ] = b <TAB> return b",if info in self . _createInstanceBinders :,if self . _createInstanceBinders . ContainsKey ( info ) :,False,90.62,67.34,,,
"def process_task ( self , body , message ) : <TAB> if "" control "" in body : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . control ( body , message ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logger . exception ( "" Exception handling control message: "" ) <TAB> <TAB> <TAB> return <TAB> if len ( self . pool ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> queue = UUID ( body [ "" uuid "" ] ) . int % len ( self . pool ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> queue = self . total_messages % len ( self . pool ) <TAB> <TAB> else : <TAB> <TAB> <TAB> queue = self . total_messages % len ( self . pool ) <TAB> else : <TAB> <TAB> queue = 0 <TAB> self . pool . write ( queue , body ) <TAB> self . total_messages + = 1 <TAB> message . ack ( )",if self . use_uuid :,"if ""uuid"" in body and body [ ""uuid"" ] :",False,95.17,67.45,,,
"def is_defined_in_base_class ( self , var : Var ) - > bool : <TAB> if var . info : <TAB> <TAB> for base in var . info . mro [ 1 : ] : <TAB> <TAB> <TAB> if base . get ( var . name ) is not None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return True <TAB> return False",if var . is_defined_in_base_class ( base ) :,if var . info . fallback_to_any :,False,89.18,70.88,,,
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp",elif col == LEGAL :,elif col == BARRIER :,False,99.16,73.99,,,
"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB> <TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB> <TAB> prompt = "" (R/F)>  "" <TAB> <TAB> answer = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> answer = raw_input ( prompt ) <TAB> <TAB> except NameError : <TAB> <TAB> <TAB> answer = input ( prompt ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB> <TAB> elif answer . upper ( ) == "" R "" : <TAB> <TAB> <TAB> logger . debug ( "" Resuming previous scan "" ) <TAB> <TAB> <TAB> config . resume = True <TAB> return config . resume","if answer . upper ( ) == ""F"" :","if answer . upper ( ) == ""F"" :",True,100.0,74.63,,,
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if view . line ( s . b ) . size ( ) > 0 : <TAB> <TAB> <TAB> <TAB> eol = view . line ( s . b ) . b <TAB> <TAB> <TAB> <TAB> return R ( s . b , eol ) <TAB> <TAB> <TAB> return s <TAB> return s",if s . b :,if count == 1 :,False,95.31,71.39,,,
"def flush ( self ) : <TAB> if not self . cuts : <TAB> <TAB> return <TAB> for move , ( x , y , z ) , cent in douglas ( self . cuts , self . tolerance , self . plane ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . write ( "" %s  X %.4f  Y %.4f  Z %.4f %s "" % ( move , x , y , z , cent ) ) <TAB> <TAB> <TAB> self . lastgcode = None <TAB> <TAB> <TAB> self . lastx = x <TAB> <TAB> <TAB> self . lasty = y <TAB> <TAB> <TAB> self . lastz = z <TAB> <TAB> else : <TAB> <TAB> <TAB> self . move_common ( x , y , z , gcode = "" G1 "" ) <TAB> self . cuts = [ ]",if move :,if cent :,False,98.77,73.67,,,
"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( ) # create a new group <TAB> new_i.id = self.id # with the same id <TAB> cls.id = old_id # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls.properties: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> if self.has(prop): <TAB> <TAB> <TAB> <TAB> val = getattr(self, prop) <TAB> <TAB> <TAB> <TAB> setattr(new_i, prop, val) <TAB> # but no members <TAB> new_i.members = [] <TAB> return new_i","if hasattr ( self , prop ) :","if prop is not ""members"" :",False,96.19,62.5,,,
"def find_region_by_value ( key , value ) : <TAB> for region in cognitoidp_backends : <TAB> <TAB> backend = cognitoidp_backends [ region ] <TAB> <TAB> for user_pool in backend . user_pools . values ( ) : <TAB> <TAB> <TAB> if key == "" client_id "" and value in user_pool . clients : <TAB> <TAB> <TAB> <TAB> return region <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return region <TAB> # If we can't find the `client_id` or `access_token`, we just pass <TAB> # back a default backend region, which will raise the appropriate <TAB> # error message (e.g. NotAuthorized or NotFound). <TAB> return list(cognitoidp_backends)[0]","if key == ""access_token"" and value in user_pool . access_tokens :","if key == ""access_token"" and value in user_pool . access_tokens :",True,100.0,74.48,,,
"def __init__ ( <TAB> self , fixed : MQTTFixedHeader = None , variable_header : PacketIdVariableHeader = None ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PUBREL , 0x02 ) # [MQTT-3.6.1-1] <TAB> else: <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException( <TAB> <TAB> <TAB> <TAB> ""Invalid fixed packet type %s for PubrelPacket init"" % fixed.packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super().__init__(header) <TAB> self.variable_header = variable_header <TAB> self.payload = None",if fixed . packet_type is not PUBREL :,if fixed . packet_type is not PUBREL :,True,100.0,74.3,,,
"def _on_event_MetadataStatisticsUpdated ( self , event , data ) : <TAB> with self . _selectedFileMutex : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . _setJobData ( <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" filename "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" filesize "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" sd "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" user "" ] , <TAB> <TAB> <TAB> )",if self . _selectedFile :,if self . _selectedFile :,True,100.0,74.23,,,
"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """""" Placeholder docstring """""" <TAB> for ( <TAB> <TAB> parameter_range_key , <TAB> <TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> if isinstance(parameter_range_value, list): <TAB> <TAB> <TAB> for categorical_value in parameter_range_value: <TAB> <TAB> <TAB> <TAB> value_hp.validate(categorical_value) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else: <TAB> <TAB> <TAB> value_hp.validate(parameter_range_value)","if parameter_range_key . startswith ( ""Categorical"" ) :","if parameter_range_key == ""scaling_type"" :",False,96.28,90.93,,,
"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB> <TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB> <TAB> if self . _is_true ( self . visit ( comparator_node , element ) ) : <TAB> <TAB> <TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> collected . append ( current ) <TAB> return collected",if current is not None :,if current is not None :,True,100.0,74.51,,,
"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set() <TAB> end = va + size <TAB> for offs in range(va, end, 1): <TAB> <TAB> loc = self.getLocation(offs, range=True) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> subs.add((loc[L_VA], loc[L_SIZE])) <TAB> <TAB> <TAB> if loc[L_TINFO]: <TAB> <TAB> <TAB> <TAB> subs = subs.union(set(loc[L_TINFO])) <TAB> return list(subs)",if loc [ L_VA ] != loc [ L_SIZE ] :,if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va :,False,91.73,66.79,,,
"def run ( self ) : <TAB> while not self . _stopped : <TAB> <TAB> try : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> test_name = next ( self . pending ) <TAB> <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> mp_result = self . _runtest ( test_name ) <TAB> <TAB> <TAB> self . output . put ( ( False , mp_result ) ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except ExitThread : <TAB> <TAB> <TAB> break <TAB> <TAB> except BaseException : <TAB> <TAB> <TAB> self . output . put ( ( True , traceback . format_exc ( ) ) ) <TAB> <TAB> <TAB> break",if self . _stopped :,"if must_stop ( mp_result . result , self . ns ) :",False,93.58,70.4,,,
"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB> <TAB> for k , v in data . items ( ) : <TAB> <TAB> <TAB> if k == key : <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> elif isinstance ( v , ( list , tuple , dict ) ) : <TAB> <TAB> <TAB> <TAB> out = get_in_inputs ( key , v ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB> <TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB> <TAB> out = [ x for x in out if x ] <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return out [ 0 ]",if len ( out ) == 1 :,if out :,False,93.04,71.38,,,
"def act_mapping ( self , items , actions , mapping ) : <TAB> """""" Executes all the actions on the list of pods. """""" <TAB> success = True <TAB> for action in actions : <TAB> <TAB> for key , method in mapping . items ( ) : <TAB> <TAB> <TAB> if key in action : <TAB> <TAB> <TAB> <TAB> params = action . get ( key ) <TAB> <TAB> <TAB> <TAB> ret = method ( items , params ) <TAB> <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> <TAB> success = False <TAB> return success",if ret is None :,if not ret :,False,97.27,95.62,,,
"def _apply ( self , plan ) : <TAB> desired = plan . desired <TAB> changes = plan . changes <TAB> self . log . debug ( "" _apply: zone= %s , len(changes)= %d "" , desired . name , len ( changes ) ) <TAB> domain_name = desired . name [ : - 1 ] <TAB> try : <TAB> <TAB> nsone_zone = self . _client . loadZone ( domain_name ) <TAB> except ResourceException as e : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . log . debug ( "" _apply:  no matching zone, creating "" ) <TAB> <TAB> nsone_zone = self . _client . createZone ( domain_name ) <TAB> for change in changes : <TAB> <TAB> class_name = change . __class__ . __name__ <TAB> <TAB> getattr ( self , "" _apply_ {} "" . format ( class_name ) ) ( nsone_zone , change )",if e . errno != errno . ENotFound :,if e . message != self . ZONE_NOT_FOUND_MESSAGE :,False,94.93,72.67,,,
"def split_artists ( self , json ) : <TAB> if len ( json ) == 0 : <TAB> <TAB> ( [ ] , [ ] ) <TAB> elif len ( json ) == 1 : <TAB> <TAB> artist = Artist . query . filter_by ( name = json [ 0 ] [ "" name "" ] ) . first ( ) <TAB> <TAB> return ( [ artist ] , [ ] ) <TAB> my_artists = [ ] <TAB> other_artists = [ ] <TAB> for artist_dict in json : <TAB> <TAB> artist = Artist . query . filter_by ( name = artist_dict [ "" name "" ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> my_artists . append ( artist . first ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> del artist_dict [ "" thumb_url "" ] <TAB> <TAB> <TAB> other_artists . append ( artist_dict ) <TAB> return ( my_artists , other_artists )",if artist . exists ( ) :,if artist . count ( ) :,False,98.96,73.81,,,
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass",if attrvalue is None :,if attrvalue == 0 :,False,98.16,73.48,,,
"def close ( self , code = errno . ECONNRESET ) : <TAB> with self . shutdown_lock : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> super ( RemoteIPRoute , self ) . close ( code = code ) <TAB> <TAB> <TAB> self . closed = True <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . _mitogen_call . get ( ) <TAB> <TAB> <TAB> except mitogen . core . ChannelError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if self . _mitogen_broker is not None : <TAB> <TAB> <TAB> <TAB> self . _mitogen_broker . shutdown ( ) <TAB> <TAB> <TAB> <TAB> self . _mitogen_broker . join ( )",if self . _mitogen_call is not None :,if not self . closed :,False,95.22,72.07,,,
"def untokenize ( self , iterable ) : <TAB> for t in iterable : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . compat ( t , iterable ) <TAB> <TAB> <TAB> break <TAB> <TAB> tok_type , token , start , end , line = t <TAB> <TAB> self . add_whitespace ( start ) <TAB> <TAB> self . tokens . append ( token ) <TAB> <TAB> self . prev_row , self . prev_col = end <TAB> <TAB> if tok_type in ( NEWLINE , NL ) : <TAB> <TAB> <TAB> self . prev_row + = 1 <TAB> <TAB> <TAB> self . prev_col = 0 <TAB> return "" "" . join ( self . tokens )","if isinstance ( t , ( list , tuple ) ) :",if len ( t ) == 2 :,False,94.41,71.01,,,
"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB> <TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB> <TAB> spk = uttid <TAB> if not self . reverse : <TAB> <TAB> if self . norm_means : <TAB> <TAB> <TAB> x = np . add ( x , self . bias [ spk ] ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB> <TAB> if self . norm_means : <TAB> <TAB> <TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x",if self . scale_norm :,if self . norm_vars :,False,96.35,72.96,,,
"def get_party_total ( self , args ) : <TAB> self . party_total = frappe . _dict ( ) <TAB> for d in self . receivables : <TAB> <TAB> self . init_party_total ( d ) <TAB> <TAB> # Add all amount columns <TAB> <TAB> for k in list(self.party_total[d.party]): <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self.party_total[d.party][k] += d.get(k, 0.0) <TAB> <TAB> # set territory, customer_group, sales person etc <TAB> <TAB> self.set_party_details(d)","if d . get ( k , 0.0 ) > 0 :","if k not in [ ""currency"" , ""sales_person"" ] :",False,91.58,60.88,,,
"def get_databases ( request ) : <TAB> dbs = { } <TAB> global_env = globals ( ) <TAB> for ( key , value ) in global_env . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> cond = isinstance ( value , GQLDB ) <TAB> <TAB> except : <TAB> <TAB> <TAB> cond = isinstance ( value , SQLDB ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> dbs [ key ] = value <TAB> return dbs",if cond :,if cond :,True,100.0,74.2,,,
"def check_twobit_file ( dbkey , GALAXY_DATA_INDEX_DIR ) : <TAB> twobit_file = "" %s /twobit.loc "" % GALAXY_DATA_INDEX_DIR <TAB> twobit_path = "" "" <TAB> twobits = { } <TAB> for i , line in enumerate ( open ( twobit_file ) ) : <TAB> <TAB> line = line . rstrip ( "" \r \n "" ) <TAB> <TAB> if line and not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> fields = line . split ( "" \t "" ) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> twobits [ ( fields [ 0 ] ) ] = fields [ 1 ] <TAB> if dbkey in twobits : <TAB> <TAB> twobit_path = twobits [ ( dbkey ) ] <TAB> return twobit_path",if i != len ( fields ) - 1 :,if len ( fields ) < 2 :,False,96.33,72.32,,,
"def action ( scheduler , _ ) : <TAB> nonlocal state <TAB> nonlocal has_result <TAB> nonlocal result <TAB> nonlocal first <TAB> nonlocal time <TAB> <IF-STMT> <TAB> <TAB> observer . on_next ( result ) <TAB> try : <TAB> <TAB> if first : <TAB> <TAB> <TAB> first = False <TAB> <TAB> else : <TAB> <TAB> <TAB> state = iterate ( state ) <TAB> <TAB> has_result = condition ( state ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = state <TAB> <TAB> <TAB> time = time_mapper ( state ) <TAB> except Exception as e : # pylint: disable=broad-except <TAB> <TAB> observer.on_error(e) <TAB> <TAB> return <TAB> <IF-STMT> <TAB> <TAB> mad.disposable = scheduler.schedule_relative(time, action) <TAB> else: <TAB> <TAB> observer.on_completed()",if has_result :,if has_result :,True,100.0,74.5,,,
def orthogonalEnd ( self ) : <TAB> if self . type == Segment . LINE : <TAB> <TAB> O = self . AB . orthogonal ( ) <TAB> <TAB> O . norm ( ) <TAB> <TAB> return O <TAB> else : <TAB> <TAB> O = self . B - self . C <TAB> <TAB> O . norm ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return - O <TAB> <TAB> else : <TAB> <TAB> <TAB> return O,if self . type == Segment . SUBTRACT :,if self . type == Segment . CCW :,False,98.06,97.8,,,
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> if isinstance ( self . _definition , dict ) : <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> elif v in self . _definition : <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) )",if v in self . _definition :,"if v == ""ANY"" :",False,97.54,66.55,,,
"def __enter__ ( self ) - > None : <TAB> try : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> signal . signal ( signal . SIGALRM , self . handle_timeout ) <TAB> <TAB> <TAB> signal . alarm ( self . seconds ) <TAB> except ValueError as ex : <TAB> <TAB> logger . warning ( "" timeout can ' t be used in the current context "" ) <TAB> <TAB> logger . exception ( ex )",if self . seconds is not None :,if threading . current_thread ( ) == threading . main_thread ( ) :,False,85.79,67.26,,,
"def __init__ ( self , fixed : MQTTFixedHeader = None ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PINGRESP , 0x00 ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise HBMQTTException ( <TAB> <TAB> <TAB> <TAB> "" Invalid fixed packet type  %s  for PingRespPacket init "" <TAB> <TAB> <TAB> <TAB> % fixed . packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = None <TAB> self . payload = None",if fixed . packet_type is not PINGRESP :,if fixed . packet_type is not PINGRESP :,True,100.0,74.39,,,
"def _put_nowait ( self , data , * , sender ) : <TAB> if not self . _running : <TAB> <TAB> logger . warning ( "" Pub/Sub listener message after stop:  %r ,  %r "" , sender , data ) <TAB> <TAB> return <TAB> self . _queue . put_nowait ( ( sender , data ) ) <TAB> if self . _waiter is not None : <TAB> <TAB> fut , self . _waiter = self . _waiter , None <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> assert fut . cancelled ( ) , ( "" Waiting future is in wrong state "" , self , fut ) <TAB> <TAB> <TAB> return <TAB> <TAB> fut . set_result ( None )",if fut . done ( ) :,if fut . done ( ) :,True,100.0,74.51,,,
"def OnAssignBuiltin ( self , cmd_val ) : <TAB> # type: (cmd_value__Assign) -> None <TAB> buf = self._ShTraceBegin() <TAB> if not buf: <TAB> <TAB> return <TAB> for i, arg in enumerate(cmd_val.argv): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> buf.write("" "") <TAB> <TAB> buf.write(arg) <TAB> for pair in cmd_val.pairs: <TAB> <TAB> buf.write("" "") <TAB> <TAB> buf.write(pair.var_name) <TAB> <TAB> buf.write(""="") <TAB> <TAB> if pair.rval: <TAB> <TAB> <TAB> _PrintShValue(pair.rval, buf) <TAB> buf.write(""\n"") <TAB> self.f.write(buf.getvalue())",if i :,if i != 0 :,False,97.94,71.87,,,
"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB> <TAB> del obj [ k ] <TAB> <TAB> if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) : <TAB> <TAB> <TAB> k = dumps ( k ) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> obj[Types.KEYS] = [] <TAB> <TAB> <TAB> obj[Types.KEYS].append(k) <TAB> <TAB> obj[k] = convertObjects(v) <TAB> return obj",if not obj . has_key ( types . KEYS ) :,if Types . KEYS not in obj :,False,93.81,70.66,,,
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """""" Check if the function argument list has a dictionary as an arg. """""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> if token . value == "" { "" : <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> if token . ClosesScope ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False","if token . value == ""}"" :",if token . OpensScope ( ) :,False,96.5,75.85,,,
"def get_editable_dict ( self ) : <TAB> ret = { } <TAB> for ref , ws_package in self . _workspace_packages . items ( ) : <TAB> <TAB> path = ws_package . root_folder <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> path = os . path . join ( path , CONANFILE ) <TAB> <TAB> ret [ ref ] = { "" path "" : path , "" layout "" : ws_package . layout } <TAB> return ret",if not os . path . exists ( path ) :,if os . path . isdir ( path ) :,False,95.88,71.55,,,
"def serialize ( self , name = None ) : <TAB> data = super ( WebLink , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> if self . width : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise InvalidWidthException ( self . width ) <TAB> <TAB> data [ "" inputOptions "" ] = { } <TAB> <TAB> data [ "" width "" ] = self . width <TAB> data . update ( { "" content "" : { "" url "" : self . linkUrl , "" text "" : self . linkText } } ) <TAB> return data","if self . width not in [ 100 , 400 ] :","if self . width not in [ 100 , 50 , 33 , 25 ] :",False,95.66,71.9,,,
"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB> <TAB> context . next_indent = len ( text ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> while context . next_indent < context . indent : <TAB> <TAB> <TAB> <TAB> context . indent = context . indent_stack . pop ( ) <TAB> <TAB> <TAB> if context . next_indent > context . indent : <TAB> <TAB> <TAB> <TAB> extra = text [ context . indent : ] <TAB> <TAB> <TAB> <TAB> text = text [ : context . indent ] <TAB> else : <TAB> <TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB> <TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB> <TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( )",if context . indent_stack :,if context . next_indent < context . indent :,False,97.07,72.81,,,
"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB> <TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB> <TAB> <TAB> if subscriber_web_sock == web_sock : <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del self . _subscribers [ index ] <TAB> <TAB> if not self . _subscribers : <TAB> <TAB> <TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) )",if index :,if index is not None :,False,97.37,71.61,,,
"def test_missing_dict_param ( ) : <TAB> expected_err = "" params dictionary did not contain value for placeholder "" <TAB> try : <TAB> <TAB> substitute_params ( <TAB> <TAB> <TAB> "" SELECT * FROM cust WHERE salesrep =  %(name)s "" , { "" foobar "" : "" John Doe "" } <TAB> <TAB> ) <TAB> <TAB> assert False , "" expected exception b/c dict did not contain replacement value "" <TAB> except ValueError as exc : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> raise",if exc . errno != errno . ENOENT :,if expected_err not in str ( exc ) :,False,92.64,69.43,,,
"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> elif op_gprv ( op ) : <TAB> <TAB> <TAB> r + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1",if op_reg ( op ) :,"if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ ""v"" ] ) :",False,83.73,54.92,,,
"def on_enter ( self ) : <TAB> """""" Fired when mouse enter the bbox of the widget. """""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB> <TAB> if hasattr ( self , "" theme_cls "" ) and not self . focus_color : <TAB> <TAB> <TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = self . focus_color","if hasattr ( self , ""theme_cls"" ) and not self . focus_color :",if not self . focus_color :,False,94.0,70.44,,,
"def __init__ ( self , * args , * * kwargs ) : <TAB> BaseCellExporter . __init__ ( self , * args , * * kwargs ) <TAB> self . comment = "" # "" <TAB> for key in [ "" cell_marker "" ] : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . metadata [ key ] = self . unfiltered_metadata [ key ] <TAB> if self . fmt . get ( "" rst2md "" ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The  ' rst2md '  option is a read only option. The reverse conversion is not  "" <TAB> <TAB> <TAB> "" implemented. Please either deactivate the option, or save to another format. "" <TAB> <TAB> ) # pragma: no cover",if key in self . unfiltered_metadata :,if key in self . unfiltered_metadata :,True,100.0,74.52,,,
"def sendQueryQueueByAfterNate ( self ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> queryQueueByAfterNateRsp = self . session . httpClint . send ( urls . get ( "" queryQueue "" ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" "" . join ( queryQueueByAfterNateRsp . get ( "" messages "" ) ) <TAB> <TAB> <TAB> <TAB> or queryQueueByAfterNateRsp . get ( "" validateMessages "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sendEmail ( ticket . WAIT_ORDER_SUCCESS ) <TAB> <TAB> <TAB> sendServerChan ( ticket . WAIT_ORDER_SUCCESS ) <TAB> <TAB> <TAB> raise ticketIsExitsException ( ticket . WAIT_AFTER_NATE_SUCCESS )","if queryQueueByAfterNateRsp . get ( ""messages"" ) :","if not queryQueueByAfterNateRsp . get ( ""status"" ) :",False,97.59,72.39,,,
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> if fn is not None : <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors","if line . startswith ( ""#"" ) :",if not line :,False,95.91,64.24,,,
"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB> <TAB> r = repr ( n ) <TAB> <TAB> if not comment : # then it can be inside a comment! <TAB> <TAB> <TAB> r = r.replace(""*/"", r""\x2a/"") <TAB> <TAB> return r <TAB> if not isinstance(n, six.integer_types): <TAB> <TAB> return n <TAB> if isinstance(n, constants.Constant): <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return ""%s /* %s */"" % (n, self.pretty(int(n))) <TAB> <TAB> else: <TAB> <TAB> <TAB> return ""%s (%s)"" % (n, self.pretty(int(n))) <TAB> elif abs(n) < 10: <TAB> <TAB> return str(n) <TAB> else: <TAB> <TAB> return hex(n)",if self . _comment :,if comment :,False,98.26,73.07,,,
"def get_pricings ( self , subscription_id : str ) : <TAB> try : <TAB> <TAB> client = self . get_client ( subscription_id ) <TAB> <TAB> pricings_list = await run_concurrently ( lambda : client . pricings . list ( ) ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> return pricings_list . value <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ ] <TAB> except Exception as e : <TAB> <TAB> print_exception ( f "" Failed to retrieve pricings:  { e } "" ) <TAB> <TAB> return [ ]","if pricings_list . status == ""ok"" :","if hasattr ( pricings_list , ""value"" ) :",False,93.74,70.52,,,
"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target.id <TAB> <TAB> if name not in variables: <TAB> <TAB> <TAB> doc = find_doc_for(target, body_lines) <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> variables[name] = doc <TAB> elif isinstance(target, ast.Tuple): <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target.elts: <TAB> <TAB> <TAB> add_doc(e, variables, body_lines)",if doc is not None :,if doc is not None :,True,100.0,74.47,,,
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right",if left == 0 and allowed_chars in text :,if right == len ( text ) :,False,95.29,71.82,,,
"def pxrun_nodes ( self , * args , * * kwargs ) : <TAB> cell = self . _px_cell <TAB> if re . search ( r "" ^ \ s* %a utopx \ b "" , cell ) : <TAB> <TAB> self . _disable_autopx ( ) <TAB> <TAB> return False <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = self . view . execute ( cell , silent = False , block = False ) <TAB> <TAB> except : <TAB> <TAB> <TAB> self . shell . showtraceback ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> result . get ( ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> self . shell . showtraceback ( ) <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> result . display_outputs ( ) <TAB> <TAB> <TAB> return False",if self . _use_autopx :,if self . view . block :,False,98.19,73.37,,,
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> if matchSelf : <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon : <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" )",if s . siblingAbove :,if s . siblingAbove is None :,False,98.62,73.34,,,
"def decTaskGen ( ) : <TAB> cnt = intbv ( 0 , min = - n , max = n ) <TAB> while 1 : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> cnt [ : ] = 0 <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> # print count <TAB> <TAB> <TAB> decTaskFunc(cnt, enable, reset, n) <TAB> <TAB> <TAB> count.next = cnt",if enable :,if reset == ACTIVE_LOW :,False,94.51,71.5,,,
"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB> <TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB> <TAB> <TAB> if layer in layer_names : <TAB> <TAB> <TAB> <TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB> <TAB> <TAB> <TAB> print ( layer_names [ layer ] ) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> # <TAB> out=[out] <TAB> return out",if stack :,"if ""self"" in stack [ 0 ] . f_locals :",False,94.06,64.26,,,
"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB> <TAB> if isinstance ( self . header , RenderedContent ) : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader <TAB> return d","if isinstance ( self . subheader , RenderedContent ) :","if isinstance ( self . subheader , RenderedContent ) :",True,100.0,74.57,,,
"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB> <TAB> form = BookMarkForm ( request . POST ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> form_type = form . save ( ) <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB> <TAB> if form_type == "" server "" : <TAB> <TAB> <TAB> url = reverse ( "" servers "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url = reverse ( "" metrics "" ) <TAB> <TAB> return redirect ( url ) <TAB> else : <TAB> <TAB> return redirect ( reverse ( "" servers "" ) )",if form . is_valid ( ) :,if form . is_valid ( ) :,True,100.0,74.56,,,
"def fee_amount_in_quote ( self , trading_pair : str , price : Decimal , order_amount : Decimal ) : <TAB> fee_amount = Decimal ( "" 0 "" ) <TAB> if self . percent > 0 : <TAB> <TAB> fee_amount = ( price * order_amount ) * self . percent <TAB> base , quote = trading_pair . split ( "" - "" ) <TAB> for flat_fee in self . flat_fees : <TAB> <TAB> if interchangeable ( flat_fee [ 0 ] , base ) : <TAB> <TAB> <TAB> fee_amount + = flat_fee [ 1 ] * price <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fee_amount + = flat_fee [ 1 ] <TAB> return fee_amount","elif interchangeable ( flat_fee [ 0 ] , quote ) :","elif interchangeable ( flat_fee [ 0 ] , quote ) :",True,100.0,74.47,,,
"def load_batch ( fpath ) : <TAB> with open ( fpath , "" rb "" ) as f : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Python3 <TAB> <TAB> <TAB> d = pickle.load(f, encoding=""latin1"") <TAB> <TAB> else: <TAB> <TAB> <TAB> # Python2 <TAB> <TAB> <TAB> d = pickle.load(f) <TAB> data = d[""data""] <TAB> labels = d[""labels""] <TAB> return data, labels","if sys . version_info < ( 3 , 0 ) :","if sys . version_info > ( 3 , 0 ) :",False,98.2,72.3,,,
"def clear_entries ( options ) : <TAB> """""" Clear pending entries """""" <TAB> with Session ( ) as session : <TAB> <TAB> query = session . query ( db . PendingEntry ) . filter ( db . PendingEntry . approved == False ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> query = query . filter ( db . PendingEntry . task_name == options . task_name ) <TAB> <TAB> deleted = query . delete ( ) <TAB> <TAB> console ( "" Successfully deleted  %i  pending entries "" % deleted )",if options . task_name :,if options . task_name :,True,100.0,99.3,,,
"def attribute_table ( self , attribute ) : <TAB> """""" Return a tuple (schema, table) for attribute. """""" <TAB> dimension = attribute . dimension <TAB> if dimension : <TAB> <TAB> schema = self . naming . dimension_schema or self . naming . schema <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> table = self . fact_name <TAB> <TAB> else : <TAB> <TAB> <TAB> table = self . naming . dimension_table_name ( dimension ) <TAB> else : <TAB> <TAB> table = self . fact_name <TAB> <TAB> schema = self . naming . schema <TAB> return ( schema , table )","if dimension == ""default"" :",if dimension . is_flat and not dimension . has_details :,False,92.63,91.98,,,
"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB> <TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB> <TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB> <TAB> if dialog . run ( ) != Gtk . ResponseType . YES : <TAB> <TAB> <TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> del song [ "" ~#rating "" ] <TAB> <TAB> <TAB> reset . append ( song ) <TAB> librarian . changed ( reset )","if not song [ ""~#rating"" ] :","if ""~#rating"" in song :",False,96.53,72.45,,,
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right",if allowed_chars and text [ right ] in allowed_chars :,elif not self . word_boundary_char ( text [ right ] ) :,False,93.86,70.69,,,
"def handle_read ( self ) : <TAB> """""" Called when there is data waiting to be read. """""" <TAB> try : <TAB> <TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB> <TAB> pass <TAB> except socket . error : <TAB> <TAB> self . handle_error ( ) <TAB> else : <TAB> <TAB> self . tot_bytes_received + = len ( chunk ) <TAB> <TAB> if not chunk : <TAB> <TAB> <TAB> self . transfer_finished = True <TAB> <TAB> <TAB> # self.close() # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> chunk = self._data_wrapper(chunk) <TAB> <TAB> try: <TAB> <TAB> <TAB> self.file_obj.write(chunk) <TAB> <TAB> except OSError as err: <TAB> <TAB> <TAB> raise _FileReadWriteError(err)",if self . _data_wrapper :,if self . _data_wrapper is not None :,False,98.3,97.48,,,
"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 100 <TAB> <TAB> if self . split > 20 : <TAB> <TAB> <TAB> self . save = self . split <TAB> <TAB> <TAB> self . split = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . save <TAB> else : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 0.3 <TAB> <TAB> if self . split < = self . min or self . split > = self . max : <TAB> <TAB> <TAB> self . split = self . save <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> self . split = self . min <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . max <TAB> self . placeChilds ( )",elif self . split < self . min :,elif self . split < 0.5 :,False,98.21,73.59,,,
"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB> <TAB> rlen = size - len ( ret ) <TAB> <TAB> x = self . fd . read ( rlen ) <TAB> <TAB> if x == b "" "" : <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret + = x <TAB> return ret",if shortok :,if not shortok :,False,98.22,72.88,,,
"def webfinger ( environ , start_response , _ ) : <TAB> query = parse_qs ( environ [ "" QUERY_STRING "" ] ) <TAB> try : <TAB> <TAB> rel = query [ "" rel "" ] <TAB> <TAB> resource = query [ "" resource "" ] [ 0 ] <TAB> except KeyError : <TAB> <TAB> resp = BadRequest ( "" Missing parameter in request "" ) <TAB> else : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> resp = BadRequest ( "" Bad issuer in request "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> wf = WebFinger ( ) <TAB> <TAB> <TAB> resp = Response ( wf . response ( subject = resource , base = OAS . baseurl ) ) <TAB> return resp ( environ , start_response )",if rel != resource :,if rel != [ OIC_ISSUER ] :,False,96.58,72.85,,,
"def _tokenize ( self , text ) : <TAB> if format_text ( text ) == EMPTY_TEXT : <TAB> <TAB> return [ self . additional_special_tokens [ 0 ] ] <TAB> split_tokens = [ ] <TAB> if self . do_basic_tokenize : <TAB> <TAB> for token in self . basic_tokenizer . tokenize ( <TAB> <TAB> <TAB> text , never_split = self . all_special_tokens <TAB> <TAB> ) : <TAB> <TAB> <TAB> # If the token is part of the never_split set <TAB> <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> <TAB> split_tokens.append(token) <TAB> <TAB> <TAB> else: <TAB> <TAB> <TAB> <TAB> split_tokens += self.wordpiece_tokenizer.tokenize(token) <TAB> else: <TAB> <TAB> split_tokens = self.wordpiece_tokenizer.tokenize(text) <TAB> return split_tokens",if token in self . basic_tokenizer . never_split :,if token in self . basic_tokenizer . never_split :,True,100.0,74.46,,,
"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB> <TAB> self . connect ( ) <TAB> try : <TAB> <TAB> if isinstance ( command , str ) : <TAB> <TAB> <TAB> command = [ command ] <TAB> <TAB> for item in command : <TAB> <TAB> <TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> _errno , errmsg = e . args <TAB> <TAB> raise ConnectionError ( <TAB> <TAB> <TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> raise","if e . args [ 0 ] in [ ""UnknownError"" , ""UnknownError"" ] :",if len ( e . args ) == 1 :,False,93.9,64.84,,,
"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> # <TAB>  taiga.projects.history.models.HistoryEntry.values_diff() <TAB> ret = {} <TAB> for key, val in value.items(): <TAB> <TAB> if key in [""attachments"", ""custom_attributes"", ""description_diff""]: <TAB> <TAB> <TAB> ret[key] = val <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> ret[key] = {k: {""from"": v[0], ""to"": v[1]} for k, v in val.items()} <TAB> <TAB> else: <TAB> <TAB> <TAB> ret[key] = {""from"": val[0], ""to"": val[1]} <TAB> return ret","elif key == ""attachments"" :","elif key == ""points"" :",False,98.82,72.74,,,
"def to_child ( cls , key = None , process = None ) : <TAB> if process is not None : <TAB> <TAB> if type ( process ) is not dict : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> ' Invalid value provided for  "" process ""  parameter, expected a dictionary ' <TAB> <TAB> <TAB> ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> # Merge class `__process__` parameters with provided parameters <TAB> <TAB> <TAB> result = {} <TAB> <TAB> <TAB> result.update(deepcopy(cls.__process__)) <TAB> <TAB> <TAB> result.update(process) <TAB> <TAB> <TAB> process = result <TAB> class Child(cls): <TAB> <TAB> __key__ = key <TAB> <TAB> __process__ = process <TAB> <TAB> __root__ = False <TAB> Child.__name__ = cls.__name__ <TAB> return Child",if key is not None and process is not None :,if cls . __process__ :,False,96.08,71.59,,,
"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB> <TAB> return passed_class <TAB> else : <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> supers = pyclass.get_superclasses() <TAB> <TAB> <TAB> if supers: <TAB> <TAB> <TAB> <TAB> return pyobjects.PyObject(supers[0]) <TAB> <TAB> return passed_self","if isinstance ( pyclass , pyobjects . PyObject ) :","if isinstance ( pyclass , pyobjects . AbstractClass ) :",False,98.49,72.74,,,
"def get_data ( row ) : <TAB> data = [ ] <TAB> for field_name , field_xpath in fields : <TAB> <TAB> result = row . xpath ( field_xpath ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> result = "" "" . join ( <TAB> <TAB> <TAB> <TAB> text <TAB> <TAB> <TAB> <TAB> for text in map ( <TAB> <TAB> <TAB> <TAB> <TAB> six . text_type . strip , map ( six . text_type , map ( unescape , result ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if text <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = None <TAB> <TAB> data . append ( result ) <TAB> return data",if result :,if result :,True,100.0,74.47,,,
"def say ( jarvis , s ) : <TAB> """""" Reads what is typed. """""" <TAB> if not s : <TAB> <TAB> jarvis . say ( "" What should I say? "" ) <TAB> else : <TAB> <TAB> voice_state = jarvis . is_voice_enabled ( ) <TAB> <TAB> jarvis . enable_voice ( ) <TAB> <TAB> jarvis . say ( s ) <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> jarvis . disable_voice ( )",if voice_state :,if not voice_state :,False,97.95,81.89,,,
"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> fromlist = list ( fromlist ) <TAB> <TAB> <TAB> fromlist . remove ( "" * "" ) <TAB> <TAB> <TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB> <TAB> for x in fromlist : <TAB> <TAB> <TAB> if isinstance ( getattr ( module , x , None ) , types . ModuleType ) : <TAB> <TAB> <TAB> <TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB> <TAB> <TAB> <TAB> if from_name in modules : <TAB> <TAB> <TAB> <TAB> <TAB> importlib . import_module ( from_name ) <TAB> return module","if ""*"" in fromlist :","if ""*"" in fromlist :",True,100.0,74.62,,,
"def _read_pricing_file ( self , region = None , pricing_file = None ) : <TAB> if not self . __pricing_file_cache : <TAB> <TAB> <IF-STMT> <TAB> <TAB> <TAB> logging . info ( "" Reading pricing file... "" ) <TAB> <TAB> <TAB> with open ( pricing_file ) as data_file : <TAB> <TAB> <TAB> <TAB> self . __pricing_file_cache = json . load ( data_file ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __pricing_file_cache = self . _download_pricing_file ( region ) <TAB> return self . __pricing_file_cache",if region :,if pricing_file :,False,97.34,72.84,,,
